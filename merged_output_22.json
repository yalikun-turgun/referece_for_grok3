{
  "md_naiduAntitrustRemediesLabor2018": {
    "reference_markdown": "# Antitrust Remedies for Labor Market Power Suresh Naidu, Eric A. Posner,2 & E. Glen Weyl  \n\nFebruary 23, 2018  \n\nAbstract. Recent research indicates that labor market power has contributed to wage inequality and economic stagnation. Although the antitrust laws prohibit firms from restricting competition in labor markets like in product markets, the government does little to address the labor market problem and private litigation has been rare and mostly unsuccessful. The reason is that the analytic methods for evaluating labor market power in antitrust contexts are primitive, far less sophisticated than the legal rules used to judge product market power. To remedy this asymmetry, we propose methods for judging the effects of mergers on labor markets. We also extend our approach to other forms of anticompetitive practices undertaken by employers against workers. We highlight some arguments and evidence indicating that market power may be even more important in labor than in product markets.  \n\n# Contents  \n\n. The Rise of Labor Monopsony 10  \n\nA. The Economics of Labor Market Power.. ..10   \n1. The Intellectual History of Monopsony. .10   \n2. The Sources of Monopsony Power. 12   \n3. The Social Cost of Monopsony... ..15   \n4. Recent Developments: Evidence of Labor Market Concentration .17   \nB. Antitrust Law and Labor Markets . .23   \n1. Antitrust Litigation Relating to Labor Markets .23   \n2. Class Action Requirements and Related Barriers to Challenges of Anticompetitive Labor   \nMarket Practices. 25  \n\n1. Merger Analysis of Labor Market Harms  \n\nA. Market Definition and Concentration 27   \nB. Downward Wage Pressure . 30   \nC. Merger Simulation.. 34   \nD. Other Factors in Merger Analysis 36   \n1. Efficiencies 36   \n2. Repositioning, Entry, and Potential Competition . 39   \nE. Case Study: The Effect of Hospital Mergers on the Labor Market for Nurses. 40  \n\nII. Legal Remedies for Other Types of Monopsonistic Behavior... .43  \n\nA. Covenants Not to Compete. 43   \nB. Supplier Wage Suppression 44   \nC. Collusion 44   \nD. More Speculative Anticompetitive Practices in Labor Markets 45  \n\nIV. Conclusion . 46  \n\nIn recent years, a declining economic growth rate and rising income inequality have taken center stage in public debate. Academic research has identified several possible causes, ranging from major structural shifts in the economy to public policy failure. One cause that has received increasing attention from economists is labor market power, the ability of employers to set wages below workers’ marginal revenue product.4 New evidence suggests that many labor markets around the country are not competitive but instead exhibit considerable market power enjoyed by employers, who use their market power to suppress wages. Wage suppression enhances income inequality because it creates a wedge between the incomes of people who work in concentrated and competitive labor markets, and often affects low-income earners the most as they have the fewest options and least bargaining power. More important, though, it reduces the incomes of workers relative to those of people who live off capital, and the latter are almost uniformly higher earners than the former. Wage suppression also interferes with economic growth since it results in underemployment of labor, although it may raise the returns to investment. With wages artificially suppressed, qualified workers decline to take jobs, and workers may underinvest in skills and schooling. Many workers exit the workforce and rely on government benefits, including disability benefits that have become a kind of hidden welfare system.6 This in turn costs the government both in lost taxes and in greater expenditures. We estimate monopsony power in the U.S. economy reduces overall output and employment by $13\\%$ , and labor's share of national output by $22\\%$  \n\nLabor market power is the mirror image of product market power. A product market is a (usually) geographic area in which a collection of products is purchased, where the collection of products is defined by frequent consumer substitution. When a small number of sellers or one seller exist, we say that each seller has (product) market power, which enables it to charge a price higher than marginal cost, or the price that would prevail in a competitive market. When a small number of employers hire from a pool of workers of a certain skill level within the geographic area in which workers commute, the employers have labor market power.  \n\nOne major source of market power in both types of markets is concentration, where only a few firms operate in a given market. Imagine, for example, a small town with only a few gas stations. Each gas station sets the price of gas to compete with the prices of other gas stations. When a gas station lowers its price, it may obtain greater market share from other gas stations which increases profits-but it also receives less revenue per sale. If only a single gas station exists, it will maximize profits by charging a high (\"monopoly'\") price because the gains from buyers willing to pay the price exceeds the lost revenue from buyers who stay away. If only a few gas stations exist, they might illegally enter a cartel in which they charge an above-market price and divide the profits, or they might informally coordinate, which is generally not illegal—though the social harm is the same. In contrast, if a large number of gas stations compete, prices will be bargained down to the efficient level—the marginal cost—resulting in low prices for consumers and high aggregate output of gasoline.  \n\nLabor market concentration creates monopsony (or, if more than one employer, oligopsony, but we use these terms interchangeably) where labor market power is exercised by the buyer rather than (as in the example of gasoline stations) the seller. Employers are buyers of labor who operate within a labor market. A labor market is a group of jobs (e.g., computer programmers, or lawyers, or unskilled workers) within a geographic area where the holders of those jobs could with relative ease switch among the jobs. The geographic area is usually defined by the commuting distance of workers. A labor market is concentrated if only one or a few employers hire from this pool of workers. For example, imagine the gas stations employ specialist maintenance workers who monitor the gas pumping equipment. If only a few gas stations exist in that area, and no other firms (for example, oil refineries) hire from this pool of workers, then the labor market is concentrated, and the employers have market power in the labor market. To minimize labor costs, the employers will hold wages down below what the workers would be paid in a competitive labor markettheir marginal revenue product. Thus, some people qualified to work will refuse to, but the employers gain more from wage savings than they lose as a result of being able to hire fewer workers.  \n\nAlthough product market concentration and labor market concentration are both covered by antitrust law, product market concentration has historically received a huge amount of attention by researchers and government officials, while labor market concentration has received hardly any attention at all.8 The Justice Department (DOJ) and Federal Trade Commission's (FTC)'s Horizontal Merger Guidelines, which are used to screen potential mergers for antitrust violations, provide an elaborate analytic framework for evaluating the product market effects of mergers. Yet, while the Merger Guidelines state that there is no distinction between seller and buyer power,9 they say nothing about the possible adverse labor market effects of mergers. Similarly, while there are thousands of reported cases involving allegations that firms have illegally cartelized product markets, there are relatively few cases involving allegations of illegally cartelized labor markets, and many if not most of those cases involve specialized settings such as sports leagues, which restrict the hiring of players. 1o  \n\nConcentration is just one source of market power. Others, as we discuss below, include product differentiation and search frictions. All of these sources of market power create inefficiency and redistribution from workers to firm owners. All sources of market power are acknowledged as potential concerns for antitrust, and all can operate on both the product market side as well as the labor market side. Yet antitrust has focused almost exclusively on mitigating product market power.  \n\nThis historic imbalance between what we will call product market antitrust and labor market antitrust has no basis in economic theory. From an economic standpoint, the dangers to public welfare posed by product market power and labor market power are exactly the same. As Adam Smith recognized, businesses gain in the same way by exploiting product market power and labor market power-enabling them to increase profits by raising prices (in the first case) or by lowering costs (in the second case).11 For that reason, businesses have the same incentive to obtain product market power and labor market power. Hence the need—-in both cases—for an antitrust regime to prevent businesses from obtaining product and labor market power except when there are offsetting social gains.  \n\nWhy, then, the imbalance between product and labor market antitrust? We do not know the answer to this question, but four possibilities suggest themselves. First, while economic theory treats product markets and labor markets similarly, legal theory has placed more emphasis on product markets. The reason for this is that since the 1960s, legal scholars have influentially argued that the amorphous norms of antitrust law that prevailed earlier in the twentieth century should be replaced with a laser-like focus on consumer welfare.12 The resulting shift in focus naturally favored product market analysis because consumers are primarily injured by price increases caused by product market power.13 In contrast, workers are primarily injured by the exercise of labor market power. Of course, workers are consumers, and so workers benefited from the law's attention to product markets--but not as much as they would have if the law had paid attention to labor markets as well.  \n\nSecond, economists assumed that labor markets are reasonably competitive, and accordingly that labor market power was not an important social problem. Most people live in urban areas where numerous employers vie for workers. Workers can (and do) move around the country if jobs are scarce or pay is low where they live, putting an upper bound on the social cost of labor market power even if it exists. It is only in recent years that many of these assumptions have been thrown into doubt. 14 Moreover, academic economics has long been divided into separate fields of industrial organization (IO) and labor economics. IO economists have focused on antitrust problems created by mergers and other corporate actions, while labor economists have focused on labor and employment law. Partly as a result, labor economists never developed the analytic tools relevant to forecasting the impact of increased labor market power that are analogous to or draw on the models IO economists use to analyze product market power.  \n\nThe DOJ and FTC rely heavily on advice from economists on their staff when evaluating mergers, and have frequently challenged mergers based on their effects on product markets.15 Relying, we suspect, on the traditional assumption of economists that labor markets are competitive, the agencies have never blocked a merger because of its effect on labor markets—or, even, as far as we know, given the labor market effects of a potential merger more than cursory attention. Indeed, those agencies have never, to our knowledge, employed an economist whose primary expertise is in labor markets.  \n\nThird, the traditional legal approach to protecting workers, which took place “outside' antitrust law, may have seemed sufficient. This traditional legal approach had two branches—labor law and employment law. Labor law protected workers who sought to form unions to combat the market power of employers. The theory was that if workers banded together, they could use legally mandated collective bargaining and the threat of strikes to prevent employers from paying them monopsony wages. Employment law granted workers specific protections—minimum wages, maximum hours, safe workplaces, privacy rights, and the like. Employment law countered employer labor market power by preventing employers from granting workers wages and benefits below a somewhat artificial floor. However, both types of legal protection have eroded over the years. Union activity has collapsed in the United States because of deregulation, foreign competition, aggressive anti-union tactics by employers, and a chilly legal environment. 16 The federal minimum wage law has eroded as a result of inflation; other employment protections are vulnerable to the vagaries of budget-setting and enforcement priorities among the relevant agencies. And all these worker protection laws assume traditional employment practices, which are rapidly being replaced by independent contractor arrangements, outsourcing, and other practices of the “gig economy.\"17\"  \n\nFourth, antitrust litigation against employers is more difficult than antitrust litigation based on product market concentration, perhaps giving the illusion that the latter problem is more significant than the former. Product-market litigation is often brought by large firms, which have the resources and incentives to bear the high costs of complex and expensive antitrust litigation. Class actions by consumers are also relatively straightforward because in a typical antitrust case involving product markets, the argument is simply that the consumers paid a higher price than they should have, which means that the consumers share a common interest as required by courts.18 In contrast, virtually no worker can hope to obtain damages in an antitrust action—even with the treble damages rule—that would compensate her for the cost of litigation. And class actions brought by workers hardly ever succeed because workers—-unlike consumers—are frequently in diverse positions, defeating the common interest requirement. Some workers are senior, others are junior; some have benefits, others do not; some have outside job opportunities, others do not; qualifications vary; contract terms vary; and so on.19  \n\nThe small number of successful antitrust cases involving labor markets bear out these observations. These cases involved highly specialized settings, including, for example, sports leagues that restricted compensation arrangements of athletes, the fashion model market, and doctors and nurses who were regulated by groups of hospitals.2° These cases were brought by sophisticated and well-paid workers in unusual market settings. Run-of-the-mill cases involving ordinary workers are mostly unheard of. And because successful antitrust actions by workers have been so rare, there is little developed law on the topic, which renders further litigation risky.  \n\nThat was the intellectual and legal landscape until a few years ago. The consensus that labor markets were competitive collapsed in response to several events. First, there was the revelation that high-profile Silicon Valley tech firms, including Apple and Google, entered nopoaching agreements, in which they agreed not to hire each other's employees.21 This type of horizontal agreement is a clear violation of the Sherman Act. The firms settled with the government but the casual way in which such major firms, with sophisticated legal staffs, engaged in such a blatant violation of the law appears to have alarmed antitrust authorities. The government subsequently issued guidelines to human resources offices warning them that even implicit agreements not to poach competitors’ employees were illegal. $^{22}\\ln2016$ the White House Council of Economic Advisors and the Department of Treasury issued reports warning of the dangers of cartelized labor markets.23 In recent months, the DOJ has announced that it has launched criminal investigations of firms for entering no-poaching agreements.24  \n\nSecond, the recent discovery that non-compete agreements are extraordinarily common, and frequently applied to low-wage workers raised suspicions that they were being used by employers to exploit their labor market power. For example, Jimmy John's, a sandwich franchise, routinely required low-wage employees to sign covenants not to compete, which apparently deterred those employees from moving to competitors.25 The covenants not to compete were generally illegal under state laws but they had an in terrorem effect on workers who could not afford to consult lawyers.26 The effect was therefore to reduce mobility between jobs, possibly suppressing wages. Researchers subsequently learned that an enormous number of workers— including low-income, relatively unskilled workers—are bound by restrictive covenants. According to one study, in $201412\\%$ of workers earning less than $\\$40,000$ per year with education below the college level were bound by non-competes.27 The study also found that workers who entered non-competes in certain labor markets did not receive a compensating wage differential, implying monopsonistic conditions in those markets that caused harm to the employees.28 Another study found similar results for low-income workers, and in addition that, among all workers, $24.5\\%$ reported that they are, or have been, bound by a non-compete agreement.29 Relatedly, large franchises like McDonald's used no-poaching agreements to reduce competition among franchisees for workers——which in some markets might have resulted in considerable increases in market power. A study found that $53\\%$ of major franchisors used no-poaching agreements in 2016, compared to $35.6\\%$ in 1996.30 News media reports provide additional anecdotal evidence of the ubiquity of non-competes and no-poaching agreements, and their powerful effect on labor mobility.31  \n\nThird, economists began investigating monopsony in labor markets. An important spark for this work was a classic study by David Card and Alan Krueger, which found that employment levels were not affected by a minimum wage hike in New Jersey in 1992.32 While controversial at the time, many other studies of minimum wage increases in other jurisdictions and at other times produced similar results.3 A possible explanation for the result is that labor markets are concentrated: if employers pay workers less than their marginal product, then a minimum wage hike—if not too great—will result in higher wages without disemployment. While other explanations are also possible, the monopsony theory gains credence from other studies of the last several years, in which economists, using a range of methodologies as well as previously unavailable sources of data, have found additional evidence of widespread labor market concentration.34  \n\nFourth, a wave of industry consolidation has given employers greater bargaining power in labor markets. This industry consolidation, which began in the 1970s,35 was hardly a secret, but commentators focused on the possible effects on product markets, not labor markets. For example, commentators worried that mergers in the airline industry, which reduced the total number of major American airlines operating in the United States from more than ten in the 1980s to four today,36 might raise ticket prices for consumers, but not that it might suppress the wages of pilots, flight attendants, and airline mechanics. Hospital consolidation has raised concerns about the creation of monopsony conditions for nurses and physicians, especially in small towns and rural areas.37 Consolidation has taken place in many less salient industries as well, where working conditions are harsh and wages are low. For example, the meat-packing industry has gone through a series of mergers.38 Because many food processing establishments are located in remote, rural areas where labor markets are concentrated, the effect of mergers in this industry on wages could be significant. Consolidation unique to the labor market has been in the freelance services industry39 and the temporary staffing industry.  \n\nWhile the government and private litigants can make inroads on labor market power by suing employers who use no-poaching agreements and other obvious forms of collusion, this type of litigation can have only limited effect. After all, if mergers that dramatically increase labor market power are allowed with little objection, companies can achieve monopsonies by merging rather than by entering agreements with each other. In fact, after years of enforcement neglect many labor markets already are concentrated, and under existing antitrust law employers in such markets are permitted to pay workers less than their marginal product. Moreover, subtle forms of anticompetitive behavior—-like parallel conduct or implicit coordination—are extremely difficult to detect and often not illegal. A similar set of problems with antitrust enforcement in product markets led to emphasis on blocking mergers and collusion over focusing on conduct. But a merger may increase both product and labor market power, both by increasing concentration and reducing wage competition. By blocking mergers more vigorously, private litigants and antitrust authorities can slow down or halt excessive market power.  \n\nIn this Article, we argue that the FTC and DOJ should take more seriously the danger that mergers may lead to labor market power as well as product market power.40 The first step is to update the Horizontal Merger Guidelines to provide a detailed legal framework, comparable to that already provided for product market power, for evaluating the effects of a merger on labor markets.  \n\nWe suggest three approaches that correspond to the three standard approaches to productmarket merger analysis. Under the first approach, which we call Market Definition and Concentration (MDC), the antitrust authorities define the relevant labor market, calculate the level of market concentration, and then estimate the increase in market concentration that would result from a merger. If the merger would take place in an already concentrated labor market, and would increase labor market concentration beyond a threshold, the merger is prohibited, unless the merging parties can prove the efficiency gains from the mergers are great enough to benefit workers on net.  \n\nUnder the second approach, which we call Downward Wage Pressure (DWP), the regulator calculates the tendency of workers who quit one merging firm as a result of an incremental decrease in wages to join the other merging firm (as opposed to other firms in the labor market or to dropping out of the labor market), and the amount by which workers’ wages are below their marginal revenue before the merger. If the product of these figures exceeds the efficiency benefits of the merger, usually $1-2\\%$ of wages, then the merger is prohibited, absent compelling evidence of efficiencies, the likelihood of entry, or other features that lessen the merger harm.  \n\nBoth of these approaches are fairly crude, rule-like ways to trigger scrutiny of mergers. Once a merger is flagged as potentially harmful, analysis should proceed to a second, more exhaustive stage where authorities conduct more detailed investigation. The central role in this stage would be played by merger simulation, as it is in product markets. In such simulations in product markets, economists build a detailed structural economic model of the product market and the behavior of firms within it. They then estimate the model econometrically and simulate how a merger is likely to change prices, quality, innovation, and so forth.41  \n\nA similar approach can be applied to labor markets. Models of imperfect competition in labor markets, driven by the difficulties with searching for jobs, by amenities that are specific to a particular work place, and by other factors, have become increasingly prominent in recent years.42 These models should be supplemented with analysis of less easily-quantified factors, including the likely effect of the merger on the quality of jobs (e.g. the nature of the workplace environment, the parental leave policy, etc.), on entry of new employers into the labor market, innovation in the workplace, and related factors. As in standard product market analysis, all these factors are worth considering in determining whether a merger should proceed.  \n\nThe paper is organized as follows. In Part I, we provide the legal and economic background to the current concerns about labor market concentration. In Part II, we propose and defend the three types of merger analysis for labor market effects. While we focus on mergers, because they are the best-developed area of antitrust law, many other areas of antitrust have strong analogs in labor markets, where they should be applied. Hence in Part II, we discuss other ways in which concepts and doctrines used in antitrust law to address concentration of product markets can be applied to labor market concentration.  \n\n## I. The Rise of Labor Monopsony  \n\nA. The Economics of Labor Market Power  \n\n### 1. The Intellectual History of Monopsony  \n\nThe term “monopsony” was coined by the British economist Joan Robinson in 1933.43 Before then, economists who wrote about industry structure focused on monopoly and market power in the product market. It had long been clear that large corporations like Standard Oil monopolized goods and services. Robinson realized that corporations also exercised market power on the “buy side\"—in their purchases of inputs, including goods, services, and labor. The monopsony power of corporations was just as common as their monopoly power, perhaps more common, but harder to detect.  \n\nTo be sure, long before Robinson's book, critics of capitalism like Karl Marx had denounced employers′ treatment of their workers. They argued that employers “exploited” their workers by underpaying them, subjecting them to substandard working conditions, and busting unions. Marx argued that employers could keep wages low by taking advantage of what he called the “reserve army of the unemployed.\"44 Because people desperately sought work, employers could keep workers′ wages below the value of their labor, at their “labor power’ (the minimum they needed to continue working). The extraction of the resulting “surplus value\" by the employer was what Marx called “exploitation.\"” Robinson's analysis of monopsonistic labor markets provided a more rigorous formulation of the problem of employer dominance. She pointed out that if labor markets are competitive, employers cannot exploit workers in Marx's sense because workers who are paid only enough to avoid starvation will be able to sell their labor to other employers at a higher wage. Yet labor markets need not be competitive, and when they are not, the outcome for workers is similar to those that Marx identified: excess unemployment, a permanent gap between wages and worker productivity, poor working conditions, and domination of the workers by employers.45  \n\nSome scholars believe that elements of feudalism, preserved through the common law, may also have helped employers gain and preserve monopsony power, and retarded the development of appropriate legal responses to it. In England, anticompetitive elements of master and servant law dated back to the 1351 Statute of Labourers.46 These rules included enticement doctrines, which blocked employers from poaching each other's workers, and criminalization of worker \"absconding,” i.e., leaving an employer without permission. The feudal legacies _ may have legitimized anticompetitive practices in labor markets.47 In the postbellum U.s. South these doctrines were resuscitated as a component of Jim Crow labor law,48 while in the North, these doctrines were used by courts to resist the rising labor movement.49 Nineteenth- century labor activists identified market power of employers as a justification for collective bargaining and regulation, complaining of \"wage slavery” and drawing analogies to chattel slavery. 7.50  \n\nWhile Marx held that the increasing concentration of labor markets under capitalism would spark a revolutionary transition to socialism, the major effect was instead unionization, which, while often militant, was focused on improving wages and conditions for workers rather than changing the world. In the United States and other western countries, governments initially resisted the labor movement, often violently, but ultimately accommodated it. Under pressure from unions, governments passed laws that protected workers from low wages, excessive hours, dangerous workplaces,51l and other abuses, and that protected labor organization from interference by employers.52  \n\nThe bottom-up nature of worker organization probably accounts for a major bifurcation in the way the law treats the problem of market power. While antitrust law, beginning with the Sherman Act of 1890,53 nominally applied to labor markets as well as product markets, it has rarely been used to protect workers. Instead, antitrust law has focused on product markets, while labor and employment law has dealt with market power in labor markets. These two traditions have developed in parallel over a century, rarely coming into contact.  \n\nThis bifurcation of the law led to a bifurcation in economic theory. To address monopolization of product markets, economists developed the field of industrial organization, which seeks to explain how market power affects the structure of business mainly in relation to product markets. To address abuses in the labor market, economists developed the field of labor economics, which focuses on unions and employment regulations. This dual bifurcation in law and theory may explain why an assumption emerged that labor markets are competitive, and hence do not need antitrust law.  \n\nHowever, labor and employment law have failed to accomplish many of their goals, with the result that labor market concentration is as bad as ever. Beginning in the 1970s and accelerating in the 1980s and 1990s, public policy turned against labor and employment law. The “neoliberal revolution reflected frustration with the rigidity of traditional labor law and the disruptions caused by labor unions that struggled to adapt to changing technology and circumstances. Yet rather than adapt new labor laws or organizations better suited to the age of globalization and digitization, reformers focused on dismantling existing labor protections and anti-union legislation.  \n\nAs unions declined, however, labor markets did not lose their rigidities. Instead, they seemed to become more concentrated. The concurrent decline of unions and rise of labor market concentration implies that the neoliberal assumption that unions, rather than employers, are the major source of cartelization of labor markets was false. This provoked economists to revisit the assumption of perfect competition.  \n\n### 2. The Sources of Monopsony Power  \n\nEconomists have identified several sources of labor market power. Because these sources have counterparts in the more familiar analysis of product markets, where they have been subject to considerable legal analysis, we will introduce each of them by way of the product market.  \n\nIn product markets, there are three primary barriers to competition. First, market concentration refers to the existence of one or a small number of sellers, usually the result of increasing returns to scale, high fixed costs, or network effects. Second, product differentiation exists when goods or services are different from each other rather than fungible; differences across products make comparison difficult, which reduces competition. Third, search frictions make it hard for consumers to compare products and seek out the best offering. In both the academic literature and legal adjudication, market concentration typically plays the central role in analysis, with less emphasis on product differentiation, and the least emphasis on search.  \n\nIn the literature on labor markets, by contrast, the problem of search frictions has played the central role, following the Nobel Prize-winning work of Peter Diamond, Dale Mortensen, and Christopher Pissarides.54 In 1998, Burdett and Mortensen proposed a model of labor markets with a large number of identical workers and identical firms where search frictions naturally lead employers to have monopsony power.5 The pioneering theoretical and empirical work of Alan Manning, culminating in his influential 2003 book Monopsony in Motion, presented a wide variety of evidence in favor of what is called the dynamic monopsony modei.56 This work assumes workers must spend and time and effort to find jobs. Because a worker's existing employer knows that the worker's search cost is high, the employer can reduce compensation—including wages, benefits, and workplace amenities—or fail to increase compensation despite the worker's contributions because the employer knows that the worker can find an alternative job only with difficulty.  \n\nIn recent years, labor economists have focused on firm-specific amenities of a workplace which is the labor market correlate to product differentiation.57 Imagine two workplaces that are identical at an initial point. The employer of each workplace seeks to deter workers from leaving. To do so, an employer might offer an amenity that its workers happen to like——say, a coffee bar, or a yoga studio, or hot showers. Other amenities might rise more naturally: for example, the location of an employer might appeal to workers because of the convenience for commuting or the attraction of nearby restaurants or other businesses. Differing amenities give rise to search frictions, as noted above, but they separately make it more difficult for workers to compare firms. Indeed, the identities of the other workers at a workplace—-whether they are driven and intense, or friendly and laid back, or young or old—matters to people, and even very similar-seeming employers, for example, law firms, might be very different in practice. As we will see below, there are good reasons to believe that such differentiation is more significant in labor than in product markets and thus that labor markets tend to be much narrower than product markets are.  \n\nThe final and most neglected cause of labor market power is the concentration of labor markets due to economies of scale, network effects, fixed costs, and other factors. The basic idea here is that in many industries a firm with many employees can churn out goods and services more efficiently—-at less cost per unit of output—-than firms with fewer employees can. The literature on this phenomenon is limited, though we discuss a few recent analyses in the next subsection.  \n\nOur discussion so far might give the impression that labor markets and product markets are similar: they are both vulnerable to market power (monopsony in the first case, monopoly in the second), and for the same reasons. But there is reason to believe that labor markets are more vulnerable to monopsony than products markets are to monopoly, thanks to yet another new literature in economics. This literature, for which Lloyd Shapley and Alvin Roth were awarded the Nobel Prize, emphasizes the importance of matching for labor markets.58 The key point is that in labor markets, unlike in product markets, the preferences of both sides of the market affect whether a transaction is desirable.  \n\nCompare buying a house in the product market and searching for a job. Both are important choices that can affect the course of a life. However, there is a crucial difference. In a house sale, only the buyer cares about the identity, nature, and features of the product in question—-the house. The seller cares nothing about the buyer or (in most cases) what the buyer plans do with the house. In employment, the employer cares about the identity and characteristics of the employee and the employee cares about the identity and characteristic of the employer. Complexity runs in both directions rather than in one. Employers search for employees who are not just qualified, but who possess skills and personality that are a good match to the culture and needs of that employer. At the same time, employees are looking for an employer with a workplace and working conditions that are a good match for their needs, preferences, and family situation. Only when these two sets of preferences and requirements “match\" will a hire be made.  \n\nThis two-sided differentiation is why low skilled workers may be as or even more vulnerable to monopsony than high skilled workers, despite possibly being seen as less differentiated by employers. Low-skill workers may have less access to transportation, wellsituated housing markets, and job information, and be more dependent on informal networks, all of which make jobs less substitutable and employers more differentiated.  \n\nThis dual set of relevant preferences means that labor markets are doubly differentiated both by the idiosyncratic preferences of employers and those of workers. In some sense this \"squares\" the differentiation that exists in product markets, naturally making labor markets thinner than product markets, meaning that the cost of entering a transaction—-in relation to the gains from trade—are on average greater in employment markets than in product markets because people are not as interchangeable as goods are.  \n\nThese matching frictions both cause and reinforce the typically long-term nature of employment relationships compared to most product purchases, leading to significant lock-in within employment relationships. They are also reinforced by the more geographically constrained nature of labor markets. In our increasingly digital and globalized world, products are easily shipped around the country and world; people are not. While traveling is easier than in the past, and telecommuting has become more common, labor markets remain extremely local while most product markets are regional, national, or even global. The overwhelming majority of jobs still require physical proximity of the employer, greatly narrowing the geographic scope of most labor markets, given that many workers are not willing to move away from family to take a job. Twoincome families further complicate these issues because each spouse must find a job in the area in which the other can, further narrowing labor markets. Together these factors naturally make labor markets highly vulnerable to monopsony power, much more vulnerable than most product markets are to monopoly power.  \n\n### 3. The Social Cost of Monopsony  \n\nThe economics of labor market power and the harms it causes is closely analogous to the theory of product market monopoly. Recall that a monopolist is a firm that need not take market prices as given, but can raise its price, at the cost of some lost demand, to increase the profits it earns. In choosing an optimal price the firm faces a trade-off. Raising the price reduces sales, but also increases the price the firm can charge on each unit. The higher the firm raises its price, the costlier it is to lose extra demand, as each sale is very profitable. Eventually the firm finds a balance point, where the value of the lost sales from raising the price further just equals the increased profits on the units it sells at the increased price. This is the “monopoly optimal price.\" The firm's absolute mark-up is the gap between this price and the firm's cost. The mark-up equals the difference between the monopoly price and the competitive price, and thus serves as a natural gauge of market power, as we will discuss below.  \n\nA similar trade-off between profit-per-unit and number of units sold applies to firms that are not literally monopolists but have some power over their price. In fact, in some sense, every firm with any market power is a “monopolist’ over some market, though maybe one too narrow and in too direct competition with other markets to matter much.  \n\nThe analysis of monopsony in labor markets is closely analogous. In a competitive labor market, firms equate the going wage of workers to their “marginal revenue product,’ the amount of additional revenue the worker can generate. When an employer has a monopsony, it considers the fact that to hire an additional worker it will have to raise the prevailing level of wages for its existing workers and that doing this will increase its overall labor costs. Conversely if it lowers wages, while it will lose some workers, it will also lower the wage bill on the workers it already employs. As in the monopoly case, a monopsonist will not internalize this effect on workers and will choose an “absolute markdown\" of wages below the marginal revenue product. Again, we will usually use “markdown\"' to refer to this absolute markdown as a proportion to the wage, which may well be greater than $100\\%$ (the marginal revenue product may be more than twice the wage). Just as with firms with market power, an employer with labor market power may not have a “\"monopsony” over some easily described market, but so long as it will not lose its entire workforce by slightly lowering its wage, it has some labor market power.59  \n\nWe must introduce two lamentable pieces of jargon here. Economists use the word \"elasticity”' to refer to the sensitivity to which one thing reacts to another. “Labor market elasticity\" refers to the sensitivity with which workers react to changes in wages. Suppose that wages across the economy decline a tiny amount, and everyone quits. Then labor market elasticity is infinity. Suppose instead that no one quits; then labor market elasticity is 0. Elasticity can range from O to infinity; the general view is that labor market elasticity across the economy is in the neighborhood of 0.5, suggesting a high level of inelasticity.60 This means, intuitively, that people tend to stay in the workforce even when wages decline: they need to support themselves.  \n\nThe second, even more awful, term is “residual labor supply elasticity,\" which refers to the sensitivity with which workers react to changes in wages at a particular firm. Suppose a computer programmer who works at Google would quit and move to Apple if wages at Google decline by a tiny amount. Then the residual labor supply elasticity is infinity. If the programmer would not quit even if Google lowered wages significantly, then the firm-level elasticity is closer to zero. Like labor market elasticity (sometimes called “aggregate labor supply elasticity,”’ to distinguish it from” residual labor supply elasticity'), residual labor supply elasticity can fall anywhere along this continuum. But it varies greatly from industry to industry, from close to O to, as we will discuss below, 5, 10, or higher.61  \n\nResidual labor supply elasticity is a simple measure of a firm's labor market power. If workers do not quit even if the firm lowers wages significantly (elasticity is low), then the firm enjoys significant market power over the workers. This is the number that antitrust policy focuses on. If residual labor supply elasticity that a firm faces is high, then the labor market from which a firm draws its workers is competitive, and the firm cannot “exploit’ workers. If it is low, workers need protection.  \n\nThe economic consequences of labor market power are analogous to those of product market power. Product market power has two well-known effects. It redistributes from consumers to the firm: consumers must pay more for products and the firm earns greater profits at their expense. And it creates waste or deadweight loss. Some consumers would be willing to pay the efficient, marginal cost price that the firm would have charged in a competitive market, but are not willing to pay the higher price the monopolist chooses to charge.  \n\nSimilarly, monoposony power has two effects. It redistributes from workers to employers by lowering wages. And it creates waste: some workers would have been willing to work for the employer if they had been paid their full marginal revenue product, but will quit if they are paid the marked-down wage the monopsonist offers. This leads to increased unemployment or nonemployment as workers find prevailing wages unacceptable and exit the labor force or refuse to take available jobs.  \n\nNote that the waste created by monopsony (and monopoly) depends crucially on the inability of firms to pay (charge) different rates to different workers (consumers), although the redistributive effects do not. If an employer can pay a worker a bit more than that worker's outside option, then every worker would be paid a different amount (depending on the value of the outside option, which in turn could reflect local connections and the like), then it can employ every worker whose marginal product revenue exceeds the wage. But employers cannot practice wage discrimination very effectively. They have little information about workers’ outside options, and are deterred by powerful pay fairness norms.62 The product market again offers a useful lesson: analogous price discrimination by sellers is difficult and rare. However, the emergence of sophisticated prediction algorithms applied to vast troves of human resource data suggest that the ability to wage discriminate in the future may be expanded.63  \n\nMonopsony power creates other negative effects as well. First, to the extent that the degree of monopsony power differs across employers, it will also lead to misemployment: workers may be more productive at employer A, which has a lot of labor market power, than at employer B which has a little. But B may offer higher wages because of its limited labor market power. The worker may thus choose to work at B, lowering the productivity of the economy.  \n\nSecond, employers will often cut benefits, rather than cut wages, to take advantage of workers who are locked into the job. The firm has no need to retain these workers and thus may wastefully degrade conditions of work these “stuck” workers particularly value, instead catering only to the workers the firm is worried about losing.64  \n\nThird, monopsony also raises prices for consumers. This may seem counterintuitive: won't lower wages to workers be reflected in reduced consumer prices? In fact, the reverse is true. To see this, note that if firms employ fewer workers, they will produce less output, resulting in higher prices. While the firm lowers wages to workers, the cost to the firm of hiring workers actually rises as the firm now takes into account the fact that, when it hires an additional worker, it also will pay the rest of its workers more. It is this full marginal cost of an additional worker and not merely the wages that the firm now accounts for and passes on to consumers as higher, not lower, prices.65  \n\nFourth, monopsony power also reinforces and exacerbates monopoly power. In fact, both can be seen at a high level as just two ways for the owners of capital to squeeze workers and thus reduce the returns to productive work and thus the output of the economy. The marked-down on wages caused by monopsony and the mark-up on prices caused by monopoly can be seen as akin to taxes—-payments that ordinary people must pay in order to go about their daily life as producers and consumers. However, the payments do not go to governments to fund programs, but to firms, and ultimately, investors. And the payments do not spur investment and raise economic growth because they depend in the first place on the willingness of managers to leave capital idle in order to obtain market power, while driving workers out of the workforce and onto taxpayer-financed relief programs.  \n\n4. Recent Developments: Evidence of Labor Market Concentration  \n\nEvidence that labor markets are monopsonistic, particularly in low-wage labor markets, has been accumulating over the past two decades. The evidence consists of studies of many different markets, which tend to show that residual labor market elasticities are extremely low. We should acknowledge at the outset that all such studies face considerable methodological difficulties. The gold-standard measure would be a large-scale experimental estimate of the laborsupply elasticity facing a firm, where the employer is somehow persuaded to randomize the wages it offers workers. One group of authors did manage such an experiment, and found a residual labor market elasticity of 2.15. But the study involved government workers in Mexico, and hence may not be generalizable for the United States.6 Convincing firms to randomize their wages in the United States has so far proven hard, and so researchers have relied on a variety of natural experiments and indirect observations to estimate the extent of labor market power.67  \n\nAn early finding that stimulated the development of monopsony as a candidate model of the labor market for low-skill labor was the evidence on minimum wage effects produced by David Card and Alan Krueger.68 Conventional wisdom in the economic profession at the time held that minimum wage laws will reduce employment, based on the assumption that low-skill workers are normally paid a competitive wage. In a given market, for example, a city, there are many employers who are willing to hire low-skill workers—including custodial workers, security guards, sandwich makers, and the like. The multiplicity of possible employment opportunities should minimize the labor market power of any particular employer. If so, then employers pay workers a wage equal to their marginal product, and an employer who is forced by law to raise wages would have to fire any workers whose marginal product is below the legal minimum or lose money. However, Card and Krueger found no such wage effect, suggesting that workers were paid less than their marginal product and hence the employer could absorb the higher wage rate. Numerous studies have attempted to replicate the Card and Krueger result, too many to discuss here. But many studies found evidence consistent with Card and Krueger's. For example, Arindrajit Dube, Suresh Naidu, and Michael Reich found that the San Francisco minimum wage law of 2007 raised wages without lowering employment, and lowered turnover.69 Recent work by Dube, Reich, and T. William Lechter expands the analysis to the entire U.s. labor market and finds that minimum wage laws increase wages without reducing overall employment.70  \n\nThe labor supply curve facing the firm consists of both flows of workers into the firm (\"recruit') and flows of workers out of the firm (\"retention\"). The sensitivity of these flows to the wage recovers the residual labor supply elasticity facing the firm. Alan Manning, who was an early developer of the empirical case for monopsony,71 showed that while quits are decreasing and recruits increasing in the wage recruits are increasing in the wage in the United States and United Kingdom, the implied elasticities are much smaller in magnitude than would be expected from a perfectly competitive model. But Manning's empirical analysis was hampered by data limitations, which introduced many confounds.  \n\nDouglas Webber was able to overcome some of these limitations by using the Longitudinal Employer Household Dynamics (LEHD) data from the U.S. Census, which provides more finegrained information about workers, and covers nearly all non-farm jobs.72 These data, which include matched worker-firm wages, allow direct estimation of the effect of firm wages on the rate of new hiring and the rate of separations, controlling for worker fixed effects, and thus eliminating some of the endogeneity of wages (for example due to worker skill). Controlling for worker and firm fixed effects, Webber estimates a residual labor supply elasticity of 1.08. In a subsequent paper, Webber show that women have lower job mobility than men, and finds that the residual labor supply elasticity for women is 0.15 less than that for men, which is also inconsistent with the hypothesis of competitive labor markets. 73 In a competitive labor market, firms would pay women and men of equal skill exactly the same amount, the competitive wage. Dube and coauthors conduct a meta-analysis of experimentally varied wages on Amazon Mechanical Turk and document surprisingly low labor supply elasticities (less than 0.5) in this market with putatively low search frictions and a large number of workers and firms.74  \n\nDavid Card and his coauthors estimate the rent-sharing elasticity (meaning, the extent to which a firm and a worker share value generated by the worker's work), where firm-level measures of value added are correlated with firm-level wages, and provide recent evidence from matched worker-firm data.75 Both of these sources of evidence suggest that firms do not simply take market wages as given, but instead transmit idiosyncratic variation in sales/profitability into wages. The importance of variations in firms in explaining wages is further evidence that the assumption of competitive markets is unwarranted, since in competitive markets only the worker's marginal product, not the firm's characteristics, determines the wage. Patrick Kline and coauthors provide recent, clean, evidence on monopsony using exogenous variation in patent grants to examine the effect of changes in firm profitability on worker wages.76 They find that wages of even low-skill workers respond to these shocks, with an implied residual labor supply elasticity facing the firm of 2.5. However, they find this effect is limited to incumbent workers, and does not increase wages of new recruits.  \n\nAnother way to assess monopsony is to estimate effects of labor market concentration on wages. The labor market is defined by commuting distance for a given occupation. Alan Manning and Barbara Petrongolo estimate a structural model on job application data from the UK to look at application behavior of workers, and find that workers? application rates to a job are quite sensitive to distance, suggesting that labor markets are quite local.77 Ioana Marinescu and Roland Rathelot also find quite sharp sensitivity of applications to distance in United States data, with application rates falling by $35\\%$ for jobs 10 miles away from a worker's residence.78 In a recent blockbuster paper, José Azar and his coauthors find substantial labor market concentration in labor markets throughout United States,79 a finding confirmed by yet another near-contemporaneous study performed using a different data source. 80  \n\nFurther evidence on monopsony is provided by (grim) evidence on worker deaths. Adam Isen estimates the effect of worker deaths on payroll and sales, and finds that sales fall more than payroll, suggesting that workers are paid less than their marginal product. Isen estimates a residual labor supply elasticity between 2.5 and 5.5.81 Another piece of indirect evidence is provided by bunching in the wage distribution. If residual labor supply elasticity is high, then employers will be careful to pay workers a wage close to their marginal product revenue, and will avoid basing wages on simple rules of thumb that may be inaccurate for particular workers. Arindrajit Dube and coauthors obtain administrative data on hourly wages and document considerable bunching at $\\$10.00$ per hour and other round numbers.82 Using a model with worker and firm behavioral biases, they translate the extent of bunching into bounds on labor market power. Their results suggest that if firms are losing no more than $5\\%$ of profits from mispricing labor at a round number, the implied residual labor supply elasticity is roughly 2.5, and if firms are only losing $1\\%$ of profits the implied elasticity is between 1 and 1.5. Labor market power allows firms that mistakenly pay wages below marginal product to survive.  \n\nWhat, concretely, do these findings suggest about wages, employment, and other features of the labor market? Recall that until the recent literature began a few decades ago, economists assumed very high elasticities. Overall, the recent evidence suggests that low labor elasticities, ranging from 1 to 5 (and possibly even lower), are surprisingly common throughout the economy. Even the residual supply of low-skill labor is relatively inelastic, in the range of 1 to 3, despite the earlier conventional wisdom that inelastic labor markets were caused by the time and cost of obtaining education and specialized training, which low-skilled workers, by definition, lack.  \n\nIn the online Appendix,83 we conduct a few simple calibrations of the efficiency and distributional consequences of a variety of levels of labor market power. We assume an economy governed by a Cobb-Douglas production function84 with a (competitive) labor share of 2/3, together with a perfectly elastic supply of capital at a $5\\%$ interest rate. We use an aggregate labor supply elasticity of 0.3, which governs employment decisions of workers, which is the midpoint of the extensive (participation in the labor market or not) and intensive (number of hours worked) elasticities of 0.17 or 0.5, both drawn from work by Raj Chetty.85 The aggregate labor supply elasticity, n, which measures the sensitivity of employment to wages, is important for recovering the aggregate disemployment, and hence deadweight loss, effects of monopsony, as it measures the extent to which workers stop working in response to the lower wages induced by monopsony. In our preferred scenario, we also incorporate a labor tax of $30\\%$ with a fiscal multiplier of 1.3, to examine the interaction of monopsony with existing taxes: monoposony, by causing workers to drop out of the labor market, may further harm society by lowering tax intake and increasing social transfers.  \n\nBack-of-the-envelope calculations indicate that across the economy, a residual labor supply elasticity, denoted $\\upbeta$ , of 3 implies that wages are marked down by $25\\%$ , and workers similarly on average lose $22\\%$ of their share of output including public goods (from $75\\%$ to $58\\%$ as a result of employer labor market power. The monopsony profit share—-meaning the share of output that firms obtain because of monopsony power rather than their productive activities—is $14\\%$ in this scenario. This inequity is compounded by inefficiency: this level of monopsony also reduces aggregate employment and overall GDP by almost $13\\%$ . This distortion is partially due to fiscal effects, as government revenue is only $70\\%$ of what it would be at the competitive equilibrium. While stylized and simplified, this suggests that the rise of monopsony power over the past few decades could be great enough to account for many of the disturbing economic trends in the United States: the fall by almost 10 percentage points in labor's share, the dramatic decline in employment rates among prime aged men, budget shortfalls, and the “secular stagnation” of economic growth.  \n\nIn Figure 1, we show how the labor and profit shares change with the degree of monopsony. As the residual labor supply elasticity increases (the horizontal axis), the labor share increases towards $73.8\\%$ $66\\%$ of private output plus $26\\%$ due to the value of public goods) and the profit share goes to O, while the remainder (the capital share which is not graphed for legibility) decreases to $26.2\\%$ (all shown on the vertical axis). This can be considered a baseline: if labor markets were perfectly competitive, as economists so long assumed, then these figures would represent labor's and capital's share of output, while the deadweight cost from monopsony would be (obviously) zero. Figure 1 also shows how the aggregate deadweight loss due to monopsony falls as the labor market becomes competitive.  \n\n![](images/f9576633fbddad2c2d79a9dab9959d93f583a98c4db1c264df7d89f00f90d8f2.jpg)  \nDWL and shares as a function of $\\upbeta,$ with labor tax  \n\nAs Figure 1 shows, we may not worry much, as a matter of public policy, if residual labor supply elasticity is not exactly infinity: as it rises into the double digits, the incremental benefit of eliminating labor market power increases very slowly. The significance of the recent empirical literature is that it shows that throughout the economy, labor market elasticities of 3 or lower are common, and here the loss to workers is significant, as is the overall economic waste. Within particular markets, where workers are vulnerable because of their lack of skills, or because of specific constraints they face on mobility (as is often the case with women), or because of other factors, addressing labor market power is extremely urgent.  \n\nWe also include Table 1 below, which ties the research we have cited more directly to our findings.  \n\n<html><body><table><tr><td>β</td><td>Implied markdown</td><td>Source</td><td>DWL</td><td>Labor share</td><td>Profit share</td><td>Fiscal Loss</td></tr><tr><td>0.1</td><td>10</td><td>Staiger et al. (2010)</td><td>60.5%</td><td>8%</td><td>59%</td><td>95.6%</td></tr><tr><td>0.12</td><td>8.3</td><td>Dube et al. (2017a)</td><td>58.3%</td><td>10%</td><td>58%</td><td>94.5%</td></tr><tr><td>0.95</td><td>1.05</td><td>Azar et al. (2017)</td><td>28.0%</td><td>40%</td><td>30%</td><td>60.7%</td></tr><tr><td>2</td><td>0.5</td><td></td><td>17.6%</td><td>53%</td><td>19%</td><td>41.0%</td></tr><tr><td>2.7</td><td>0.37</td><td>Kline et al. (2017)</td><td>14.1%</td><td>57%</td><td>15%</td><td>33.6%</td></tr><tr><td>3</td><td>0.33</td><td>Dube et al. (2017b) Ransom and Sims (2010)</td><td>13.0%</td><td>58%</td><td>14%</td><td>31.2%</td></tr><tr><td>3.7</td><td>0.27</td><td></td><td>11.0%</td><td>61%</td><td>12%</td><td>26.7%</td></tr><tr><td>5.5</td><td>0.18</td><td>Isen (2013)</td><td>7.9%</td><td>65%</td><td>8%</td><td>19.5%</td></tr><tr><td>10</td><td>0.1</td><td></td><td>4.6%</td><td>68%</td><td>5%</td><td>11.7%</td></tr><tr><td>100</td><td>0.01</td><td></td><td>0.5%</td><td>73%</td><td>1%</td><td>1.3%</td></tr></table></body></html>\n\nTable 1: Cobb Douglas estimates under a $\\tau=30\\%$ , competitive capital share $\\alpha=.33$ , aggregate market labor supply elasticity $\\eta=.3$ , and labor tax with effciency multiplier of $m=1.3$  \n\nThe studies suggest residual labor market elasticities ranging from 0.1 to 5.5. These correspond to deadweight loss ranging from $60.5\\%$ down to $7.9\\%$ , and a labor share ranging from $8\\%$ to $65\\%$ Thus, even if one takes a conservative approach and believes the studies with weaker findings, it remains clear that monopsony causes considerable harm both to the economy and to workers. We offer by comparison hypothetical residual labor market elasticities of 10 and 100. By the time one reaches 10o, the harm to the economy is only $0.5\\%$ , and arguably no longer a matter for public concern. The “implied markdown” column shows the effect on wages. If a worker with a marginal revenue product of $\\$50,000$ is employed by a firm facing elasticity of 100, she will be paid $\\$49,504.95$ . If the elasticity is 3, she will be paid $\\$37,500$ . If the elasticity is 0.1, then she will be paid $\\$4,545.45$ (at least in theory).  \n\n## B. Antitrust Law and Labor Markets  \n\n### 1. Antitrust Litigation Relating to Labor Markets  \n\nThe antitrust laws broadly prohibit firms from creating monopolies and cartels, and taking other actions that reduce the competitiveness of markets. Section 1 of the Sherman Act prohibits contracts “in restraint of trade \\*86 Section 2 of the same law prohibits attempts to “monopolize .. any part of the trade or commerce among the several States.?\\*87 The Clayton Act prohibits various practices associated with market concentration, including price discrimination?8 and—of special interest to us—mergers and asset acquisitions where “the effect of such [merger or] acquisition may be substantially to lessen competition, or tend to create a monopoly.89 The unusually broad language of the antitrust laws have been given specific meaning by the courts over many decades of judicial development.  \n\nThe vast majority of cases have involved efforts to block sellers from cartelizing or monopolizing product markets. However, the law and the cases are not limited to anticompetitive behavior by sellers. The courts have recognized that buyers can engage in anticompetitive behavior. When all the sellers in a market sell to a single buyer, the buyer is said to have a monopsony. When only a few buyers exist, an oligopsony exists, and the buyers violate the antitrust laws if they conspire to suppress prices by agreeing not to compete for products sold by sellers in the market. Because the statutes do not distinguish sell-side and buy-side anticompetitive behavior, and buy-side anticompetitive behavior produces the same type of harm as sell-side anticompetitive behavior, the Supreme Court and other courts have not hesitated to recognize that the antitrust laws apply to both types of behavior.90  \n\nMost monopsony cases involve allegations that buyers have tried to monopsonize or cartelize markets for goods and services. Consider, for example, a big retailer like Walmart, which may possess the buy-side market power to suppress the prices that it pays to wholesalers. A handful of such cases involve buyers who have tried to monopsonize or cartelize the labor market. Again, nothing in the antitrust laws distinguish labor markets from other types of market, and the courts have agreed that anticompetitive behavior in labor markets violates the antitrust law. The partial exception is section 6 of the Clayton Act, which provides that workers do not violate antitrust laws when they organize unions--a form of labor cartel, at least in the economic sense.91 Indeed, prior to the Clayton Act, the most frequent use of antitrust in labor markets was to enjoin labor unions as anti-competitive. But no court has held that section 6 immunizes an employer from antitrust liability if that employer attempts to suppress competition in the labor markets.  \n\nHowever, antitrust litigation based on anticompetitive behavior by employers in labor markets has historically been quite rare, and mostly involved narrow and idiosyncratic settings like sports leagues. 92 In a handful of cases, employees have challenged cartel-like arrangements under section 1 of the Sherman Act, arguing that employers have fixed wages or taken other actions to suppress competition among themselves for labor. The most prominent cases have involved hospitals, which have been accused of coordinating pay scales for doctors and nurses. 93  \n\nMoreover, as far as we have been able to discover, antitrust challenges relating to labor markets have never gone beyond the most overt type of cartelization among rival employers. The Horizontal Merger Guidelines focus almost entirely on the risk of product market concentration, and says nothing about the risks of labor market concentration.94 As far as we know, the DOJ and FTC have never challenged a merger because of its possible anticompetitive effects on labor markets, or even rigorously analyzed the labor market effects of mergers as they do for product market effects. Nor have we found a reported case in which a court found that a merger resulted in illegal labor market concentration.95  \n\nThe infrequency and rather unusual nature of antitrust litigation involving labor markets for a long time seemed to verify economists’ assumption that labor markets are normally competitive. But the erosion of this assumption in recent years—driven, as noted above, by the consolidation of employers, the non-compete scandal, and empirical evidence of wage stagnation and labor market concentration—-has been accompanied by significantly greater legal and regulatory activity.  \n\nIn 2010, the Justice Department entered a settlement with major high-tech firms— including Apple, Google, and Amazon—-which had entered into no-poaching agreements, which are agreements not to hire away each other's employees.9% The DOJ and FTC also issued a guidance document informing firms that it is illegal to enter into such agreements.97 The scandal over non-competes led the White House and Department of Treasury to issue reports criticizing the use of non-compete agreements, while many state legislatures have considered bills and passed laws restricting non-compete agreements involving low-wage workers.98 The White House report also noted substantial evidence of labor market concentration, warranting stricter enforcement of antitrust laws against employers. Litigation has also been commenced against McDonald's and other firms that use no-poaching agreements within franchises.99 The Justice Department has revealed that it has begun criminal investigations against employers suspected of entering nopoaching agreements.1o  \n\nA key worry in this flurry of activity is that anticompetitive practices targeted the most vulnerable workers, those with limited education and low skills. Moreover, the tech industry notwithstanding, there remains relatively little evidence of explicit cartelization that can be easily targeted by the antitrust laws. This means that the anticompetitive behavior has taken the form either of employer consolidation through mergers, or hard-to-detect parallel behavior, in which firms play follow the leader without making any explicit agreements. In both cases, the problem boils down to excessive merger activity, which has led to concentrated labor markets. This is hardly surprising given that there is no enforcement against mergers for their effects on employment: why would employers take the risk of colluding when they could just merge?  \n\n2. Class Action Requirements and Related Barriers to Challenges of Anticompetitive Labor MarketPractices  \n\nAntitrust cases are notoriously complex and expensive. A typical antitrust violation raises prices (or lower wages) a relatively small amount over a vast number of people. This means that individuals rarely have an incentive to sue even while the social cost of anticompetitive behavior may be high. For product market antitrust violations, lawsuits occur in three ways. First, victims may often be large firms, such as downstream buyers, whose losses are large enough to justify the expense of litigation. Second, when victims are consumers, lawyers can sometimes aggregate them into a class and bring a class action on their behalf. Third, the DOJ and FTC bring lawsuits in the most serious cases. While the remedy of treble damages helps encourage lawsuits in the first two scenarios, an array of other doctrines relating to standing, enforcement, and related matters,101 deprive certain victims of the power to bring suit.  \n\nThese problems are even more significant for labor market cases. The DOJ and the FTC paid little attention to labor market concentration until a couple years ago. There is no such thing as a worker who can afford to bring an antitrust case on her own. And class actions are harder to bring in labor market cases than in product market cases.  \n\nOne case, Weisfeld v. Sun Chem. Corp., illustrates the difficulties faced by class action lawyers.102 The plaintiff class argued that a group of companies that manufacture printing inks entered into a “no hire” agreement, in which each company agreed not to hire the workers of its competitors in violation of section 1 of the Sherman Act. The proposed class consisted of \"personnel who provide technical services and who possess specialized knowledge and skills in the manufacture, distribution and sale of printing inks.103 The plaintiff argued that a class action was justified because economists could calculate how much wages were suppressed as a result of the illegal agreement.  \n\nThe court rejected this argument because common issues did not “predominate,”’ as required by federal class action rules. There was extensive variation among employees, including their propensity to seek out new jobs if they were unhappy with their wages; the extent of their skills and responsibilities, which result in different salary levels; the transferability of an employee's skill to other industries; the existence of a non-compete agreement; and so on.104 Because the employer's market power thus differed from employee to employee, the extent of the injury for each employee was different, nor could it be determined by a simple algorithm with a limited number of observable inputs.  \n\nThese sorts of variations are ubiquitous in labor markets: workers, even in the most rigidly controlled workplaces, are not as fungible as goods are. It is thus not hard to understand why labor market litigation is so rare.105 In recent years, worker class actions have enjoyed more success, but again in nearly all cases the workers are professionals or specialists rather than the most vulnerable workers. 106 This means that firms have a far freer hand to exploit (and obtain) market power over labor than market power over products, and goes a long way to explaining why labor market concentration has become such a significant problem.  \n\n## I1. Merger Analysis of Labor Market Harms  \n\nIn this section, we develop a variety of metrics and analytic tools that can be used to evaluate the effects of mergers on product markets. We begin by extending two techniques used to screen mergers in product markets at early stages to labor markets, then turn to additional factors and techniques employed at later stages, where we also consider possible merger defenses. We conclude this section with a brief case study that applies these techniques to an example from the labor market for nurses.  \n\n### A. Market Definition and Concentration  \n\nThe Market Definition and Concentration (MDC) approach involves three steps, which we lay out below. For expository ease, we rely on a simple example. Imagine that a small town has four large firms that manufacture widgets for the national market. The firms employ two types of workers: specialists, who are experienced and skilled in the manufacture of widgets; and generalists, who provide services that are also in demand by other types of employers. Custodial services would be an example of generalist work. If a firm fires a custodian, she may find work at any other firm with floors that need to cleaned, while a specialist who is fired would be able to find work only at another widget manufacturer. The four firms are identical in size: they both produce the same number of widgets and employ the same number of workers. Two of the firms propose to merge, and we must evaluate the possible effect of the merger on the labor market.  \n\nMarket Definition. To determine market definition, we can use, by analogy to the \"hypothetical monopolist test,\\*107 a hypothetical monopsonist test. Under this test,the analyst asks whether a single monopsonist—in this case, a single hypothetical firm that employs all specialists who live in this town (rather than the actual four firms, acting independently)—could reduce wages by a “small but significant and non-transitory\" amount, what we call the small but significant and non-transitory decrease in wages (SSNDW) test. The intuition here is that a labor market comprises firms that compete by offering a particular type of job to attract workers with a particular skill set. If only a single firm offers that job or desires that sort of worker, and lowers the wage from the competitive amount, many of the workers would accept the lower wage because the alternative would be to undergo retraining or accept a job at another firm that does not exploit the worker's education, skills, or experience. In our example, workers who specialize in manufacturing widgets would likely accept a lower wage because the alternative is either to move to another area (which is expensive and involves loss of local attachments) or to accept a worse job. Thus, the specialists form a labor market. By contrast, the generalists—say, custodians—-may be able to find jobs at other employers, including schools, office buildings, and so on, in which case the relevant labor market is quite broad.  \n\nIn some cases, the market may be narrower than this. As we noted above, labor markets are matching markets so not only the needs of firms, but also the preferences of workers, help determine the bounds of the market. Suppose that the other two firms (those not merging) both have a production process that is easy to keep within normal, 9-5 business hours, while the merging firms, while requiring the same specialist expertise, have a process that must be kept going all hours of the night. The merging firms thus require specialists willing to work the night shift and only a relatively small set of workers may be willing to do this.1o8 Given that many workers are not willing to do this, “specialist work, in this area, on the night shift\"’ may constitute a relevant market.  \n\nAnother key factor in defining labor markets is geographic and is determined by how far and by what means of transit workers are willing to commute to a job. Imagine that a fifth firm that employs widget specialists is located in a nearby town. If specialists in the first town are willing to commute to this nearby town, then the number of firms that draw from the specialist labor market is actually five rather than four, and (as we will see) market concentration is lower. Complicated questions arise as to how far workers are willing to commute and under what conditions. For example, younger workers may be willing to commute farther or even move from one location to another, while older married workers or those with children may be less mobile. However, as in the case of product market analysis, rules of thumbs can be used to define the relative geographic area and be further refined in more-detailed analysis.109  \n\nWhat counts as a SSNDW and how is it determined? In analysis of product markets, a rule of thumb is $5\\%$ for one year. A similar threshold could be used for labor market analysis as well. In our example, if a hypothetical widget specialist labor monopsonist could reduce wages from (say) $\\$80,000$ per year to $\\$76,000$ per year for the specialists, then the specialist widget workers would compose a labor market. Profit-maximizing employers will find it in their interest to institute such a wage reduction if the elasticity of labor supply in the relevant market is twenty or less assuming the market was previously competitive, or under other conditions that can easily be defined empirically if there was pre-existing labor market power.110o  \n\nEconometric studies can be used to measure whether the market definition is appropriate, as is often done in product markets. For example, shocks to firm production processes or firmspecific input prices may move around the marginal revenue product of workers, leading to changes in their wages. The induced movement of workers provides a measurement of residual labor supply elasticities. Another loose but creative way to measure market definition is proposed by Azar et al., who use the patterns of job searches on an online job matching platform to define which careers job seekers view as substitutes for one another.111  \n\nMarket Concentration. Market concentration refers to the number of firms in a relevant market. Market concentration increases as the number of firms decline, indicating that the remaining firms have greater market power. In product markets, the HHI is used to measure market concentration. HHI equals the sum of the squares of the percent market shares of the firms that sell into a market. HHI can also be used to represent labor market concentration. In labor markets, HHI equals the sum of the squares of the share of the labor market. The highest possible HHI is 10,000, which occurs when a market has a single monopolist $(100^{2}=10,000)$ . As the number of firms increase indefinitely, HHI approaches (but never quite reaches) zero.  \n\nIn our example, we stipulated that the four employers sell widgets into a national market. If each firm has a, say, $1\\%$ market share, and 96 other firms also have a $1\\%$ market share, then the HHI is 100 $(1^{2}+1^{2}+...)$ . We also stipulate that the four employers equally divided the market of widget specialists. This means that the HHI for widget specialists is 2500 $(4^{*}25^{2})$ . The HHI for generalists will be lower. If, say, 1,0oo firms in the town hire custodians and all have a small fraction of the custodian labor market, the HHI for custodians is close to 10.  \n\nThe Horizontal Merger Guidelines classify markets as unconcentrated (HHI less than 1,500); moderately concentrated (HHI between 1,500 and 2,500); and highly concentrated (HHI above 2,500).112 These classifications serve as triggers: the government will (generally speaking) allow mergers in unconcentrated product markets and scrutinize those in highly concentrated markets, while taking a moderate approach to those in the middle. Because of the symmetrical nature of labor and product markets, we believe that the government (and the law generally) should take the same approach when analyzing the effects of mergers on labor markets.  \n\nEffect on Market Concentration. The risk posed by a merger is that it increases market concentration, which can cause harm in two different ways. In product markets, a firm that gains market power through concentration can raise prices by reducing output (\"unilateral effects\").113 And as the number of firms decline, the remaining firms can more easily engage in either explicit or implicit collusion such as parallel pricing, which also result in higher prices and reduced output (\"coordinated effects\").14 Mergers pose the same risks to labor markets. A firm that gains power in the labor market may be able to reduce wages and employment; when the number of employers decline, they can more easily engage in implicit or explicit collusion with the same effects.  \n\nThe Merger Guidelines hence treat increases in market concentration as a parallel trigger for scrutiny. If the post-merger product market remains unconcentrated, or the merger increases the HHI by fewer than 100 points, the government generally allows the merger. If the merger results in a moderately concentrated market and an increase of the HHI by more than 1o0 points, then the government will scrutinize the merger. If the merger results in a highly concentrated market along with an HHI increase of 100-200 points, the merger will also receive scrutiny; and if the HHI increase exceeds 200 points, the merger is subject to a rebuttable presumption that it is illegal, as we discusbelow.li5  \n\nAgain, because of the symmetry of product market and labor market concentration, we believe that the government should use the same standard to evaluate the effects of mergers on labor markets. In our example, a merger of the two firms would increase HHI for widget specialists from 2,500 to 3,750 $(50^{2}+25^{2}+25^{2})$ , a substantial increase that would create a rebuttable presumption that the merger excessively concentrates the market, generating significant anticompetitive effects in violation of the antitrust laws. The HHI increase for generalists is trivial, as it is on the product market side.  \n\nComments. We have shown that the MDC approach to merger analysis can be used to analyze the labor market effects of mergers just as it is used to analyze the product market effects of mergers. We find it mysterious that this analysis has never been performed—-as far we know—- by the government or in private litigation. One argument we have heard is that labor markets are more difficult to define than product markets are. Commuting distances are not always easy to calculate: workers are willing to commute farther for some types of jobs than others.l16 And job differences are not always clear. However, we are skeptical that these problems are any more severe than in the case of product markets, where products often differ from each other in incremental and complex ways, so that the distinctions between products are not always clear. Furthermore, geographic scope is often just as complex in product markets, where the willingness of consumers to travel to purchase is at least as slippery. Meanwhile, modern job clearinghouses like CareerBuilder and LinkedIn are accumulating data on the boundaries of labor markets; their data can be used by antitrust authorities.117  \n\nA more significant argument is that the MDC approach does not make sense even for product markets, and therefore should not be used for labor markets as well.l18 Some readers might wonder where the various HHI thresholds come from, and the answer is that they are, to some extent, arbitrary. The MDC approach can be derived from standard economic models of oligopoly, which show that firms gain less by raising prices over marginal cost as their market share declines. But the derivation depends on strong assumptions that may not be sufficiently realistic to justify heavy reliance on MDC. Our purpose here is not to defend the MDC approach, but to argue that if the MDC approach is accepted for product markets (as it is by the government and courts), then it should be used for labor markets as well. Otherwise, firms that are thwarted in their efforts to raise prices by merging with product market rivals will naturally be led to merge with labor market rivals to lower the cost of labor. But for skeptics of the MDC approach, we offer the alternative DWP approach, which we discuss in the next section.  \n\n### B. Downward Wage Pressure  \n\nIn recent years, the MDC approach in product markets has increasingly been supplanted by the use of “Upward Pricing Pressure (UPP)\" indices. These indices are more closely tied to credible economic models of unilateral effects than the MDC approach is. Because it was invented recently,119 it has not played as important a role in litigation as MDC has, but it does receive a brief mention, and the government's imprimatur, in the Merger Guidelines.120 Like MDC, UPP has been used only to analyze the product market effects of mergers. Here, we develop an analogous idea that we call Downward Wage Pressure (DWP) for labor market harms, using our example from above. Like UPP, DWP is the product of two terms, which we now discuss in turn. These two terms correspond roughly to market concentration and the increase in concentration caused by the merger, as they measure the degree of pre-existing market power and the increased market power created by the merger.  \n\nMarkdown. To measure pre-existing market power, rather than define a market and measure its concentration, UPP more directly measures the extent to which firms, prior to the merger, can hold wages below their competitive level. This is measured by the “markup,”’ the percent by which the price the firms charge exceeds the marginal cost that they would charge under competition.  \n\nIn labor markets, we instead consider the markdown. The markdown is a direct measure of power the firm has over the market and, as we noted above, is the inverse of the elasticity of the labor supply facing that employer for a profit-maximizing employer. 121 The markdown is the percent by which the wage falls below the worker's marginal revenue product, the amount of additional revenue that employing that worker generates. To be precise, the markdown equals 100 times the ratio of the gap between the marginal revenue product and the wage. The markdown for each merging firm may be different. And markdowns can be measured either by using accounting data from firms or, as in the case of market definition, through econometric studies that measure the elasticity of residual labor supply.  \n\nDiversion Ratio. To measure the degree to which a merger will tend to increase market power, the DWP approach uses the concept of a “diversion ratio\" rather than the increase in concentration caused by a merger. To understand what this is, note that firms may merge either to combine operations to reduce costs or in order to internalize the externalities each firm's competition has on the other. Consider, for example, the calculations that would go into a merger of GM and Ford. Before the merger, GM earns a profit on each car equal to revenue minus marginal costs. When it decides whether to sell an additional car by lowering its price, it makes a tradeoff: it sells more cars (while Ford sells fewer cars), but it earns less profit (or “markup'\") per car as its price falls. The optimal price perfectly balances these two forces, which is why the elasticity (the ratio of additional cars sold to the price fall) determines the optimal mark-up to set.  \n\nNow imagine that the two automakers merge. To understand the effect of the merger on the firm's pricing decision, one can usefully imagine that GM and Ford continue as divisions of the merged entity. The CEO of the merged entity directs the division head of GM and the division head of Ford to maximize profits for the merged entity, not for the individual divisions. The GM head will think as follows. When GM lowers its price to sell a car, the merged entity not only forgoes the higher markups per GM car that comes with a higher price. The merged entity also loses the markups on Ford cars that are not sold because of the additional sales of GM cars at the lower price. The opportunity cost of the lost sale of a Ford car enters GM's calculations, resulting in a weaker incentive for the GM division head to lower prices (or a stronger incentive to increase prices). The same is true for the Ford division head.  \n\nThese effects can be represented as diversion ratios. The GM-to-Ford diversion ratio is the fraction of additional Ford sales that are diverted from GM (rather than from another car company or that are new sales that would not otherwise have been made) when Ford lowers its prices. A diversion ratio is calculated from Ford to GM as well.  \n\nIn the case of labor market effects, we engage in an analogous analysis. When two of our widget producers seek to merge, the analyst calculates diversion ratios with respect to their workers. In the case of specialists, the diversion ratio for each merging firm is the fraction of specialists who would quit and join the other merging firm (rather than joining a non-merging firm or dropping out of the labor market) if the first firm lowers wages. The diversion ratio will obviously be higher for the specialists than for the generalist. If a specialist quits Firm 1, then she can find work only at one of the three other firms, and so, even if she acts randomly, there is a 1/3 chance that she would end up at the other merging firm. In contrast, if a generalist quits Firm 1, she can find work at any of the dozens of other firms in the town that hire generalists.  \n\nThe diversion ratio measures the extent to which a merger increases market power more directly than HHI does. The problem with the HHI method is that different employers within a market may be different quality substitutes for each other in a way that HHI obscures.  \n\nTake our example of the night shift. Should we define the market for specialist workers working the night shift to include only the two merging firms, on the assumption that those currently not working night shifts would be unwilling to do it? Or should we define the market more broadly, to include all firms hiring specialists? Obviously neither definition is ideal. The diversion ratio allows us to express this “in between\" case through the fraction of specialists who would take a nightshift job if a higher wage is offered. If $100\\%$ of the nightshift specialists are employed at the other merging firm, the diversion ratio is $100\\%$ . If these workers are evenly divided among all the firms that hire specialists, the diversion ratio will be only $33\\%$ .Normally, the diversion ratio will fall somewhere in between: nightshift workers will be more likely to take these additional jobs, but they will not be the only ones to take the job, and they will not come equally from all other employers. We might imagine that $50\\%$ of the specialists will come from the other nightshift job at the other merging employer, so the diversion ratio will be around twothirds.  \n\nAnother advantage of diversion ratios is that they are easier to estimate than market definitions are. One natural proxy for diversion ratios is turnover. Surveys and other methods can determine the fraction of workers at Firm 1 who move to Firm 2 rather than to other firms or out of the labor market. If Firm 1 and $\\mathrm{Firm}2$ then merge, this ratio provides a starting point for estimating the diversion ratio. Another source of information that can be used to estimate the diversion ratio is job hunting data. This data source reveals information about where workers interview; if many of Firm 1's hires also interviewed at Firm 2, this suggests that the two firms compete for workers, and hence that a merger between them will reduce labor market competition.  \n\nEffects. The DWP index for Employer A is the markdown of Employer $B$ multiplied by the diversion ratio from Employer B to Employer A. To understand why, consider the difference between what happens to Employer A's finances if it lowers wages pre-merger and if it lowers wages post-merger. To hire an additional worker pre-merger, Employer A must raise its wage. The worker it hires will, with a chance equal to the diversion ratio, be taken from Employer B, but Employer A really does not care where the worker comes from.  \n\nAfter the merger, this changes dramatically. Employer A now cares about the profits earned by Employer B. If the worker is diverted from Employer B, Employer A now effectively suffers a loss equal to the markdown Employer B was earning off that employee. This loss occurs with a probability equal to the diversion ratio from Employer B to Employer A, and thus the product of the B-to-A diversion ratio with B's markdown constitutes the additional cost of an additional employee A faces after the merger that it did not face before the merger.  \n\nThe DWP does not directly tell us how much worker's wages will fall. Instead, it tells us the tax on wages to which the merger is equivalent. The merger taxes wages because it makes hiring the worker effectively more expensive for the employers. How much of this tax is passed through to workers as a decreased wage and how much will be absorbed by the employer and/or passed through to consumers as higher prices depends on market conditions usually summarized as the \\*pass-through rate. 122 In some cases worker wages may fall by even more than the amount of this tax. Thus, while DWP comes much closer than the MDC to measuring the effects of mergers on wages, it does not go all the way, much less determine the losses to worker or social welfare caused by the merger.  \n\nUPP numbers are usually compared to some small standard threshold, like $1-2\\%$ ,to determine whether cases are worth reviewing. A $1-2\\%$ tax on wages is a material weight on the decision of firms. Of course, any positive DWP is a cause for concern, but authorities have typically assumed in product markets that there are usually some efficiency gains from mergers, perhaps on the order of $1-2\\%$ , that are likely to offset at least some harms from reduced competition. Analogously it seems reasonable as a starting point to “flag” for serious consideration mergers where DWP for both firms exceeds $2\\%$ and to give less scrutiny to mergers where both arebelow $1\\%$ . Intermediate cases must be carefully considered.  \n\nComments. The DWP, like the MDC, should be understood as a “rule,”' that is, a (relatively) simple proxy that provides guidance to regulated parties but only an approximation of the underlying social value of a proposed merger. We do not take a position in this paper whether the MDC or the DWP is a better rule, or in fact whether either of them is an optimal rule; they might well work better in different market settings. The MDC is better-established and draws on long experience of the agencies and courts. The DwP seems more theoretically sound, and recent work has continued to refine it as well as provide reason to believe that it may work better than the MDC.  \n\nA virtue of both approaches is that they are flexible and can be easily modified if further evidence suggests that they are too strict or to not strict enough. In the case of the MDC, one can raise or lower the HHI thresholds, to make merger challenges harder or easier. In the case of the DWP, one can adjust the assumed efficiency level of a merger.  \n\nA last point concerns the complexity of many mergers, which can have different effects in different markets. A merger can reduce competition in both product markets and labor markets, and it can reduce competition in some geographic (product) markets and not others, and the same with labor markets. Consider, for example, the merger of two nationwide hospital chains. The merger might reduce the number of rival hospitals in big city X from 15 to 14 and the number of rival hospitals in small town Y from 3 to 2. Obviously, the product market and labor market effects will be greater in the small town than in the big city. But even within the small town, the product market and labor market effects are likely to be different. If there is no other place to obtain medical care, the product market effects will be significant. However, if the small town happens to have a large retirement community with assisted-living facilities, where nurses are frequently employed, then it is possible that the labor market effects of the merger—with respect to the market in nurses-is less severe. Most employers offer multiple jobs, just as most producers offer many products, and the rich interactions between the many products or jobs of one merging firm with the many products or jobs of the other must be considered. When evaluating mergers, all these complex product and labor market effects must be considered, and remedies (as in the case of traditional merger analysis) might involve spinning off some of the underlying entities in some of the markets.  \n\n### C. Merger Simulation  \n\nWhile MDC and DWP are the dominant tools for early-stage screening in merger analysis and have played a large role even in later stages, economic modeling of industries and simulation of merger effects have become increasingly common in recent years. While MDC and DWP identify triggers that justify further scrutiny of a merger, or may in themselves strongly indicate that a proposed merger is socially harmful, a model is used to make fine-grained predictions of all effects of a merger. The model assumes that firms maximize profits; rely on a presumed production technology; and react, in game-theoretic terms, to the behavior of other firms. The parameters of the model are estimated using industry data and techniques that are increasingly standard in the industrial organization literature.123  \n\nIn recent years, economists have extended the traditional models so as to account for a greater variety of phenomena. These phenomena include dynamic effects such as the possibility that a merger will encourage entry or discourage innovation; vertical effects such as the possibility that a merger may reduce the so-called “double marginalization problem\" or conversely may increase the incentives of a firm to raise the cost of its rivals; and the effect of mergers on bargaining between firms in business-to-business industries.124 Much of the field of industrial organization (IO) in economics (especially the branch known as “structural IO\") is a factory for producing these new methodologies which are then quite rapidly or even concurently employed in merger reviews. 125  \n\nAn analogous set of tools has developed in structural labor economics, to some extent influenced by the developments in IO. While structural modeling is common in models of dynamic monopsony,126 these models tend to assume a large number of firms and are thus unsuited to merger analysis.  \n\nBut there is no technical reason why the models developed for analysis product markets cannot be applied to the labor market. The monopsony model proposed by David Card and coauthors 127 adapts a workhorse model of demand estimation to the labor market. Dynamic discrete choice models of schooling and work have been developed by Michael Keane and Kenneth Wolpin.128 More sophisticated variants, including nested labor market supplies (e.g. first choose an occupation, then a location, then a firm) as well as allowing heterogeneous tastes for particular workplaces could be incorporated relatively easily.  \n\nLabor demand modeling, recovering marginal products of workers, is also likely no more or less challenging than modeling costs of firms in the product market. Predictions about merger effects on wages could then be obtained by estimating a labor supply system to firms, recovering the implied observed and predicted markdowns, and applying predicted markdowns to predicted marginal labor productivity.  \n\nOn the other hand, models of employer behavior in labor markets are generally more primitive than of producer behavior in industrial organization. Bringing state-of-the-art merger analysis to labor markets would require pairing the sophisticated analyses of labor supply and worker behavior with models analogous to those applied in industrial organization to firm behavior. While we have not explicitly developed such models ourselves and are not aware of work on them at present, in principle we see no fundamental challenges impeding such analysis beyond those that have been overcome in IO. Many of the same tools, in terms of production function estimation, estimation of games such as differentiated products price competition and so forth could be directly imported. Some of the more sophisticated dynamic elements might differ between product and labor markets because of the long-term nature of employment relationships, but again the well-developed analysis of worker behavior from structural labor economics could likelybe used.129  \n\n### D. Other Factors in Merger Analysis  \n\nIn the previous section, we mentioned that later-stage merger analysis of product markets uses sophisticated formal economic models and discussed how later stage analysis of mergers for labor markets might do the same. But in both cases, formal economic models cannot answer all questions; they must be supplemented by informal analysis of factors that the models exclude. These factors include efficiency gains of mergers, extensive margins of competition (entry into the market), and external influences on firm conduct. Such informal analysis is already common for product market effects of mergers. Informal analysis is even more important for labor markets than for product markets because, as we noted above, formal models of many important features of labor markets for merger analysis have not yet been developed. Here, we apply some of these factors to labor market analysis, pointing out where modification may be required.  \n\n#### 1. Efficiencies  \n\nThe most important factors considered at this stage of merger analysis are “efficiencies\" that may make the merger beneficial despite its anticompetitive effects. Such efficiencies fall into three major categories: productive efficiencies associated with economies of scale or network effects; contracting efficiencies and other ways in which the merger may reduce market power or facilitate commerce; and what might be called “viability efficiencies,”’ referring to the possibility that one merging party might exit the market or become unviable as a competitor in the absence of the merger, in which case the merger merely hastens that party's exit from the scene.130 While these efficiencies are sometimes quantifiable, they are typically addressed in qualitative fashion.  \n\nJust as product cost may fall with an efficiency-enhancing merger, labor productivity could increase. For example, a single large factory might be able to produce airplanes more efficiently than two small factories because the large factory can subdivide the assembly line so as to achieve greater gains from labor specialization. The increase in labor market productivity may cause labor demand to increase or decrease, depending on the structure of the product market.  \n\nUnder the Merger Guidelines, the merging firms are permitted to argue that the efficiencies justify a merger that otherwise would be deemed anticompetitive.131 However, this type of defense is subject to two important limits. First, the “consumer welfare\" standard implies that the efficiency gain must be large enough that on net consumer welfare increases despite an increase in market power. 132 In contrast, if consumers lose on net, the efficiency does not count in favor of the merger even if the firms’ profits are greater than the consumers’ loss. Thus, for example, mergers that only reduce each firm's fixed costs but do not reduce the marginal cost of production, and hence lower prices, would be banned. 133  \n\nSecond, the relevant efficiencies must be merger-specific in the sense that they are possible, or possible at reasonable cost, only through the merger. 134 For example, if there are two wireless carriers who could and naturally would (but for the prospect of a merger) interconnect their networks so that subscribers to both carriers could benefit from the network of the other, these carriers could not use the prospects of broader shared networks as a merger defense. If the carriers can connect their networks at reasonable cost through contract, then cannot claim that a merger is necessary.  \n\nMost of the principles naturally carry over, in suitably modified form, to the analysis of merger effects on labor markets, though a few subtle issues arise. Many of the same factors that could act as efficiencies on the product side are also efficiencies on the labor side. By analogy to the “consumer welfare” standard, we believe that mergers that trigger scrutiny by reducing labor market competition should be subject to a “worker welfare”' standard.135 The fact that the merger might raise firm profits more than it harms workers should not be sufficient to excuse the merger. Instead, the merger would be permitted if the merger sufficiently increases worker productivity (workers’ marginal revenue product) in a way that will not fully be absorbed by lower prices or increased employer profits. Thus, harms from reduced competition are more than fully offset and therefore workers’ wages, benefits, or conditions will improve because of the merger.  \n\nThis is not to say that mergers that harm workers should never be approved. The losses to workers could be offset by gains elsewhere in the economy. Indeed, the merger of two firms that operate in a frictionless labor market should not greatly harm workers even if it does result in significant layoffs, because in a competitive labor market the laid-off workers can easily find equally good jobs. In contrast, a merger that does create competitive concern should not be excused simply on the basis that it allows the firm to cut costs by destroying jobs. In such cases, antitrust doctrine does not allow efficiency gains in other markets to offset losses in one market. 136 Thus, typically, the worker surplus implications of a merger will indicate its competitive effects, just as in product markets consumer surplus is a strong but not perfect proxy for competitive effects.  \n\nIn some cases a merger may prove overall competitively harmful in labor markets (viz. harm worker welfare) and beneficial in product markets (viz. benefit consumer welfare). Such cases should be treated roughly like ones where competitive harm occurs in one product market but there are competitive benefits in another product market. To the extent possible, antitrust authorities should try to find remedies that address the competitive harms while preserving the benefits, such as requiring the spinning off of critical units that would allow an increase in market power. However, the frequency of such cases should not be exaggerated; mergers that increase labor market power and thus raise effective costs will not typically or usually bring lower prices to consumers, and mergers increasing product market power and thus reducing sales will not typically create great jobs. Similar analysis applies to the merger-specificity of the efficiency gains: productivity gains that could be achieved absent the anticompetitive effects of the merger should not play a role in merger analysis.  \n\nThe second broad category of efficiencies typically considered in mergers relate to the socalled “double marginalization problem’ and other complementarities in the production or consumption of the products of the merging firms. Firms that supply complementary products to a consumer or that supply intermediate inputs to each other may, absent a merger, each demand a mark-up on their own product, leading _to the stacking of mark-ups in a manner that reduces both firm profits and consumer welfare.137 A recent example is the providers of premium cable channels, often regional sports networks, which have sometimes merged with cable companies. Recent research has found that such mergers generally lead to lower marginal channel prices for consumers purchasing from the merging cable company because the internalization of the channel provider's profits by the cable company induces lower prices (though such mergers may also have anticompetitive foreclosure effects).138  \n\nSuch mergers are said to have a “vertical component’ as well as the “horizontal component\" that causes antitrust concern. For example, a household paper goods firm mostly complements a grocery store that sells a high volume of its products but may also compete with a house brand of the grocery store. A merger may thus both have vertical benefits and horizontal harms that must be balanced to determine the net competitive effect. Matters are similar in labor markets. Jobs may be complementary to each other directly because workers are complementary. For example, the researchers at a company that mostly invents new products may be more productive if they merge with another company that is focused on commercialization of new products. The two groups of workers may be able to interact with each other and cooperate more closely if they work for the same firm than if they work for different firms, even if those firms cooperate via contract.  \n\nThere may also be less direct complementarities. For example, engineers with an expertise in materials may not directly collaborate with electrical engineers but having them around the office may help spark creativity during lunchtime conversations and thus a merger of two engineering firms may increase the productivity and thus wages of both types of workers. A merger of these two companies may be highly pro-competitive even if the two engineering teams from different firms could go out to local restaurant together in any case, because the merged firm internalizes the extra productivity each group of workers brings to the other. The enhanced productivity will result in higher wages for both engineering teams. Such vertical benefits of a merger between employers must be weighed against the fact that, for example, they may compete in the market for engineers without a clear specialization in that location.  \n\nThe final, viability efficiency consideration that arises in many mergers is the possibility that, but for the merger, one of the merger partners would go out of business or otherwise would become an ineffectual competitor in the market. This issues often arises for firms that are either near bankruptcy or that are losing money in some critical markets. To the extent that it can be clearly demonstrated that absent the merger the firm would exit and that the competitive harm of the merger is less than that of exit by the failing firm (or that the merger could strengthen the competitive position of the non-failing merger partner), the merger will typically be allowed to proceed. In labor markets similar arguments may be relevant: that an employer would otherwise \"ship the factory to China” may be used to defend a merger. However, as in product markets, it will usually be necessary to demonstrate that there was no other feasible route to stabilize the profitability of the business, such as selling it to an alternative purchaser who is not a direct competitor.  \n\n#### 2. Repositioning, Entry, and Potential Competition  \n\nWhile efficiencies are the most prominent factor in late-stage product-market merger analysis, other considerations also play a role. In the interests of space, we will discuss the role of some of these other considerations in merger analysis involving labor markets.  \n\nOne of the most prominent such factor is product repositioning, changes to the non-price characteristics of products that the merger may provoke. 139 The ability of other firms in the market to reposition their products in response to the merger of two firms whose products are close substitutes may mitigate some of the harms of a merger. For example, the merger of Whole Foods and Wild Oats, two gourmet organic grocers, may lower the quality of the organic food the merged firm offers because they are no longer competing for core consumers. However, other grocers may well upgrade their products to muscle in on the territory vacated. This effect can only reduce anticompetitive harms from the merger, not eliminate them.  \n\nSimilar considerations apply to labor markets. If a merger of the two largest coal mines in a region leads to widespread unemployment of coal workers, other companies may reposition their jobs to take advantage of coal workers’ unique skills (such as the ability to deal with extreme conditions). Conditions of work, classifications of workers, flexibility, sick leave and so forth vary so widely that non-wage amenities are likely to be a critical way in which employers who gain market power through mergers will exercise this power. Thus, we expect analysis of job repositioning to be even more important in labor markets than analysis of product repositioning is in product markets.  \n\nMergers (and especially anticompetitive mergers) tend to encourage firm entry. To the extent that the merging firms raise prices and compete less intensely, they leave profit opportunities for a new firm to exploit. In principle, this tendency to encourage entry may be a reason for excusing the anticompetitive effects of entry. Some commentators, however, are skeptical that firms can enter markets as easily as this theory suggests.  \n\nWhoever is right, this argument is even weaker for labor markets. The extensive labor market frictions deter entry. In the product market case, a firm can enter a market merely by supplying products identical or similar to those being sold by the merged firm. In the labor market case, a firm can in principle enter a market by hiring workers laid off by merging firms, but the new entrant will need to duplicate hard-to-observe workplace conditions that may have attracted the workers originally, and also contend with a workforce that was demoralized by the earlier layoffs. Case law and views within the economics community have largely drifted in this direction.140  \n\nAnother increasingly important factor in the analysis of mergers in product markets is their effect on potential competition. Instagram may not have directly competed with Facebook at the time Facebook purchased Instagram, but Facebook may have been rightly concerned that Instagram might, if left to itself, succeed in reorienting the social media landscape around images rather than the image-text mixture that Facebook has profited from.  \n\nPurchases to forestall potential competition may also take place when firms fear competition in the labor market. In recent years, tech companies have rushed to hire programmers who specialize in machine learning. A common way of acquiring such talent is to purchase machine learning start-ups: Google bought DeepMind, Microsoft bought Maluuba, Apple bought Lattice Data. In contrast, the tech companies could have tried to hire workers directly by luring them with promises of high compensation from the incumbent employers. It seems likely that the share of the gains accruing to workers (as opposed to investors and the few at the top of these startups) from open competition would have been greater than under an acquisition strategy. The acquisition thus effectively killed off potential competition for workers. Analyses of potential labor market competition, especially in highly dynamic labor market, should form an important part of antitrust analysis of the labor market harms from mergers. This type of threat may not be easily gauged by the standard MDC and UPP/DWP approaches which focus on the present state of competition rather than the future competitive landscape.  \n\n### E. Case Study: The Effect of Hospital Mergers on the Labor Market for Nurses  \n\nTo give a sense of how our merger approaches would work in the real world, we provide a brief example that uses real-world data, albeit in a hypothetical setting. We use the example of nursing because a considerable amount of work on the topic has yielded fine-grained data on which wecan rely.  \n\nSuppose two hospitals, each with one third of the nurses in a particular labor market area, propose a merger. Should the government block the merger because of its labor market effects? We can use existing evidence to calculate the predicted fall in nurse wages, and check if the three approaches we have discussed generate results consistent with the evidence.  \n\nMDC. The merger would increase the HHI from 3333 to 5556, for a difference of 2223.141 Under the Merger Guidelines, the proposed merger would be presumptively blocked because of the high initial HHI and the high increase in HHI. Barry Hirsch and Edward Schumacher estimate the effect of hospital concentration on nurses’ log wages, and find (when controlling for fixed effects) that the coefficient on hospital concentration is -0.4, which implies that the merger would lower nurse wages by almost $9\\%$ 142 If we instead use a more recent study by Azar, Marinescu and  \n\nSteinbaum, who find a log HHI point estimate of -0.12 (and a mean baseline HHI of 0.3), the implied increase in HHI would decrease wages by $20\\%$ .143 Thus, given an average salary of $\\$68,500$ per year for registered nurses,14 the merger would lower their salary by $\\$6,165–13,700$ while also eliminating some jobs. The hospitals could try to rebut by showing that efficiency savings would allow them to raise wages. It is possible, for example, that nursing labor can be used more efficiently in one hospital than in two, but the merging hospitals would need to prove an efficiency gain of sufficient magnitude.  \n\nDWP. In a symmetric merger, the UPP reduces to $\\mathrm{m}^{*}\\mathrm{D}$ , where D is the diversion ratio and m is the markup. Some algebra reveals that the analogous measure for the labor market case would be the same, $\\mathrm{m}^{*}\\mathrm{D}$ , with m now the markdown. Staiger, Spetz, and Phibbs estimate a residual labor supply elasticity facing the hospital of 0.1,145 which would imply a markdown of 10, and the symmetry of the merger would imply $\\mathrm{D}=0.5$ ,andso $\\mathrm{DWP}=.5^{*}10=5$ . Hence labor productivity would have to more than double after the merger in order to keep wages constant in this example. Again, the burden would be on the merging hospitals to prove this efficiency gain.  \n\nIf we instead used the cross-wage elasticity (effect of other hospital's wage on own employment) of 0.028 implied by the VA wage effect on nearby non-VA hospitals studied by Staiger, Spetz, and Phibbs,146 the Diversion Ratio would be . $028/.1{=}.28$ and this would imply a DWP $=10^{*}.28/=2.8$ . Both of these DWP numbers are far larger than the minimum required to trigger merger scrutiny.  \n\nThe magnitude of DWP for a hospital merger depends on the residual labor supply elasticity of nurses and other health care workers. Table 2 shows DWP across a range of nurse (and nurse-aide) residual labor supply elasticities from the literature. The estimates of residual labor supply curves vary widely in this literature. The article with the most credible identification strategy shows the lowest.147 Table 2 shows DWP predictions under both high and low estimates of the cross-elasticity, and across the range of own-elasticities. For the ranges of residual supply elasticities below 3.5, the DWP predictions for a symmetric merger suggest that scrutiny would be warranted under the current guidelines. Even with larger residual labor supply elasticities from Sullivan,148 the DWP is greater than 0.01. Of course, as the degree of market power falls, the DWP falls, and there are estimates of nurse149 and nurse aide residual supply elasticities150 that would imply a DWP below any meaningful threshold. This strongly suggests that many hospital mergers should be carefully watched for labor market effects, in sharp contrast to the status quo.  \n\nbiversion Ratios and Downward Wage Pressure from Merger of Ex-ante Symmetric Firm:   \n\n\n<html><body><table><tr><td></td><td></td><td></td><td>Own-Elasticity Cross-Elasticity Div.RatioDWP(DR*markdown)</td><td>OwnSource</td><td>Cross-Source</td></tr><tr><td>0.183</td><td>0.028</td><td>0.15301</td><td>8.4E-01</td><td>StaigeretalTable6,Column6</td><td>StaigeretalTable6,Column6</td></tr><tr><td>1.26</td><td>0.028</td><td>0.02222</td><td>1.8E-02</td><td>Sullivan1989Short-run</td><td>StaigeretalTable6,Column6</td></tr><tr><td>3.85</td><td>0.028</td><td>0.00727</td><td>1.9E-03</td><td>Sullivan1989long-run</td><td>StaigeretalTable6,Column6</td></tr><tr><td>29</td><td>0.028</td><td>0.00097</td><td>3.3E-05</td><td>Hansen1992LowerEnd</td><td>Staigeret alTable6,Column6</td></tr><tr><td>56</td><td>0.028</td><td>0.00050</td><td>8.9E-06</td><td>Hansen1992UpperEnd</td><td>StaigeretalTable6,Column6</td></tr><tr><td>1000</td><td>0.028</td><td>0.00003</td><td>2.8E-08</td><td>Matsudaira2012approximation</td><td>StaigeretalTable6,Column6</td></tr><tr><td>0.199</td><td>0.116</td><td>0.58291</td><td>2.9E+00</td><td>StaigeretalTable6,Column3</td><td>StaigeretalTable6,Column3</td></tr><tr><td>1.26</td><td>0.116</td><td>0.09206</td><td>7.3E-02</td><td>Sullivan1989Short-run</td><td>StaigeretalTable6,Column3</td></tr><tr><td>3.85</td><td>0.116</td><td>0.03013</td><td>7.8E-03</td><td>Sullivan1989long-run</td><td>StaigeretalTable6,Column3</td></tr><tr><td>29</td><td>0.116</td><td>0.00400</td><td>1.4E-04</td><td>Hansen1992LowerEnd</td><td>StaigeretalTable6,Column3</td></tr><tr><td>56</td><td>0.116</td><td>0.00207</td><td>3.7E-05</td><td>Hanse1992UpperEnd</td><td>StaigeretalTable6,Column3</td></tr><tr><td>1000</td><td>0.116</td><td>0.00012</td><td>1.2E-07</td><td>Matsudaira2012approximation</td><td>StaigeretalTable6,Column3</td></tr></table></body></html>\n\nCalculations done assuming each of 2 merging firms has 1/3 of the market and hourly wage of 10.  \n\nMerger simulation. While it is beyond the scope of this paper to conduct a merger simulation for the effect of a hypothetical hospital merger on the wages of nurses, it is quite feasible. Data on hospital employment of different types of nurses (in hours) and hourly wages are already publically available for the state of California. This is precisely the raw material required to estimate a “labor supply system” analogous to widely used “labor demand system” estimation used for conducting merger simulations (for example the widely used Berry-Levinsohn-Pakes methodology151). Further, demand system estimates often require instruments with sometimes dubious exogeneity assumptions, but labor economists regularly use exogenous product price shocks to identify residual labor supply curves. With the kind of detailed data available to regulators, there are no obstacles to deploying the full IO toolkit for conducting merger simulations in the labor market for nurses.  \n\nDefenses. Because we have never seen an attempt to justify anticompetitive labor market effects of mergers, it is hard to know what efficiencies merging partners would attempt to bring to bear. One possibility, noted above, is that a merger could reduce redundancy. Another possibility would be increased productivity because of greater ease of medical record sharing or cross-hospital referrals. The merging parties would have to show that these were likely to increase wages and could not be achieved without a merger. Other informal factors seem important here, especially changes to hours, benefits, and job descriptions, as these can be highly specific to a particular hospital and nurses can be asked to work odd hours. Given large economies of scale in hospitals and often the necessity of affiliating with a major university, we doubt that entry analysis would play a large role in this case, nor potential competition. However, the prospect of coordinated effects might be important given the close geographic proximity of hospital and their frequent communication about community health, which may serve as a ruse for collusion on wages.  \n\nIn short, the tools already used by antitrust regulators to predict the product-market price effects of mergers can be readily applied to predicting their labor-market wage effects. Using available estimates of hospital market power in the nursing market and existing antitrust heuristics, we guess that the wage effects of hospital mergers are substantial, suggesting that antitrust regulators should subject them to an additional level of scrutiny.  \n\n## III. Legal Remedies for Other Types of Monopsonistic Behavior  \n\n### A. Covenants Not to Compete  \n\nCovenants not to compete, also called non-compete agreements, provide that if an employee quits or is fired from a job, she may not work for a rival employer. Non-competes typically define an industry, geographic scope, and time limit. In the common law, courts scrutinize non-competes and refuse to enforce them if they are “unreasonable,” meaning that they are stricter than necessary to protect the employer's legitimate interests, such as trade secrets or investments in training. i52 Despite the explicit restrictions on competition, courts have been unsympathetic to claims that non-competes may violate the antitrust laws.153  \n\nAs we noted in the Introduction, concerns have been growing in recent years that noncompetes are used not just for legitimate means, but to suppress competition. The widespread inclusion of non-compete clauses in the contracts of low-skilled workers, including sandwichmakers who work for chains, suggests that they are being used to raise the cost for workers of quitting and working for a competitor. Aside from the immediate hardship for workers, the extensive use of non-competes may further concentrate labor markets. To see why, imagine that a single firm (or small group of firms) dominates a labor market in a geographic area. If the firm uses non-competes, then new firms will be deterred from entering the labor market because they will have trouble hiring workers. Thus, the non-compete may be used to consolidate or extend labor market power.  \n\nThe traditional common law analysis of non-competes misses these effects because the court is not required to look at market power. The analysis is focused on the possible hardship on the worker who is subject to the non-compete. But the problems created by non-competes are much broader. If a labor market monopsonist uses non-competes, it can deter other firms from entering the labor market and offering superior wages and working conditions to workers. Thus, the social cost of a non-compete does not depend on its effect on a particular worker (who in principle could be compensated in the form of higher wages for entering it) but on the broader labor market—and, specifically, on the extent of the labor market power of the employer. Indeed, consistent with this theory, Starr et al. find that non-competes make workers worse off in monopsonistic markets but not in competitive markets. 154 This calls for antitrust analysis rather than common law analysis.  \n\nAntitrust law already contains the conceptual resources for addressing this problem. For a product market analogy, consider an exclusive dealing arrangement. If a large seller with product market power sells only to distributors who agree not to sell the products of rival sellers, then the initial seller would be able to strengthen its position in the market against possible rivals. For this reason, an exclusive dealing arrangement can be, and are frequently challenged, under the antitrust laws.155 For example, courts have found that exclusive dealing relationships between firms with market power and independent contractors violate the antitrust laws.156 The same analysis should apply to covenants not to compete as well.  \n\n### B. Supplier Wage Suppression  \n\nNathan Wilmers has found evidence that large buyers like Walmart have tried to control the wages that their suppliers pay their (the suppliers') workers. 157 His research indicates that when suppliers sell to a concentrated retailer such as Walmart, overtime wages of their workers fall. While the exact mechanism of this effect is unclear, one possibility is that large retailers require their suppliers to pay workers below some firm-imposed cap to reduce competition for workers among the suppliers, enabling suppliers to pass on labor cost savings to the retailer.  \n\nIf this speculative account is correct, then firms like Walmart are engaging in anticompetitive behavior that has harmed workers. Walmart's behavior is the mirror-image of resale price maintenance, where a seller (like a manufacturer) requires its customers (wholesalers or retailers) to sell goods at a price above a set amount. When the seller has market power, the effect of its behavior is to orchestrate a cartel among the customers, who charge the set price rather than compete on price. Supplier wage suppression results in an effective cartel among suppliers, who are able to pay their workers below the marginal product, and pass on some of the savings to the buyer. Supplier wage suppression should similarly be considered a violation of the antitrust laws.  \n\n### C. Collusion  \n\nCourts and regulators have already recognized that collusion in labor markets violates the antitrust laws. Firms may be held liable for agreeing to fix wages and sharing wage information so as to facilitate coordination of wages.158 They have also been held liable for agreeing not to make employment offers to each other's workers (\\*no-poaching agreements,’ “no-switching agreements') and related activities. $^{159}\\mathrm{~In~}2010\\$ numerous high-tech firms that had agreed not to poach each other's employees settled with the Justice Department. 160  \n\nIn a variation on this practice, franchisors have increasingly prohibited franchisees from competing for workers. More than half of major franchisors engaged in this practice as of 2016, up from about a third in 1996.161 In 2017, McDonald's employees sued the company for blocking franchisees from hiring each other's workers.162 Franchises have in the past been able to avoid antitrust liability under the single entity doctrine.163 If franchise is defined as a single company, rather than a collection of companies, then collusion is impossible, since collusion involves more than one entity acting in cooperation.164 However, from a policy standpoint, the only question is whether multiple franchisees in a single labor market possess market power, and hence can suppress wages by colluding. If they can, it should be irrelevant that they are nominally controlled by a single franchisor.  \n\n### D. More Speculative Anticompetitive Practices in Labor Markets  \n\nCourts have recognized other anticompetitive practices in product markets that have parallels as well in labor markets. Although we are unaware of any cases or allegations of the labor-market behavior, it is worthwhile to explore the parallels.  \n\nPredatory pricing / predatory hiring. A seller with market power may find it profitable to charge customers below-market prices in order to bankrupt an entrant into a market, then charging above-market prices after that firm disappears. In a typical pattern, a monopolist charges high prices until the entrant materializes, then charges below-market prices to prevent the entrant from acquiring customers, doing so long enough to force the entrant to quit the market, and then raising prices again. While predatory pricing can be difficult to prove, it constitutes illegal anticompetitive behavior.165  \n\nIf predatory pricing is a rational strategy of a monopolist, then “predatory hiring” is a rational strategy of a labor monopsonist. Imagine that a large employer—say, a hospital-in a small town pays nurses a below-market wage. A new firm enters the market, hoping to attract nurses by charging them a market wage. The incumbent responds by raising wages above the workers’ marginal revenue product, drawing on its earlier monopsony profits to fund the temporarily loss-producing strategy. The new firm quits the market because it cannot hire nurses at the market wage; then the incumbent lowers wages or worsens working conditions. The incumbent's behavior would constitute predatory hiring, and should be considered unlawful for the same reasons that predatory pricing is.  \n\nVertical foreclosure. Antitrust law takes a more relaxed attitude toward vertical mergers than horizontal mergers because vertical mergers do not as frequently consolidate product markets. But certain vertical mergers pose risks. Suppose an upstream seller (a manufacturer or other supplier) possesses market power and merges with one of two (or a few) downstream buyers. The merged firm then sells to the other downstream buyer (or buyers) at an elevated price, giving itself (in its capacity as downstream firm, the result of the merger) a competitive advantage. This is known as foreclosure and is illegal under the antitrust laws.  \n\nDownstream product and labor markets behave similarly in this case. Suppose the market for nurse aides has two hospitals in it, both of which serve patients covered by the same HMO. Now suppose the HMO acquires hospital 1, and lowers reimbursement rates for patients served at hospital 2. This will lower labor market demand for nurse aides in hospital 2, and give hospital 1 the ability to lower wages for its own nurse aides.  \n\n## IV. Conclusion  \n\nLabor market power is ubiquitous and costly to society. It is bad for economic growth, equality, and well-being. Yet labor market power is generally ignored by antitrust authorities, and never considered as a justification for subjecting mergers to scrutiny. This contrasts with the regulatory concern for product market power. We argue that this asymmetry is not justified by either legal doctrine or economic theory, and suggest that applying the economic analysis of product markets regularly deployed in the scrutiny of mergers can easily be applied to the labor market.  \n\nIt is also worth considering whether more severe corrective action in labor markets, given their current highly concentrated state, may be called for. In the nineteenth century, years without antitrust led to a business landscape dominated by a small number of highly powerful trusts. After the Sherman Act was passed, and the political will could be mustered, several of largest trusts were broken up. Our present business landscape exhibits a number of extremely powerful employers as a result of the neglect of mergers and other anticompetitive behavior in labor markets. While a more detailed examination would be needed to draw any firm conclusions, antitrust investigations into massive employers (such as Compass Group, Accenture,166 Amazon, Uber and Walmart), as well as platform-based firms that receive vast flows of valuable data services without any compensation (such as Facebook and Google), seem warranted.167 It may be that some of these firms have achieved such powerful monopsonies that they should be broken up.  "
  },
  "md_ransomLaborMarketFrictions2022": {
    "reference_markdown": "# Labor Market Frictions and Moving Costs of the Employed and Unemployed  ?  \n\n# Tyler Ransom  \n\n# ABSTRACT  \n\nSearch frictions and switching costs may grant monopsony power to incumbent employersbyreducingworkers'outsideoptions.This paper examines therole of labor market frictions and moving costs in explaining worker flows across U.S. labor markets. Using data on non-college-educated workersfromtheSurveyofIncomeandProgramParticipation(SIPP), Iestimateadynamicmodelofjobsearchandlocationchoice.Ifindthat movingcosts aresubstantial andthat labormarketfrictions primarilyinhibit the employed.Reducing these frictions would result ina higherwage elasticity of labor supply to thefirm and could reduce employer monopsony power.  \n\n## 1. Introduction  \n\nMigration is widely considered to be a key indicator of labor market health, for two reasons. First, it is understood to be the primary way by which local labor markets adjust to shocks (Topel 1986; Blanchard and Katz 1992; Yagan 2014). Second, lower levels of migration may indicate a less competitive labor market—when workers are unable or unwilling to move, their outside options are diminished, and employers can compensate them below their market value (Ransom 1993; Fox 2010) or recruit only within the local area (Karahan and Rhee 2017).'  \n\nIn this work, I develop and estimate a dynamic structural model that incorporates switching costs and search frictions—two commonly cited sources of monopsony power. In the model, workers choose labor markets in which to live, but face frictions in obtaining employment and costs to moving locations or entering or exiting the labor force. Moving costs depend on employment status, and frictions depend on both employment status and local labor market conditions. These dimensions of migration have not yet been looked at in the literature. I use the model to compute moving costs by employment status and to examine workers’ relocation behavior in response to local labor market shocks or to a moving subsidy (for example Moretti 2012; H.R. 2755 2015). I also examine how firm switching costs relate to monopsony power by simulating a related model of workers’ choices over firms.  \n\nI study individual migration, employment, and labor force transitions across U.S. metropolitan areas over the period 2004-2013. My primary data source is a confidential panel data set collected by the Survey of Income and Program Participation (SIPP). My sample consists of prime-age white men who are not college educated. The large coverage of the SIPP allows me to observe many moves and to accurately observe the conditions of many local labor markets. The SIPP also contains detailed information on demographic characteristics and labor market experience.  \n\nThe econometric model characterizes locations in three dimensions that enter workers’ utility functions and govern their decision-making: (i) market and nonmarket amenities, (ii) expected earnings, and (i) expected employment. Each worker has common preferences for a location's market amenities (for example, climate), but workers may value nonmarket amenities differently (for example, proximity to family). Earnings and employment differ across workers based on differences in their observable and unobservable characteristics. For unobservables, workers are also classified into two discrete types, labelled type 1 and type 2, which differ in terms of wages, employment, and switching costs.  \n\nThe model specifies locational choice and labor supply as a discrete choice dynamic programming problem.2 Search frictions enter the model in a reduced form, where those who choose to supply labor are assigned to employment according to a weighted lottery. The employment probability depends on local labor market conditions, as well as the worker's previous location decision and individual characteristics.? In order to estimate the model, I use recent developments in the estimation of large-state-space dynamic discrete choice models. By using conditional choice probabilities (CCPs) and the property of finite dependence, I tractably estimate a model that includes many alternative choices and uncertainty in choice outcomes.  \n\nA key component of this analysis is that search frictions differ based on current employment and residence status. That is, in the style of Burdett and Mortensen (1998), the employed and nonemployed face different search processes. This paper builds on their framework by also allowing the search process to differ based on whether a worker has recently moved from another labor market. Descriptive statistics show that these dimensions are important to migration and job search. I show that the nonemployed are much more likely than the employed to move.4 I also show that employed movers are much less likely to remain in employment than employed stayers. On the other hand, employment probabilities are about the same for nonemployed movers and stayers.  \n\nUsing estimates of worker preferences and productivity, I calculate each type of worker's willingness to move under alternative scenarios, such as a local labor market shock or a government-provided moving subsidy. Migration responses to changes in the local labor market are similar to a spatial labor supply elasticity in the situation where workers have few within-location employment options.?  \n\nThe estimated parameters imply that moving costs are substantial and that labor market frictions are especially burdensome for the employed. Iestimate the moving cost to the average person to have a present value on the order of $\\$400,000$ .Althoughlarge, this estimate is in line with many other studies. The primary reason for the large magnitude is that there is a weak empirical relationship between expected earnings and observed moves. With regard to search frictions, the descriptive finding of reduced job offer arrivals for employed movers continues to hold in the structural model after allowing for employment to depend on unobserved worker ability. Thus, search frictions act as an additional hindrance to migration for the employed. In contrast, the nonemployed are equally likely to receive an offer whether or not they move, so search frictions are less binding to their migration behavior, and their outside options are not affected by moving.  \n\nI use the structural model estimates to study migration responses to local labor market shocks and to a government move subsidy. Employed workers are more likely to stay in a place experiencing a local economic downturn, but less so if the economic downturn is nationwide. The opposite is true for the unemployed, who are more likely to move in response to a local economic downturn. If the government were to offer a $\\$10,000$ moving subsidy to the unemployed (for example, as proposed in the American Worker Mobility Act; H.R. 2755 2015), my model predicts that there would be low take-up rates $(\\approx3-5$ percent), with even lower take-up rates among those who are already in their home location.6 Response to the subsidy differs by the conditions of the local labo1 market and the desirability of the location.  \n\nTo illustrate the impact of switching costs on monopsony power more precisely, I simulate a dynamic model of worker choices over firms. The model shares features of Card et al. (2018) and Lamadon, Mogstad, and Setzler (2019), but adds firm switching costs. I calibrate the parameter values of the model to match the estimates of my empirical model and moments in the SIPP. I use the model to compute the wage elasticity of labor supply to individual firms, following Hirsch et al. (2022). When switching costs are infinite, labor supply is perfectly inelastic. At the level of firm switching observed in the SIPP, the elasticity of labor supply is about 1 for the average firm. Further reducing switching costs would result in higher labor supply elasticities. These results indicate that when workers face costs to switching firms, this market imperfection grants employers monopsony power.  \n\n## II. Data and Stylized Facts about Migration and Unemployment  \n\nI now introduce the main data sources used in the study and present stylized facts about moving costs and labor market frictions that motivate the structural model.  \n\n### A. Data  \n\nThe main data source is the 2004 and 2008 panels of the Survey of Income and Program Participation (SIPP). I supplement the SIPP with data on location characteristics and local labor market conditions (Ransom 2021).  \n\n#### 1. The SIPP  \n\nThe SIPP is a longitudinal survey of a stratified random sample of residents of the United States, administered by the United States Census Bureau. Respondents are interviewed every four months over a four- or five-year span. Each four-month period is referred to as a wave. Survey respondents are asked questions regarding their living arrangements, labor force participation, earnings, assets, government program participation, migration, and education, among many other topics. Within each wave, respondents provide additional information on many of these activities at the monthly level.  \n\nIn order to preserve confidentiality, the data used here—which make use of detailed residence location and earnings that are not top-coded—are not released publicly by the SIPP and are only available through the Census Research Data Center (RDC) Network.?  \n\nFurthermore, the confidential version of the SIPP is linked via the respondent's social security number to Internal Revenue Service (IRS) and Social Security Administration (SSA) administrative data on annual earnings, employment history, government program participation, and social security benefits receipts. I make use of this link to create work experience profiles based on the administrative data that are less vulnerable to survey recall error.  \n\nThe SIPP's longitudinal structure, combined with its large-sized cross-section make it useful for studying migration and labor supply behavior. Because it is a survey, it can distinguish between unemployment and labor force detachment—two effects that are conflated in studies that use administrative data such as tax records (Yagan 2014; Schluter and Wilemme 2018; Schmutz and Sidibe 2019).  \n\nThe main disadvantages of the SIPP are twofold. First, its panels are relatively short at four to five years in length. Second, attrition rates in the SIPP are higher than in other longitudinal surveys. However, there is evidence that the high attrition rates do not bias labor market outcomes (Zabel 1998).  \n\n#### 2. Individual variables  \n\nI now introduce the outcome and explanatory variables used in the analysis. There are three main outcomes of interest: location, labor force and employment status (employed, unemployed, or out of the labor force), and monthly earnings if employed.  \n\nLabor force participation and unemployment are defined in terms of strength of attachment, as follows. Labor force participants are those who have a full-time job or who are seeking a full-time job. Those who are self-employed or who voluntarily work part-time are excluded from my definition of the labor force. Unemployment is defined here as labor force participation that is not full-time employment. Full-time employment is defined as working 35 or more hours per week for all weeks in the survey month.  \n\nAlthough the definitions I use for labor force participation and unemployment are unconventional, I use these definitions because my model focuses on the relationship between migration and labor market frictions. People who are only weakly attached to the labor force are by definition less likely to move for employment reasons. Later on, I show that my descriptive results are not sensitive to these unconventional definitions of labor force status and employment.  \n\nFocusing on full-time employment (rather than any employment) has additional benefits. First, full-time employees are most likely to be employed throughout the year, which more closely matches the time horizon of the model. Second, the SIPP does not measure hours worked at the monthly level—only at the wave level. Thus, measuring earnings at the hourly level is more difficult. I focus on full-time jobs because these jobs are most likely to be salaried, and an hourly earnings measure does not appropriately capture marginal labor productivity for salaried workers. I define monthly earnings as the sum of earnings across all jobs in the survey month. I deflate earnings by cost of living in the location, as described later in this section. All monetary figures throughout this paper are expressed in constant $2000\\:\\mathrm{U}.\\mathrm{S}$ . dollars unless otherwise noted.  \n\nThe primary explanatory variables are work experience, age, and birth location. I indirectly use additional demographic variables, such as education level, sex, and race/ ethnicity, to determine the estimation subsample. I create work experience from IRS records as an annualized measure of the sum of all quarters worked. I similarly construct age from the SSA data by comparing the calendar year and month with the birth year and month. Respondents report their state or country of birth in Wave 2 of each SIPP panel.  \n\n#### 3. Geographical variables  \n\nI define locations as cities (Core Based Statistical Areas, or CBSAs).& In order to maintain tractability, I restrict to the 35 cities that are most frequently observed in the SIPP. I construct an additional 20 residual synthetic locations to ensure that the choice set is geographically exhaustive. These synthetic locations are grouped into two population bins (small and medium) based on population. Online Appendix Table A4 contains a complete list of all 55 locations. A map of the 35 cities can be found in Online AppendixFigure A1.  \n\nModeling a large number of locations is essential to capturing the actual locational choice alternatives that individuals face. I focus on cities rather than states because business cycles are heterogeneous across cities, even within the same state.? Furthermore, because many cities cross state boundaries, focusing on cities more closely characterizes the actual local labor market. Modeling the largest cities is also a parsimonious way of categorizing the choice set: 43 percent of the U.S. population resides in the 30 largest cities (CBSAs).1° Finally, the residual locations are divided into population categories because there is evidence in the urban economics literature that a variety of labor market outcomes differ systematically by city size due to agglomeration economies, thick market effects, human capital externalities, and labor market competition (Glaeser and Maré 2001;Gould 2007; Baum-Snow and Pavan 2012; Hirsch et al. 2022). Breaking out the residual categories by city size is a parsimonious way of capturing these effects.  \n\nBeyond the geographical definition of location, I also make use of the population, unemployment rate and price level of the worker's city. Population is defined as the 2000 Census population level in the county of residence, aggregated to the CBSA level. It is used to divide locations that are smaller than the top 35 cities. The unemployment rate is taken at the county level from the Bureau of Labor Statistics (BLS) Local Area Unemployment Statistics data series and aggregated to the CBSA level, weighting by county population.11 This variable is used in the model to inform individuals about their employment prospects in each location. I merge these city characteristics using a crosswalk that maps counties to CBSAs. Further details on data sources can be found in Online Appendix Table A3.  \n\nTable1 Descriptive Statistics of theEstimation Subsample of the SIPP, 2004-2013   \n\n\n<html><body><table><tr><td>Variable</td><td>Mean</td><td>SD</td></tr><tr><td>Log monthly earnings (2000 dollars)</td><td>7.96</td><td>0.52</td></tr><tr><td>Work experience (years)</td><td>22.60</td><td>9.49</td></tr><tr><td>Age (years)</td><td>42.29</td><td>9.76</td></tr><tr><td>Lives inlocation inbirth state</td><td>0.74</td><td>0.44</td></tr><tr><td>Lives in location in birth census division</td><td>0.75</td><td>0.43</td></tr><tr><td>Number ofpersons</td><td colspan=\"2\">16,648</td></tr><tr><td>Numberofobservations</td><td colspan=\"2\">50,415</td></tr></table></body></html>\n\nNotes: For complete sample selection rules, see Online Appendix Table A1. a. Conditional on being employed full-time with monthly earnings between $\\mathbf{\\hat{\\$400}}$ and $\\$22,000$ .Thisvariable has 29,238 person-year observations. The earnings variable is spatially deflated to account for differences in cost of living according to the procedure outlined in Online Appendix A.7.  \n\nFollowing a number of papers in the literature, I spatially deflate earnings using the American Chamber of Commerce Research Association's Cost of Living Index (ACCRA-COLI).12 I follow Baum-Snow and Pavan (2012) and Winters (2009). Further details on the construction of this index can be found in Online Appendix SectionA.7.  \n\n#### 4.Estimation subsample  \n\nI estimate the model using non-Hispanic white men of prime working age (ages 18-55 at the beginning of the survey), who have completed school and who do not have a bachelor's degree. I remove college graduates because their job search process across space is much different from that of non-college graduates (Balgova 2018). I focus on men of a particular education level, race, and ethnicity in order to form a homogeneous sample and because migration is a household decision where the male head's employment prospects are more likely to dictate a geographical move. 1′ However, I show later that my basic stylized facts about employment and migration hold for other demographic groups. The final estimation subsample comprises 16,648 men, each averaging 3.03 annual observations.  \n\nTables 1 and 2 list descriptive statistics for the estimation subsample. The average individual in the sample is 42 years old and has 23 years of work experience. Living near one's location of birth is common, with almost 75 percent of the sample residing in their state of birth. Table 2 lists the migration statistics in the sample, which contains 568 movers who make 653 moves.  \n\nTable 2 Migration in the SIPP, 2004-2013   \n\n\n<html><body><table><tr><td></td><td>16,648</td></tr><tr><td>Number of persons (age 18-55) Movers</td><td>568</td></tr><tr><td>Movers (%)</td><td>3.41</td></tr><tr><td>Moves</td><td>653</td></tr><tr><td>Movesper mover</td><td>1.15</td></tr><tr><td>Repeat moves (% of all moves)</td><td>13.38</td></tr><tr><td>Return moves (% of all moves)</td><td>8.98</td></tr></table></body></html>  \n\nNotes: Moves are defined as changing locations as specified in the model.  \n\nIuse four annual observations for the 2004 panel—the interview month of Waves 2, 5, 8, and 11—to measure location, labor market outcomes, and individual characteristics. The 2008 Panel is slightly longer, so I use the same waves in addition to Wave 14. The entire data set spans the years 2004-2013, but any given individual can only appear in at most five of those years. Most of the sample has at least three observations. For more details on sample selection and construction of key variables, see Online Appendix Section A.6 and Table A1.  \n\n### B. Stylized Facts about Migration and Unemployment  \n\nWith the data in hand, I now present three stylized facts about migration and unemployment that will show motivating evidence on the two sources of monopsony power that I focus on: moving costs and search frictions.  \n\nFirst, the nonemployed are more geographically mobile than the employed. Second, employed workers who move are much less likely to become employed after the move than employed workers who stay. This phenomenon is restricted to employed movers; nonemployed movers are just as likely to get a job as nonemployed stayers. Third, the employment prospects of nonemployed workers are relatively worse during local economic downturns, compared to employed workers. For expositional reasons, I illustrate these facts using publicly available SIPP data on all workers in the United States, as opposed to the confidential data on non-Hispanic white men that I use in the structural model. In all cases, employment is defined as described previously.  \n\nFigure 1 shows that, across multiple distances, the nonemployed move more frequently than the employed. The difference amounts to about a 50 percent higher mobility rate for across-state moves, and about a 30 percent higher mobility rate for withinstate, across-county moves.14  \n\nTo see if movers and stayers tend to have different employment outcomes, I estimate a simple linear probability model. The left-hand side variable is an indicator for full-time employment in the current period. The right-hand side variables include race-by-gender  \n\n#### Panel A: Employed  \n\n![](images/86ba5701dc18870e72ad3f2e91abb2a06470951a5ca44469aa623eed9fcb14be.jpg)  \nFigure 1 Annual Migration Rates by Lagged Employment Status and Migration Distance  \n\nSource: 2004 and 2008 panels of the public-use Survey of Income and Program Participation. Figures include all non-college graduates aged 18-55 who have completed their schooling. Employment is defined as full-time employment.  \n\nTable3 Linear Probability Models of Employment, by Lagged Employment Status   \n\n\n<html><body><table><tr><td rowspan=\"2\">Variable</td><td colspan=\"2\">Prev. Employed</td><td colspan=\"2\">Prev. Nonemployed</td></tr><tr><td>Coeff.</td><td>SE</td><td>Coeff.</td><td>SE</td></tr><tr><td>Constant</td><td>0.7243***</td><td>0.0071</td><td>0.1976***</td><td>0.0059</td></tr><tr><td>Experience</td><td>0.0123***</td><td>0.0005</td><td>0.0077***</td><td>0.0004</td></tr><tr><td>Experience2/100</td><td>-0.0200***</td><td>0.0012</td><td>-0.0142***</td><td>0.0011</td></tr><tr><td>Lagged state unempl. rate</td><td>-0.0038***</td><td>0.0006</td><td>-0.0060***</td><td>0.0006</td></tr><tr><td>Moverdummy</td><td>-0.1219***</td><td>0.0080</td><td>0.0468***</td><td>0.0076</td></tr><tr><td></td><td></td><td></td><td></td><td></td></tr><tr><td>RaceX gender dummies Observations</td><td colspan=\"2\">83,324</td><td colspan=\"2\">78,057</td></tr></table></body></html>\n\nNotes: Dependent variable is an indicator for being employed full-time in the current period. Sample includes all non-college graduates aged 18-55 in the 2004 and 2008 panels of the public-use SIPP who have completed theirschooling. ${}^{*}p<0.10$ $^{**}p<0.05$ $***}p<0.01$  \n\ndummies, a quadratic in experience, the previous-period unemployment rate in the current state of residence, and an indicator for having made a move since the previous period. Here, I define a move as changing counties or states, that is, moving to a different local labor market. I estimate this linear probability model separately by previous employment status.  \n\nThe results of these descriptive regressions are shown in Table 3. For employed workers, the mover dummy coefficient is $^{-12}$ percentage points, indicating a large penalty for employed movers. For the nonemployed, there is actually a slight gain to moving—nonemployed movers are about five percentage points more likely to be employed than nonemployed stayers.15 Finally, an increase in the state unemployment rate reduces the employment probability of the nonemployed by more than it does the employed. In this sense, the employed are more insulated from local economic downturns than those who are not employed.  \n\nAlthough the above facts are illustrative, they are likely biased due to mismeasurement of the local labor market, endogeneity of migration, and unobserved worker heterogeneity. Additionally, the incentives to move faced by the employed and nonemployed are myriad and require a more careful unpacking. In the next section, I introduce a structural model in which forward-looking individuals choose where to live and whether to supply labor. Individuals take into account that moving is costly and that employment is uncertain and is affected bylocal labor market conditions. I then estimate the model on the estimation subsample using restricted-access SIPP data that allow me to more precisely observe local labor markets. The model's inclusion of switching costs and search frictions allows me to examine the extent to which these phenomena might confer monopsony power to firms that have competitors in other labor markets, but not in their own labor market.  \n\n## II. A Model of Search Frictions, Labor Supply, and Migration  \n\nI now introduce the model that I will estimate and use to quantify moving costs and labor market frictions and to examine counterfactual scenarios that will shed light on workers′ spatial responsiveness to changes in their local labor market.  \n\n### A. Overview  \n\nIn each period, individuals choose whether or not to supply labor in one of 55 locations. The choice set is exhaustive in that in covers every possible location in the United States and every possible labor market status. Search frictions are a key element of the model. That is, although an individual in the sample may control their labor supply decision, they cannot control their employment outcome. For example, a nonemployed worker may exogenously receive a job offer, or an employed worker may exogenously be laid off. Furthermore, these job offer and destruction rates are allowed to vary by location, migration status, and calendar time, thus capturing heterogeneity in local business cycles and spatial frictions in job search. Allowing individuals to choose to supply labor is essential to the model because the employment probabilities are conditional on labor force participation.16 I specify the job search parameters in a reduced form, but the underlying search process relates to a Burdett and Mortensen (1998) approach where workers can move locations and enter or exit the labor force.  \n\nIndividuals are forward-looking and in each period choose the alternative that maximizes their present discounted value of utility. Thus, individuals take into account local labor market conditions when choosing where to locate—in addition to amenities and earnings prospects, which have been traditionally modeled in the migration literature.17 Individuals also understand that there are costs associated with changing locations or labor force status. These costs motivate individuals to be forward-looking when considering their decision in each period.  \n\nThis model is the first to examine locational choice and labor supply in a dynamic setting with time-varying search frictions that are tied to local business cycles. It is also the first to examine how moving costs differ by employment status. I now present each feature of the model in more detail, beginning with the individual's dynamic optimization problem. Complete details of the model are included in Online Appendix Section A.1.  \n\n### B. The Individual's Dynamic Optimization Problem  \n\nIn each period $t$ , individual $i$ observes a vector of state variables $Z_{i t}$ and preference shocks $\\varepsilon_{i j\\ell t}$ and receives utility equal to $u_{i j\\ell t}(Z_{i t})+\\mathfrak{E}_{i j\\ell t},$ according to a potential choice pair $(j,\\ell)$ , which indexes labor force status and location, respectively. The individual sequentially chooses $d_{i t}$ to maximize the sum of their present discounted utility according to the following expression:  \n\n$$\n\\operatorname*{max}_{d_{i t}}E\\left[\\sum_{t=0}^{T}\\mathbb{\\beta}^{t}\\sum_{j}\\sum_{\\ell}(u_{i j\\ell t}(Z_{i t})+\\varepsilon_{i j\\ell t})1\\left\\{d_{i t}=(j,\\ell)\\right\\}\\right]\n$$  \n\nwith discount factor $\\upbeta$ and where $1\\{\\cdot\\}$ is the indicator function. The individual observes the current-period vector of preference shocks $\\mathbf{\\delta}\\mathbf{\\varepsilon}_{i t}$ before making a decision, but does not observe future shocks and must take expectations accordingly. The individual also may not observe future values of the states $Z_{i t}$ and may have to integrate over those aswell.  \n\nUnder mild regularity conditions, Equation 1 follows Bellman's optimality principle.18 The ex ante value function, just before $\\mathbf{\\delta}\\mathbf{\\varepsilon}_{i t}$ is revealed, is given below.  \n\n$$\nV_{i t}(Z_{i t})=E_{\\varepsilon}\\operatorname*{max}_{j,\\ell}\\left\\{u_{i j\\ell t}(Z_{i t})+\\varepsilon_{i j\\ell t}+\\upbeta\\int V_{i t+1}(Z_{i t+1})\\mathrm{d}{\\cal F}(Z_{i t+1}|Z_{i t})\\right\\}\n$$  \n\nEquations 1 and 2 establish the mathematical framework through which individuals make forward-looking decisions. Specifically, individuals integrate over unknown future preference shock realizations $\\varepsilon_{i j\\ell t}$ using the value function.19  \n\n### C. Amenities, Expected Earnings, Employment Probabilities, and Switching Costs  \n\nI now briefly discuss how the flow utility terms in Equation 2 are specified. The model incorporates unobserved heterogeneity by means of a finite mixture model, where individuals are divided into latent groups. Online Appendix Section A.1 contains complete details of every equation and parameter that enters the model. In all, the model has 1,012 parameters.20 Although the number of parameters appears to be large, there are multiple equations in the model, and the equations with continuous outcomes contain the majority of the parameters. I discuss these details further in Section IV.A.  \n\n#### 1.Amenities  \n\nBecause individuals choose among various locations, amenities are a key component of utility. I specify two types of amenities: local amenities on which all individuals rankings are identical, and private amenities on which individual rankings may differ. Local amenities include attributes such as climate, crime, and geography. Private amenities include whether the location is in the state or census division where the individual was born. Specifying private amenities in this way allows for individuals to have preferences for family proximity or other nonmarket local ties, which have been shown to be an important aspect of location choice (Kosar, Ransom, and van der Klaauw2021).  \n\n#### 2. Expected log earnings  \n\nIndividuals also choose whether or not to supply labor. Naturally, earnings are a function of flow utility if a person becomes employed. However, as a simplifying assumption, I specify that the expected portion of the natural logarithm of earnings is what enters utility.2 I assume that expected earnings are composed of a location-time fixed effect, a quadratic function of experience, and a type dummy that represents productivity that is unobserved to the researcher but observed to the individual. Because earnings are a function of a location-time fixed effect, individuals must forecast their future evolution. They do so using an autoregressive [AR(1)] process (with drift) specific to each labor market.  \n\n#### 3.Employment probabilities  \n\nEmployment probabilities also affect whether someone decides to supply labor. I specify the flow utility of labor force participation to be a weighted sum of the flow utility of being employed (which includes earnings) and the flow utility of being unemployed (which includes a job search cost), where the employment probabilities are the weights.  \n\nThe employment probabilities follow a form similar to the descriptive linear probability models reported in Table 2: they depend on prior employment status, whether the person is a new move-in, the lagged unemployment rate of the location, and the same unobserved type that enters earnings. As with earnings, individuals must forecast how location-specific employment probabilities will evolve over time. They forecast the local unemployment rate according to an AR(1) process (with drift) specific to each location.  \n\n#### 4. Switching costs  \n\nAn important component of the flow utility is switching costs. These are specified in two dimensions: switching locations (that is, moving costs) and switching labor force status. The moving cost includes a constant, a quadratic in distance, a quadratic in age, dummies for prior employment status, and the same unobserved type that enters the earnings and employment probabilities. Labor force switching costs include a constant, a quadratic in age, and the unobserved type.  \n\n## IV. Identification and Estimation  \n\nThis section informally discusses identification of the model and pro vides further details on the estimation procedure.  \n\n### A.Identification  \n\nI now briefly discuss how the key parameters of the model are identified. These include the earnings and employment parameters, as well as the amenities and moving and switching costs, each of which comes from a separate equation of the model (Willis and Rosen 1979). With sufficient variation in the outcome and covariates of each equation, the parameters are identified. The equation with the least amount of variation in the outcome (the multinomial choice equation) thus contains the fewest number of parameters. I provide more comprehensive details on identification in Online Appendix SectionA.2.  \n\nAs with any causal analysis using observational panel data, identification ultimately requires making assumptions. In my case, where the model is a system of nonlinear equations, these include the following assumptions: (i) person-specific unobservables follow a discrete distribution, (i) there are valid exclusion restrictions to tell apart different equations in the model, (ii) individuals pre-commit to working when entering the labor force, and (iv) functional form assumptions that are standard in structural econometrics.2  \n\nThe unobserved type—which enters the earnings, employment probabilities, and moving and switching costs—-is the way in which the model accounts for selection on unobservables. A crucial assumption for identification is that the person-specific unobservables are discretely distributed. Additionally, in a nonlinear panel model such as the one used here, the unobservable type needs to be treated as a random effect for consistent estimation. This means that the unobserved type is necessarily uncorrelated with the time-invariant variables included in the model, but it can be correlated with the model's time-varying variables or with other characteristics observed in the data but left out of the model. As with other panel models, identification of this latent type relies on withinperson serial correlation in the residuals of each equation. For example, workers with earnings that are persistently higher than their observables would predict are labeled as the “high type.\"'23  \n\nAnother key to identification is exclusion restrictions for the flow utility. Identification of the coefficient on expected log earnings requires variation in expected log earnings that is not elsewhere present in the flow utility equation. I follow Arcidiacono et al. (2016) in specifying that work experience and calendar time dummies do not enter the flow utility except through expected log earnings. Likewise, the employment probabilities enter the flow utility, and identification of the disutility of unemployment is aided by excluding the local unemployment rate and work experience from the flow utility equation.  \n\nFinally, identification of the employment probability parameters also requires the assumption of pre-commitment to work.  \n\n### B. Estimation of Earnings, Employment, and Utility Parameters  \n\nI estimate the parameters of the model using maximum likelihood and an iterative procedure know as the expectation-maximization (EM) algorithm. This is an algorithm that greatly simplifies the estimation of finite mixture models like the one I specify here. The key idea is that I can estimate each equation of the model separately, treating the latent type as given. I fully detail this estimation algorithm in Online Appendix Sections A.3.1-A.3.3.  \n\nUnder the simplification of the EM algorithm, estimation of the log earnings equation amounts to weighted ordinary least squares (OLS). The two employment probability equations—conditional on either employment or nonemployment in the previous period—simplify to weighted binary logits. The labor market forecasting equations for the local earnings level and local unemployment rate are each a system of 55 AR(1) equations that are estimated using equation-by-equation OLS.  \n\nEstimation of the flow utility parameters is much more involved than the other parameters in the model. This is because the value function in Equation 2 is a recursive object, and I would need to solve it at each iteration of the maximum likelihood estimation algorithm. Rather than pursue this strategywhich would be computationally infeasible for my model—I break the recursion by using two separate simplification tools that are closely related: (i) conditional choice probabilities (CCPs; see Hotz and Miller 1993) and (ii) finite dependence (see Arcidiacono and Miller 2011, 2019). Conditional choice probabilities make use of a function mapping future value terms from the individual's dynamic programming problem into the probability of making a discrete choice. Finite dependence allows the researcher to formulate the recursive future value terms into a finite sequence of future payoffs. Together, the two strategies yield substantial computational savings by eliminating the need to solve the dynamic programming problem using backwards recursion.  \n\nUnder the simplification of CCPs and finite dependence, estimation of the recursive flow utility parameters reduces to a multistage static problem, which can be estimated using a McFadden (1974) conditional logit model with an adjustment term that captures the future value associated with each alternative.  \n\n## V. Empirical Results  \n\nI discuss estimates of employment probabilities, earnings, and unobserved types. I then use the estimates to compute implied moving costs and amenity values. The results show that labor market frictions are especially hindering to employed workers, who see on average a 20 percentage point lower likelihood of finding a job after a move. The results also show that moving costs are large, with an average net present value on the order of $-\\$400,000$ . Combined, these two factors inhibit worker flows across labor markets, thus granting market power to firms in sectors where workers have few within-location employment options.  \n\n### A.Employment Probabilities, Earnings, and Unobserved Types  \n\nI begin by discussing the estimated employment probabilities and their evolution over the business cycle, as reported in Table 4. This table lists the estimates of separate binary logits that predict the probability of being employed conditional on previous employment status. I present the estimates for two different specifications: no unobserved heterogeneity and two unobserved types.24 The results confirm the findings in Section II.B. The employed are more shielded from local economic downturns, but employed movers face a steep employment penalty (=20 percentage points) in the new location.25 This employment penalty for employed movers relative to nonemployed movers indicates that search frictions are a hindrance for the employed. An additional finding from the structural model is that there is comparative advantage in job-finding based on employment status. That is, type 1 workers are much more likely than type 2 workers to stay employed, but are much less likely to be hired from nonemployment.  \n\nTable 5 presents estimates of the structural log earnings equation. The main takeaway is that type 1 workers are more productive when employed, as they earn a wage premium of 67 log points over type 2 workers.  \n\nAs discussed in Section IV.A, unobserved types play a crucial role in accounting for unobservable characteristics and increasing the plausibility of the structural model. By virtue of it being a random effect, the unobserved type is uncorrelated with the model's time-invariant state variables. However, it may be correlated with time-varying state variables (such as work experience) or other information in the SIPP that is not included in the model, such as industry, occupation, marital status, home ownership status, or years of completed education.  \n\nWithout the ability to include measurements of cognitive or noncognitive skills (because the SIPP does not collect information on these), the interpretation of the unobserved type must come from the equations where it enters in the model. The earnings equation indicates a substantial earnings premium for type 1 workers, and the employment probability equations indicate that type 1 workers are more likely to remain employed. Coupled with the flow utility parameter estimates in Table 6 (which indicate that type 1 workers are more mobile), this suggests that type 1 workers possess higher levels of cognitive and/or noncognitive skills than type 2 workers.26 The fact that type 1 workers have a comparative advantage in remaining employed could also reflect the variety of industries or occupations in which they participate. If type 1 workers tend to work in industries or occupations with connections, being employed would open doors to other offers, but it may be difficult to get an offer if unemployed.  \n\n<html><body><table><tr><td rowspan=\"6\">2 Types 1 Type</td><td rowspan=\"8\">Prev. Nonemployed Prev. Employed Prev. Employed</td><td rowspan=\"8\">SE Coeff. SE Variable</td><td>0.2264</td><td>0.0087 0.0221 0.0111 0.1572</td><td>0.0429 9,949 一</td></tr><tr><td>0.5035*** Coeff. 0.2241 0.0092 E</td><td>0.0366*** -0.0937*** -0.5751*** -0.0310 0.2359</td><td rowspan=\"2\">0.0105 0.1300 0.0400</td></tr><tr><td>0.0211 0.9812*** 0.0847*** -0.1224***</td><td>30,898 -0.0342*** -1.0483*** 0.7958***</td></tr><tr><td rowspan=\"4\">Prev. Nonemployed SE Coeff.</td><td></td><td rowspan=\"4\">0.1557 9,949</td></tr><tr><td>0.2237 0.0086 0.0219 0.0110</td></tr><tr><td>0.0359*** -0.0922*** 0.2566 -0.0285 0.1929</td></tr><tr><td>0.2220 0.0091 0.0208 0.0104 0.1280 1.3056*** 0.0858***</td></tr><tr><td colspan=\"2\">Coeff. Constant</td><td>30,898 -0.1228*** -0.0314*** -0.9257*** Lagged local unempl. rate Location fixed effects Unobserved type 1</td></tr></table></body></html>  \n\nTable5 Structural Earnings Equation Estimates   \n\n\n<html><body><table><tr><td rowspan=\"2\">Parameter</td><td colspan=\"2\">1 Type</td><td colspan=\"2\">2 Types</td></tr><tr><td>Coeff.</td><td>SE</td><td>Coeff.</td><td>SE</td></tr><tr><td>Constant</td><td>7.5708***</td><td>0.0673</td><td>7.2074***</td><td>0.0470</td></tr><tr><td>Experience</td><td>0.0432***</td><td>0.0015</td><td>0.0411***</td><td>0.0010</td></tr><tr><td>Experience2/100</td><td>-0.0595***</td><td>0.0033</td><td>-0.0575***</td><td>0.0023</td></tr><tr><td>Unobserved type1</td><td></td><td></td><td>0.6773***</td><td>0.0039</td></tr><tr><td></td><td></td><td></td><td></td><td></td></tr><tr><td>Location-timefixedeffects</td><td>11,404</td><td></td><td>11,404</td><td></td></tr><tr><td>Persons Observations</td><td>29,238</td><td></td><td>29,238</td><td></td></tr></table></body></html>\n\nNotes: Reported numbers are coefficients from an OLS log earnings regression conditional on full-time employment and observing earnings. See footnote (a) of Table 1 for complete details on this subsample. $^{*}p<0.10$ $**_{p<0.05}$ $***}p<0.01$  \n\n### B. Moving Costs and Amenity Values  \n\nTable 6 presents the flow utility parameter estimates, which can be used to compute moving costs and amenity values. The highlight of this table is that both employed and type 1 workers have lower moving costs. This is because a positive coefficient indicates a cost that is smaller in magnitude because the fixed cost of moving is a large and negative number. It is somewhat surprising that the employed have lower moving costs, given that Figure 1 showed that these workers are less mobile than the nonemployed. This apparent contradiction is resolved by the findings in Section V.A that showed that the employed face a greater degree of search frictions when moving. Workers? movement may be inhibited either by search frictions or moving costs. My results highlight the asymmetry in these two inhibitors based on whether the worker is currently employed.  \n\nThe finding of lower moving costs among type 1 workers is consistent with other studies that have found that cognitive and noncognitive abilities are correlated with migration—that is, those who are more productive in the labor market also have lower moving costs (Bitikofer and Peri 2021). This is because type 1 workers have much higher earnings and hence are likely to have greater endowments of abilities, although this claim is impossible to evaluate in the SIPP due to a lack of measurements of abilities. In other aspects, the flow utility parameter estimates conform to economic theory and the previous literature.27  \n\nTable6 Structural ChoiceEquationEstimates   \n\n\n<html><body><table><tr><td rowspan=\"2\">Parameter</td><td rowspan=\"2\">Symbol</td><td colspan=\"2\">1 Type</td><td colspan=\"2\">2 Types</td></tr><tr><td>Coeff.</td><td>SE</td><td>Coeff.</td><td>SE</td></tr><tr><td>Job&locationpreferences</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>Expectedlogearnings</td><td>(Yo)</td><td>0.916**</td><td>0.397</td><td>1.001**</td><td>0.412</td></tr><tr><td>Home production benefit</td><td>(Y1)</td><td>-0.902</td><td>3.477</td><td>11.333***</td><td>3.453</td></tr><tr><td>Search cost</td><td>(Y2)</td><td>-1.195***</td><td>0.069</td><td>-1.008***</td><td>0.070</td></tr><tr><td>Birth state bonus</td><td>(Y3)</td><td>0.207***</td><td>0.072</td><td>0.210***</td><td>0.072</td></tr><tr><td>Birth division bonus</td><td>(Y4)</td><td>-0.002</td><td>0.073</td><td>-0.003</td><td>0.073</td></tr><tr><td>Switching costs</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>Fixed cost</td><td>(012 - 08)</td><td>0.335**</td><td>0.127</td><td>0.910***</td><td>0.126</td></tr><tr><td>Age</td><td>(013 - 09)</td><td>-0.095***</td><td>0.006</td><td>-0.106***</td><td>0.006</td></tr><tr><td>Age~/100</td><td>(014 - 010)</td><td>0.109***</td><td>0.008</td><td>0.121***</td><td>0.008</td></tr><tr><td>Unobserved type 1</td><td>(015 - 011)</td><td></td><td></td><td>-0.746***</td><td>0.019</td></tr><tr><td>Moving costs</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>Fixed cost</td><td>(00)</td><td>-3.148***</td><td>0.361</td><td>-3.165***</td><td>0.362</td></tr><tr><td>Distance (1,000 miles)</td><td>(01)</td><td>-2.063***</td><td>0.078</td><td>-2.066***</td><td>0.078</td></tr><tr><td>Distance</td><td>(02)</td><td>0.369***</td><td>0.025</td><td>0.369***</td><td>0.025</td></tr><tr><td>Age</td><td>(03)</td><td>-0.094***</td><td>0.018</td><td>-0.101***</td><td>0.018</td></tr><tr><td>Age²/100</td><td>(04)</td><td>0.056**</td><td>0.023</td><td>0.063***</td><td>0.023</td></tr><tr><td>Employedt-1</td><td>(05)</td><td>0.197*</td><td>0.110</td><td>0.252**</td><td>0.110</td></tr><tr><td>Unemployed-1</td><td>(06)</td><td>-0.230*</td><td>0.128</td><td>-0.239*</td><td>0.129</td></tr><tr><td>Unobserved type 1</td><td>(0-)</td><td></td><td></td><td>0.256***</td><td>0.045</td></tr><tr><td>Pr(type = 1)</td><td>(πr)</td><td>N/A</td><td></td><td>0.4926</td><td></td></tr><tr><td>Observations</td><td></td><td>50,415</td><td></td><td>50,415</td><td></td></tr><tr><td>Persons</td><td></td><td>16,648</td><td></td><td>16,648</td><td></td></tr><tr><td>Discount factor</td><td>(β)</td><td>0.9</td><td></td><td>0.9</td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr></table></body></html>\n\nNotes: Reported numbers are flow utility parameter estimates from the dynamic choice model detailed in Online Appendix Section A.1. Estimates of location-specific amenities (the $\\mathfrak{X}_{\\ell}\\mathrm{s}$ are not reported due to Census Bureau rules regarding disclosure risk. $^{*}p<0.10$ $^{**}p<0.05$ $***_{p<0.01}$  \n\nUsing the parameter estimates in Table 6, I can calculate the monetary value of moving costs and amenity values. The expected earnings parameter can be used to convert utility to money and thus to express the structural parameter estimates in monetary units. I provide complete details in Online Appendix Section A.4 on how this is done. It is also important to note that these moving cost estimates represent the moving costs faced by the average individual, not the marginal individual (that is, not the person who is just indifferent between staying and moving). In Table 7, I present sample moving costs by previous employment status and unobserved type in two forms: net present value and percentage equivalent of per-period earnings. The latter form can be used to compare the results with other papers in the dynamic migration literature, while the former can be used to compare the results with other papers that have calculated moving costs in terms of willingness to pay.  \n\n<html><body><table><tr><td rowspan=\"8\">Monetary Value</td><td rowspan=\"8\">Unemployed Type 2 Employed Unemployed Type 1 Employed Utility Component</td><td rowspan=\"8\">Panel A: Net Present Value (US$)</td><td>-140,023 -459,270 -650,115 -358,186</td></tr><tr><td>-116,777 -416,095 -597,202 -327,841</td></tr><tr><td>23,356 91,603 57,328 -127,749 -436,458 -622,158 -342,163</td><td>-37.3 -112.8 -160.8 -128.0</td></tr><tr><td>-105,095 -394,446 -570,671 -312,595</td><td>-30.6 -101.9 -147.5 -116.9</td></tr><tr><td></td><td></td></tr><tr><td>Average mover, New York to Los Angeles Panel B: Percentage of Flow Earnings</td><td>Range of local amenities</td></tr><tr><td></td><td>Average mover, 500-mile move SD of local amenities Amenities</td></tr><tr><td>Young mover, New York to Los Angeles Average mover, 500-mile move Range of local amenities Fixed cost of moving SD of local amenities Birth state bonus Moving costs Amenities</td><td>Fixed cost of moving Moving costs</td></tr></table></body></html>  \n\nIn terms of net present value, the fixed cost of moving ranges from $-\\$105,000$ for an employed type 1 person to $-\\$140,000$ for an unemployed type 2 person. The moving cost evaluated at the average person's characteristics and for the average move path ranges from $-\\$394,000$ to $-\\$459,000$ . These figures are similar in magnitude to those reported in Kennan and Walker (2011), Bishop (2012), and Bartik (2018).28 Importantly, the monetary value of the moving cost reflects psychological costs of moving (for example, acclimating to a new location or leaving behind friends and family) in addition to monetary costs (for example, costs to procure a moving truck or close on a mortgage). In terms of percentage of flow earnings, the fixed cost of moving is between $-30$ percent and $-40$ percent, meaning that a person would not be willing to move unless they received at least a 30-40 percent increase in earnings in perpetuity. For the average move, this number is above 100 percent. Kosar, Ransom, and van der Klaauw (2021) find similar magnitudes, although their model is static.  \n\nIn addition to moving costs, I compute amenity values and find them to be economically significant, but not nearly as large as moving costs. The results indicate that a one standard deviation increase in local amenities has a net present value of about $\\$23,000$ , while moving from the bottom to the top of the amenity distribution would be worthmore than $\\$91,000$ . Preferences for birth state proximity are in between these two values at about $\\$57,000$ . This value partly explains why such a high fraction of individuals in the data are observed to be living in their birth state.  \n\nOne might wonder why the estimated moving costs are so large. The primary explanation is that there is a weak relationship between expected earnings and observed moves. Salary is just one of a list of many potential reasons for moving, and although the elasticity of earnings is positive (as predicted by economic theory), the moves observed in the data on average are not strongly related to increases in expected earnings. Additionally, the moving cost represents the cost faced by the average individual if they were forced to move to an arbitrary location in an arbitrary time period, and the current model assumes that individuals consider moving to each location in every period.29 This assumption is likely unrealistic, since moving is only salient when certain events in life trigger a move (for example, pursuit of education, change of job, change of household structure, health of family members, etc.). For recent work that incorporates this feature, see Schluter and Wilemme (2018) and Schmutz and Sidibé (2019). Even if my estimated moving costs are overstated, it is still the case that preferences for nonmarket amenities and labor market frictions reduce mobility across labormarkets.  \n\n## VI. Model Fit and Counterfactual Simulations  \n\nIn this section, I verify that the structural model fits the data well and then discuss the results obtained from counterfactual simulations of the model. The results of these simulations illustrate the extent to which workers remain in their labor market in response to a variety of shocks, and hence the extent to which monopsony power may generally operate. I also calibrate a model of firm choice to illustrate the effect of switching costs on a firm's labor supply elasticity.  \n\n### A.Model Fit  \n\nIt is crucial to check the fit of the model to ensure that the model-based counterfactuals are credible. In Tables 8 and 9, I show migration probabilities and employment transitions in the model and in the data. Panel A of Table 8 shows how migration varies by previous employment status and calendar time. The model matches these differences well over adjacent time periods. Migration probabilities over previous employment crossed with age and distance are shown in Panels B and C of this table. The model and data also match up well along these dimensions.  \n\nTable 9 compares employment transitions across successive time periods in the data and model, conditional on migrating or staying. Panel A compares employment transition rates conditional on migrating. These match up very closely, with the exception of remaining out of the labor force for nonparticipants. This is likely due to the fact that, in the data, there are relatively few nonparticipant movers who remained out of the labor force after moving. Panel B compares these transitions conditional on staying in a location. Again, the data and model match up well.  \n\nI present the model fit for adjacent time periods—-and not longer horizons——-because the counterfactual simulations also only cover adjacent time periods. The reason for only considering counterfactuals of this sort stems from how the model is estimated. The CCP method explained in Section IV.B eliminates the need to solve the value function. It also allows the future value terms to not be driven by assumptions about how expectations are formed far out into the future. The downside is that these future value terms are not valid in counterfactual scenarios that go beyond $t+1$ .Counterfactuals covering a longer time period would require fully solving the value function, which in this case is computationally infeasible.  \n\n### B. Counterfactual Simulations  \n\nNow that I have established that the model fits the data well, I discuss counterfactual simulations of the model that further illustrate the importance of moving costs and search frictions. To get a sense of the degree to which workers would migrate, I simulate the migration response to five different counterfactual policies of 25-year-olds who were not born in the location. I examine heterogeneity in migratory response by separately analyzing each unobserved worker type living in two artificial cities—one with very desirable amenities and the other with very undesirable amenities.30 The five policies I  \n\nTable8 ModelFit:Observedvs.PredictedMigrationProbabilities   \n\n\n<html><body><table><tr><td rowspan=\"2\">t-1Employment Status</td><td>2004-2008</td><td>2009-2013</td><td></td><td>All</td><td></td></tr><tr><td>Data Model</td><td>Data</td><td>Model Data</td><td>Model</td><td></td></tr><tr><td colspan=\"5\">Panel A: Migration Probabilities by Calendar Time and t --1 Employment Status</td></tr><tr><td></td><td></td><td>1.28% 1.24%</td><td>1.29% 1.29%</td><td></td><td></td></tr><tr><td>Employed Unemployed</td><td>1.30% 1.33% 1.21% 1.25%</td><td>1.15% 1.10%</td><td>1.19%</td><td>1.19%</td><td></td></tr><tr><td>Outoflaborforce</td><td>1.88% 1.73%</td><td>1.52% 1.66%</td><td>1.69%</td><td>1.70%</td><td></td></tr><tr><td>Overall</td><td>1.14% 1.27%</td><td>1.38% 1.22%</td><td>1.25%</td><td>1.25%</td><td></td></tr><tr><td></td><td>Employed</td><td>Unemployed</td><td>Out of LF</td><td></td><td>All</td></tr><tr><td>Age Range</td><td>Data Model</td><td>Data</td><td>Model Data</td><td>Model</td><td>Data Model</td></tr><tr><td colspan=\"6\">Panel B: Migration Probabilities by Age and t-1 Employment Status</td></tr><tr><td>18-25</td><td>2.31% 2.11%</td><td>2.54% 3.62%</td><td>3.37%</td><td>3.31%</td><td>2.52% 2.84%</td></tr><tr><td>26-35</td><td>1.90% 1.65%</td><td>2.31% 2.32%</td><td>1.97%</td><td>2.13%</td><td>2.00% 1.86%</td></tr><tr><td>36-45 46-55</td><td>1.00% 1.20%</td><td>1.57% 1.42%</td><td>1.23%</td><td>1.30%</td><td>1.13% 1.25%</td></tr><tr><td></td><td>0.80% 0.82%</td><td>1.09% 0.85%</td><td>0.88%</td><td>0.84%</td><td>0.86% 0.83%</td></tr><tr><td colspan=\"2\">Employed</td><td>Unemployed</td><td>Out of LF</td><td></td><td>All</td></tr><tr><td>Distance (Miles)</td><td>Data Model</td><td>Data Model</td><td>Data</td><td>Model</td><td>Data Model</td></tr><tr><td colspan=\"6\">Panel C: Migration Probabilities by Distance Migrated and t -1 Employment Status</td></tr><tr><td>0-500</td><td>0.72% 0.70%</td><td>0.68%</td><td>0.65% 0.92%</td><td>0.94%</td><td>0.72% 0.70%</td></tr><tr><td>501-1,000 1,001-1,500</td><td>0.31% 0.35%</td><td>0.29% 0.33%</td><td>0.41%</td><td>0.45%</td><td>0.31% 0.35%</td></tr><tr><td></td><td>0.13% 0.13%</td><td>0.10% 0.12%</td><td>0.20%</td><td>0.17% 0.13%</td><td>0.13%</td></tr><tr><td>1,501-2,000</td><td>0.07% 0.05%</td><td>0.06% 0.05%</td><td>0.11%</td><td>0.07%</td><td>0.07% 0.05%</td></tr><tr><td>2,001+</td><td>0.06% 0.05%</td><td>0.07% 0.04%</td><td>0.05%</td><td>0.06%</td><td>0.06% 0.05%</td></tr></table></body></html>\n\nNotes: All numbers in this table correspond to migration probabilities (multiplied by 100 and expressed as percentages). Data probabilities consist of conditional means of an indicator for migration. Model probabilities consist of conditional means of the predicted probability of leaving the current location.  \n\nTable9 Model Fit:EmploymentTransitions by Migration Status   \n\n\n<html><body><table><tr><td></td><td colspan=\"6\">Period t</td></tr><tr><td></td><td colspan=\"3\">Data</td><td colspan=\"3\">Model</td></tr><tr><td>Period t-1</td><td>E</td><td>n</td><td>N</td><td>E</td><td>n</td><td>N</td></tr><tr><td colspan=\"7\">Panel A: Employment Transitions Conditional on Migrating</td></tr><tr><td>Employed (E)</td><td>70.98%</td><td>22.69%</td><td>6.33%</td><td>71.99%</td><td>22.26%</td><td>5.75%</td></tr><tr><td>Unemployed (U)</td><td>41.40%</td><td>46.50%</td><td>12.10%</td><td>45.06%</td><td>44.77%</td><td>10.17%</td></tr><tr><td>Out oflaborforce (M)</td><td>16.52%</td><td>17.39%</td><td>66.09%</td><td>13.88%</td><td>12.58%</td><td>73.54%</td></tr><tr><td colspan=\"7\">Panel B: Employment Transitions Conditional On Staying</td></tr><tr><td>Employed (E)</td><td>86.92%</td><td>9.86%</td><td>3.23%</td><td>86.45%</td><td>9.83%</td><td>3.71%</td></tr><tr><td>Unemployed (U)</td><td>36.33%</td><td>49.75%</td><td>13.93%</td><td>38.09%</td><td>49.60%</td><td>12.31%</td></tr><tr><td>Out of labor force (M)</td><td>10.81%</td><td>10.41%</td><td>78.78%</td><td>10.56%</td><td>12.22%</td><td>77.21%</td></tr></table></body></html>  \n\nNotes: All numbers in this table correspond to employment transition probabilities (multiplied by 100 and expressed as percentages). Data probabilities consist of conditional means of employment transition by migration status. Model probabilities consist of conditional means (by employment status) of the predicted conditional probability of making an employment transition (conditional on leaving or staying).  \n\nexamine are: two separate shocks to local expected earnings, two separate shocks to the local unemployment rate, and a moving subsidy worth 10 percent of the fixed cost of moving $\\mathbf{\\Psi}\\approx\\mathbb{S}10$ , 000 in net present value). For earnings and unemployment, I consider, respectively, a purely localized shock and a shock that is spatially correlated (but originating in the current location).31 For reasons discussed above, I only examine temporary counterfactual policies. That is, each policy is in effect for only one calendar year. However, because of the autocorrelated structure of some components of the model, the effect of each counterfactual policy may not be temporary.  \n\nIfocus my discussion on the impact of the policies on out-migration of young workers who were not born in the impacted location because these are the workers who are most responsive to such policies. As such, the migration responses I document are upper bounds on the population-level average response. Repeating the exercise for older workers or for workers born in the origin location would result in much lower responses because these other groups are more tied to their current location.  \n\nThe results of the simulations are reported in Figure 2, which shows the change in outmigration probability for each policy. Baseline predicted out-migration rates for each city and employment group are listed just above the horizontal axis.32 The first four bars in each panel report the simulated response to independent and correlated adverse shocks to earnings and employment in each location, while the last bar reports the moving subsidyresponse.33  \n\n![](images/bdecee358ec5b518cd9bec93ea327809c5c07f629b888d328c652965c246bf02.jpg)  \n\nThe key result from Figure 2 is the difference in behavior between employed and unemployed workers when faced with unemployment shocks (the third and fourth bars).34 This difference stems from the difference in employment probabilities that these groups face when moving, and it highlights the importance of labor market frictions in explaining worker mobility across labor markets. Employed workers are more likely to stay in their current location when faced with either a localized or correlated shock, whereas the opposite is true for unemployed workers. 35  \n\nIn addition to the importance of labor market frictions, Figure 2 also shows the role of moving costs in explaining migration behavior. The last bar of each panel of Figure 2 reports the simulated impact of a moving cost subsidy of approximately $\\$10,000$ (10 percent of the fixed cost of moving for employed type 1 workers). For all cities and employment statuses, out-migration rates increase, but are relatively modest. The increase in migration probability is on the order of 33 percent (or an increase of no more than five percentage points offa base of 15 percent).36  \n\n### C. Monopsony and Firm Switching Costs  \n\nThe results of these counterfactual simulations illustrate the importance of labor market frictions and moving costs in inhibiting the movement of workers across labor markets, even if workers are offered a sizable moving subsidy. However, they do not directly lead to an estimate of employer market power, such as a firm-level labor supply elasticity. To show how labor market frictions lead to monopsony power, I calibrate a model of firm choice that bears resemblance to my empirical model. The model combines elements of the so-called new classical monopsony literature (Card et al. 2018; Lamadon, Mogstad, and Setzler 2019; Azar, Berry, and Marinescu 2019; Manning 2021) with the s0-called modern monopsony literature (Manning 2003; Hirsch et al. 2022; Manning 2021). In \"new classical” models, workers have idiosyncratic tastes for wage and nonwage amenities offered by firms, while in “modern”' models, workers face frictions in changing jobs. Both preferences for nonwage amenities and frictions in changing jobs grant market power to employers.  \n\nI leave the complete details of the calibrated model to Online Appendix A.9. Briefly summarizing, the model has workers choosing a firm at which to work, with firms differentiated by wages and nonwage amenities. Firms are located in geographic markets, where there are 35 markets each with 20 firms. Workers have idiosyncratic preferences for a given firm, and workers also face costs to switching firms. I focus on switching costs because search frictions can be characterized as a type of switching cost. In the model, it is more costly for workers to switch to a firm in a different geographic market. The model allows me to calculate the labor supply elasticity of each firm, given calibrated parameter values. In Online Appendix Table A13 I report the implied average labor supply elasticity for an array of parameter values.  \n\nMy main findings are that the firm labor supply elasticity ranges from 0.4 to 3, depending on how responsive workers are to outside wages and on how costly it is for workers to change employers. Using the estimate of $\\hat{\\gamma}_{0}=1$ as reported in Table 6, this would imply that firms’ labor supply elasticity ranges from 0.4 to 1 over a reasonable range of switching costs. These numbers correspond to a wage markdown of 50-72 percent. Under the more reasonable assumption that workers are more responsive to outside wages within their location (for example, $\\gamma_{0}=3$ ), the labor supply elasticity ranges from 1 to 3. This implies a wage markdown of 25-50 percent, which is much more in line with other papers from the monopsony literature (Manning 2011).  \n\n## VIl. Conclusion  \n\nSearch frictions and switching costs are thought to grant monopsony power to incumbent employers because they reduce workers’ outside options. This study has investigated the extent to which labor market frictions and moving costs inhibit migration of American workers who are not college graduates. To quantify these two determinants of employer market power, I have developed and tractably estimated a rich dynamic structural model that incorporates search frictions.  \n\nI find that moving costs are substantial and that employed movers see a steep reduction in the job-finding rate after a move. Because migration decisions observed in the data are only loosely related to cross-location earnings differences, this implies that moving costs must be large. That is, workers have sizable preferences for market and nonmarket amenities, which weaken the role of earnings in the migration decision. Labor market frictions are also important. Even though the employed have lower moving costs, counterfactual simulations of the model show that they are less likely to move in response to a shock to the local unemployment rate. This is because they face a steep decline in employment likelihood if they move locations.  \n\nI use the model to simulate the effect of a moving subsidy offered to both employed and unemployed workers. Owing to large moving costs, the subsidy has low take-up rates $\\mathord{\\left(\\sqrt{\\mathord{\\left.\\right.}\\right.}\\right.}\\approx3-5$ percent). The unemployed are more likely to take the subsidy because they have roughly the same likelihood of employment whether or not they move.  \n\nTaking my model of location choice and extrapolating it to a model of firm choice illustrates that firm switching costs grant a substantial amount of market power to firms. In the absence of switching costs, a worker's wage markdown would fall by as much as One-half.  \n\n## References  \n\nAmior, Michael, and Alan Manning. 2018. “The Persistence of Local Joblessness.\" American Economic Review 108(7):1942-70.   \nArcidiacono, Peter, Esteban Aucejo, Arnaud Maurel, and Tyler Ransom. 2016. “College Atrition and the Dynamics of Information Revelation.\" NBER Working Paper 22325. Cambridge, MA: NBER.   \nArcidiacono, Peter, and Robert A. Miller. 2011. “\"Conditional Choice Probability Estimation of Dynamic Discrete Choice Models with Unobserved Heterogeneity Econometrica 79(6): 1823-67. -. 2019. “Nonstationary Dynamic Models with Finite Dependence?\" Quantitative Economics 10(3):853-90.   \nAzar, José, Steven Berry, and Ioana Marinescu. 2019. “Estimating Labor Market Power\" Working paper, IESE Business School.   \nBalgova, Maria. 2018. “\"Why Don't Less Educated Workers Move? The Role of Job Search in Migration Decisions.\" Working paper. Oxford, UK: Oxford University.   \nBartik, Alexander W. 2018. “Moving Costs and Worker Adjustment to Changes in Labor Demand: Evidence from Longitudinal Census Data. Working paper. Urbana-Champaign, IL: University of Illinois.   \nBaum-Snow, Nathaniel, and Ronni Pavan. 2012. \"Understanding the City Size Wage Gap.\" Review of Economic Studies 79(1):88-127.   \nBayer, Patrick, Nathaniel Keohane, and Christopher Timmins. 2009. “Migration and Hedonic Valuation: The Case of Air Quality?\" Journal of Environmental Economics and Management 58(1):1-14.   \nBhaskar, V., Alan Manning, and Ted To. 2002. “Oligopsony and Monopsonistic Competition in Labor Markets.\" Journal of Economic Perspectives 16(2):155-74.   \nBhaskar, V, and Ted To. 1999.\"Minimum Wages for Ronald McDonald Monopsonies: A Theory of Monopsonistic Competition.\" Economic Journal 109(455):190-203.   \nBhaskar, V., and Ted To. 2003. \"Oligopsony and the Distribution of Wages?\" European Economic Review 47(2):371-99.   \nBishop, Kelly. 2012. \"A Dynamic Model of Location Choice and Hedonic Valuation\" Working paper. St. Louis, MO: Washington University.   \nBlanchard, Olivier, and Lawrence F. Katz. 1992. \\*Regional Evolutions.” Brookings Papers on Economic Activity 1992(1):1-75.   \nBurdett, Kenneth, and Dale T. Mortensen. 1998. “Wage Differentials, Employer Size, and Unemployment.?\" International Economic Review 39(2):257-73.   \nBuitikofer, Aline, and Giovanni Peri. 2021. “How Cognitive Ability and Personality Traits Affect Geographic Mobility.\" Journal of Labor Economics 39(2):559-95.   \nCaliendo, Marco, Steffen Kinn, and Robert Mahlstedt. 2017. “Mobility Assistance Programmes for Unemployed Workers, Job Search Behaviour and Labour Market Outcomes.\" IZA Discussion Paper 11169. Bonn, Germany: IZA.   \nCard, David, Ana Rute Cardoso, Joerg Heining, and Patrick Kline. 2018. “Firms and Labor Market Inequality: Evidence and Some Theory.\" Journal of Labor Economics 36(S1):S13-S70.   \nCoate, Patrick. 2013. “Parental Influence on Labor Market Outcomes and Location Decisions of Young Workers.\" Working paper. Durham, NC: Duke University.   \nCoate, Patrick, and Kyle Mangum. 2019. \"Fast Locations and Slowing Labor Mobility\" Working Paper 19-49, Federal Reserve Bank of Philadelphia.   \nDiamond, Rebecca. 2016. The Determinants and Welfare Implications of US Workers Diverging Location Choices by Skill: 1980-2000\" American Economic Review 106(3):479-524.   \nFoote, Andrew, Michel Grosz, and Ann Stevens. 2019. “Locate Your Nearest Exit: Mass Layoffs and Local Labor Market Response ILR Review 72(1):101-26.   \nFox, Jeremy T. 2010. “Estimating the Employer Switching Costs and Wage Responses of Forward-Looking Engineers.?\" Journal of Labor Economics 28(2):357-412.   \nGardner, John, and Joshua R. Hendrickson. 2018. “If I Leave Here Tomorrow: An Option View of Migration When Labor Market Quality Declines.\"' Southern Economic Journal 84(3):786-814.   \nGlaeser, Edward, and David Mare. 2001. “Cities and Skills.\" Journal of Labor Economics 19(2):316-42.   \nGould, Eric. 2007. “Cities, Workers and Wages: A Structural Analysis of the Urban Wage Premium. Review of Economic Studies 74(2):477-506.   \nHandwerker, Elizabeth Weber, and Matthew Dey. 2019. “\"Variation in the Impact of Explicit Oligopsony by Occupation.\" Working paper. Washington, DC: Bureau of Labor Statistics.   \nHirsch, oris, Eke J Ja, Alan Maning, and Michal Oberfichr. 2022.“TheUban Wa Premium in Imperfect Labor Markets?\" Journal of Human Resources 57:S111-S136 (this issue). https://doi.org/10.3368/jhr.monopsony.0119-9960R1   \nHotelling, Harold. 1929. “Stability in Competition\" Economic Journal 39(153):41-57.   \nHotz, V. Joseph, and Robert A. Miller. 1993. \"Conditional Choice Probabilities and the Estimation of Dynamic Models.\" Review of Economic Studies 60(3):497-529.   \nH.R. 2755. 2015. \"American Worker Mobility Act of 2015:\" 114th Congress.   \nHuttunen, Kristina, Jarle Men, and Kjell G. Salvanes. 2018.\"Job Loss and Regional Mobility\" Journal of Labor Economics 36(2):479-509.   \nKarahan, Fatih, and Serena Rhee. 2017. “Population Aging, Migration Spillovers, and the Decline in Interstate Migration.\" Staff Report 699, Federal Reserve Bank of New York. URL https:// www.newyorkfed.org/medialibrary/media/research/staff _reports/sr699.pdf (accessed April 15, 2021).   \nKennan, John, and James R. Walker. 2011. “The Effect of Expected Income on Individual Migration Decisions.\" Econometrica 79(1):211-51.   \nKosar, Gizem, Tyler Ransom, and Wilbert van der Klauw. 2021. “Understanding Migration Aversion Using Elicited Counterfactual Choice Probabilities.\" Journal of Econometrics. Forthcoming.   \nLamadon, Thibaut, Magne Mogstad, and Bradley Setzler. 2019. “Imperfect Competition, Compensating Differentials and Rent Sharing in the U.S. Labor Market.?\" NBER Working Paper 25954. Cambridge, MA: NBER.   \nMangum, Kyle. 2015. \"Cities and Labor Market Dynamics.\" Working Paper 2015-2-3. Atlanta, GA: Georgia State University.   \nManning, Alan. 2003. Monopsony in Motion: Imperfect Competition in LaborMarkets. Princeton, NJ: Princeton University Press. .-. 2011. \"Imperfect Competition in the Labor Market.\" In Handbook of Labor Economics, Volume 4, Part B, ed. Orley Ashenfelter and David Card, 973-1041. New York: Elsevier. . 2021. “Monopsony in Labor Markets: A Review. ILR Review 74(1):3-26.   \nMarinescu, Ioana, and Roland Rathelot. 2018. “Mismatch Unemployment and the Geography of Job Search?\" American Economic Journal: Macroeconomics 10(3):42-70.   \nMcFadden, Daniel. 1974. “Conditional Logit Analysis of Qualitative Choice Behavior:\" In Frontiers in Econometrics, ed. Paul Zarembka, 105-42. New York: Academic Press.   \nMolloy, Raven S., and Abigail Wozniak. 2011. “Labor Reallocation over the Business Cycle: New Evidence from Internal Migration.?\" Journal of Labor Economics 29(4):697-739.   \nMonras, Joan. 2018. “Economic Shocks and Internal Migration.\" CEPR Discussion Paper 12977. London: Centre for Economic Policy Research.   \nMoretti, Enrico. 2012. The New Geography of Jobs. New York: Houghton Mifflin Harcourt.   \nMorten, Melanie, and Jaqueline Oliveira. 2016. “Paving the Way to Development: Costly Migration and Labor Market Integration.\" NBER Working Paper 22158. Cambridge, MA: NBER.   \nNotowidigdo, Matthew J. 2020. “The Incidence of Local Labor Demand Shocks.\" Journal of Labor Economics 38(3):687-725.   \nRansom, Michael R. 1993. “\"Seniority and Monopsony in the Academic Labor Market.\" American EconomicReview83(1):221-33.   \nRansom, Tyler. 2021. “tyleransom/frictions-JHR: Replication Files for Journal of Human Resources. Version 1.0. Zenodo. http://doi.org/10.5281/zenodo.4495571   \nSalop, Steven C. 1979. “Monopolistic Competition with Outside Goods.\" Bell Journal of Economics 10(1):141-56.   \nSastry, Narayan, and Jesse Gregory. 2014. \"The Location of Displaced New Orleans Residents in the Year after Hurricane Katrina.\" Demography 51(3):753-775.   \nSchlottmann, Alan M., and Henry W. Herzog Jr. 1981. “Employment Status and the Decision to Migrate.\" Review of Economics and Statistics 63(4):590-98.   \nSchluter, Christian, and Guillaume Wilemme. 2018. “A Dynamic Empirical Model of Frictional Spatial Job Search. Working paper. Marseille, France: Aix-Marseille University.   \nSchmutz, Benoit, and Modibo Sidibe. 2019. “Frictional Labour Mobility\" Review of Economic Studies 86(4):1779-826.   \nShenoy, Ashish. 2016. “Migration Decisions and Persistent Earnings Differentials: Evidence from Thailand.\" Working paper. Davis, CA: University of California.   \nStaiger, Douglas O., Joanne Spetz, and Ciaran S. Phibbs. 2010. “Is There Monopsony in the Labor Market? Evidence from a Natural Experiment.\" Journal of Labor Economics 28(2):211-36.   \nTopel, Robert H. 1986. “Local Labor Markets.\" Journal of Political Economy 94(3):S111-S143.   \nWillis, Robert J., and Sherwin Rosen. 1979. “Education and Self-Selection\" Journal of Political Economy 87(5, Part 2):S7-S36.   \nWilson, Riley. 2021a. “Moving to Economic Opportunity: The Migration Response to the Fracking Boom.\" Journal of Human Resources. Forthcoming. https://doi.org/10.3368/jhr.57.3 .0817-8989R2 . 2021b. “Moving to Jobs: The Role of Information in Migration Decisions.\" Journal of Labor Economics 39(4):1083-128.   \nWinters, John V. 2009. \\*Wages and Prices: Are Workers Fully Compensated for Cost of Living Differences? Regional Science and Urban Economics 39(5):632-43.   \nYagan, Danny. 2014. “Moving to Opportunity? Migratory Insurance over the Great Recession.\" Working paper. Berkeley, CA: University of California.   \nZabel, Jeffrey E. 1998. “An Analysis of Attrition in the Panel Study of Income Dynamics and the Survey of Income and Program Participation with an Application to a Model of Labor Market Behavior:\" Journal of Human Resources 33(2):479-506.  "
  },
  "md_schiavoneLaborMarketConcentration2023": {
    "reference_markdown": "# Labor market concentration and labor share dynamics for US regional industries  \n\nAnsel Schiavone1  \n\nDepartment of Economics and Finance,St. John's University,0oo Utopia Parkway,Queens,NY,United States of America  \n\n# ARTICLE INFO  \n\n# ABSTRACT  \n\nKeywords: Labor share Structural change Monopsony Labor markets  \n\nThis paper establishes labor market concentration as an important determinant of the total output share received by workers. The existing monopsony literature has established a link between employer power in the labor market and worker compensation. From this starting point, I identify and test a causal link between monopsony and labor shares at the industry level, utilizing regional data from the U.s. Economic Census and Bureau of Economic Analysis from 2002-2016. I find an increase in labor market monopsony is associated with labor share decline in several industries. Those industries with strongest negative concentration effects include those that have been identified in the literature as most responsible for driving aggregate labor share decline. The results suggest non-competitive labor markets are important for explaining inequality.  \n\n## 1. Introduction  \n\nThere are two primary contributions of this work. First, I develop a theoretical framework for linking the microeconomic foundations of labor monopsony - defined as a labor market with few employers - to the share of output received by labor at the industry-level. In doing so, I uncover two potential sources of bias that are present for any analysis of labor market concentration that does not utilize firm-level data: structural bias caused by firm reweighting, and reverse causality between labor shares and industry concentration. I propose a strategy to address these issues that exploits the lagged nature of wage-setting in labor markets. Second, utilizing the developed identification strategy, I test the hypothesis that labor market monopsony reduces labor share using US regional industry panel data for 2002-2016. 1 find that labor market concentration is a significant negative determinant of labor share among several important industries.  \n\nThe labor share is an important macroeconomic variable with respect to dynamics of income inequality, as it links the purely technological structure of production processes to the social question of income distribution among its contributors.2 While most individuals are suppliers of labor in some form, suppliers of capital are disproportionately high income (Piketty, 2014; Milanovic, 2016; Galbraith, 2012). The observed decline in US labor share over the past four decades implies a larger portion of total income is being distributed to high earners via capital income, thereby explaining in part the general rise in income inequality over the past fifty years.  \n\nThe existing literature surrounding US labor share decline has thus far paid little attention to the impact of competition (or lack thereof) among employers in labor markets. In this paper, I explore the role of regional labor market monopsony in the decline of industry labor shares. I establish and test a mechanism whereby increased labor market concentration decreases the labor share via wage suppression under conditions of monopsony. Using regional data, I find evidence of the posited mechanism across several industries, with particular acuteness in manufacturing — the industry most responsible for driving labor share decline at the national level. The findings of the paper highlight the importance of labor market conditions with respect to long-term labor share dynamics, an area that is overlooked in the existing literature.  \n\nThe remainder of the paper is structured as follows: Section 2 provides a review of the existing literature on labor share dynamics. Section 3 presents a simple model linking labor monopsony to industry labor shares, thereby identifying two potential sources of bias. Section 4 provides an introduction of the data, introduces a strategy to address endogeneity, and discusses estimation results. Section 5 concludes.  \n\n# A.Schiavone  \n\n## 2. Literature review  \n\nBeginning first with the mainstream economic interpretation, the neoclassical explanation of labor share decline revolves around the notion of capital-labor substitutability. Envisioning a well-behaved aggregate production function and competitive input markets, marginalist theory implies the labor share (as a residual of the capital share) is solely a function of the effective capital-labor ratio. This insight was first developed by Hicks (1932), preceding the sustained decline in the labor share since the 1980s, a period often referred to as the “neoliberal era\". Contemporary authors such as Karabarbounis and Neiman (2014) and Bentolila and Saint-Paul (2003) have seized upon this result to argue that the labor share is a decreasing function of the capital-labor ratio — necessitating an elasticity of substitution between capital and labor greater than unity. It follows that observed labor share decline is the result of a process of capital deepening (i.e. an increase in the capital-labor ratio). As to why capital deepening has occurred over the past few decades, Greenwood et al. (1997), Fisher (2006), and Karabarbounis and Neiman (2014) have argued that a decline in the price of investment goods relative to the efficiency of new forms of capital has led to capital deepening which, under an elasticity of substitution greater than one, results in labor share decline. Another explanation for capital deepening is the offshoring of labor intensive activities, leaving behind only capital intensive industries leading to a compositional rise in the capital-labor ratio (Karabarbounis and Neiman, 2014; Feenstra and Hanson, 1996). A more secular view is presented by Piketty (2014), who argues that an increase in the capital-income ratio and therefore a decrease in the labor share is a stylized fact of developed economies that is only reversed under crisis conditions.  \n\nWhile some authors (Bentolila and Saint-Paul, 2003; Fisher, 2006; Karabarbounis and Neiman, 2014) more or less support this “passive\" explanation provided by the neoclassical school, most hypotheses in the rapidly expanding literature rely on deviation from strict marginalist assumptions to explain labor share decline. One such argument that has garnered significant attention is that of the “superstar firm” presented by Autor et al. (2020). Briefly, the argument claims that highly productive firms across most sectors of the economy have become increasingly dominant in terms of their product market share. This increased concentration results in a greater ability of these “superstar firms\" to impose markups of final product price over cost of production, thereby resulting in a decreased share of overall output apportioned to labor. It is thus concentration in product markets (i.e. oligopolistic competition) that explains the decline in the labor share.3 Importantly, however, the argument assumes perfectly competitive input markets, and thus labor is assumed to be compensated equal to its marginal productivity, just as under the neoclassical formulation.  \n\nIt is unsurprising that the arguments presented in Autor et al. (2020) have garnered notoriety; increased product market concentration has become an undeniable feature of the US economy over recent decades, particularly in industries such as information and finance. However, the product market is only one of several markets where powerful firms can take advantage of non-competitive forces.4 Markets for inputs - specifically labor - are potentially subject to similar conditions as well. In an institution as complex as the labor market, these imperfections manifest in a variety of ways that span the map of economic disciplines. Most explicitly, the resurgent anti-trust literature has produced a wide body of research highlighting the impact of labor market monopsony on wages (Boal and Ransom, 1997; Ashenfelter et al., 2010; Steinbaum,  \n\n2019; Yeh et al., 2022; Azar et al., 2020). These works generally find that (1) monopsony in labor markets tends to be widespread, and (2) the existence of monopsony reduces wages. Both these results are inconsistent with the assumption of perfectly competitive input markets made by Autor et al. (2020). Curiously, existing labor share and monopsony literatures have paid little attention to each other, particularly at the regional level. While some recent works such as Brooks et al. (2021a,b) explore the impact of labor market monopsony on labor markdowns (a strong correlate of labor share), these analyses are performed for India and China, respectively, and consider only manufacturing industries. It is this gap at the intersect of these two bodies of work that this paper is intends to fill.  \n\nExplanations of labor share decline outside the neoclassical framework employ a variety of explanations generally predicated on institutionalfactors anddistributionalconflictswithin thelabor market. A common explanation for falling labor share is decreased prevalence of union membership (Young and Zuleta, 2018; Wallace et al., 1999; Fitchenbaum, 2011). The basic argument is that unions increase workers’ bargaining power, allowing labor to obtain a larger share of total output. Similar arguments have been made for other labor market institutions including minimum wage laws (Aaronson and French, 2007), labor market deregulations (Blanchard and Giavazzi, 2003), demographic changes (Hopenhayn et al., 2022), and the general traumatization of displaced workers in an increasingly polarized economy (Storm,2017).  \n\nAspects of heterodox theories of growth and distribution have as well been employed to explain labor share decline. Labor market “imperfections'5 are fundamental to Marxian and post-Keynesian models, which generally interpret labor markets as an arena of conflicting claims between workers and firms (Rowthorn, 1977; Lavoie, 1998; Hein and Stockhammer, 2011; Blecker and Setterfield, 2019). In a conflicting-claims framework, the bargaining position of labor is determined by institutional factors such as labor militancy, unionization, reserve armies, unemployment, employer concentration, etc. Wages are thus a product of class conflict rather than labor market equilibrium. The now-popularized model of Goodwin (1967) establishes a cyclical predator-prey relationship between the labor share and employment. While the original Goodwin framework is intended to model cyclical fluctuations in the labor share rather than persistent decline, authors such as Rada et al. (2022) have adapted the model to produce both cyclical and long-run labor share dynamics. An appealing feature of these models is their adherence to other stylized facts such as secular stagnation and moderation of prices in the neoliberal era.  \n\nThe notion of wage bargaining has also been incorporated into the mainstream literature, coming to form the neoclassical synthesis (McDonald and Solow, 1981; Carlin and Soskice, 1990; Manning, 1993; Flaschel and Franke, 1996). Such a framework focuses on the micro foundations of wage-setting in the labor market, while remaining roughly attached to the neoclassical theory of marginal product pricing. Again, this literature generally employs institutional explanations for short-run fluctuations in wages, despite its adherence to long-run marginalist wage determination (hence the adage that the synthesis is \"Keynesian in the short-run and neoclassical in the long-run\").  \n\nStructuralist approaches have provided valuable empirical insights from industry decompositions of labor share decline. Mendieta-Munioz et al. (2021) find that over the past four decades, labor share decline at the national level has been driven by declines in manufacturing and, to a lesser extent, information and wholesale trade. These findings are confirmed by Manyika et al. (2019) who argue that manufacturing, mining, information, and wholesale trade are primarily responsible for labor share decline over the past two decades. Importantly, both (Mendieta-Munoz et al.,2021) and Manyika et al.(2019) find that labor share decline is primarily a within-industry rather than between-industry phenomenon; that is, the decline in industry labor shares themselves (referred to by Mendieta-Munioz et al. (2021) as “decoupling” of industry wages and productivity) rather than an increase (decrease) in the relative weights of low (high) labor share industries, is primarily responsible for aggregate labor share decline.  \n\nFrom the empirical literature, one can take away the following points: first, the industries responsible for driving US labor share decline tend to be those with relatively high labor productivity growth. Wage-productivity decoupling in these “progressive” industries suggests that the mechanism(s) behind such declines are rooted within labor and/or product markets rather than compositional effects caused by between-industry reweighting. Such an observation is relevant for empirical investigation, as it implies explanations of aggregate labor share decline can be tested using industry-specific data. This has the added benefit of simplifying the econometrics, as well as more efficiently isolating potential mechanisms.  \n\nThe second takeaway is that manufacturing matters with respect to labor share dynamics. While much has been made by media, politicians, and academics alike about the US transition to a post-industrial economy, manufacturing still makes up a significant share of employment and value-added. In particular, manufacturing is still a major employer of low and middle skill workers, providing compensation well above alternative employment opportunities in services (Natalija and Pugacheva, 2019). Over the past four decades, the industry has been the largest contributor to labor share decline (Mendieta-Munoz et al., 2021).  \n\nThe growing body of research from disparate camps pointing to explanations of labor share decline rooted in labor market mechanisms6 must be taken as evidence that the convenient assumptions of perfectly competitive labor markets impede our understanding of distribution between labor and capital. This paper establishes labor market monopsony as an additional mechanism that fits alongside explanations that accurately reflect the stylized fact of imperfections within the market for labor.  \n\n## 3. Connecting monopsony and labor share at the industry level  \n\nI turn now to a theoretical analysis linking the micro framework of monopsony to industry labor share dynamics. Specifically, the proposed mechanism argues that regional labor markets with few employers create conditions unfavorable to workers, thereby undermining their ability to negotiate for compensation relative to productivity. While the impact of labor market concentration on individual wages has become a popular area of study in recent decades, the majority of such analyses are done using firm or individual-level data. As such, this body of literature does not provide insights for how labor market concentration impacts labor compensation in a macroeconomic industry perspective. Second, these studies deal primarily with the relationship between labor monopsony and wages, not worker share of income (labor share). This is understandable, as labor share is an economic variable primarily in used to analyze distribution at a macro level. To my knowledge, the contribution of this paper linking these two traditionally disparate fields is entirely novel.  \n\nThe analysis begins with Boal and Ransom (1997), generally considered the seminal work of the new monopsony literature. Specifically, I begin with the most generalized case of oligopsony under classic differentiation (see Boal and Ransom 1997; pp. 91). “Oligopsony” refers to a case of multiple profit-maximizing firms operating as employers in a non-competitive labor market. The term “classic differentiation\" describes a situation where firm characteristics and workers′ preferences are heterogeneous along dimensions of distance, working conditions, culture, etc. Under these conditions, each firm faces an individual labor supply that is decreasing in overall labor market concentration. Importantly, the assumptions of oligopsony (vs. pure monopsony) and classic differentiation (vs. homogeneous preferences) are more restrictive, implying that results of the proceeding analysis hold even if these assumptions are relaxed.  \n\nAssume each firm draws a random location from the geographic space, for which workers have heterogeneous preferences (i.e. workers prefer firms in closer proximity). Firm i's inverse labor supply is given:  \n\n$$\n\\omega_{i}=\\omega_{i}(\\delta);\\quad\\partial\\omega_{i}/\\partial\\delta<0\n$$  \n\nwhere $\\omega_{i}$ is firm wage and $\\delta$ is the degree of industry labor market concentration. Assuming firm i produces real output according a production function $R_{i}(L_{i})_{\\cdot}$ where $L_{i}$ is employment of $\\mathrm{firm}i$ , the firm's labor share is:  \n\n$$\n\\psi_{i}=\\frac{\\omega_{i}(\\delta)L_{i}}{R_{i}(L_{i})};\\quad\\partial\\psi_{i}/\\partial\\delta<0\n$$  \n\nNote, however, that $\\delta$ is itself a function of $L_{i}$ , as a change in firm $i$ employment effects industry concentration. $\\delta$ is also a function of all other firms' employment, $\\mathbf{\\delta}\\mathbf{{L}}_{\\gamma i}$  \n\n$$\n\\delta=\\delta(L_{i},L_{\\lnot i})\n$$  \n\nThe signs of $\\partial\\delta/\\partial L_{i}$ and $\\partial\\delta/\\partial\\pmb{L}_{\\neg i}$ depend on the particular industry employment structure. More on this below.  \n\nFor illustrative purposes, assume the industry consists of only two firms, $i$ and $j$ , which produce according to individual functions $R_{i}(L_{i})$ and $R_{j}(L_{j})$ . Firms simultaneously select optimal employment levels, $\\boldsymbol{L}_{i}^{*}$ and $L_{j}^{*}$ , according to optimization under Cournot competition (see Boal and Ransom 1997). For notational clarity, I suppress the asterisk moving forward, referring to optimal employment simply as $L_{i}$ and $L_{j}$ . The industry labor share is thus:  \n\n$$\n\\psi=\\frac{\\omega_{i}(\\delta(L_{i},L_{j}))L_{i}+\\omega_{j}(\\delta(L_{i},L_{j}))L_{j}}{R_{i}(L_{i})+R_{j}(L_{j})}\n$$  \n\nwhich may also be expressed as:  \n\n$$\n\\psi=\\theta_{i}\\psi_{i}+\\theta_{j}\\psi_{j}\n$$  \n\nwhere $\\theta_{i}$ and $\\theta_{j}$ are nominal value added shares of firms $i$ and $j_{:}$ respectively. Let the explicit form of $\\delta$ be given by the Herfindahl-Hirschman Index (HHI), such that:  \n\n$$\n\\delta=\\biggl(\\frac{L_{i}}{L_{i}+L_{j}}\\biggr)^{2}+\\biggl(\\frac{L_{j}}{L_{i}+L_{j}}\\biggr)^{2}\n$$  \n\nAssume that employment of $\\mathrm{firm}i$ is greater than that of $j$ ,such that $L_{i}>L_{j}$ . The comparative statics of Eq. (6) are thus:  \n\n$$\n\\begin{array}{l}{\\displaystyle\\frac{\\partial\\delta}{\\partial L_{i}}=\\frac{2L_{j}(L_{i}-L_{j})}{(L_{i}+L_{j})^{3}}>0}\\ {\\displaystyle\\frac{\\partial\\delta}{\\partial L_{j}}=\\frac{2L_{i}(L_{j}-L_{i})}{(L_{i}+L_{j})^{3}}<0}\\end{array}\n$$  \n\nEqs. (7) and (8) demonstrate the obvious result that in a two firm framework, a rise in labor market concentration can occur via an increase (decrease) in employment of the larger (smaller) firm. Deriving the comparative statics of Eq. (4) with respect to $L_{i}$ and $L_{j}$ yields:  \n\n$$\n\\frac{\\partial\\psi}{\\partial L_{i}}=\\frac{1}{R_{i}+R_{j}}\\bigg[\\bigg(\\frac{\\partial\\omega_{i}}{\\partial\\delta}L_{i}+\\frac{\\partial\\omega_{j}}{\\partial\\delta}L_{j}\\bigg)\\frac{\\partial\\delta}{\\partial L_{i}}+\\omega_{i}-\\psi\\frac{\\partial R_{i}}{\\partial L_{i}}\\bigg]\n$$  \n\n$$\n\\frac{\\partial\\psi}{\\partial L_{j}}=\\frac{1}{R_{i}+R_{j}}\\bigg[\\bigg(\\frac{\\partial\\omega_{i}}{\\partial\\delta}L_{i}+\\frac{\\partial\\omega_{j}}{\\partial\\delta}L_{j}\\bigg)\\frac{\\partial\\delta}{\\partial L_{j}}+\\omega_{j}-\\psi\\frac{\\partial R_{j}}{\\partial L_{j}}\\bigg]\n$$  \n\nEqs.(9) and (10) illustrate how changes in employment of either firm impact the industry labor share. A change in employment has two effects: a change in labor market concentration, which impacts the wages of both firms (\"concentration effect\"), as well as different levels of output and employment of the changing firm, transforming the relative weight of each firm in the industry (\"structural bias\"). The word “bias” is chosen purposefully. By definition, a change in labor market concentration requires changing employment levels by one or more firms. However, the impact on industry labor share due to firm reweighting is only tangentially related to changes in monopsony conditions.  \n\nRecall that under the assumption $L_{i}>L_{j}$ $\\partial\\delta/\\partial L_{i}>0$ and $\\partial\\delta/\\partial L_{j}<$ 0. Thus, the concentration effect is negative for Eq. (9) and positive for Eq. (10). This in turn implies that a rise in $\\delta$ ,either through an increase in $L_{i}$ or a decrease in $L_{j}$ (or both), will have a negative impact on the industry labor share via the concentration effect.  \n\nThe impact of structural bias requires significant attention. Note that R/ and s/, represent marginal unit cost forfirms and respectively, while $\\psi$ represents average unit cost for the industry. Under the simplifying assumption of constant returns to labor, $\\partial R_{i}/\\partial L_{i}=\\varepsilon_{i}$ and $\\partial R_{j}/\\partial L_{j}=\\varepsilon_{j}$ are constant values, such that $\\psi_{i}~=~\\omega_{i}/\\varepsilon_{i}$ and $\\psi_{j}~=~\\omega_{j}/\\varepsilon_{j}$ 7 Direction of the structural bias for firm i and $j$ thus depends on the sign of ${\\psi}_{i}\\mathrm{~-~}{\\psi}$ and $\\psi_{j}\\mathrm{~-~}\\psi$ , respectively. In other words, if the firm increasing employment has above (below) average labor share, the impact on the industry labor share will be positive (negative). The question as to whether large firms tend to have lower labor shares is not entirely settled. There is significant evidence in the labor market literature that firm size is a positive determinant of wages (Oi and Idson, 1999; Schmidt and Zimmermann, 1991; Zabojnik and Bernhardt, 2001; Black et al., 1999). The causes are attributed to a variety of mechanisms, including productivity matching between workers and firms, reducing monitoring costs via eficiency wages, and rent sharing through wage dispersal. However, these analyses deal only with the impact of firm size on wages, not labor share (a measure of wages relative to productivity). With respect to productivity differentials, there is again ample research supporting a positive relationship between labor productivity and firm size. The classic argument among industrial organization literature is that larger firms enjoy higher labor productivity due to economies of scale (Miller, 1978; Stigler, 1958). This interpretation has been affirmed by several empirical studies (De and Nagaraj, 2014; Tran et al., 2009; Idson and Oi, 1999). Autor et al. (2020) reverses the mechanism, arguing that certain “superstar’ firms achieve higher labor productivity due to technological advantages, leading them to obtain larger shares of industry employment and output. More recent research examines directly the question of firm size relative to labor share (Autor et al., 2020; Bockerman and Maliranta, 2012; Dorn et al., 2017). These works find substantial evidence that large firms tend to have lower labor shares relative to industry average. Thus, structural bias is most likely negative for $\\partial\\psi/\\partial L_{i}$ and positive for $\\partial\\psi/\\partial L_{j}$  \n\nThe comparative statics given by Eqs. (9) and (10) reveal an important insight with respect to the goal of extending monopsony from a microeconomic labor market mechanism to a determinant of macroeconomic distribution. Given that an increase in labor market concentration is associated with an increase in $L_{i}.$ decrease in $L_{j},$ orboth, the structural bias is likely to be of the same sign as the concentration effect. This is due to the fact that concentration is endogenous to individual firms’ employment levels. Thus, simply estimating a structural equationof $\\psi=f(\\delta)$ at the industry level risks biasing results toward the hypothesis that monopsony reduces industry labor share.  \n\nOf course, if researchers have access to firm-level data for an entire industry, structural bias can easily be removed. Unfortunately, such data is difficult to obtain. This is particularly true for the US, where the Bureau of Labor Statistics (BLS) restricts access to those approved under the Restricted Data Access Program.8 The focus thus turns to pursuit of a valid instrument capable of addressing this issue of endogenity. In Section 4.2, 1 develop one such approach using the lagging nature of the concentration effect on labor share.  \n\n## 4. Estimation  \n\n### 4.1. Data  \n\nData for labor shares and labor market concentration come from two sources. The first, from the Bureau of Economic Analysis (BEA), provides observations for compensation and output at the county industry level9 starting in 2001. These data are used to construct industry labor share measures, defined as the ratio of nominal compensation of employees1o over nominal output in the specified regional industry. The ten industries (and associated NAICS codes) analyzed include mining (11), construction (23), manufacturing (31-33), trade (42-45), transportation & warehousing (48-49), information (51), finance (52), professional $\\&$ business services (54-55), education & healthcare (61- 62), and miscellaneous services (71-81).11 The second dataset comes from the US Census County Business Patterns (CBP), and provides information concerning the distribution of firm size by county industry. Data are available for the NAICS industries described above, as well as for 3-6 digit NAICS sub-industries. Observations provide counts for the number of establishments in a county (sub-)industry within a particular employment bin size.12 To measure labor market concentration, I compute the Herfindahl-Hirschman Index (HHI) of firm employment shares for 3-digit county sub-industries, assuming each firm within a particular bin employs the mean number of workers. I then aggregate HHI to the 2-digit county industry level by computing the average of relevant county sub-industries weighted by employment share.13 The purpose for obtaining concentration measures at the 3-digit level is to more accurately capture the degree of concentration within skill-segmented labor markets. For example, if a particular sub-industry is highly concentrated and is also the largest employer within the industry, one would likely conclude that there is a high degree of concentration within the county-industry. However, by computing HHI at the 2-digit level, all firms are treated as homogeneous in terms of the type of labor they employ, and the degree of labor market concentration will appear less. In other words, the strategy of constructing measures of concentration from sub-industries allows for the possibility of significant differences in workers’ skill and compensation levels between  \n\nA.Schiavone  \n\n![](images/2b5ce10fba00a03a748a05e4f335d9857a9e4fa38f3aaade9559c5bc6b3651cf.jpg)  \nFig. 1. Map of commuting zones as defined by US Department of Agriculture.  \n\nsub-industries.14 CBP data is available starting in 1986. Unfortunately, beginning in 2017, observations for county industries with three or fewer firms are withheld to avoid disclosure of proprietary information. Thus, measures of labor market concentration after 2016 are unreliable, as any sub-industry with fewer than four firms is removed from the data.  \n\nThrough combination of these two datasets, I obtain ten panels of county industry labor share and labor market concentration for 3143 counties over the period 2001-2016.15 However, county-level grouping is undesirable, as it ignores the fact that many people commute between counties for work — something an investigation of regional labor markets should take into account. Following general practice among regional literature (Autor et al., 2020; Afonso and Venancio, 2016; Killian and Tolbert, 2019), I aggregate counties into 740 “commuting zones\" (CZ). CZs are geographic units generated by the US Department of Agriculture (USDA), designed to capture local economies and labor markets that do not necessarily conform to county boundaries. Counties that are not integrally linked to other counties are treated as independent CZs (see Fig. 1 for a map of CZs used in the estimation).  \n\nImportant implications associated with the use of CZ data should not be overlooked. By treating CZs as independent units of observations, I make the assumption that labor is largely immobile between regional labor markets in the short-run. CZs are constructed to be treated as such (Fowler et al., 2016), however, this assumption may be more or less valid depending on the macroeconomic variables of interest. Indeed, recent evidence from Carpenter et al. (2022) suggests that despite design intentions, use of CZs is not a panacea for addressing spatial autocorrelation, reinforcing the need for case-by-case testing and treatment. These issues are addressed in Section 4.2.  \n\nOther controls include union coverage, capital cost, import exposure, and unemployment rate. Union coverage as a percentage of private workforce by industry and by metropolitan area are available from the Union Membership and Coverage Database, developed and maintained by Hirsch and Macpherson (2004). Metropolitan regions are translated to commuting zones using National Bureau of Economic Research (NBER) crosswalks.16 I approximate CZ-industry union coverage by taking the simple average of industry and commuting zone rates.  \n\nI obtain measures of cost of capital from Bureau of Economic Analysis (BEA) Fixed Asset tables. I utilize data for net stock of private equipment by industry measured in historical prices and current prices to construct price indeces. Historical-cost valuation measures the value of fixed assets in the prices of the periods in which the assets were purchased new. Current-cost valuation measures the value of these assets in the prices of the given period, which are end of year for net stocks and annual averages for depreciation. To obtain price indexes, I divide current cost by historical cost, then divide by the aggregate GDP price index. This approach follows that of Elsby et al. (2013). With industry price indexes available at the more granular 3-digit NAICS sub-industries, I follow the method established by Autor et al. (2015) and Dorn et al. (2020) to approximate CZ-industry price indexes by computing the average across relevant sub-industries weighted by CZ sub-industry employment shares. These data are available only for information, manufacturing, and mining.  \n\nObservations for import exposure are obtained in a similar manner. Again following Elsby et al. (2013), import exposure is measured as the percent increase in value added necessary to satisfy US final demand for a given industry. These data are obtained from the US Bureau of Labor Statistics (BLS) Input-Output tables. These tables provide observations for both domestic and total requirements at the sub-industry level, the difference of which reflects the degree of import exposure (see Elsby et al. 2013 for details). To translate these measures to CZ-industry format, I take the average of relevant sub-industries’ import exposure weighted by their CZ shares of employment. These data are available only for manufacturing and mining.  \n\nFinally, I include the CZ unemployment rate as a control. Observations are obtained by averaging county unemployment rate weighted by industry employment shares for counties within a given Cz. County unemployment rates are obtained from BLS Local Area Unemployment Statistics.  \n\n![](images/9c30442d4caf6441c28baa2c5c1d69102d768e5d25e0e3b63db1525c6786acc4.jpg)  \nFig. 2. Kernel density estimates for CZ labor share by industry, 2002 vs. 2016.  \n\nDescriptive statistics of all variables are presented in Tables 1-3. A few observations are worth highlighting. First, distribution of median (and mean) industry labor share values at the CZ level corresponds closely with that of the national level. As highlighted by MendietaMunoz et al. (2021), service-based industries with generally high labor intensity and low productivity tend to exhibit higher labor shares. These include education & healthcare, professional & business services, and miscellaneous services. Conversely, those industries with higher capital intensity and labor productivity, such as manufacturing, mining, and information, tend to have lower labor shares. This paradigm that exists at the national level appears persistent at the Cz level as well. Kernel density estimates of CZ-industry labor shares for 2002 and 2016 are shown in Fig. 2.  \n\nWith respect to labor market concentration, those industries with highest median HHI across the entire panel are manufacturing (0.560), information (0.480), and mining (0.480). However, the standard deviation is also highest for these three industries (see Table 3 and Fig. 3). While service industries tend to have lower levels of average concentration, education & healthcare stands out as another industry with relatively high degree of labor monopsony (0.330). Interestingly, industries with highest initial median labor market concentration - manufacturing, information, and mining - also experience the greatest median labor share decline (see Fig. 4).  \n\nTurning now to the relationship between industry labor share and labor market concentration, the Pearson correlation coefficient between these two variables for the entire panel is $-0.247$ ,with statistical significance at the $1\\%$ level. Broken down by industry, all but information exhibit negative, statistically significant correlation coefficients.17 These preliminary statistics indicate a strong relationship between regional industry labor market monopsony and labor share. In the following section, I formalize an explicit test for the proposed causal mechanism.  \n\n### 4.2. Identification strategy  \n\nThe relationship of interest in is the impact of labor market monopsony on labor share at a regional industry level, as expressed in Eq. (4). In a linear form, the structural equation is:  \n\n$$\n\\psi_{k}=\\beta_{1}\\delta_{k}+\\epsilon_{k}\n$$  \n\n![](images/4ad5f343929656f7263cb33b2069689d796b32ab5c22b13b674066865dc30886.jpg)  \nFig. 3. Kernel density estimates for $\\mathrm{CZ}$ labor market concentration (HHI) by industry, 2002 vs. 2016.  \n\nwhere $\\psi_{k}$ and $\\delta_{k}$ are the labor share and labor market concentration of industry $I$ in region $k$ , respectively. For panel data, the contemporaneous relationship is:  \n\n$$\n\\psi_{k t}=\\beta_{1}\\delta_{k t}+\\pmb{\\beta}\\pmb{X}_{k t}+\\pmb{\\nu}_{k}+\\pmb{\\lambda}_{t}+\\epsilon_{k t}\n$$  \n\nwhere $\\pmb{X}_{k t}$ is a vector of additional explanatory variables derived from the literature, $\\pmb{v}_{k}$ is a vector of unobserved time-invariant covariates, and $\\lambda_{t}$ unobserved unit-invariant effects. To control for these unobserved effects, all estimations are run using two-way fixed effects, as is standard for panels with more than two time periods.  \n\nAs shown in Section 3, estimation of Eq. (12) will result in inaccurateestimateof $\\hat{\\beta}_{1}$ , since the coefficient captures both the concentration effect and structural bias. Furthermore, the estimation likely suffers as well from endogeneity caused by reverse causality; if firms' location choices are affected by capital's share of income (and by extension, rate of profit), labor market concentration will be impacted by regional labor shares as firms enter, exit, or relocate based on profit conditions.  \n\nTo address these concerns of bias, I propose a simple estimation strategy of instrumenting contemporary instances of $\\delta$ onlagged instances of itself. The motivation for such instrumentation is as follows: structural bias has an immediate contemporary impact on industry labor share due to firm reweighting (Taylor et al., 2016), while the impact of concentration has a lag (perhaps of multiple years) due to the staggered nature of wage setting (Taylor John, 1979). In other words, firm output adjusts instantaneously to a change in employment such that $\\begin{array}{r}{\\frac{\\partial\\theta_{i t}}{\\partial\\delta_{t}}^{\\star}\\neq0,\\frac{\\mathsf{\\check{\\partial}}\\theta_{i t}}{\\partial\\delta_{t-1}}=0,}\\end{array}$ 0i=0,..·，00t-n B = O, but the effects on labor market conditions have lingering impacts: $\\begin{array}{r}{\\frac{\\partial\\psi_{i t}}{\\partial\\delta_{t}}<0,\\frac{\\partial\\psi_{i t}}{\\partial\\delta_{t-1}}<0,...,\\frac{\\partial\\psi_{i t}}{\\partial\\delta_{t-n}}<0.}\\end{array}$ The structural two-stage estimable equation is thus:  \n\n$$\n\\begin{array}{r l}&{\\psi_{k t}=\\beta_{1}\\hat{\\delta}_{k t}+\\pmb{\\beta}\\pmb{X}_{k t}+\\pmb{\\nu}_{k}+\\lambda_{t}+\\epsilon_{k t}}\\ &{\\hat{\\delta}_{k t}=\\gamma_{1}\\delta_{k t-1}+\\dots+\\gamma_{n}\\delta_{k t-n}+\\mu_{k t}}\\end{array}\n$$  \n\nImportant to establishing confidence in the results is confirming instrument validity, as well as testing for rank condition (model underidentification) and weak identification. Overidentification is tested using the Sargan-Hansen test and subsequent Hansen $\\mathrm{J}$ statistic (Sargan, 1958, 1988; Hansen, 1982). Failure to reject the null hypothesis suggests joint validity of all instruments used. This test is only meaningful when the number of instruments is greater than the number of endogenous variables, or one in the case where $\\delta_{k t}$ is the sole endogenous variable. To test for underidentification, I perform the Kleibergen and Paap LM statistic, under which rejection of the null hypothesis implies that the model is identified, thereby satisfying the rank matrix condition. With respect to testing for weak instrumentation, I perform the Kleibergen and Paap Wald F statistic, which is valid when the assumption of i.i.d is dropped (more on this in a moment).18 While the Kleibergen and Paap Wald statistic lacks adjusted weak instrument critical values equivalent to those established by Stock and Yogo (2005) for the Cragg and Donald (1993) F statistic, the Staiger and Stock rule of thumb where $F<10$ implies weak instruments can be loosely applied. The lag structure of instruments for each industry estimation is selected based on which combination of one to three-year lags best satisfy requirements of a valid instrument. Estimations using the complete set of lagged instruments over three years are also performed.  \n\n![](images/5fa4a319ed48ed938ecd2adf247958818cfd74ec9a0005565dff5dbba44f8279.jpg)  \nFig. 4. Median labor market concentration vs. average labor share by industry; 2002-2016, two-year increments.  \n\n![](images/c8fc8c3d235be0c327008434e6ce7733c39e0186f0c7771e33b43fe2a9a0d610.jpg)  \nFig. 5. Moran I statistic for error term of Eq. (13) with no additional controls. Statistic value of 1 corresponds to perfect positive spatial autocorrelation, $^{-1}$ toperfectnegative spatial autocorrelation, and 0 to no spatial autocorrelation.  \n\nTable 1 Descriptive statistics, 2002.   \n\n\n<html><body><table><tr><td colspan=\"2\"></td><td>Labor share</td><td>Labor market HHI</td><td>Union coverage</td><td>Capital cost index</td><td>Import exposure</td><td>Unemployment rate</td></tr><tr><td rowspan=\"5\">Construction</td><td>Mean</td><td>0.600</td><td>0.140</td><td>4.760</td><td></td><td>-</td><td>5.620</td></tr><tr><td>Median</td><td>0.610</td><td>0.110</td><td>4.350</td><td></td><td></td><td>5.470</td></tr><tr><td>Min</td><td>0.180</td><td>0.000</td><td>3.440</td><td>-</td><td></td><td>2.200</td></tr><tr><td>Max</td><td>0.920</td><td>0.800</td><td>14.040</td><td></td><td></td><td>16.440</td></tr><tr><td>SD</td><td>0.130</td><td>0.110</td><td>1.300</td><td></td><td></td><td>1.650</td></tr><tr><td rowspan=\"5\">Ed.&Healthcare</td><td>Mean</td><td>0.790</td><td>0.340</td><td>6.790</td><td>-</td><td>-</td><td>5.620</td></tr><tr><td>Median</td><td>0.810</td><td>0.320</td><td>6.400</td><td></td><td></td><td>5.530</td></tr><tr><td>Min</td><td>0.270</td><td>0.020</td><td>4.700</td><td></td><td></td><td>2.280</td></tr><tr><td>Max</td><td>0.940</td><td>0.970</td><td>15.690</td><td>-</td><td></td><td>16.330</td></tr><tr><td>SD</td><td>0.080</td><td>0.180</td><td>1.390</td><td>-</td><td></td><td>1.610</td></tr><tr><td rowspan=\"5\">Finance</td><td>Mean</td><td>0.420</td><td>0.170</td><td>4.540</td><td>3.170</td><td>-</td><td>5.650</td></tr><tr><td>Median</td><td>0.410</td><td>0.140</td><td>4.100</td><td>2.890</td><td></td><td>5.500</td></tr><tr><td>Min</td><td>0.080</td><td>0.010</td><td>3.210</td><td>1.900</td><td></td><td>1.900</td></tr><tr><td>Max</td><td>0.740</td><td>0.800</td><td>15.950</td><td>4.810</td><td></td><td>16.140</td></tr><tr><td>SD</td><td>0.120</td><td>0.110</td><td>1.470</td><td>0.570</td><td></td><td>1.650</td></tr><tr><td rowspan=\"5\">Information</td><td>Mean</td><td>0.430</td><td>0.420</td><td>9.940</td><td>3.250</td><td></td><td>5.670</td></tr><tr><td>Median</td><td>0.430</td><td>0.410</td><td>9.820</td><td>3.480</td><td></td><td>5.500</td></tr><tr><td>Min</td><td>0.180</td><td>0.030</td><td>6.420</td><td>1.370</td><td>-</td><td>2.240</td></tr><tr><td>Max</td><td>0.620</td><td>1.000</td><td>18.520</td><td>3.650</td><td></td><td>16.340</td></tr><tr><td>SD</td><td>0.060</td><td>0.190</td><td>1.090</td><td>0.490</td><td></td><td>1.690</td></tr><tr><td rowspan=\"5\">Manufacturing</td><td>Mean</td><td>0.600</td><td>0.550</td><td>13.820</td><td>16.050</td><td>0.010</td><td>5.700</td></tr><tr><td>Median</td><td>0.610</td><td>0.560</td><td>13.920</td><td>16.970</td><td>0.000</td><td>5.570</td></tr><tr><td>Min</td><td>0.140</td><td>0.030</td><td>8.570</td><td>1.130</td><td>0.000</td><td>2.200</td></tr><tr><td>Max</td><td>0.990</td><td>1.000</td><td>19.230</td><td>23.350</td><td>0.260</td><td>16.220</td></tr><tr><td>SD</td><td>0.110</td><td>0.210</td><td>1.010</td><td>5.350</td><td>0.020</td><td>1.690</td></tr><tr><td rowspan=\"5\">Mining</td><td>Mean</td><td>0.320</td><td>0.440</td><td>14.420</td><td>2.450</td><td>0.220</td><td>5.770</td></tr><tr><td>Median</td><td>0.330</td><td>0.420</td><td>14.600</td><td>2.410</td><td>0.100</td><td>5.680</td></tr><tr><td>Min</td><td>0.010</td><td>0.090</td><td>7.450</td><td>1.130</td><td>0.000</td><td>2.410</td></tr><tr><td>Max</td><td>0.850</td><td>1.000</td><td>20.830</td><td>3.450</td><td>0.980</td><td>11.670</td></tr><tr><td>SD</td><td>0.180</td><td>0.200</td><td>1.180</td><td>0.750</td><td>0.250</td><td>1.540</td></tr><tr><td rowspan=\"5\">Misc. services</td><td>Mean</td><td>0.600</td><td>0.110</td><td>5.500</td><td>-</td><td></td><td>5.610</td></tr><tr><td>Median</td><td>0.610</td><td>0.090</td><td>5.210</td><td></td><td></td><td>5.470</td></tr><tr><td>Min</td><td>0.240</td><td>0.010</td><td>3.450</td><td></td><td></td><td>1.900</td></tr><tr><td>Max</td><td>0.900</td><td>0.580</td><td>14.650</td><td></td><td></td><td>16.340</td></tr><tr><td>SD</td><td>0.070</td><td>0.090</td><td>1.340</td><td></td><td></td><td>1.680</td></tr><tr><td rowspan=\"5\">Prof. business services</td><td>Mean</td><td>0.620</td><td>0.190</td><td>6.680</td><td>-</td><td></td><td>5.640</td></tr><tr><td>Median</td><td>0.640</td><td>0.170</td><td>6.440</td><td>-</td><td></td><td>5.460</td></tr><tr><td>Min</td><td>0.030</td><td>0.000</td><td>1.890</td><td></td><td></td><td>1.800</td></tr><tr><td>Max</td><td>1.000</td><td>0.910</td><td>17.890</td><td></td><td></td><td>16.470</td></tr><tr><td>SD</td><td>0.120</td><td>0.140</td><td>1.670</td><td></td><td>-</td><td>1.700</td></tr><tr><td rowspan=\"5\">Trade</td><td>Mean</td><td>0.560</td><td>0.220</td><td>4.030</td><td></td><td></td><td></td></tr><tr><td>Median</td><td>0.560</td><td>0.200</td><td>3.610</td><td>-</td><td></td><td>5.640 5.470</td></tr><tr><td>Min</td><td>0.230</td><td>0.010</td><td>2.940</td><td>-</td><td></td><td>1.800</td></tr><tr><td>Max</td><td>0.790</td><td>0.900</td><td>13.880</td><td>-</td><td></td><td>16.170</td></tr><tr><td>SD</td><td>0.060</td><td>0.140</td><td>1.360</td><td>-</td><td></td><td>1.750</td></tr><tr><td rowspan=\"5\">Trans.& Warehousing</td><td>Mean</td><td>0.620</td><td>0.290</td><td>14.360</td><td></td><td></td><td>5.780</td></tr><tr><td>Median</td><td>0.650</td><td>0.270</td><td>14.510</td><td>- -</td><td></td><td>5.630</td></tr><tr><td>Min</td><td>0.080</td><td>0.040</td><td>8.840</td><td></td><td></td><td>2.300</td></tr><tr><td>Max</td><td>0.950</td><td>0.860</td><td>20.600</td><td>一</td><td></td><td>16.730 1.720</td></tr><tr><td>SD</td><td>0.140</td><td>0.130</td><td>1.110</td></table></body></html>  \n\nAs discussed in Section 4.l, use of CZs as the unit-level does not absolve concerns of spatial autocorrelation.19 Using the Moran (1950) I-statistic, I test for spatial dependence of the error terms $\\varepsilon_{k t}$ for Eq. (13) both with and without additional controls $\\pmb{X}_{k t}$ .These results are displayed in Figs. 5 and 6. I find that both estimations suffer from spatial autocorrelation, ranging from mild (transportation & warehousing, professional & business services, education & healthcare), to moderate (manufacturing, trade, miscellaneous services), to severe (mining, finance).  \n\nThere is a lack of established methods for dealing with autocorrelation between CZs. However, clustering of standard errors is a general approach for dealing with any type of serial correlation. The challenge is determining the appropriate clustering of CZs with respect to error terms. To achieve this, I perform K-means clustering over geographic space combined with estimated residual vectors of Eq. (13), with and without controls. This method is intended to provide clustering of CZs conforming roughly to existing spatial autocorrelation. Standard errors can thus be clustered at these K-means cluster levels to address spatial autocorrelation (as well as heteroskedasticity). Following convention, I select 50 to be the number of clusters to allow for robustness in estimation of standard errors. Maps of clusters used for estimation of (13) with and without additional controls are displayed in Figs. 7 and 8,respectively.  \n\nTable2 Descriptive statistics, 2016.   \n\n\n<html><body><table><tr><td colspan=\"2\"></td><td>Labor share</td><td>Labor market HHI</td><td>Union coverage (%)</td><td>Capital cost index</td><td>Import exposure</td><td>Unemployment rate (%)</td></tr><tr><td>Construction</td><td>Mean</td><td>0.590</td><td>0.140</td><td>13.870</td><td>-</td><td>-</td><td>6.300</td></tr><tr><td></td><td>Median</td><td>0.600</td><td>0.110</td><td>14.600</td><td></td><td></td><td>5.800</td></tr><tr><td></td><td>Min</td><td>0.060</td><td>0.000</td><td>3.440</td><td></td><td></td><td>0.090</td></tr><tr><td></td><td>Max</td><td>6.160</td><td>0.890</td><td>27.100</td><td>一 一</td><td></td><td>26.060</td></tr><tr><td></td><td>SD</td><td>0.150</td><td>0.110</td><td>3.230</td><td></td><td></td><td>2.510</td></tr><tr><td>Ed.& Healthcare</td><td>Mean</td><td>0.800</td><td>0.330</td><td>6.980</td><td>-</td><td>-</td><td>6.310</td></tr><tr><td></td><td>Median</td><td>0.810</td><td>0.310</td><td>6.410</td><td></td><td></td><td>5.810</td></tr><tr><td></td><td>Min</td><td>0.140</td><td>0.020</td><td>2.960</td><td></td><td>-</td><td>0.140</td></tr><tr><td></td><td>Max</td><td>1.260</td><td>1.000</td><td>22.610</td><td></td><td></td><td>26.650</td></tr><tr><td></td><td>SD</td><td>0.060</td><td>0.180</td><td>1.940</td><td></td><td></td><td>2.500</td></tr><tr><td>Finance</td><td>Mean</td><td>0.480</td><td>0.160</td><td>2.940</td><td>-</td><td>-</td><td>6.340</td></tr><tr><td></td><td>Median</td><td>0.490</td><td>0.140</td><td>2.020</td><td>-</td><td></td><td>5.830</td></tr><tr><td></td><td>Min</td><td>0.070</td><td>0.010</td><td>0.690</td><td></td><td></td><td>0.080</td></tr><tr><td></td><td>Max</td><td>1.210</td><td>0.850</td><td>19.800</td><td></td><td>-</td><td>26.710</td></tr><tr><td></td><td>SD</td><td>0.120</td><td>0.110</td><td>2.180</td><td></td><td></td><td>2.530</td></tr><tr><td>Information</td><td>Mean</td><td>0.380</td><td>0.480</td><td>8.460</td><td>1.790</td><td>-</td><td>6.350</td></tr><tr><td></td><td>Median</td><td>0.380</td><td>0.480</td><td>8.730</td><td>1.790</td><td></td><td>5.830</td></tr><tr><td></td><td>Min Max</td><td>0.050 1.050</td><td>0.030</td><td>3.440</td><td>0.000</td><td></td><td>0.070</td></tr><tr><td></td><td>SD</td><td>0.070</td><td>1.000 0.210</td><td>22.340</td><td>3.650</td><td></td><td>26.260</td></tr><tr><td>Manufacturing</td><td></td><td></td><td></td><td>1.930</td><td>0.510</td><td></td><td>2.540</td></tr><tr><td></td><td>Mean Median</td><td>0.550</td><td>0.550</td><td>11.670</td><td>16.290</td><td>0.010</td><td>6.380</td></tr><tr><td></td><td>Min</td><td>0.560 0.070</td><td>0.560 0.030</td><td>11.720</td><td>17.230 1.130</td><td>0.000 0.000</td><td>5.860</td></tr><tr><td></td><td>Max</td><td>1.360</td><td>1.000</td><td>4.890 24.170</td><td>24.600</td><td>0.400</td><td>0.190</td></tr><tr><td></td><td>SD</td><td>0.120</td><td>0.210</td><td>2.180</td><td>5.520</td><td>0.020</td><td>27.180</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>2.580</td></tr><tr><td>Mining</td><td>Mean Median</td><td>0.260</td><td>0.440 0.430</td><td>12.810</td><td>2.490</td><td>0.190 0.100</td><td>6.390</td></tr><tr><td></td><td>Min</td><td>0.240 0.000</td><td>0.040</td><td>13.480 4.690</td><td>2.470 1.080</td><td>0.000</td><td>5.940</td></tr><tr><td></td><td>Max</td><td>0.920</td><td>1.000</td><td>26.820</td><td>3.580</td><td>1.230</td><td>0.080</td></tr><tr><td></td><td>SD</td><td>0.160</td><td>0.200</td><td>2.590</td><td>0.730</td><td>0.220</td><td>17.010</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>2.430</td></tr><tr><td>Misc. services</td><td>Mean Median</td><td>0.630 0.630</td><td>0.110 0.090</td><td>5.240 4.770</td><td></td><td></td><td>6.290</td></tr><tr><td></td><td>Min</td><td>0.220</td><td>0.010</td><td>1.840</td><td></td><td></td><td>5.790</td></tr><tr><td></td><td>Max</td><td>1.090</td><td>0.710</td><td>21.320</td><td></td><td></td><td>0.080</td></tr><tr><td></td><td>SD</td><td>0.070</td><td>0.090</td><td>1.750</td><td></td><td></td><td>26.430</td></tr><tr><td>Prof. business services</td><td>Mean</td><td></td><td></td><td></td><td></td><td></td><td>2.540</td></tr><tr><td></td><td>Median</td><td>0.610 0.640</td><td>0.180 0.160</td><td>4.280</td><td>-</td><td>-</td><td>6.340</td></tr><tr><td></td><td>Min</td><td>0.010</td><td>0.000</td><td>3.560 0.990</td><td></td><td></td><td>5.820</td></tr><tr><td></td><td>Max</td><td>1.000</td><td>1.000</td><td>20.560</td><td></td><td></td><td>0.040</td></tr><tr><td></td><td>SD</td><td>0.120</td><td>0.130</td><td>2.140</td><td></td><td></td><td>26.220</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>2.540</td></tr><tr><td>Trade</td><td>Mean</td><td>0.530</td><td>0.240</td><td>3.420</td><td>-</td><td>-</td><td>6.300</td></tr><tr><td></td><td>Median</td><td>0.540</td><td>0.220</td><td>2.700</td><td>-</td><td></td><td>5.780</td></tr><tr><td></td><td>Min</td><td>0.050</td><td>0.010</td><td>1.130</td><td>-</td><td>-</td><td>0.120</td></tr><tr><td></td><td>Max</td><td>0.800</td><td>0.960</td><td>20.110</td><td>-</td><td></td><td>26.890</td></tr><tr><td></td><td>SD</td><td>0.060</td><td>0.150</td><td>1.940</td><td></td><td></td><td>2.580</td></tr><tr><td>Trans.& Warehousing</td><td>Mean</td><td>0.590</td><td>0.340</td><td>24.410</td><td>-</td><td>-</td><td>6.470</td></tr><tr><td></td><td>Median</td><td>0.620</td><td>0.320</td><td>26.270</td><td></td><td>-</td><td>5.970</td></tr><tr><td></td><td>Min</td><td>0.010</td><td>0.020</td><td>8.840</td><td>-</td><td>-</td><td>0.050</td></tr><tr><td></td><td>Max</td><td>1.360</td><td>0.920</td><td>31.600</td></table></body></html>  \n\n### 4.3. Discussion of results  \n\nEstimation results of Eq. (13) with and without additional controls under optimal lagged instrument structure are displayed in Tables 4 and 5, respectively. Results for estimation using full three-year lagged instrument sets are reported in Tables 6 and 7. Under optimal lagged instrument structure, I find evidence for the negative effect of labor market concentration on regional labor shares across five of the ten industries considered. These industries are mining, manufacturing, information, finance, and education & healthcare. The results are robust with respect to added controls from the literature. Statistically significant negative effects under the full lagged instrument set are observed for these same industries except education & healthcare, for which the effect is negative but insignificant.2o The remainder of the discussion focuses on results from estimations run on optimal lag structures that meet the criteria of strong, valid instruments for each specific industry. However, results are largely robust to instrument specification.  \n\nThe negative impact of labor market concentration on industry labor share appears particularly strong in manufacturing. This result is important for a variety of reasons. First, it has been shown that manufacturing is the industry most responsible for driving labor share decline at the US level (Mendieta-Munoz et al., 2021; Manyika et al., 2019). The significant results of the estimation for manufacturing suggest that rising labor market monopsony in particular regions may play an important role in the industry's declining labor share. An anecdotal yet poignant example of this mechanism is detailed in documentary film American Factory (Bognar and Reichart, 2018): a worker who was interviewed claimed that she earned $\\$29$ anhour working at the General Motors plant in Dayton, Ohio before it closed in 2008 due to the financial turmoil and increased competition from foreign imports (Helper and Henderson, 2014). When the plant reopens in 2018 under new ownership, she receives just over $\\$12$ an hour, but nonetheless expresses gratitude for her employment, noting that work at the reopened factory is “the best game in town right now\".  \n\nTable3 Descriptive statistics, 2002-2016.   \n\n\n<html><body><table><tr><td></td><td></td><td>Labor share</td><td>Labor market HHI</td><td>Union coverage (%)</td><td>Capital cost index</td><td>Import exposure</td><td>Unemployment rate (%)</td></tr><tr><td>Construction</td><td>Mean</td><td>0.590</td><td>0.140</td><td>13.870</td><td>-</td><td>-</td><td>6.300</td></tr><tr><td></td><td>Median</td><td>0.600</td><td>0.110</td><td>14.600</td><td></td><td></td><td>5.800</td></tr><tr><td></td><td>Min</td><td>0.060</td><td>0.000</td><td>3.440</td><td></td><td></td><td>0.090</td></tr><tr><td></td><td>Max</td><td>6.160</td><td>0.890</td><td>27.100</td><td></td><td></td><td>26.060</td></tr><tr><td></td><td>SD</td><td>0.150</td><td>0.110</td><td>3.230</td><td></td><td></td><td>2.510</td></tr><tr><td>Ed.& Healthcare</td><td>Mean</td><td>0.800</td><td>0.330</td><td>6.980</td><td>-</td><td></td><td>6.310</td></tr><tr><td></td><td>Median</td><td>0.810</td><td>0.310</td><td>6.410</td><td></td><td></td><td>5.810</td></tr><tr><td></td><td>Min</td><td>0.140</td><td>0.020</td><td>2.960</td><td>一</td><td></td><td>0.140</td></tr><tr><td></td><td>Max</td><td>1.260</td><td>1.000</td><td>22.610</td><td>-</td><td></td><td>26.650</td></tr><tr><td></td><td>SD</td><td>0.060</td><td>0.180</td><td>1.940</td><td></td><td></td><td>2.500</td></tr><tr><td>Finance</td><td>Mean</td><td>0.480</td><td>0.160</td><td>2.940</td><td>-</td><td>-</td><td>6.340</td></tr><tr><td></td><td>Median</td><td>0.490</td><td>0.140</td><td>2.020</td><td></td><td></td><td>5.830</td></tr><tr><td></td><td>Min</td><td>0.070</td><td>0.010</td><td>0.690</td><td></td><td></td><td>0.080</td></tr><tr><td></td><td>Max</td><td>1.210</td><td>0.850</td><td>19.800</td><td></td><td>-</td><td>26.710</td></tr><tr><td></td><td>SD</td><td>0.120</td><td>0.110</td><td>2.180</td><td></td><td></td><td>2.530</td></tr><tr><td>Information</td><td>Mean</td><td>0.380</td><td>0.480</td><td>8.460</td><td>1.790</td><td></td><td>6.350</td></tr><tr><td></td><td>Median</td><td>0.380</td><td>0.480</td><td>8.730</td><td>1.790</td><td></td><td>5.830</td></tr><tr><td></td><td>Min</td><td>0.050</td><td>0.030</td><td>3.440</td><td>0.000</td><td></td><td>0.070</td></tr><tr><td></td><td>Max</td><td>1.050</td><td>1.000</td><td>22.340</td><td>3.650</td><td></td><td>26.260</td></tr><tr><td></td><td>SD</td><td>0.070</td><td>0.210</td><td>1.930</td><td>0.510</td><td></td><td>2.540</td></tr><tr><td>Manufacturing</td><td>Mean</td><td>0.550</td><td>0.550</td><td>11.670</td><td>16.290</td><td>0.010</td><td>6.380</td></tr><tr><td></td><td>Median</td><td>0.560</td><td>0.560</td><td>11.720</td><td>17.230</td><td>0.000</td><td>5.860</td></tr><tr><td></td><td>Min Max</td><td>0.070 1.360</td><td>0.030 1.000</td><td>4.890</td><td>1.130</td><td>0.000</td><td>0.190</td></tr><tr><td></td><td>SD</td><td>0.120</td><td>0.210</td><td>24.170 2.180</td><td>24.600</td><td>0.400</td><td>27.180</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td>5.520</td><td>0.020</td><td>2.580</td></tr><tr><td>Mining</td><td>Mean</td><td>0.260</td><td>0.440</td><td>12.810</td><td>2.490</td><td>0.190</td><td>6.390</td></tr><tr><td></td><td>Median</td><td>0.240</td><td>0.430</td><td>13.480</td><td>2.470</td><td>0.100</td><td>5.940</td></tr><tr><td></td><td>Min</td><td>0.000 0.920</td><td>0.040 1.000</td><td>4.690 26.820</td><td>1.080 3.580</td><td>0.000 1.230</td><td>0.080</td></tr><tr><td></td><td>Max</td><td>0.160</td><td>0.200</td><td>2.590</td><td>0.730</td><td>0.220</td><td>17.010</td></tr><tr><td></td><td>SD</td><td></td><td></td><td></td><td></td><td></td><td>2.430</td></tr><tr><td>Misc. services</td><td>Mean</td><td>0.630</td><td>0.110</td><td>5.240</td><td>-</td><td>-</td><td>6.290</td></tr><tr><td></td><td>Median</td><td>0.630</td><td>0.090</td><td>4.770</td><td></td><td>-</td><td>5.790</td></tr><tr><td></td><td>Min Max</td><td>0.220 1.090</td><td>0.010 0.710</td><td>1.840</td><td>-</td><td>-</td><td>0.080</td></tr><tr><td></td><td>SD</td><td>0.070</td><td>0.090</td><td>21.320 1.750</td><td></td><td></td><td>26.430</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>2.540</td></tr><tr><td>Prof. business services</td><td>Mean</td><td>0.610</td><td>0.180</td><td>4.280</td><td>-</td><td>-</td><td>6.340</td></tr><tr><td></td><td>Median</td><td>0.640</td><td>0.160</td><td>3.560</td><td></td><td>-</td><td>5.820</td></tr><tr><td></td><td>Min Max</td><td>0.010 1.000</td><td>0.000 1.000</td><td>0.990</td><td></td><td></td><td>0.040</td></tr><tr><td></td><td></td><td>0.120</td><td></td><td>20.560</td><td></td><td>-</td><td>26.220</td></tr><tr><td></td><td>SD</td><td></td><td>0.130</td><td>2.140</td><td></td><td></td><td>2.540</td></tr><tr><td>Trade</td><td>Mean</td><td>0.530</td><td>0.240</td><td>3.420</td><td></td><td></td><td>6.300</td></tr><tr><td></td><td>Median</td><td>0.540</td><td>0.220</td><td>2.700</td><td></td><td></td><td>5.780</td></tr><tr><td></td><td>Min</td><td>0.050</td><td>0.010</td><td>1.130</td><td>一</td><td>一</td><td>0.120</td></tr><tr><td></td><td>Max</td><td>0.800</td><td>0.960</td><td>20.110</td><td></td><td></td><td>26.890</td></tr><tr><td></td><td>SD</td><td>0.060</td><td>0.150</td><td>1.940</td><td></td><td></td><td>2.580</td></tr><tr><td>Trans.& Warehousing</td><td>Mean</td><td>0.590</td><td>0.340</td><td>24.410</td><td></td><td></td><td>6.470</td></tr><tr><td></td><td>Median</td><td>0.620</td><td>0.320</td><td>26.270</td><td></td><td></td><td>5.970</td></tr><tr><td></td><td>Min</td><td>0.010</td><td>0.020</td><td>8.840</td><td>-</td><td></td><td>0.050</td></tr><tr><td></td><td>Max</td><td>1.360</td><td>0.920</td><td>31.600</td><td></td><td>一</td></table></body></html>  \n\nTable4 Estimation of effect of indusry labor market concentration on industry labor share using optimal lagged instrumentation. U.S. commuting zones, 2002-2016. All estimations ru with two-way fixed effects. Standard errors clustered using K-means spatial residual methodology (see Fig. 7).   \n\n\n<html><body><table><tr><td></td><td>Mining</td><td>Construction</td><td>Manufacturing</td><td>Trade</td><td>Trans.&Ware.</td><td>Information</td><td>Finance</td><td>Prof. services</td><td>Ed.& Health</td><td>Misc.services</td></tr><tr><td>Labor monopsony (HHI)</td><td>-0.178***</td><td>0.184*</td><td>-0.410***</td><td>0.022</td><td>-0.022</td><td>-0.069*</td><td>-0.154**</td><td>-0.003</td><td>0.114*</td><td>-0.021</td></tr><tr><td></td><td>(0.048)</td><td>(0.103)</td><td>(0.123)</td><td>(0.058)</td><td>(0.092)</td><td>(0.041)</td><td>(0.075)</td><td>(0.074)</td><td>(0.064)</td><td>(0.056)</td></tr><tr><td>Obs.</td><td>4353</td><td>6639</td><td>6588</td><td>8423</td><td>5885</td><td>5859</td><td>5976</td><td>5895</td><td>5743</td><td>8255</td></tr><tr><td>Regions Clusters</td><td>365</td><td>664</td><td>659</td><td>702</td><td>589</td><td>651</td><td>664</td><td>655</td><td>575</td><td>688</td></tr><tr><td>Instrument lags</td><td>50 1:1</td><td>50 1:2</td><td>50 2:3</td><td>50</td><td>50</td><td>50</td><td>50</td><td>50</td><td>50</td><td>50</td></tr><tr><td>Kleibergen-PaapFStat.</td><td>940.10</td><td>70.32</td><td>64.88</td><td>1:1 302.60</td><td>2:3 77.83</td><td>1:3 196.60</td><td>1:3 41.43</td><td>1:2 24.39</td><td>1:2 348.30</td><td>1:2</td></tr><tr><td>Hansen J Stat.</td><td>一</td><td>0.17</td><td>0.46</td><td>一</td><td>0.74</td><td>0.35</td><td>0.28</td><td>2.68</td><td>0.77</td><td>236.80 -</td></tr><tr><td>Kleibergen-Paap LM Stat.</td><td>39.50***</td><td>24.26***</td><td>29.65***</td><td>22.80***</td><td>31.99***</td><td>35.68***</td><td>20.31***</td><td>26.66***</td><td>29.10***</td><td>23.58</td></tr></table></body></html>\n\nStandard errors in parentheses $\\ddot{\\cdot}p<0.10$ $^{**}p<0.05$ $\\stackrel{**}{\\sim}p<0.01$  \n\n![](images/9d7d1fc595e4201ff98eaec2a23f69dbb65920134a8e7435a0cd0d5dd1906aa2.jpg)  \nFig. 6. Moran I statistic for error term of Eq. (13) with additional controls. Statistic value of 1 corresponds to perfect positive spatial autocorrelation, $^{-1}$ toperfectnegative spatia autocorrelation, and 0 to no spatial autocorrelation.  \n\nTable5 Estmationf efet ofindsry labormarket cnentrationnindustrylbr hareusing optimallaged instrmentation with adde cotrolscomtin zones, 2 Al estimations run with two-way fixed effects. Standard errors clustered using K-means spatial residual methodology (see Fig. 8).   \n\n\n<html><body><table><tr><td></td><td>Mining</td><td>Construction</td><td>Manufacturing</td><td>Trade</td><td>Trans.& Ware.</td><td>Information</td><td>Finance</td><td>Prof. services</td><td>Ed.&Health</td><td>Misc. services</td></tr><tr><td rowspan=\"2\">Labor monopsony (HHI)</td><td>-0.177***</td><td>0.180*</td><td>-0.401***</td><td>0.027</td><td>-0.026</td><td>-0.073*</td><td>-0.142*</td><td>-0.014</td><td>-0.113*</td><td>-0.008</td></tr><tr><td>(0.043)</td><td>(0.102)</td><td>(0.116)</td><td>(0.100)</td><td>(0.107)</td><td>(0.041)</td><td>(0.082)</td><td>(0.063)</td><td>(0.064)</td><td>(0.065)</td></tr><tr><td rowspan=\"2\">Union coverage (%)</td><td>-0.269</td><td>0.006</td><td>-0.022</td><td>0.001</td><td>0.133</td><td>-0.006</td><td>-0.239*</td><td>-0.089</td><td>-0.029</td><td>-0.043</td></tr><tr><td>(0.234)</td><td>(0.175)</td><td>(0.115)</td><td>(0.050)</td><td>(0.081)</td><td>(0.089)</td><td>(0.125)</td><td>(0.087)</td><td>(0.033)</td><td>(0.049)</td></tr><tr><td rowspan=\"2\">Capital cost index</td><td>-0.007</td><td></td><td>0.003**</td><td></td><td>0.005</td><td>0.0223**</td><td>0.005</td><td></td><td></td><td></td></tr><tr><td>(0.008)</td><td></td><td>(0.002)</td><td></td><td>(0.004)</td><td>(0.010)</td><td>(0.005)</td><td></td><td></td><td></td></tr><tr><td rowspan=\"2\">Import exposure</td><td>-0.031</td><td></td><td>0.139</td><td></td><td>0.034</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>(0.024)</td><td></td><td>(0.278)</td><td></td><td>(0.068)</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td rowspan=\"2\">Unemployment rate (%)</td><td>0.298</td><td>0.213</td><td>-0.238</td><td>0.290***</td><td>-0.004</td><td>0.153</td><td>-0.331*</td><td>-0.036</td><td>0.003</td><td>-0.064</td></tr><tr><td>(0.209)</td><td>(0.232)</td><td>(0.173)</td><td>(0.084)</td><td>(0.147)</td><td>(0.165)</td><td>(0.199)</td><td>(0.126)</td><td>(0.095)</td><td>(0.097)</td></tr><tr><td>Obs.</td><td>4353</td><td>6639</td><td>6588</td><td>7020</td><td>5885</td><td>5859</td><td>5976</td><td>6550</td><td>5743</td><td>6880</td></tr><tr><td>Regions</td><td>365</td><td>664</td><td>659</td><td>702</td><td>589</td><td>651</td><td>664</td><td>655</td><td>575</td><td>688</td></tr><tr><td>Clusters</td><td>50</td><td>50</td><td>50</td><td>50</td><td>50</td><td>50</td><td>50</td><td>50</td><td>50</td><td>50</td></tr><tr><td>Instrument lags</td><td>1:1</td><td>1:2</td><td>2:3</td><td>1:1</td><td>2:3</td><td>1:3</td><td>1:3</td><td>1:2</td><td>1:2</td><td>1:2</td></tr><tr><td>Kleibergen-Paap F Stat.</td><td>794.10</td><td>66.22</td><td>56.58</td><td>51.44</td><td>77.08</td><td>223.70</td><td>61.78</td><td>33.18</td><td>426.40</td><td>93.07</td></tr><tr><td>Hansen J Stat.</td><td>一</td><td>0.13</td><td>0.40</td><td></td><td>0.75</td><td>0.38</td><td>0.14</td><td>2.19</td><td>0.71</td><td>0.37</td></tr><tr><td>Kleibergen-PaapLM Stat.</td><td>37.24***</td><td>21.70***</td><td>27.39***</td><td>一 23.15***</td><td>31.25***</td><td>36.12***</td><td>23.22***</td><td>26.43***</td><td>35.44***</td><td>17.81***</td></tr></table></body></html>\n\nStandard errors in parentheses $\\ddot{\\tau}p<0.10.$ $^{**}p<0.05$ $\\stackrel{**}{\\sim}p<0.01$  \n\nA second implication of the results for manufacturing is the distribution of its employment across important economic and social dimensions. Insofar as manufacturing activities are not uniformly distributed across regions, classes, income, race, and others, the impact of rising monopsony conditions is more acutely felt by some more than others. While manufacturing employs a “mere\" $7.5\\%$ oftotal private nonfarm employment, it is a much more important employer when considering workers who lack a college degree — nearly $52\\%$ of the workforce over 25 years old.21 For those with less than an associates degree, $10.3\\%$ are employed in manufacturing, making it the third-largest 2-digit NAICS employer behind accommodations and food services $(14.8\\%)$ and retail trade $(13.6\\%)$ .22 By comparison, information, education, professional, scientific, and technical services, and management of companies and enterprises — which collectively may be thought of as high-skill serves, employ only $7.4\\%$ of workers without a college degree. Thus, labor share decline via rising manufacturing labor market concentration is almost certainly born disproportionately by less educated, lower income workers.  \n\nTable6 Estimation of effect of industry labor market concentration on industry labor share using fullagged instrumentation (three years). U.S. commuting zones, 2002-2016. All estimations run with two-way fixed effects. Standard errors clustered using K-means spatial residual methodology (see Fig. 7). Caution: rejection of the Hansen J null hypothesis suggests potentially invalid instrument for Mining and Manufacturing estimation.   \n\n\n<html><body><table><tr><td></td><td>Mining</td><td>Construction</td><td>Manufacturing</td><td>Trade</td><td>Trans.&Ware.</td><td>Information</td><td>Finance</td><td>Prof.services</td><td>Ed.& Health</td><td>Misc.services</td></tr><tr><td>Labor monopsony (HHI)</td><td>-0.132** (0.052)</td><td>0.180 (0.126)</td><td>-0.182* (0.096)</td><td>0.016 (0.082)</td><td>0.020 (0.058)</td><td>-0.069** (0.035)</td><td>-0.154** (0.074)</td><td>-0.009 (0.071)</td><td>-0.078 (0.038)</td><td>-0.034 (0.069)</td></tr><tr><td>Obs.</td><td>3269</td><td>5975</td><td>5931</td><td>6318</td><td>5301</td><td>5859</td><td>5976</td><td>5940</td><td>5217</td><td>6192</td></tr><tr><td>Regions</td><td>365</td><td>664</td><td>659</td><td>702</td><td>589</td><td>651</td><td>664</td><td>661</td><td>582</td><td>688</td></tr><tr><td>Clusters</td><td>50</td><td>50</td><td>50</td><td>50</td><td>50</td><td>50</td><td>50</td><td>50</td><td>50</td><td>50</td></tr><tr><td>Instrument lags</td><td>1:3</td><td>1:3</td><td>1:3</td><td>1:3</td><td>1:3</td><td>1:3</td><td>1:3</td><td>1:3</td><td>1:3</td><td>1:3</td></tr><tr><td>Kleibergen-PaapF Stat.</td><td>113.10</td><td>40.99</td><td>343.00</td><td>109.10</td><td>95.32</td><td>200.60</td><td>54.70</td><td>25.90</td><td>205.80</td><td>83.89</td></tr><tr><td>HansenJStat.</td><td>7.65**</td><td>0.82</td><td>4.87**</td><td>1.75</td><td>0.66</td><td>0.39</td><td>0.24</td><td>2.26</td><td>1.82</td><td>0.88</td></tr><tr><td>Kleibergen-PaapLM Stat.</td><td>37.11***</td><td>25.98***</td><td>35.00***</td><td>26.24***</td><td>32.70***</td><td>37.85***</td><td>21.16***</td><td>25.32***</td><td>28.10***</td><td>19.36</td></tr></table></body></html>\n\nStandard errors in parentheses $\\ddot{\\tau}p<0.10.$ $^{**}p<0.05_{;}$ $\\stackrel{**}{\\sim}p<0.01$  \n\nTable7 Estimation of effect of industry labor market concentration on industry labor share using full lagged instrumentation (three years) with added controls. U.s. commuting zones, 2002-2016. All estimations run with two-way fixed effects. Standard errors clustered using K-means spatial residual methodology (see Fig. 8). Caution: rejection of the Hansen J null hypothesis suggests potentially invalid instrument for Mining and Manufacturing estimation.   \n\n\n<html><body><table><tr><td></td><td>Mining</td><td>Construction</td><td>Manufacturing</td><td>Trade</td><td>Trans.& Ware.</td><td>Information</td><td>Finance</td><td>Prof.services</td><td>Ed.&Health</td><td>Misc.services</td></tr><tr><td>Labor monopsony (HHI)</td><td>-0.131**</td><td>0.176</td><td>-0.171*</td><td>0.031</td><td>0.015</td><td>-0.073**</td><td>-0.142**</td><td>-0.009</td><td>-0.078</td><td>-0.035</td></tr><tr><td></td><td>(0.061)</td><td>(0.121)</td><td>(0.090)</td><td>(0.076)</td><td>(0.063)</td><td>(0.037)</td><td>(0.072)</td><td>(0.088)</td><td>(0.065)</td><td>(0.068)</td></tr><tr><td>Union coverage (%)</td><td>0.064</td><td>0.068</td><td>-0.130</td><td>-0.046</td><td>0.122</td><td>-0.006</td><td>-0.239**</td><td>-0.079</td><td>-0.000</td><td>0.012</td></tr><tr><td></td><td>(0.181)</td><td>(0.179)</td><td>(0.118)</td><td>(0.043)</td><td>(0.147)</td><td>(0.100)</td><td>(0.119)</td><td>(0.121)</td><td>(0.034)</td><td>(0.073)</td></tr><tr><td>Capital cost index</td><td>-0.007</td><td></td><td>0.004**</td><td></td><td>0.005*</td><td>0.022***</td><td>0.005</td><td></td><td></td><td></td></tr><tr><td></td><td>(0.006)</td><td></td><td>(0.002)</td><td></td><td>(0.003)</td><td>(0.008)</td><td>(0.005)</td><td></td><td></td><td></td></tr><tr><td>Import exposure</td><td>-0.004</td><td></td><td>-0.066</td><td></td><td>-0.012</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td>(0.021)</td><td></td><td>(0.329)</td><td></td><td>(0.063)</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>Unemployment rate (%)</td><td>0.119</td><td>0.136</td><td>-0.359**</td><td>0.269***</td><td>0.005</td><td>0.153</td><td>-0.331</td><td>-0.012</td><td>0.031</td><td>-0.058</td></tr><tr><td></td><td>(0.254)</td><td>(0.317)</td><td>(0.177)</td><td>(0.094)</td><td>(0.155)</td><td>(0.149)</td><td>(0.221)</td><td>(0.111)</td><td>(0.072)</td><td>(0.091)</td></tr><tr><td>Obs.</td><td>3269</td><td>5975</td><td>5931</td><td>6318</td><td>5301</td><td>5859</td><td>5976</td><td>5940</td><td>5217</td><td>6192</td></tr><tr><td>Regions Clusters</td><td>365</td><td>664</td><td>659</td><td>702</td><td>589</td><td>651</td><td>664</td><td>661</td><td>582</td><td>688</td></tr><tr><td>Instrument lags</td><td>50</td><td>50</td><td>50</td><td>50</td><td>50</td><td>50</td><td>50</td><td>50</td><td>50</td><td>50</td></tr><tr><td></td><td>1:3</td><td>1:3</td><td>1:3</td><td>1:3</td><td>1:3</td><td>1:3</td><td>1:3</td><td>1:3</td><td>1:3</td><td>1:3</td></tr><tr><td>Kleibergen-Paap F Stat.</td><td>141.70</td><td>39.02</td><td>160.80</td><td>102.80</td><td>84.70</td><td>226.70</td><td>65.47</td><td>20.17</td><td>165.60</td><td>64.16</td></tr><tr><td>Hansen J Stat.</td><td>7.20**</td><td>1.13</td><td>10.90***</td><td>2.07</td><td>0.87</td><td>0.51</td><td>0.14</td><td>2.30</td><td>1.42</td><td>0.85</td></tr><tr><td>Kleibergen-PaapLM Stat.</td><td>32.89***</td><td>23.93***</td><td>34.22***</td><td>24.99***</td><td>36.55***</td><td>33.00***</td><td>22.87***</td><td>27.01***</td><td>27.95***</td><td>17.66***</td></tr></table></body></html>\n\nStandard errors in parentheses $\\ddot{\\tau}p<0.10.$ $^{**}p<0.05$ $\\stackrel{**}{\\sim}p<0.01$  \n\nTable8 Estimation of effect of industry labor market concentration on industry labor share using contemporaneous variation. U.S. commuting zones, 2002-2016. Two-way fixed effect applied. Note: these results capture both the concentration effect as well as structural bias, and thus must be considered with caution.   \n\n\n<html><body><table><tr><td></td><td>Mining</td><td>Construction</td><td>Manufacturing</td><td>Trade</td><td>Trans.& Ware.</td><td>Information</td><td>Finance</td><td>Prof.services</td><td>Ed.&Health</td><td>Misc.services</td></tr><tr><td>Labor monopsony (HHI)</td><td>-0.093***</td><td>0.119***</td><td>0.002</td><td>-0.008</td><td>0.021</td><td>0.011</td><td>-0.004</td><td>-0.027**</td><td>-0.062***</td><td>-0.027</td></tr><tr><td></td><td>(0.015)</td><td>(0.024)</td><td>(0.018)</td><td>(0.013)</td><td>(0.013)</td><td>(0.009)</td><td>(0.018)</td><td>(0.0128)</td><td>(0.014)</td><td>(0.016)</td></tr><tr><td>Obs.</td><td>5082 365</td><td>9294 664</td><td>9224</td><td>9827</td><td>8237 589</td><td>9111 651</td><td>9292</td><td>9246</td><td>8120 582</td><td>9631</td></tr><tr><td>Regions</td><td></td><td></td><td>659</td><td>702</td><td></td><td></td><td>664</td><td>661</td><td></td><td>688</td></tr></table></body></html>\n\nStandard errors in parentheses $\\ddot{\\tau}p<0.10.$ $^{**}p<0.05$ $\\stackrel{**}{\\sim}p<0.01$  \n\nMining exhibits the second strongest negative effect. Similar to manufacturing, it has a high median labor market HHI with a high degree of variance (see Fig. 3), as well as substantial decline in median labor share over 2002-2016 (see Fig. 2). Unlike manufacturing, however, mining on average makes up a very small percentage of a region's total employment $(0.83\\%$ for mining vs. $12.1\\%$ for manufacturing). However, for a select set of CZs, mining plays a very important role, as demonstrated by the fat right tail of the employment share distribution (see Fig. 9). These CZs, for which mining employment share is greater than $30\\%$ , are located entirely within five states: Alaska, Kansas, North Dakota, Nevada, and Texas. This is unsurprising, as mining activities are distributed according to the distribution of natural resources. The general takeaway is that while the negative concentration effect of mining is quite strong on industry labor share, the relatively small size of the mining employment for most commuting zones means that the effect on the aggregate labor share will be minimal. However, for regional economies that depend heavily on mining, the effect of on the aggregate distribution is likely to be substantial.  \n\nTable9 Estimation of effect of industry labor market concentration on industry labor share using contemporaneous variation, controlling for union membership. S. commuting zones 2002-2016. Two-way fixed effects applied. Note: these results capture both the concentration effect as well as structural bias, and thus must be considered with caution.   \n\n\n<html><body><table><tr><td></td><td>Mining</td><td>Construction</td><td>Manufacturing</td><td>Trade</td><td>Trans.&Ware.</td><td>Information</td><td>Finance</td><td>Prof.services</td><td>Ed.&Health</td><td>Misc.services</td></tr><tr><td rowspan=\"2\">Labor monopsony (HHI)</td><td>-0.085***</td><td>0.116***</td><td>0.004</td><td>-0.004</td><td>0.016</td><td>0.008</td><td>-0.003</td><td>-0.027**</td><td>-0.069***</td><td>-0.025</td></tr><tr><td>(0.015)</td><td>(0.024)</td><td>(0.018)</td><td>(0.013)</td><td>(0.013)</td><td>(0.009)</td><td>(0.018)</td><td>(0.013)</td><td>(0.015)</td><td>(0.016)</td></tr><tr><td rowspan=\"2\">Union coverage (%)</td><td>-0.426***</td><td>0.079</td><td>-0.098</td><td>-0.099***</td><td>0.100**</td><td>0.034</td><td>-0.365***</td><td>-0.031</td><td>-0.113**</td><td>-0.086**</td></tr><tr><td>(0.133)</td><td>(0.109)</td><td>(0.098)</td><td>(0.035)</td><td>(0.049)</td><td>(0.067)</td><td>(0.060)</td><td>(0.070)</td><td>(0.048)</td><td>(0.042)</td></tr><tr><td rowspan=\"2\">Capital costindex</td><td>-0.006</td><td></td><td>0.002***</td><td></td><td>0.006***</td><td>0.015***</td><td>0.014***</td><td></td><td></td><td></td></tr><tr><td>(0.004)</td><td></td><td>(0.001)</td><td></td><td>(0.002)</td><td>(0.004)</td><td>(0.003)</td><td></td><td></td><td></td></tr><tr><td rowspan=\"2\">Importexposure</td><td>-0.055***</td><td></td><td>0.140</td><td></td><td>-0.023</td><td>0.100</td><td></td><td></td><td>2.543</td><td></td></tr><tr><td>(0.013)</td><td></td><td>(0.102)</td><td></td><td>(0.046)</td><td>(0.214)</td><td></td><td></td><td>(1.604)</td><td></td></tr><tr><td rowspan=\"2\">Unemployment rate (%)</td><td></td><td>0.287***</td><td>-0.225***</td><td>0.291***</td><td>0.033</td><td>0.121**</td><td>-0.263***</td><td>-0.133*</td><td>-0.008</td><td>0.055</td></tr><tr><td></td><td>(0.107)</td><td>(0.077)</td><td>(0.032)</td><td>(0.084)</td><td>(0.058)</td><td>(0.063)</td><td>(0.074)</td><td>(0.045)</td><td>(0.037)</td></tr><tr><td>Obs.</td><td>5082</td><td>9294</td><td>9224</td><td>9827</td><td>8237</td><td>9111</td><td>9292</td><td>9246</td><td>8120</td><td>9631</td></tr><tr><td>Regions</td><td>365</td><td>664</td><td>659</td><td>702</td><td>589</td><td>651</td><td>664</td><td>661</td><td>582</td><td>688</td></tr></table></body></html>\n\nStandard errors in parentheses $\\ddot{\\tau}p<0.10.$ $^{**}p<0.05$ $\\stackrel{**}{\\sim}p<0.01$  \n\nTable10 First stage estimation results, three year lagged instruments for labor market monopsony (HHI).   \n\n\n<html><body><table><tr><td></td><td>Mining</td><td>Construction</td><td>Manufacturing</td><td>Trade</td><td>Trans.& Ware.</td><td>Information</td><td>Finance</td><td>Prof.services</td><td>Ed.& Health</td><td>Misc.services</td></tr><tr><td>1 year lag</td><td>***069'0</td><td>0.688***</td><td>0.763***</td><td>0.718***</td><td>0.748***</td><td>0.785***</td><td>***6690</td><td>0.636***</td><td>0.715***</td><td>0.696***</td></tr><tr><td></td><td>(0.0174)</td><td>(0.0133)</td><td>(0.0129)</td><td>(0.0121)</td><td>(0.0137)</td><td>(0.0128)</td><td>(0.0133)</td><td>(0.0128)</td><td>(0.0136)</td><td>(0.0127)</td></tr><tr><td>2 yearlag</td><td>0.151***</td><td>0.131***</td><td>0.149***</td><td>0.164***</td><td>0.161***</td><td>0.132***</td><td>0.167***</td><td>0.191***</td><td>0.130***</td><td>0.196***</td></tr><tr><td></td><td>(0.022)</td><td>(0.016)</td><td>(0.016)</td><td>(0.015)</td><td>(0.016)</td><td>(0.016)</td><td>(0.017)</td><td>(0.015)</td><td>(0.017)</td><td>(0.015)</td></tr><tr><td>3yearlag</td><td>0.104***</td><td>0.148***</td><td>0.078***</td><td>0.123***</td><td>0.063***</td><td>0.063***</td><td>0.108***</td><td>0.129***</td><td>0.146***</td><td>0.092***</td></tr><tr><td></td><td>(0.018)</td><td>(0.014)</td><td>(0.013)</td><td>(0.012)</td><td>(0.012)</td><td>(0.012)</td><td>(0.013)</td><td>(0.012)</td><td>(0.014)</td><td>(0.012)</td></tr><tr><td>Obs.</td><td>3269</td><td>5975</td><td>5931</td><td>6318</td><td>5301</td><td>5859</td><td>5976</td><td>5940</td><td>5217</td><td>6192</td></tr><tr><td>F-stat.</td><td>6242.6***</td><td>14026.3***</td><td>56814.6***</td><td>94805.7***</td><td>13630.8***</td><td>30094.2***</td><td>23490.2***</td><td>11742.3***</td><td>72323.8***</td><td>39127.0***</td></tr></table></body></html>\n\nStandard errors in parentheses $\\ddot{\\cdot}p<0.10$ $^{**}p<0.05$ $\\stackrel{**}{\\sim}p<0.01$  \n\nTable11 First stage estimation results, select optimal lagged instruments for labor market monopsony (HHI).   \n\n\n<html><body><table><tr><td>Mining</td><td></td><td>Construction</td><td>Manufacturing</td><td>Trade</td><td>Trans.&Ware.</td><td>Information</td><td>Finance</td><td>Prof.services</td><td>Ed.& Health</td><td>Misc.services</td></tr><tr><td>1 year lag</td><td>0.920***</td><td>0.725***</td><td></td><td></td><td></td><td>0.785***</td><td>***669'0</td><td>0.684***</td><td>0.758***</td><td>0.745***</td></tr><tr><td></td><td>(0.006)</td><td>(0.012)</td><td></td><td></td><td></td><td>(0.013)</td><td>(0.013)</td><td>(0.011)</td><td>(0.012)</td><td>(0.011)</td></tr><tr><td>2yearlag</td><td></td><td>0.237***</td><td>0.737***</td><td>0.713***</td><td>0.769***</td><td>0.132***</td><td>0.167***</td><td>0.258***</td><td>0.231***</td><td>0.238***</td></tr><tr><td></td><td></td><td>(0.012)</td><td>(0.015)</td><td>(0.014)</td><td>(0.014)</td><td>(0.016)</td><td>(0.017)</td><td>(0.011)</td><td>(0.012)</td><td>(0.011)</td></tr><tr><td>3yearlag</td><td></td><td></td><td>0.241</td><td>0.291***</td><td>0.174***</td><td>0.063***</td><td>0.108***</td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td>(0.015)</td><td>(0.014)</td><td>(0.014)</td><td>(0.012)</td><td>(0.013)</td><td></td><td></td><td></td></tr><tr><td>Obs.</td><td>4353</td><td>6639</td><td>6588</td><td>7020</td><td>5885</td><td>5859</td><td>5976</td><td>6601</td><td>5799</td><td>6880</td></tr><tr><td>F-stat.</td><td>24594.8***</td><td>23758.9***</td><td>59141.8***</td><td>104036.2***</td><td>14160.3***</td><td>30094.2***</td><td>23490.2***</td><td>18968.2***</td><td>119239.0***</td><td>65837.8***</td></tr></table></body></html>\n\nStandard errors in parentheses $\\ddot{\\cdot}p<0.10$ $^{**}p<0.05$ $\\stackrel{**}{\\sim}p<0.01$  \n\nAnother industry with negative labor market concentration effect is education & healthcare. This is, perhaps, to be expected. Healthcare and education are services that tend to provided by larger establishments (i.e. hospitals and schools) relative to other service industries. Median employee count per establishment over 2002-2016 for education $\\&$ healthcare is 19.8, as compared to 11.7 for finance, 13.7 for professional $\\&$ business services, and 13.9 for miscellaneous services.23 Furthermore, these establishments are likely to be more geographically isolated. A relatively dated study from Luft and Maerki (1984) findsthat $47\\%$ of hospitals have no neighbors within a 5-mile radius, and $77\\%$ have fewer than five neighbors. More contemporary work of Burkey (2012) suggests this geographic distribution has remained largely unchanged, finding an average travel distance to the nearest hospital of approximately five and a half miles for individuals living within southern US states. While there is a lack of analogous studies for the geographic distribution of primary, secondary, and higher education establishments, it seems reasonable to assume some degree of negative spatial correlation between employers in the industry.24 The result is that education & healthcare embodies unique characteristics that consequentially produce conditions favorable to labor market monopsony.  \n\nTurning now to information and finance, I find both industries exhibit negative concentration effects. The effect in finance is approximately double the magnitude of information. The explanation for this difference in effect size remains unanswered. However, it should be noted that over the period 2002-2016, employee county per establishment increased for finance (10.7 to 12.7), but shrank for information (15.6 to 13.2). Nationwide, the number of information establishments increased by $5\\%$ Vs. $4.7\\%$ for financebetween 2002-2016. The number of establishments with fewer than twenty employees - a reasonable approximation for startups - grew by $9.1\\%$ for information vs. $8.4\\%$ for finance.25 In other words, the competitive startup environment among tech companies following the dot-com bubble vs. the general consolidation among financial firms in the years after the financial crisis (Wheelock et al., 2011) may partially explain a less pronounced concentration effect in the information industry.  \n\n![](images/4694ff5b033f619de62ad0c9822beb4140dc881a588ae910bdd069d200338d79.jpg)  \nFig. 7. K-means clustering based on residual estimations of Eq. (13) with no additional controls. Number of clusters $k=50$  \n\nAnother potential explanation is the degree of remote employment within information. Because the industry is integrally linked with digital technology, information workers have long experienced a higher probability of work-from-home arrangements. This implies that worker bargaining power in the industry is perhaps less sensitive to regional labor market concentration. Without further investigation, these explanations remain speculative. Nevertheless, the results suggest that labor shares in both finance and information are affected by conditions of monopsony.  \n\nIt is interesting to note that of those industries with high median HHI (manufacturing, mining, information, transportation & warehousing, education & healthcare), all but transportation $\\&$ warehousing exhibit statistically significant negative labor market concentration effects. By comparison, the effects in industries with low median HHI (trade, professional & business services, finance, construction, and miscellaneous services) exhibit no significance negative effect, with the exception of finance. This suggests the existence of non-linearities within the proposed mechanism. In other words, the effect of labor market monopsony on industry labor shares becomes more acute at higher levels of concentration. I view this as an important question to be addressed in future work.  \n\n![](images/0923e045f5bfd9d1a6e263ad8b0f733c49880be785f954300bd37847c198e4d7.jpg)  \nFig. 8. K-means clustering based on residual estimations of Eq. (13) with additional controls. Number of clusters $k=50$  \n\nOverall, I find that five of the ten industries analyzed exhibit negative labor market concentration effects. In terms of aggregate US employment, this suggests that approximately one third of all privatesector employees in 2016 were potentially subject to monopsonistic conditions with the potential to reduce their share of total output. This is a significant portion of the American workforce to be hand-waved away by the assumptions of perfect labor markets a la (Autor et al., 2020) and Karabarbounis and Neiman (2014).  \n\nWith respect to additional controls in Table 5, I do not find robust evidence for the arguments of union density, import exposure, or unemployment rate impacts on industry labor shares. Importantly, this does not suggest these mechanisms are invalid for explaining labor share decline at the aggregate level, as the analyses of Elsby et al. (2013), Fitchenbaum (2011), Storm (2017) and Karabarbounis and Neiman (2014), and others are conducted using national industry data. It is entirely possible that the impacts of these mechanisms are seen only in a subset of regions that have disproportionate weight in the aggregate economy. This may be obscured under the regional analysis provided in this paper, which treats CZs as equally weighted observations. Interestingly, I do find evidence for the capital cost hypothesis of Greenwood et al.(1997), Fisher (2006), and Karabarbounis and Neiman (2014) within manufacturing and information. These results suggest that substitution between labor and capital in response to changes in the price of investment goods is seen across regional economies for these capitalintensive activities. This is perhaps due to the fact that markets for investment goods are less regionally segmented (Atkeson and Bayoumi, 1993), such that the effect of capital-labor substitution remains observable at the regional industry level, as opposed to those mechanisms rooted in labor markets (union density, unemployment rate) or product markets (import exposure).  \n\n![](images/8bfcfcfef0b2092a3e0f7b3d394e20b1e7436b7acd70243838b1d0aa659f03f0.jpg)  \nFig. 9. Kernel density estimate for right tails of manufacturing and mining CZ employment share distributions, 2002-2016  \n\nA few limitations with the analysis presented in this paper must be discussed. First is the quality of additional control variables derived from the literature. While the approach used for obtaining measures of import exposure and capital cost at the CZ-industry level via subindustry weighted averages follows directly that of Autor et al. (2015) and Dorn et al. (2020), there is undoubtedly some degree of misspecification introduced to the analysis from these approximations. Unfortunately, there is little recourse to improve these estimates, as data for price of capital goods and import exposure is only collected at the national industry level. Similarly, observations for union coverage and unemployment, while available for the CZ-level (translated from county-level), lack industry disaggregation, requiring approximation by combining national industry and CZ-aggregate observations. These data limitations and imperfect solutions likely explain the general lack of statistical significance among these additional controls. In turn, it must be acknowledged that the results presented in Table 5 are misspecified to some degree due to observational mismeasurement. However, the consistency of estimates for the labor market concentration effect between estimations with and without addition controls suggests the degree of bias introduced by inclusion of these imperfect instruments is limited.  \n\nA second limitation of the results is that the model does not take into consideration the possibility of cross-industry labor market effects.  \n\nSimply put, it does not consider the degree of labor market concentration in other industries which may impact firms' labor supply functions. The logic is that reservation wages of workers are not just influenced by the degree of employer concentration within their current industry, but also in other industries that the worker could potentially transfer to. This of course requires careful consideration of the skill requirements within each industry. For example, a worker may transition from manufacturing to transportation $\\&$ warehousing or construction with relative ease, but not to, say, finance or information. Such an endeavor is beyond the scope of this paper, but is worthy of future consideration.  \n\nFinally, it should be noted that because of a change in data privacy policy, the most recent observations are restricted to 2016. While data for 2017-2021 is available and will continues to be released by the US Census, the nondisclosure of firm size for industries with fewer than four establishments makes use of these data in combination with prior years quite difficult. Efforts to control for the distortion caused by this change may allow for a longer panel to be constructed, but great care must be taken in order to avoid spurious results.  \n\n## 5. Concluding remarks  \n\nThis paper contributes to the existing literature on US labor share dynamics by presenting a mechanism rooted in imperfect competition in labor markets. I demonstrate that increased monopsony conditions suppress labor shares in several industries, including those most responsible for driving aggregate labor share decline at the national level — manufacturing and information. I find evidence of this mechanism as well in a mining, finance, and education & healthcare.  \n\nInherent to the mechanism described in previous sections is an assumption of labor immobility, both at the regional and industry level. Such rigidities reduce labor's ability to escape noncompetitive labor markets. Workers facing increased monopsony conditions within a particular industry often lack the ability to readily transition to alternative types of work with similar levels of compensation, as detailed by Storm (2017) and Rada et al. (2022). Instead, workers are forced to choose between continued employment under depressed wages, employment in low-skill service activities, or labor market exit. While regional labor mobility is clearly a feature of the US economy, migration based on economic conditions is generally associated with high-income earners (Topel, 1994; Morrison and Clark, 2011), implying that low and middle skill workers are unlikely to be willing or able to engage in mass relocation due to labor market conditions. In terms of implications for policy, this paper demonstrates the importance of institutionally focused approaches to combating inequality. Programs of reskilling aimed particularly at workers in highly monopsonistic industries will allow individuals to transition into activities with more competitive labor markets. This is particularly important for manufacturing and mining workers, given the average educational gap between workers in these industries vs. other monopsonistic industries. Such efforts will as well reduce the ability of firms to exploit workers' unfavorable positions by offering marginal wage premiums as the “best game in town\". Reskilling is likely to be a more effective and permanent solution than efforts to reestablish or reshore lost manufacturing employment, as evidenced by the continued decline in manufacturing employment despite past and present administrations’ efforts to revitalize American manufacturing.  \n\nThis paper is by no means intended to serve as a final analysis of the relationship between labor market conditions and labor share dynamics. Rather, it illustrates and tests one mechanism linking regional labor market monopsony to industry labor shares. There is significant opportunity for researchers to improve upon the theoretical and empirical methodology of this work. In particular, the linkage between forces of globalization and structural change, and regional labor market conditions is deserving of substantial future investigation.  \n\n# Declaration of competing interest  \n\nAll author declares that they have no conflict of interest.  \n\n# Data availability  \n\nData will be made available on request.  \n\n## Appendix  \n\nA.1.OLS estimation results See Tables 8 and 9.   \nA.2.First stage estimation results See Tables 10 and 11.  \n\n### A.3. Additional figures  \n\nSee Figs. 5-9.  \n\n# References  \n\nAaronson, Daniel, French, Eric, 2007. Product market evidence on the employment effects of the minimum wage. J. Labor Econ. 25 (1), 167-200.   \nAfonso, Antonio, Venancio, Ana, 2016. The relevance of commuting zones for regional spending efficiency. Appl. Econ.48 (10),865-877.   \nAshenfelter, Orley C., Farber, Henry, Ransom, Michael R., 2010. Labor market monopsony. J. Labor Econ. 28 (2), 203-210.   \nAtkeson, Andrew, Bayoumi, Tamim, 1993. Do private capital markets insure regional risk? Evidence from the United States and Europe. Open Econ. Rev. 4, 303-324.   \nAutor, David H., Dorn, David, Hanson, Gordon H., 2015. Untangling trade and technology: Evidence from local labour markets. Econ. J. 125 (584), 621-646.   \nAutor, David, Dorn, David, Katz, Lawrence F., Patterson, Christina, Van Reenen, John, 2020. The fall of the labor share and the rise of superstar firms. Q. J. Econ. 135 (2),645-709. Economic Modeing 125 (2023) 106342   \nAzar, Jose, Marinescu, loana, Steinbaum, Marshall, 2020. Labor market concentration. J. Hum. Resour. 1218-9914R1.   \nBentolila, Samuel, Saint-Paul, Gilles, 2003. Explaining movements in the labor share. Contrib. Macroecon. 3 (1).   \nBlack, Dan A, Nl, rett J.,ang, Zheng, 1999. O-thejob traning, establist size, and firm size: evidence for economies of scale in the production of human capital. South. Econ. J. 66 (1), 82-100.   \nBlanchard, Olivier, Giavazzi, Francesco, 2003. Macroeconomic effects of regulation and deregulation in goods and labor markets. Q. J. Econ. 118 (3), 879-907.   \nBlecker, Robert A., Settefield, Mark, 2019. Heterodox Macroeconomics: Models of Demand, Distribution and Growth. Elgar.   \nBoal, Wiliam M, Ransom, Michael R., 1997. Monopony in the labor market J Eon. Lit. 35 (1), 86-112.   \nBockerman, Petri, Maliranta, Mika, 2012 Glbalization, creative destruction, and labor share change: evidence on the determinants and mechanisms from longitudnal plant-level data. Oxf. Econ. Pap. 64 (2), 259-280.   \nBognar, S., Reichart, J, 2018. American Factory. Higher Ground Production.   \nBrooks, WyattJ,Kabki, JsehP, nd, ln ,Li, Yamr, Qan, 2021b. Infastructure invetment and labor monpsony power. IMF Econ. Rev.69 (3), 470-504.   \nBrooks, Wyatt J., Kaboski, Joseph P., Li, Yao Amber, Qian, Wei, 2021a. Exploitation of labor? Classcal monopsony power and labor's share. J. Dev. Econ. 150, 10227.   \nBurkey, Mark L, 202.emosing geographc accesibiltynt cmponet ats: methods and an application to hospitals. Ann. Reg. Sci. 48 (3), 78800   \nCarlin, Wedy, Soskie, David, 9.Macronmi and th Wae Bargain, V. 9. Oxford Universty Pess, Oxford.   \nCarpent Craigel,LtaMhal  T, haM22. to use commuting zones? An empirical description of spatial autocorrelation in US counties versus commuing zones. Ls One17 7), e02003   \nCrag,J,nt, ealya ii instrumental variable models. Econom, Theory 9 (2), 222-240.   \nDe, Prabal K, Nagaraj, Priya 2014. Productivity and frm size in India. Small Bus. Econ. 42 (4), 891-907.   \nDorn, David, Hanson, Gordon, Majlsi, Kaveh, et al, 2020. Imporing political polarization? The electoral consequences of rising trade exposure. Amer. Econ. Rev. 110 (10), 3139-3183.   \nDorn, David, Katz, Lawrence F., Patterson, Christina, Van Reenen, John, et al., 2017. Concentratng on te fallof te labr share.mer onRe 17(5), .   \nElsby, Hb, Sahn, Dl f tULaha Papers On Economic Activity, pp. 1-63.   \nFeenstra, Roer C. Hanson, Gordn H, 1996. Globalizaton, outsouring, and wa inequality. Amer. Econ. Rev. 86 (2), 240-245.   \nFisher, Jonas D.M., 2006. The dynamic effects of neutral and investment-specific technology shocks. J. Polit Econ. 114 (3), 413-451.   \nFitchenbamudyn aft abrs harein panel data: Do unions afect labor's share of income. Am. J. Econ. Sociol. 70 (3), 784-810.   \nFlaschel, Peter, Franke, Reiner, 1996. Wage flexibility and the stability arguments of the neoclassical synthesis. Metroeconomica 47 (1), 1-18.   \nFowler, Christ a, nill Jee  2ain revising commuting zones for 2010: History, assessment, and updates for US “labor-sheds' 1990-2010. Popul. Res. Policy Rev. 35 (2), 263-286.   \nGalbraith, Jmes K, 2012.Iquality and Istabity: A Stuy of the World Ecomy Just before the Great Crisis. Oxford University Press.   \nGoodwin, RM, 1967. A Growth Cyle Palgrave Mamilan U, London, pp. 165170.   \nGreenwood, Jeremy, Hercowitz, Zvi, Krusell Per, 1997. Long-run implications of investment-specific technological change. Amer. Econ. Rev. 87 (3), 342-362.   \nHansen, ars Per, 192. Lre ame rpt of geeralizd d f m estimators. Econometrica 1029-1054.   \nHnEcadckhangbstiamcrmi of inflation, distribution and employment. In: A Modern Guide to Keynesian Macroeconomics and Econmic Policies. pp 1136.   \nHelper, Susan, Henderson, Rebea, 2014. Management practics, relatnal contrat and the decline of general motors. J. Econ. Perspect. 28 (1), 49-72.   \nHicks, Joh, 1932 The Theory of Wages. Springer.   \nHrsch, ary T,Macphron,David , 2004.inmmberhip and cvera database from the curent population survy. Ind Labor Relat. Rev.   \nHopenhayn, Hugo, Neira, Julian, Singhania, Rish, 2022. From population growth to firm demographics: Implications for concentration, entrepreneurship and the labor share. Econometrica 90 (4), 1879-1914.   \nIdsn, T, i al, ers areme ptiv  lae fm. Econ. Rev. 89 (2), 104-108.   \nKarabarbounis, Loukas, Neiman, Brent, 2014. The global deline of the labor share.(report). Q. J. Econ. 129 (1).   \nKillian, Molly Sizer, Tolbert, Charles M, 2019. Mapping Social and Economic Space: The Delineation of Local Labor Markets in the United States. In: Inequalities in Labor Market Areas, Roe, pp9.   \nKeibergen, Frank, Paap, Richard, 2006. Generalized redd rank tests using th   \nLavoie, Marc, 1998. Simple comparative statics of class conflict in kaleckian and marxist short-run models. Rev. Radic. Political Econ. 30 (3), 101-113.   \nLuft, Harold S., Maerki, Susan C., 1984. Competitive potential of hospitals and their neighbors. Contemp. Econ. Policy 3 (2), 89-102.   \nManning, Alan, 1993. Wage bargaining and the phillips curve: The identification and specification of aggregate wage equations. Econ. J. 103 (416), 98-118.   \nManyika, James, Mischke, Jan, Bughin, Jacques, Woetzel, Jonathan, Krishnan, Mekala, Cudre, Samuel, 2019. A New Look at the Declining Labor Share of Income in the United States. McKinsey Global Institute.   \nMcDonald, Ian M., Solow, Robert M., 1981. Wage bargaining and employment. Amer. Econ. Rev. 71 (5), 896-908.   \nMendieta-Munoz, Ivan, Rada, Codrina, Arnim, Rudi, 2021. The decline of the US labor share across sectors. Rev. Income Wealth 67 (3), 732-758.   \nMilanovic, Branko, 2016. Global Inequality: A New Approach for the Age of Globalization. Harvard University Press.   \nMiller, Edward M., 1978. The extent of economies of scale: the effects of firm size on labor productivity and wage rates. South. Econ. J. 470-487.   \nMoran, Patrick AP., 1950. Notes on continuous stochastic phenomena. Biometrika 37 (1/2),17-23.   \nMorrison, Philip S., Clark, William A.V., 2011. Internal migration and employment: Macro flows and micro motives. Environ. Plan. 43 (8), 1948-1964.   \nNatalija, Novta, Pugacheva, Evgenia, 2019. Manufacturing Jobs and Inequality: Why Is the US Experience Different?. International Monetary Fund.   \nOi, Walter Y., Idson, Todd L., 1999. Firm size and wages. HandBook of Labor Economics 3,2165-2214.   \nPiketty, Thomas, 2014. Capital in the 21st Century. Harvard University Press.   \nRada, Codrina, Schiavone, Ansel, von Arnim, Rudiger, 2022. Goodwin, baumol & lewis: How structural change can lead to inequality and stagnation. Metroeconomica 73 (4),1070-1093.   \nRowthorn, R.E., 1977. Conflict, inflation and money. Camb. J. Econ. 1 (3), 215-239.   \nSargan, John D., 1958. The estimation of economic relationships using instrumental variables. Econometrica 393-415.   \nSargan, J.D., 1988. Estimating using instrumental variables. Contrib. Econ. 1 (1), 213.   \nSchmidt, Christoph M., Zimmermann, Klaus F., 1991. Work characteristics, firm size and wages. Rev. Econ. Stat. 705-710.   \nStaiger, Douglas, Stock, James H., 1997. Instrumental variables regression with weak instruments. Econometrica 65 (3), 557-586.   \nSteinbaum, Marshall, 2019. Antitrust, the gig economy, and labor market power. Law Contemp. Probl. 82 (45).   \nStigler, George J., 1958. The economies of scale. J. Law Econ. 1, 54-71.   \nStock, James, Yogo, Motohiro, 2005. Asymptotic distributions of instrumental variables statistics with many instruments. In: Identification and Inference for Econometric Models: Essays in Honor of Thomas Rothenberg, Vol. 6. pp. 109-120.   \nStorm, Servaas, 2017. The new normal: Demand, secular stagnation, and the vanishing middle class. Int. J. Political Econ. 46 (4), 169-210.   \nTaylor, Lance, Rezai, Armon, Foley, Duncan K., 2016. An integrated approach to climate change, income distribution, employment, and economic growth. Ecol. Econom. 121, 196-205.   \nTaylor John, B., 1979. Staggered wage setting in a macro model. Amer. Econ. Rev. 69 (2), 108-113.   \nTopel, R.H., 1994. Regional labor markets and the determinants of wage inequality. Amer. Econ. Rev. 84 (2), 17-22.   \nTran, Thi Bich, Grafton, Quentin, Kompas, Tom, 2009. Contribution of productivity and firm size to value-added: Evidence from Vietnam. Int. J. Prod. Econ. 121 (1), 274-285.   \nWallace, Michael, Leicht, Kevin T., Raffalovich, Lawrence E., 1999. Unions, strikes, and labor's share of income: A quarterly analysis of the United States, 1949-1992. Soc. Sci. Res. 28 (3), 265-288.   \nWheelock, David C., et al., 2011. Banking industry consolidation and market structure: impact of the financial crisis and recession. Fed. Reserve Bank St. Louis Rev. 93 (6), 419-438.   \nYeh, Chen, Macaluso, Claudia, Hershbein, Brad, 2022. Monopsony in the US labor market. Amer. Econ. Rev. 112 (7), 2099-2138.   \nYoung, Andrew T., Zuleta, Hernando, 2018. Do unions increase labor shares? Evidence from US industry-level data. East. Econ. J. 44 (4), 558-575.   \nZabojnik, Jan, Bernhardt, Dan, 2001. Corporate tournaments, human capital acquisition, and the firm size—Wage relation. Rev. Econom. Stud. 68 (3), 693-716.  "
  },
  "md_webberFirmMarketPower2015": {
    "reference_markdown": "# ECONSTOR  \n\nMakeYourPublicationsVisible.  \n\nA Service of  \n\nWebber, Douglas A.  \n\nWorking Paper Firm market power and the earnings distribution  \n\nIZA Discussion Papers, No. 7342  \n\nProvided in Cooperation with: IZA - Institute of Labor Economics  \n\nSuggested Citation: Webber, Douglas A. (2013) : Firm market power and the earnings distribution, IZA Discussion Papers, No. 7342, Institute for the Study of Labor (IZA), Bonn  \n\n# This Version is available at: https://hdl.handle.net/10419/71733  \n\n# Standard-Nutzungsbedingungen:  \n\n# Terms of use:  \n\nDieDokumente auf EconStor durfen zu eigenen wissenschaftlichen Zwecken und zum Privatgebrauch gespeichert und kopiert werden.  \n\nDocuments in EconStormaybesaved and copied foryourpersonal andscholarlypurposes.  \n\nSie durfendieDokumente nichtfuroffentliche oderkommerzielle Zwecke vervielfaltigen, offentlich ausstellen, offentlich zugänglich machen, vertreiben oder anderweitig nutzen.  \n\nYou arenottocopy documentsforpublicorcommercialpurposes,to exhibithedocumentspublicly,tomakethempubliclyavailableonthe internet,ortodistributeorotherwiseusethedocumentsinpublic.  \n\nSofern die Verfasser die Dokumente unter Open-Content-Lizenzen (insbesondere CC-Lizenzen) zur Verfuigung gestelt haben solten, gelten abweichend von diesen Nutzungsbedingungen die in der dort genannten Lizenz gewahrtenNutzungsrechte.  \n\nIf thedocumentshavebeenmadeavailableunderanOpenContent Licence(especially CreativeCommons Licences),you may exercise furtherusagerightsasspecifiedintheindicated licence.  \n\n![](images/dd994142309d22fcc4abf76a0fb6cf04e2537ddb411d78cf07e41393065b8774.jpg)  \n\n# Firm Market Power and the Earnings Distribution  \n\nDouglas A. Webber  \n\nForschungsinstitut zur Zukunft der Arbeit Institute for the Study of Labor  \n\n# Firm Market Power and the Earnings Distribution  \n\nDouglas A. Webber Temple University and IZA  \n\nDiscussion Paper No. 7342 April 2013  \n\nIZA  \n\nP.O. Box 7240 53072Bonn Germany  \n\nAny opinions expressed here are those of the author(s) and not those of IZA. Research published in this series may include views on policy, but the institute itself takes no institutional policy positions. The IZA research network is committed to the IZA Guiding Principles of Research Integrity.  \n\nThe Institute for the Study of Labor (IZA) in Bonn is a local and virtual international research center and a place of communication between science, politics and business. IZA is an independent nonprofit organization supported by Deutsche Post Foundation. The center is associated with the University of Bonn and offers a stimulating research environment through its international network, workshops and conferences, data service, project support, research visits and doctoral program. IZA engages in (i) original and internationally competitive research in all fields of labor economics, (i) development of policy concepts, and (i) dissemination of research results and concepts to the interested public.  \n\nIZA Discussion Papers often represent preliminary work and are circulated to encourage discussion. Citation of such a paper should account for its provisional character. A revised version may be availabledirectlyfromtheauthor.  \n\n## ABSTRACT  \n\n# Firm Market Power and the Earnings Distribution  \n\nUsing linked employer-employee data, I compute firm-level measures of the labor supply elasticity facing each private non-farm firm in the US. I provide the first direct evidence of the positive relationship between a firm's labor supply elasticity and the earnings of its workers. 1 also contrast the dynamic model method employed by this paper with the more traditional use of concentration ratios to measure a firm's labor market power. Finally, I construct a counterfactual earnings distribution which allows the effects of firm market power to vary across the earnings distribution.  \n\nJEL Classification: J42, J21  \n\nKeywords: monopsony  \n\nCorresponding author:  \n\nDoug Webber   \nTemple University   \nRitter Annex 883   \n1301 Cecil B. Moore Ave.   \nPhiladelphia, PA 19122   \nUSA   \nE-mail: douglas.webber@temple.edu  \n\n## 1 Introduction  \n\nThere is good reason to believe that some firms have non-trivial power in the labor market, that not all frms act as price takers and pay their employees the prevailing market wage. Intuitively, most would not switch jobs following a wage cut of one cent, and we would not expect a firm which raises wages by a small amount to suddenly have an infinite stream of workers. So it becomes an empirical question of whether the departure from perfect competition is meaningful; whether perfect competition is a good approximation for our economy, or whether a model with substantial frictions fits better.  \n\nThe existence of significant firm effects in wage regressions, even after controlling for detailed person and industry characteristics, is cited as strong suggestive evidence of frm market power (Abowd et al., 1999a; Goux and Maurin, 1999). For instance, Goux and Maurin (1999) conclude that on average firm effects alter an individual's wage by more than 20 percent. Furthermore, they find these firm effects are related more to firm characteristics such as size rather than productivity, implying that the firm effects are not simply absorbing workers’ unmeasured marginal product of labor.  \n\nEstimating the degree of wage competition in the labor market is important for both theoretical research and policy analysis. Since perfect competition is a standard feature in many models of the labor market, evidence of significant distortions in the labor market would suggest labor economists should reevaluate the perfect competition assumption and its implications in their models. From a policy perspective, the degree of imperfect competition can drastically change the effects of institutions such as the minimum wage (Card and Krueger, 1995) or unions (Feldman and Schefler, 1982).  \n\nWhile the industrial organization literature has theoretically and empirically modeled similar frictions in the product market, there has been comparatively less work done to account for distortions of the labor market. This is primarily due to the comparative lack of rich labor market data (such as linked employer-employee data) versus product market data. Most of the theoretical work done on this topic resides in the search theory literature, with major contributions coming from Burdett and Mortensen (1998) and Shimer (2005) to name a few'. This line of research has given rise to a \"new monopsony\" literature, popularized by Alan Manning's (Manning, 2003) careful analysis of labor-related topics absent the assumption of perfect competition. The new monopsony model of the labor market views a firm's market power as derived from search frictions rather than solely geographic power as in a classic monopsony model. These search frictions originate from imperfections in the labor market such as imperfect information about available jobs, worker immobility, or heterogeneous preferences.  \n\nEven if the existence of monopsony power is accepted, estimating the degree of market power possessed by a firm is not a simple task. Economists since Bunting (1962) have searched for empirical evidence of monopsony, with the predominant method being the use of concentration ratios, the share of a labor market which a given firm employs. The most commonly examined market in the empirical monopsony literature has been that of nurses in hospitals (Hurd, 1973; Feldman and Scheffer, 1982; Hirsch and Schumacher, 1995; Link and Landon, 1975; Adamache and Sloan, 1982; Link and Settle, 1979). This market lends itself to monopsony because nurses have a highly specific form of human capital and there are many rural labor markets where hospitals are the dominant employer. Despite the relatively large literature on this narrow labor market, the concentration ratio approach has yielded mixed results and no clear consensus.  \n\nMore recently, studies have attempted to directly estimate the average slope of the labor supply curve faced by the firm, which is a distinct concept from the market labor supply elasticity2. Studying the market for nurses, Sullivan (1989) finds evidence of monopsony using a structural approach to measure the difference between nurses’ marginal product of labor and their wages. Examining another market commonly thought to be monopsonistic, the market for schoolteachers, Ransom and Sims (2010) instrument wages with collectively bargained pay scales and estimate a labor supply elasticity between 3 and 4. In a novel approach using German administrative data, Schmieder (2010) finds evidence of a positive sloping labor supply curve through an analysis of new establishments.  \n\nUsing a dynamic approach similar to this study, Ransom and Oaxaca (2010) and Hirsch et al. (2010) both separately estimate the labor supply elasticities to the firm of men and women, each finding strong evidence of monopsonistic competition. Ransom and Oaxaca (2010) use data from a chain of grocery stores, and find labor supply elasticities of about 2.5 for men and 1.6 for women. Hirsch et al. (2010) uses administrative data from Germany to estimate elasticities ranging from 2.5-3.6 and 1.9-2.5 for men and women respectively. Applying this approach to survey data, Manning (2003) finds labor supply elasticities ranging from 0.68 in the NLSY to 1.38 in the PSID. In a developing country context, Brummund (2011) finds strong evidence of monopsony in Indonesian labor markets, estimating labor supply elasticities between .6 and 1.  \n\nUtilizing data from the US Census Bureau's Longitudinal Employer Household Dynamics (LEHD) program, I estimate the market-level average labor supply elasticity faced by firms in the US economy, similar to the Hirsch et al. (2010) study using German data. I then extend the approach to estimate firm-level labor supply elasticities. This is accomplished through an extension to the dynamic model of labor supply proposed by Manning (2003). This method allows me to examine the effects of monopsonistic competition on the earnings distribution in great detail, and contributes to the existing literature in a number of ways. First, it is the first examination of monopsony power using comprehensive administrative data from the US. Second, my particular empirical strategy allows me to examine the distribution of monopsony power which exists in the US, and to provide the first direct evidence on the negative impact of a firm's market power on earnings. I compare the performance of the market power measures derived in this study to that of the more traditional concentration ratio to illustrate the significant contribution of the new monopsony models. Finally, I construct a counterfactual earnings distribution in which frms’ market power is reduced in order to demonstrate the impact of imperfect competition on the shape of the earnings distribution.  \n\nI estimate the average labor supply elasticity to the firm to be approximately 1.08. Estimates in this range are robust to various modeling assumptions and corrections for endogenous mobility. Furthermore, I find evidence of substantial heterogeneity in the market power possessed by firms, ranging from negligible to highly monopsonistic. While a link between monopsony power and wages has traditionally been assumed (Pigou, 1924), I provide the first direct evidence of a positive relationship between a frm's labor supply elasticity and the earnings of its workers, estimating that a one-unit increase is associated with a decrease of between .05 and .15 in log earnings. I demonstrate that the effect of monopsony power is not constant across workers: unconditional quantile regressions imply that impacts are largest among low paid and negligible among high paid workers. Finally, implications in the inequality literature are addressed through the construction of a counterfactual earnings distribution, which implies that a one standard deviation increase of each firm's labor supply elasticity would decrease the variance of earnings distribution by 9 percent.  \n\nThe paper is organized as follows, Section 2 describes the definition of market power utilized in this study. Section 3 lays out the theoretical foundation for this study. The data and methods are described in Section 4. Section 5 presents the results and sensitivity analyses, and Section 6 concludes.  \n\n## 2 Discussion of Monopsony Power  \n\nThe concept of “\"monopsony” was first defined and explored as a model by Robinson (1933). In her seminal work, Robinson formulated the analysis which is still taught in undergraduate labor economics courses. Monopsony literally means “one buyer\", and although the term is most often used in a labor market context, it can also refer to a firm which is the only buyer of an input.  \n\nIt should be pointed out that in the “new monopsony” framework, the word monopsony is synonymous with the following phrases: monopsonistic competition, imperfect competition, finite labor supply elasticity, or upward sloping labor supply curve to the firm. While the classic monopsony model is based on the idea of a single firm as the only outlet for which workers can supply labor, the new framework defines monopsony as any departure from the assumptions of perfect competition. Additionally, the degree of monopsonistic competition may vary significantly across labor markets, and even across firms within a given labor market.  \n\nIn order to think about what determines a firm's monopsony power, we must consider why we do not observe the predicted behavior from a perfectly competitive model. What gives a firm fexibility in offering a wage rather than being forced to offer the market wage? Put another way, why do we not observe workers jumping from job to job whenever they observe a higher paying opportunity for which they are qualified?  \n\nOne of the most prominent reasons is that the typical worker does not have a continuous stream of job offers (this point will be discussed further in the theoretical model section). This source of monopsony power has roots in the classic monopsony framework in that, all else held constant, workers in labor markets with more frms are likely to have a greater number of offers. However, this idea takes an overly simplistic view of the boundaries of a given labor market. Most employers are likely operating in many labor markets at any given time. A prestigious university may be competing in a national or international labor market for professors, a regional labor market for its high-level administrators and technical staff, and a local labor market for the low-level service workers. Even if the arrival rate of job offers were the only source of monopsony power, it seems that geographic modeling alone would do a poor job of measuring that power. Another source of monopsony power is imperfect information about job openings (McCall, 1970; Stigler, 1962), which is not completely distinct from the arival rate of job offers since a decrease in information can cause a reduction in job offers. This is a particularly compelling example since studies such as Hofer and Murphy (1992) and Polachek and Robst (1998) estimate that imperfect information about job prospects depresses wages by approximately ten percent.  \n\nThe costs (both monetary and psychic) associated with changing jobs can also be thought of as giving market power to the firm. Moving costs are typically thought of as a short run cost, particularly when a worker is young. However these costs can grow significantly when a worker has a family and roots in a community. Consider the scenario of a dual-career family. Two job offers will be needed to induce either of the partners to move, a fact which gives significant bargaining power to the employers of each partner, particularly the one who is paid less. Additionally, changing jobs means that workers must adjust to a new system which will require at least a small degree of learning on the job.  \n\nFirm specific human capital also can be thought of as giving market power to the firm, since there is in effect a barrier to leaving a firm when an individual's firm specific capital is large relative to their general human capital. In fact, Wasmer (2006) concludes that markets with substantial search frictions induce workers to overinvest in firm specific human capital. Reputation costs likely also play a large role in the mobility of workers. Potential employers would be very suspicious of hiring a worker who changes jobs the moment he is offered any wage increase. For all of these reasons, and likely many more, workers must be selective with the wage offers they choose to accept, thus leading to a labor market with substantial frictions.  \n\nAs discussed in Manning (2011), another way to think about imperfect competition in the labor market is in terms of the rents received by the employee and the employer. On the worker's side, the rents to a given job match would be the difference between the current wage (utility) and the worker's opportunity cost, either a wage (utility) from a different frm or unemployment benefits. Studies such as Jacobson et al. (1993) implicitly estimate these rents by exploring the impacts of exogenous job destruction. This literature estimates wage losses of 20-30 percent, implying significant rents to employees from a given job match. From the employer's perspective, the rents from the ith job match are the difference between $(M P_{i}-w_{i})$ and $(M P_{j}-w_{j})$ , where j is the next worker who would be hired if worker i leaves the firm. This is a harder quantity to measure empirically, but can be approximated (assuming that the marginal product is the same for workers i and j) by hiring and training costs. The estimates of hiring and training costs as a fraction of total wages paid tend to be in the range of 3-7 percent (Oi, 1962; Abowd and Kramarz, 2003). The ratio of worker rents to employer rents can be thought of as a measure of the firm's market power. If the worker's opportunity cost is high relative to her employer's opportunity cost, then the employer will be able to extract a large amount of the surplus from the job match. However, if the converse is true, the worker will be in the position of power.  \n\nA relatively new branch of labor economics which focuses on the initial labor market conditions when a worker enters the labor market may also provide insight into the mobility of workers. A number of studies (Oyer, 2006, 2008; Genda and Kondo, 2010; Kahn, 2010) find persistent and negative wage effects from entering the labor market in a bad economy, lasting for at least 20 years. These persistent effects provide further evidence that there are significant long-run frictions in the economy.  \n\nFinally, while a worker's earnings represent an important market outcome, it is important to remember that wages make up only a part of the total “compensation\" to the worker. The true quality of a job match has many dimensions, such as benefits, working conditions, and countless other compensating differentials. The interaction of monopsony with these non-wage goods should be explored in future research.  \n\n## 3 Theoretical Model  \n\nA central feature of perfect competition is the law of one wage, that all workers of equal ability should be paid the same market clearing wage. In an attempt to explain how wage dispersion can indeed be an equilibrium outcome, Burdett and Mortensen (1998) develop a model of the economy in which employers post wages based on the wage-posting behavior of competing employers. Even assuming equal ability for all workers, wage dispersion is an equilibrium outcome as long as one assumes that the arrival rate of job offers is positive but finite (perfect competition characterizes the limiting case, as the arrival rate tends to infinity). While I do not explicity estimate the Burdett and Mortensen model in this paper, the intuition of monopsony power derived from search frictions is central to this study. See Kuhn (2004) for a critique of the use of equilibrium search models in a monopsony context.  \n\nThe Burdett and Mortensen model of equilibrium wage dispersion  \n\nAssume there are M $\\mathrm{\\Deltat}$ equally productive workers (where productivity is given by p), each gaining utility b from leisure. Further assume there are M $\\mathrm{e}$ constant returns to scale firms which are infinitesimally small when compared to the entire economy. A firm sets wage w to maximize steady-state profits π = (p-w)N(w) where N(w) represents the supply of labor to the frm. Also define F(w) as the cdf of wage offers observed in the economy, and f(w) is the corresponding pdf. All workers within a firm must be paid the same wage. Employed workers will accept a wage offer w’ if it is greater than their current wage w, and nonemployed workers will accept w? if w'≥b where b is their reservation wage. Wage offers are drawn randomly from the distribution F(w), and arrive to all workers at rate $\\lambda$ .Assume an exogenous job destruction rate $\\delta$ , and that all workers leave the job market at rate $\\delta$ to be replaced in nonemployment by an equivalent number of workers. $R^{N}$ denotes The recruitment fow and separation rate functions are given by:  \n\n$$\nR(w)=R^{N}+\\lambda\\int_{0}^{w}f(x)N(x)d x\n$$  \n\n$$\ns(w)=\\delta+\\lambda(1-F(w))\n$$  \n\nBurdett and Mortensen (1998), or alternatively Manning (2003), show that in this economy, as long as $\\lambda$ is positive and finite, there will be a nondegenerate distribution of wages even when all workers are equally productive. As $\\lambda$ tends to zero, the wage distribution will collapse to the monopsony wage, which in this particular economy would be the reservation wageb.As $\\lambda$ tends to infinity the wage distribution will collapse to the perfectly competitive wage, the marginal product of labor p.  \n\nNote that the following primarily relies on the model presented in Manning (2003), and incorporates a key insight from the recent working paper by Depew and Sorensen (2011) to derive the least restrictive formula for the labor supply elasticity facing the frm currently in the literature. We can recursively formulate the supply of labor to a firm with the following equation, where R(w) is the fow of recruits to a firm and s(w) is the separation rate.  \n\n$$\nN_{t}(w)=N_{t-1}(w)[1-s_{t-1}(w)]+R_{t-1}(w)\n$$  \n\nEquation (3) formalizes the definitionally true statement that a firm's employment this period is equal to the fraction of workers from last period who stay with the firm plus the number of new recruits. Noting that $N_{t}=\\gamma N_{t-1}$ where $\\gamma$ is the rate of employment growth between period t-1 and $\\mathrm{t}$ , we can rewrite Equation (3) as  \n\n$$\nN_{t}(w)=\\frac{R_{t}(w)}{1-(1-s_{t}(w))\\frac{1}{\\gamma_{t}}}\n$$  \n\nTaking the natural log of each side, multiplying by w, and differentiating we can write the elasticity of labor supply, $\\boldsymbol{\\varepsilon}$ , at time t as a function of the long-run elasticities of recruitment and separations, as well as the contemporary separation and growth rates.  \n\n$$\n\\varepsilon_{t}=\\varepsilon_{R}-\\varepsilon_{S}\\frac{s_{t}(w)}{\\gamma_{t}+s_{t}(w)-1}\n$$  \n\nWe can further decompose the recruitment and separation elasticities in the following wa.y  \n\n$$\n\\varepsilon_{t}=\\theta^{R}\\varepsilon_{R}^{E}+(1-\\theta^{R})\\varepsilon_{R}^{N}-\\theta^{S}\\varepsilon_{S}^{E}\\frac{s_{t}^{E}(w)}{\\gamma_{t}+s_{t}^{E}(w)-1}-(1-\\theta^{S})\\varepsilon_{S}^{N}\\frac{s_{t}^{N}(w)}{\\gamma_{t}+s_{t}^{N}(w)-1}\n$$  \n\nWhere the elasticity of recruitment has been broken down into the elasticity of recruitment of workers from employment $\\left(\\varepsilon_{R}^{E}\\right)$ and the elasticity of recruitment of workers from nonemployment $\\left(\\varepsilon_{R}^{N}\\right)$ . Similarly the elasticity of separation has been decomposed into the elasticity of separation to employment $\\left(\\varepsilon_{S}^{E}\\right)$ and the elasticity of separation to nonemployment $\\left(\\varepsilon_{S}^{N}\\right)$ $\\theta^{R}$ and $\\theta^{S}$ represent the share of recruits from employment and the share of separations to employment respectively.  \n\nWhile there are established methods for estimating separation elasticities with standard job-fow data, recruitment elasticities are not identified without detailed information about every job offer a worker receives. Therefore, it would be helpful to express the elasticities of recruitment from employment and noemployment as functions of estimable quantities.  \n\nLooking first at the elasticity of recruitment from employment, we can write the recruitment from employment function and its derivative as  \n\n$$\nR^{E}(w)=\\lambda\\int_{0}^{w}f(x)N(x)d x\n$$  \n\n$$\n\\frac{\\partial R^{E}(w)}{\\partial w}=\\lambda f(w)N(w)\n$$  \n\nCombining Equations (4), (7), and (8), along with the definition of an elasticity ( $\\varepsilon_{R}^{E}=$ $\\frac{w}{R^{E}(w)}\\frac{\\partial R^{E}(w)}{\\partial w}\\Big)$  \n\n$$\n\\varepsilon_{R}^{E}=\\frac{w\\lambda f(w)}{1+\\frac{s_{t}^{E}(w)}{\\gamma_{t}}-\\frac{1}{\\gamma_{t}}}\n$$  \n\nIn dealing with the numerator, note that the the derivative of the separation to employment function, $s^{E}(w)=\\lambda(1-F(w))$ ,is  \n\n$$\n\\frac{\\partial s^{E}(w)}{\\partial w}=-\\lambda f(w)\n$$  \n\nCombining equations (9), (10), and the definition of an elasticity $\\begin{array}{r}{\\varepsilon_{s}^{E}=\\frac{w}{s^{E}(w)}\\frac{\\partial s^{E}(w)}{\\partial w})}\\end{array}$ ，we  \n\ncan write the elasticity of recruitment from employment as a function of estimable quantities:  \n\n$$\n\\varepsilon_{R}^{E}=\\frac{-\\varepsilon_{S}^{E}s_{t}^{E}(w)}{1+\\frac{s_{t}^{E}(w)}{\\gamma_{t}}-\\frac{1}{\\gamma_{t}}}\n$$  \n\nNext, Manning (2003, p. 100) notes that the elasticity of recruitment from nonemployment can be written as  \n\n$$\n\\varepsilon_{R}^{N}=\\varepsilon_{R}^{E}-w\\theta^{\\ast R}(w)/\\theta^{R}(w)(1-\\theta^{R}(w))\n$$  \n\nThis is derived from the simple definition of $\\theta^{R}$ , the share of total recruits which come from employment, which implies $R^{N}=R^{E}(1-\\theta^{R})/\\theta^{R}$ ，where $R^{N}$ and $R^{E}$ are the recruits from nonemployment and employment respectively. Taking the natural log of each side of this relation and differentiating yields the relation depicted in Equation (12). The second term on the right-hand side of Equation (12) can be thought of as the bargaining premium that an employee receives from searching while currently employed. Thus, the labor supply elasticity to the firm can be written as a function of both separation elasticities, the premium to searching while employed, and the calculated separation and growth rates. To my knowledge, no other study has estimated this model before.  \n\nIn an economy where the arrival rate of job offers is finite (and thus the labor supply elasticity is finite) firms are not bound by market forces to pay workers their marginal product of labor. The model presented above implies that, even in a world where all firms and individuals are identical, a decrease in the arrival rate of job offers will both lower the average wage and increase inequality. To see how a firm's labor supply elasticity affects the wage it pays, consider a profit-maximizing firm which faces the following objective function:  \n\n$$\n\\begin{array}{r}{M a x}{{\\Pi}=p Q(L)-w L(w)}\\ {w}\\end{array}\n$$  \n\nP is the price of the output produced according to the production function Q. The  \n\nchoice of wage w determines the labor supplied to the firm L. Taking first order conditions, substituting $\\begin{array}{r}{\\varepsilon=\\frac{w}{L(w)}\\frac{\\partial L(w)}{\\partial w}}\\end{array}$ , and solving for w yields:  \n\n$$\nw={\\frac{p Q^{\\prime}(L)}{1+{\\frac{1}{\\varepsilon}}}}\n$$  \n\nThe numerator in Equation (14) is simply the marginal product of labor, and $\\boldsymbol{\\varepsilon}$ isthe labor supply elasticity faced by the firm. It is easy to see that in the case of perfect competition $\\varepsilon=\\infty$ ) that the wage is equal to the marginal product of labor, but the wage is less than then marginal product for all $0<\\varepsilon<\\infty$  \n\nEvery empirical study in the new monopsony literature attempts to estimate the labor supply elasticity to the firm at the market level. In other words, they measure the (frm-size weighted) average slope of each firm's supply curve in the market. In a highly competitive market we would expect these elasticities to be very large numbers. Among the contributions of this paper is to separately estimate each firm's labor supply elasticity rather than a market average.  \n\n## 4 Data and Methodology  \n\n### Data  \n\nThe Longitudinal Employer Household Dynamics (LEHD) data are built primarily from Unemployment Insurance (UI) wage records, which cover approximately 98 percent of wage and salary payments in private sector non-farm jobs. Information about the firms is constructed from the Quarterly Census of Employment and Wages (QCEW). The LEHD infrastructure allows users to follow both workers and firms over time, as well as to identify workers who share a common employer. Firms in these data are defined at the state level, which means that a Walmart in Florida and a Walmart in Georgia would be considered to be different firms. However, all Walmarts in Florida are considered to be part of the same firm. These data also include demographic characteristics of the worker and basic firm characteristics, obtained through administrative record and statistical links. For a complete description of these data, see Abowd et al. (2009).  \n\nMy sample consists of quarterly observations on earnings and employment for 47 states between1985 and $2008^{3}$ . I make several sample restrictions in an attempt to obtain the most economically meaningful results. These restrictions are necessary in large part because the earnings data are derived from tax records, and thus any payment made to an individual, no matter how small, will appear in the sample. As a consequence, there are many “job spells\" which appear to last only one quarter, but are in fact one-time payments which do not conform with the general view of a job match between a firm and worker.  \n\nFirst, I only include an employment spell in the sample if at some point it could be considered the dominant job, defined as paying the highest wage of an individual's jobs in a given quarter4. I also remove all spells which span fewer than three quarters.5 This sample restriction is related to the construction of the earnings variable. Since the data do not contain information on when in the quarter an individual was hired/separated, the entries for the first and last quarters of any employment spell will almost certainly underestimate the quarterly earnings rate (unless the individual was hired on the first day or left employment on the last day of a quarter). Thus, in order to get an accurate measurement of the earnings rate I must observe an individual in at least one quarter other than the first or last of an employment spell. I remove job spells which have average earnings greater than $\\$1$ million per quarter and less than $\\$100$ per quarter, which corresponds approximately to the top and bottom 1 percent of observations  \n\nAdditionally, I limit the analysis to firms with 100 total employment spells of any length over the lifespan of the firm. For the full-economy monopsony model, these sample restrictions yield a final sample of approximately 149,710,000 unique individuals who had 325,630,000 total employment spells at 670,000 different firms. Additionally, for analyses using the frm-level measure of the labor supply elasticity, only firms which have greater than 25 separations to employment, 25 separations to unemployment, and 25 recruits from employment over the lifespan of the firm are considered. This reduces the analysis sample to approximately 121,190,000 unique individuals having 267,310,000 employment spells at 340,000 unique firms.  \n\n### Empirical Strategy  \n\nThe primary reason for the small empirical literature on monopsony is a lack of high quality data. In order to identify a firm's market power, the researcher must have a credible frmlevel instrument for each firm studied or detailed employer-employee linked data to identify worker fows. I employ the latter approach in this study since finding a credible instrument for nearly every firm in the US is unlikely. The construction of the market power measures most closely represents an augmented firm-level implementation of the methodology proposed in Manning (2003).  \n\nI first describe in detail how the market power measures are calculated, followed by a description of how they are used to examine the US earnings distribution.  \n\n#### Location-Based Measures  \n\nI construct an overall measure of the percent of the industry-specific labor market that each frm employs (Number of workers at firm i/number of workers in firm i's county and in firm i's industry) using North American Industry Classification System (NAICS) industry definitions. While this variable is far from a perfect measure of an employer's power to set wages, it has several advantages over the dynamic measures to be used later in the paper. Both the construction of these measures and the regression estimates using them are transparent. Endogeneity, misspecified equations, etc. are of less concern in the construction of these labor concentration measures, and the interpretation of the regression coeffcients on these variables is straightforward. This analysis corresponds to the traditional concentration ratio approach of analyzing labor market power.  \n\n#### Dynamic Measure  \n\nThe simplest way to estimate the labor supply elasticity to the firm would be to regress the natural log of firm size on the natural log of firm wages. However, even when controlling for various demographic characteristics, this is deemed to produce a potentially biased estimate?. I therefore rely on estimating parameters presented in the theoretical section which are plausibly identified, and then combine them using results from Manning (2003) and equation (6) to produce an estimate of the labor supply elasticity to the firm.  \n\nTo my knowledge, only Hirsch et al. (2010) has used a similar, but considerably more restrictive, method with administrative data which yielded an economy-wide estimate of the average labor supply curve facing the frm. Manning (2003) also estimates an economy-wide measure of the degree of monopsony using surveys such as the National Longitudinal Survey of Youth (NLSY) 1979. One of the major contributions of this paper is that I estimate the labor supply elasticities for each frm, rather than the average over the whole economy. Additionally, these prior studies imposed a steady-state assumption on their model, which the model in this paper does not impose. Estimating the labor supply elasticities at the firm level does have several advantages. First, the estimation of each of the elasticity components is much more fexible than even the least constrained specifications of Hirsch et al. (2010). Second, I will be able to use the measures as an explanatory variable, and can test a number of different models. Finally, I will be able to examine the effect of market power on earnings at each point in the market power distribution, rather than examining only the average effect. This is particularly important because theory predicts significant nonlinear effects relating to the labor supply elasticity and a frm's ability to mark down wages (Pigou, 1924). However, this strategy has the drawback that I am unable to estimate the relevant parameters, and thus the labor supply elasticity, for the smallest firms (sample restrictions are discussed in the data section).  \n\nAccording to the results presented in the theoretical model section, three quantities must be estimated in order to construct the labor supply elasticity measure, ( $\\varepsilon_{S}^{E}$ $\\varepsilon_{S}^{N}$ and $w\\theta^{R^{\\prime}}(w)/\\theta^{R}(w)(1-\\theta^{R}(w)))$ , as well as the calculated separation and growth rates for each firm. Each of the following models will be run separately for every firm in the sample (as well as on the whole sample for comparison purposes), where the unit of observation is an employment spell, thus one individual can appear in multiple firm's models. Looking first at the separation elasticities, I model separations to nonemployment as a Cox proportional hazard model $7$ givenby  \n\n$$\n\\lambda^{N}(t|\\beta^{N,s e p}l o g(e a r n i n g s)_{i}+X_{i}\\gamma^{N,s e p})=\\lambda_{0}(t)\\exp(\\beta^{N,s e p}l o g(e a r n i n g s)_{i}+X_{i}\\gamma^{N}\n$$  \n\nwhere $\\lambda()$ is the hazard function, $\\lambda_{0}$ is the baseline hazard, t is the length of employment, log(earnings) is the natural log of individual i's average quarterly earnings,& and X is a vector of explanatory variables including gender, race, age, education, and year control variables (industry controls are also included in the full-economy model). While the entire sample will be used, workers who transition to a new employer or who are with the same employer at the end of the data series are considered to have a censored employment spell. In this model, the parameter $\\beta$ represents an estimate of the separation elasticity to nonemployment. In an analogous setting, I model separations to employment as  \n\n$$\n\\lambda^{E}(t|\\beta^{E,s e p}l o g(e a r n i n g s)_{i}+X_{i}\\gamma^{E,s e p})=\\lambda_{0}(t)\\exp(\\beta^{E,s e p}l o g(e a r n i n g s)_{i}+X_{i}\\gamma^{E,s e p})\n$$  \n\nwith the only difference being that the sample is restricted to those workers who do not have a job transition to nonemployment. As before, $\\beta$ represents an estimate of the separation elasticity to employment. To estimate the third quantity needed for equation (6), $w\\theta^{\\cdot R}(w)/\\theta^{R}(w)(1-\\theta^{R}(w))$ , Manning (2003) shows that this is equivalent to the coefficient on log earnings when estimating the following logistic regression  \n\n$$\nP_{r e c}=\\frac{\\exp(\\beta^{E,r e c}l o g(e a r n i n g s)_{i}+X_{i}\\gamma^{E,r e c})}{1+\\exp(\\beta^{E,r e c}l o g(e a r n i n g s)_{i}+X_{i}\\gamma^{E,r e c})}\n$$  \n\nwhere the dependent variable takes a value of $1$ if a worker was recruited from employment and $0$ if they were recruited from nonemployment. To enable this coefficient to vary over time, log earnings is interacted with time dummies. The same explanatory variables used in the separation equations are used in this logistic regression. At this point the results listed in the theoretical section can be used (along with calculating the share of recruits and separations to employment, separation rates, and growth rates for each firm) in conjunction with equation (6) to produce an estimate of the labor supply elasticity facing each firm. 9  \n\nTo provide some intuition on the models being estimated, consider the analysis of separations to employment. A large (in absolute value) coeffcient on the log earnings variable implies that a small decrease in an individual's earnings will greatly increase the probability of separating in any given period. In a perfectly competitive economy, we would expect this coefficient to be infinitely high. Similarly, a very small coefcient implies that the employer can lower the wage rate without seeing a substantial decline in employment. One concern with this procedure is that this measure of monopsony power is actually proxying for high-wage frms, reflecting an efficiency wage view of the economy where firms pay a wage considerably above the market wage in exchange for lower turnover. This is much more of a concern in the full economy estimate of the labor supply elasticity to the firm found elsewhere in the literature than in my firm-level estimation since the models in this paper are run separately by firm. The logic behind this difference is that in the full economy model cross-sectional variation in the level of earnings is used to identify the labor supply elasticity. In a frm-specific model, however, the labor supply elasticity of firm A does not mechanically depend on the level of earnings at firm B. This efficiency wage hypothesis will be directly tested.  \n\n### Analysis  \n\nIn addition to the full-economy models of monopsony, I include the concentration ratio and firm-level labor supply elasticity measures in earnings regressions. This provides direct evidence of the effect of firm market power on earnings, a feature not possible in the fulleconomy models. Additionally, it serves as a test of the effciency wage hypothesis, which predicts that firms with low estimated labor supply elasticities will pay the highest wages. The main focus of this paper is on this model, explicitly written as:  \n\n$$\nl o g(q u a r t e r l y e a r n i n g s_{i j})=\\beta m a r k e t p o w e r_{j}+\\gamma X_{i j}+\\delta Y_{j}+\\theta Z_{i}+\\varepsilon_{i j}\n$$  \n\nThe dependent variable is the natural log of individual i's quarterly earnings in employment spell j. The market power variable represents firm j's estimated labor supply elasticity or the share of the local working population employed at the firm. X is a vector of person and frm characteristics, which may vary by the employment spell, including age, age-squared, tenure (quarters employed at firm), tenure-squared, education $_{10}$ , gender, race, ethnicity, year effects, indicator variables for the two-digit NAICS sector, and the size (employment) of the firm. Y is a vector of firm fixed-effects, Z is a vector of person fixed-effects, and $\\boldsymbol{\\varepsilon}$ is the error term. Time-invariant characteristics in X are excluded in models with person or firm fixed-effects.  \n\nFinally, to examine whether there is a disproportionate impact of imperfect competition on workers near the bottom of the earnings distribution, I construct a counterfactual earnings distributions in which each firm's labor supply elasticity is increased. The counterfactual distribution is constructed according to the unconditional quantile approach decomposition suggested in Firpo et al. (2011). Unconditional quantile regression, first introduced in Firpo et al. (2009), estimates the parameters of a regression model as they relate to the quantiles of the dependent variable. This contrasts with traditional quantile regression, which estimates parameters corresponding to the conditional (on the included regressors) quantiles of the dependent variable. The unconditional quantile approach is most advantageous in models with relatively low R-squared (i.e. all wage regressions) since the quantiles of y are most likely to diverge from the quantiles of y-hat (predicted dependent variable) in this scenario.  \n\nUnder this approach, unconditional quantile regressions are performed on every 5th quantile of the earnings distribution using the same model as Equation (18). The estimated coefficients on the labor supply elasticity variable from each regression will then be used to simulate the impact of a one unit increase in the labor supply elasticity to the firm on earnings in the associated quantile.  \n\n## 5 Results  \n\n### Summary Statistics  \n\nTable 1 reports both employment spell and firm-level summary statistics. Since the unit of observation is the employment spell rather than the individual, and only dominant jobs are included, some statistics deviate slightly from typical observational studies of the labor market (such as a nearly even split of job spells between men and women). The average employment spell lasts about two and a half years, with more than sixty percent of spells resulting from a move from another job. The quarterly nature of the LEHD data make it difficult to precisely identify $_{11}$ whether an individual separated to employment or nonemployment, and therefore the proportion of separations to employment is slightly higher than comparable statistics reported in Manning (2003).  \n\nThe average firm in my sample employs nearly 3000 workers and hires almost 500 in a given quarter. Several qualifications must be made for these statistics. First, the distributions are highly skewed, with the median firm employing only 400 and hiring 75 in a given quarter. Second is that statistics are not point in time estimates, but rather totals throughout an entire quarter. Finally, remember that these are at the firm (state-level) rather than at the establishement (individual unit) level. Also of note are the employment concentration ratios, with the average firm employing roughly 9 percent of their county's industry specific labor force.  \n\n#### Location-Based Measure  \n\nAs previously noted, many studies have attempted to search for evidence of monopsony in the labor market through the use of concentration ratios. While this approach was the best available given prior data constraints, it assumes that monopsony power is derived only from geographical constraints.  \n\nTable 2 presents the estimated impact of a ten percentage point increase in the concentration ratio in various specifications of Equation (18). These results suggest that, in general, a firm's geographic dominance does not appear to significantly alter the wage bill it pays. Note that when the models are run separately by North American Industry Classification System (NAICS) sector, as depicted in Table 3, there is evidence that firms with high concentration ratios in certain industries (such as the utilities sector) pay slightly lower wage bills. However, the effect sizes are small relative to the observed distribution of concentration ratios. Given the small results, and the fact that the industry-specific effects seem to be centered around zero, it seems plausible to conclude that geographic constraints in the labor market play at most a small role in wage determination for the average worker.  \n\n#### Full-Economy Model  \n\nI first compute the average labor supply elasticity to the firm prevailing in the economy by estimating Equations (15)-(17) on a pooled sample of all (dominant) employment spells, and combining the results according to Equation (6). Table 4 presents the output of a several specifications of the full-economy monopsony model. The estimated elasticities range from 0.76 to 0.82 depending on the specification.12 These elasticities are certainly on the small side, implying that at the average firm a wage cut of one percent would only reduce employment by .8 percent. However, this magnitude is still within the range observed by Manning (2003) in the NLSY79. Additionally, even the inclusion of fixed-effects still puts many more restrictions on the parameter estimates than separate estimations for each firm. Based on a comparison of the full-economy model and the firm-level model presented in the next section, the failure to fully saturate the full economy model likely produces downward biased estimates. A detailed discussion of factors which may attenuate these estimates, 12i.e. The inclusion of random effects and the use of a conditional logit model to account for person or as well as structural reasons we should expect these results from US data, is given in the \"Discussion and Extensions\" section.  \n\n#### Firm-Level Measure  \n\nTable 5 presents the elasticities estimated through Equations (15)-(17). The first four columns report the average firm-level elasticities of recruitment from employment and nonemployment, and the separation elasticities to employment and nonemployment respectively. The final column combines these elasticities, along with the calculated shares of separations/recruits to/from employment to obtain the labor supply elasticity. Of note is that the labor supply elasticity does not appear to depend substantially on the regressors included in the model. The first three rows report only the long-run elasticities, while the final row describes the elasticities when each quantitiy is allowed to vary over time. Not accounting for the time-varying nature of the labor supply elasticity, as has been common in the prior literature, appears to underestimate its magnitude by $20\\%$  \n\nTable 6 displays information about the distribution of firms’ labor supply elasticities, and Figure 2 presents a kernel density plot of the market power measurel3. This distribution is constructed by separately estimating Equations (15)-(17) for each firm. While the median supply elasticity (0.75) is close to the estimate from the full-economy model, there appears to be significant variation in the market power possessed by firms. I estimate a mean labor supply elasticity of 1.08, however, there are many firms (about 3 percent of the sample) with labor supply elasticities greater than 5. It appears that while there is a nontrivial fraction of firms whose behavior approximates a highly competitive labor market, the majority of the distribution is characterized by significant frictions. While not surprising, to my knowledge this is the first documentation of the large discrepancy in firms' ability to set the wage.  \n\nTable 7 reports average labor supply elasticities broken down by NAICS sector. I find significant variation in these estimates across industries. The manufacturing sector appears 13For confidentiality reasons, the long right tail of the kernel density plot has been suppressed  \n\nto enjoy the least wage-setting power, with a labor supply elasticity of 1.82. As manufacturing is likely the most heavily unionized of all sectors, this result is not surprising. By contrast, firms in the health care (0.78) and administrative support (0.72) sectors seem to wield the greatest wage-setting power. This is consistent with the focus on the healthcare market among economists investigating monopsony power.  \n\nThe central focus of this paper is presented in Table 8, which estimates various specifcations of Equation (18) in order to measure the impact of market power on the earnings distribution. Unconditionally, a one unit increase in the labor supply elasticity increases earnings by .13 log points. Even the specifications with the most detailed controls estimate a strong positive relationship between a firm's labor supply elasticity and the earnings of its workers. These estimates range from an impact of 0.05 log points in the model with person fixed-effects to an impact of 0.15 log points (or 16 percent after applying the forumula $\\exp(\\beta),$ with an AKM variant which accounts for both person and firm effects. 14. This is an important result for the new monopsony literature, because it rules out the possibility that the dynamic model identification strategy is actually identifying high-wage firms whose employees do not often switch jobs due to the high wages.  \n\nThere is good reason to believe that the estimates in Table 8 are lower bounds of the true impact of firm market power on earnings. Each labor supply elasticity is a weighted average of many more precisely defined elasticities which would more accurately measure a firm's market power over a particular individual. For example, firms likely face different supply elasticities for every occupation, and potentially different elasticities across race and gender groups. From a measurement error perspective, regressing the log of earnings on the average labor supply elasticity to the firm would attenuate the estimates relative to the ideal scenario where I could separately identify every occupation specific elasticity.  \n\nreason to believe that firms are not using the majority of labor market power available to them. Bronfenbrenner (1956) first made this point, arguing that most frms in our economy likely faced upward sloping labor supply curves but that these firms would not pay substantially less than the competitive wage. This could be because firm's choose to maximize some function of profits and other quantities such as public perception and worker happiness.  \n\nTo test this assertion, we can calculate what the coeffcient on labor supply elasticity should be in an economy where frms only maximize profits and the mean labor supply elasticity is 1.08. This is done by taking the derivative of the coefficient on the marginal product of labor in Equation (14) and dividing this by the coefficient itself, a formula which simpifes to $\\frac{1}{\\varepsilon^{2}+\\varepsilon}$ . Evaluating this at a labor supply elastity of 1.08 implie that if frmns were exploiting all of their market power then the markdown from the marginal product of labor implied by the coefficient on labor supply elasticity in Table 8 should be about 0.45, roughly three times greater than the estimated 0.16. Even assuming a high degree of measurement error in the assignment of the average labor supply elasticity to all workers in a firm would likely not account for this disparity. One possibility is that firms reduce labor costs through other avenues than wages which are more easily manipulated such as benefits. Alternatively, this may be evidence that firms do not solely maximize profits, but instead maximize some combination of profits and other quantities (i.e. public perception).  \n\nAlso of note in Table 8 is how the coefficient on the gender-specific labor supply elasticity variable changes as person and firm fixed effects are added. The noticable increase in the coefficient, both when firm and person effects are added to the model, imply that on average low-wage firms have higher labor supply elasticities, and low-wage workers have higher labor supply elasticities. This is in line with the current thinking regarding monopsony power and its interaction with skilled and unskilled labor (Stevens, 1994; Muehlemann et al., 2010).  \n\n#### Counterfactual Distribution  \n\nTable 9 details the disproportionate effect which firms’ market power has on workers at the low end of the earnings distribution. Assuming a one unit increase in the labor supply elasticity for each firm (approximately 1 standard deviation), the 10th percentile of the earnings distribution increases by 0.09 log points under the counterfactual assumption, while the median worker sees an increase of 0.04 log points and the 90th percentile remains unchanged. The nonlinear impacts are also clearly seen in the unconditional quantile regression coefficients, which are 4-5 times greater than the OLS coefficient at lower quantiles and essentially zero at the upper end of the distribution.  \n\nStandard measures of inequality are also reported in Table 9 for both the empirical and counterfactual distributions. A one unit increase in frms labor supply elasticity is associated with a 9 percent reduction in the variance of the earnings distribution (0.94 to 0.86 log points). Similarly, we see decreases in the 90-10 ratio (1.32 to 1.3), 50-10 ratio (1.18 to 1.16), and 90-50 ratio (1.12 to 1.11).  \n\nThese results could arise from a number of different scenarios, the examination of which is beyond the scope of the current paper. It may refect low-ability workers having few outside options for employment. This could be due to strict mobility constraints, a less effective job referral network (Ioannides and Loury, 2004), lower job search “ability” (Black, 1981), or simply being qualified for fewer jobs. Another mechanism through which a firm's market power might differentially affect low wage workers is gender discrimination, as suggested by Hirsch et al. (2010) or racial discrimination. These questions deserve a much deeper treatment, and should be explored in future research.  \n\nFigure 3 plots both the empirical earnings distribution and the counterfactual distribution under a more drastic assumption which more closely approximates perfect competition, that each firm's labor supply elasticity is increased by a factor of 10 (median elasticity goes from .74 to 7.4). The variance of the counterfactual distribution is considerably lower, with nearly all of the movement occurring in the lower half of the distribution. The striking fact about  \n\nFigure 3 is that the Burdett and Mortensen model predicts this same behavior as the arrival rate of job offers increases.  \n\nIt is important to note that the results in the counterfactual distribution are estimated from a model which includes all person and firm controls, but no person or firm fixed effects. This is because identifying off of within person/firm variation in a sense redefines the unconditional quantiles of the distribution, and can introduce substantial bias into the results. Given that the OLS estimates of the impact of firm market power are larger in the specifications which include fixed effects, the results in Table 9 should be taken as lower bounds.  \n\n### Discussion and Ectensions  \n\nThe labor supply elasticities reported in this paper imply that firms possess a high degree of power in setting the wage. For a variety of reasons, these elasticities are on the lower end of those present in the literature. In this section I address the factors which contribute to these results.  \n\nFirst, it should be noted that the only other studies to estimate the labor supply elasticity to the firm with comprehensive administrative data used European data. Given the very restrictive (from the point of view of the employer) employment laws in place in many European countries, this result is not surprising. Assuming that job security accrues over time within frm but drops following a transition to a new firm, any law which makes it more difficult to fire a worker effectively lowers the cost to the employee of switching jobs because job security is less of a factor.  \n\nOne potential criticism of the labor supply elasticities derived in this paper is that the data do not contain detailed occupation characteristics. This problem is mitigated by the fact that the measures are constructed at the firm level in that I am only comparing workers in the same firm in the construction of a firm's monopsony power. Additionally, previous studies such as Hirsch et al. (2010) and Manning (2003) find that the addition of individuallevel variables had little impact on the estimated labor supply elasticities and that it was the addition of firm characteristics which altered the results. As a further check of this problem, I compute the aggregate monopsony measures in the NLSY, as done in Manning (2003), both with and without detailed occupation characteristics. As shown in Table 10, I find that the difference between these labor supply elasticities is about 0.2 and is not statistically significant. Keep in mind that even if this difference were statistically significant, the estimates in this paper are still a long way from implying perfect competition. Thus, I conclude that the absence of occupation controls in the LEHD data will not seriously bias the results of this study. Additionnally, the firm-level analyses performed in this paper were estimated at the occupation level on a small subset of the LEHD data which does include occupation codes. The resulting labor supply elasticity distribution is quite similar to the firm-level elasticity distribution.  \n\nA potentially more serious problem in the estimation of the labor supply elasticity to the firm is endogenous mobility. Consider the standard search theory model with on the job search: A worker will leave their current job if they receive a higher wage offer from another firm. Their wage at the new firm is then endogenously determined since in effect it was drawn from a distribution truncated at the wage of the their previous job. In this sense, the earnings data for those individuals who were hired away from another job is biased upward, which will bias estimates of the labor supply elasticity to the firm downward. I deal with the endogenous mobility bias in several different ways. First, I estimate the average earnings premium an individual gets from moving to their nth job (where n is the job number in a string of consecutive employment spells). For instance, workers? earnings increase on average .19 log points when they move from their first to their second jobs. I then reduce the earnings of all job movers by the average premium associated with a move from job n-1 to n. For example, all workers in their second jobs of a string of employment spells would have their earnings reduced by .19 log points.15 The rationale behind this adjustment is that I only observe workers moving from one job to another if they receive a higher wage offer (This is a typical assumption of on-the-job search models, and is overwhelmingly true in the data). Thus, the earnings I observe in the second job are endogenously determined, since they were in a sense drawn from a strictly positive offer distribution.  \n\nSecond, I recalculate the labor supply elasticities with a Heckman selection correction. In this model I define the selected group as those who separate from one job to another, and use the number of new jobs in an individual's state and industry as the excluded variable. The logic behind this restriction is that the state-industry specific labor market should be highly correlated with the likelihood that an individual moves to a new job, but should be uncorrelated with that individual's unobserved “ability” to move. The inverse Mills ratio from the Heckman selection model is included as a regressor in each of the Equations (15)- (17). As noted in Table 10, each of these corrections leads to a trivial change in the labor supply elasticity distribution.  \n\nOne final concern regarding endogenous mobility is that we do not observe the complete history of workers, only that within the time-frame of the LEHD infrastructure. Thus, any employment spells in progress at the beginning of our window which are the result of a hire from another firm may introduce bias into the results. To assess the degree to which this is a problem, I again employ the NLSY79. I use a Monte Carlo approach to compare the estimated labor supply elasticities using the complete worker histories and using only employment spells which occurred in the final third of the sample window. This is the ideal comparison, where the first calculation takes into account the entire work histories of each individual and the second calculation uses only those spells observed after an arbitrary date. The Monte Carlo analysis finds that using the complete worker histories leads to a statistically insignificant decrease of the estimated labor supply elasticity. This implies that the use of some partial histories in this study is not likely a problem, and at worst yields an underestimate of monopsony power.  \n\nFor the reasons mentioned in this section and probably many others, critics may claim that this paper does not accurately estimate the labor supply elasticity to the frm, and they could be right. As with any identification strategy, this study relies on assumptions, not all of which are testable. But while the average firm's labor supply elasticity may not be exactly 1.08, the variable which I call a supply elasticity is certainly some kind of weighted average highly correlated with mobility and individuals’ responsiveness to changes in earnings. The fact that this measure is highly correlated with earnings, especially for those at the bottom of the distribution, tells us that our economy is less competitive than we commonly assume.  \n\n## 6 Conclusion  \n\nThis study finds evidence of significant frictions in the US labor market, although the severity of these frictions varies greatly between labor markets. I estimate the average firm's labor supply elasticity to be quite monopsonistic at 1.08, however there is a nontrivial fraction of firms who do appear to be operating in an approximately competitive labor market. While identifying the precise frictions which contribute to firms’ labor market power is beyond the scope of this study, I can conclude that a firm's geographical dominance alone does not account for all or even most of their ability to affect the wage offer distribution.  \n\nI extend the dynamic model-based empirical strategy proposed by Manning (2003) to identify firm level labor supply elasticities. The use of these measures of firm market power in earnings regressions provides the first direct test of the validity of the new monopsony model. I find that a one unit increase in a firm's labor supply elasticity is associated with a 5-16 percent increase in earnings on average. Further exploring the earnings distribution, I find highly nonlinear effects implying that the negative effects of monopsony power are concentrated at the lower end of the distribution. While these effects are certainly not trivial, it is important to note that there is evidence that firms only utilize a fraction of their market power.  \n\nThe development of the firm-level measures of labor market power described in this paper could have a significant impact on how we view the interaction of imperfect competition with traditional models of the labor market. Future research will examine topics such as gender/race wage gaps, minimum wage laws, unionization, labor demand over the business cycle, agglomeration, and many others.  \n\n## References  \n\nJ. Abowd and F. Kramarz, “The costs of hiring and separations,” Labour Economics, vol. 10, Pp. 499-530, 2003.   \nJ. Abowd and L. Vilhuber, “National estimates of gross employment and job fows from the quarterly workforce indicators with demographic and industry detail,” Journal of Econometrics, vol. 161, pp. 82-99, 2011.   \nJ. Abowd, H. Finer, and F. Kramarz, “Individual and firm heterogeneity in compensation: An analysis of matched longitudinal employer-employee data for the state of washington,\" in The Creation and Analysis of Employer-Employee Matched Data, J. Haltiwanger, Ed. Amsterdam: North Holland, 1999, pp. 3-24.   \nJ. Abowd, F. Kramarz, and D. Margolis, “High wage workers and high wage firms,” Econometrica, vol. 67, pp. 251-335, 1999.   \nJ. Abowd, B. Stephens, L. Vilhuber, F. Andersson, K. McKinney, M. Roemer, and S. Woodcock, “\"The lehd infrastructure files and the creation of the quarterly workforce indicators,\" in Producer Dynamics: New Evidence from Micro Data, J. B. J. T. Dunne and M. J. Roberts, Eds. The University of Chicago Press, 2009, pp. 149-234.   \nK. Adamache and F. Sloan, “Unions and hospitals, some unresolved issues,” Journal of Health Economics, vol. 1(1), pp. 81-108, 1982.  \n\nM. Black, “An empirical test of the theory of on-the-job search,” Journal of Human Resources, vol. 16(1), Pp. 129-140, 1981.  \n\nM. Bronfenbrenner, “Potential monopsony in labor markets,” Industrial and Labor Relations Review, vol. 9(4), pp. 577-588, 1956.   \nP. Brummund, “\"Variation in monopsonistic behavior across establishments: Evidence from the indonesian labor market,” 2011, working Paper.   \nR. Bunting, Employer Concentration in Local Labor Markets. University of North Carolina Press, 1962.   \nK. Burdett and D. Mortensen, “Wage differentials, employer size, and unemployment,” International Economic Review, vol. 39(2), pp. 257-273, 1998.   \nD. Card and A. Krueger, Myth and Measurement: The New Economics of the Minimum Wage. Princeton University Press, 1995.   \nB. Depew and T. Sorensen, “Elasticity of labor supply to the frm over the business cycle,\" 2011, working Paper.   \nR. Feldman and R. Scheffer, “The union impact on hospital wages and fringe benefits\" Industrial and Labor Relations Review, vol. 35, pp. 196-206, 1982.   \nS. Firpo, N. Fortin, and T. Lemieux, “Unconditional quantile regressions,” Econometrica, vol. 77(3), Pp. 953-973, 2009. —, Decomposition Methods in Economics, 4th ed., ser. Handbook of Labor Economics. Elsevier, 2011, vol. 3, pp. 1-102.   \nY. Genda and A. Kondo, “Long-term effects of a recession at labor market entry in japan and the united states,\" Journal of Human Resources, vol. 45(1), pp. 157-196, 2010.   \nE. Goux and E. Maurin, “Persistence of inter industry wage differentials: A reexamination using matched worker-firm panel data” Journal of Labor Economics, vol. 17, pp. 492-533, 1999.   \nB. Hirsch and E. Schumacher, “Monopsony power and relative wages in the labor market for nurses,” Journal of Health Economics, vol. 14(4), pp. 443-476, 1995.   \nB. Hirsch, T. Schank, and C. Schnabel, “Diferences in labor supply to monopsonistic firms and the gender pay gap: An empirical analysis using linked employer-employee data from germany,” Journal of Labor Economics, vol. 28(2), pp. 291-330, 2010.   \nR. Hofer and K. Murphy, \"Underpaid and overworked: Measuring the effect of imperfect information on wages,” Economic Inquiry, vol. 30(3), pp. 511-529, 1992.   \nR. Hurd, “Equilibrium vacancies in a labor market dominated by non-profit firms: The shortage of nurses,” Review of Economics and Statistics, vol. 55(2), pp. 234-240, 1973.   \nY. Ioannides and L. Loury, “Job information networks, neighborhood effects, and inequality,\" Journal of Economic Literature, vol. 42(4), pp. 1056-1093, 2004.   \nL. Jacobson, R. LaLonde, and D. Sullivan, “Earnings losses of displaced workers,” American Economic Review, vol. 83(3), pp. 685-709, 1993.   \nL. Kahn,μ“The long-term consequences of graduating from college in a bad economy,” Labour Economics, vol. 17(2), pp. 303-316, 2010.   \nP. Kuhn, “Is monopsony the right way to model labor makrets,”’ International Journal of the Economics of Business, vol. 11(3), pp. 369-378, 2004.   \nC. Link and J. Landon, “Monopsony and union power in the market for nurses,” Sourthern Economic Journal, vol. 41, pp. 649-659, 1975.   \nC. Link and R. Settle, “Labor supply responses of married professional nurses: New evidence,\" Journal of Human Resources, vol. 14, pp. 256-266, 1979.   \nA. Manning, Monopsony In Motion. Princeton University Press, 2003.   \n, Imperfect Competition in the Labor Market, 4th ed., ser. Handbook of Labor Economics. Elsevier, 2011, vol. 4, pp. 973-1041.   \nJ. McCall, “Economics of information and job search,” Quarterly Journal of Economics, vol. 81(1), Pp. 113-126, 1970.   \nD. Mortensen, Wage Dispersion. MIT Press, 2003.   \nS. Muehlemann, H. Pfeifer, G. Walden, F. Wenzelmann, and S. Wolter, “The financing of apprenticeship training in the light of labour market regulations,” Labour Economics, vol. 17, pp. 751-774, 2010.   \nW. Oi, “Labor as a quasi-fixed factor,” Journal of Policital Economy, vol. 70, pp. 538-555, 1962.   \nP. Oyer, “Initial labor market conditions and long-term outcomes for economists,”’ The Journal of Economic Perspectives, vol. 20(3), pp. 143-160, 2006. —, \"The making of an investment banker: Macroeconomic shocks, career choice and lifetime income” The Journal of Finance, vol. 63(12), pp. 2601-2628, 2008.   \nA. Pigou, The Economics of Welfare. Macmillan, 1924.   \nS. Polachek and J. Robst, “Employee labor market information: comparing direct world of work measures of workers? knowledge to stochastic frontier estimates” Labour Economics, vol. 5(2), pPp. 231-242, 1998.   \nM. Ransom and R. Oaxaca, “New market power models and sex dierences in pay” Journal of Labor Economics, vol. 28(2), pp. 267-290, 2010.   \nM. Ransom and D. Sims, “Estimating the frm's labor supply curve in a 'new monopsony\" framework: School teachers in missouri” Journal of Labor Economics, vol. 28(2), pp. 331-355, 2010.   \nJ. Robinson, The economics of imperfect competition. Macmillan, 1933.   \nR. Rogerson, R. Shimer, and R. Wright, “Search-theoretic models of the labor market: A survey,” Journal of Economic Literature, vol. 43(4), pp. 959-988, 2005.   \nJ. Schmieder, “Labor costs and the evolution of new establishments,” 2010, working Paper.   \nR. Shimer, “\"The assignment of workers to jobs in an economy with coordination frictions,\" Journal of Political Economy, vol. 113(5), pp. 996-1025, 2005.   \nM. Stevens,“\"A theoretical model of on-the-job training with imperfect competition,” Oxford Economic Papers, vol. 46, pp. 537-562, 1994.   \nG. Stigler, “Information in the labor market,” Journal of Political Economy, vol. 70(5), pp. 94-104,1962.   \nD. Sullivan, “Monopsony power in the market for nurses,” Journal of Law and Economics, vol. 32, pp. S135-S178, 1989.   \nE. Wasmer, \"General versus specific skills in labor markets with search frictions and firing costs,” American Economic Review, vol. 96(3), pp. 811-831, 2006.  \n\nFigure 1: Proportion of Employment Covered by the LEHD Infrastructure  \n\n![](images/c181c2e254860368c36ca73d398244b9b4fe9d6f6f6bee962c980383f19e2336.jpg)  \n\nReproduced with permission from Abowd and Vilhuber (2011)  \n\n![](images/c98943c690029ad2a97584c398bf2ecacdafc06c1ab25950cdd519f0759b183d.jpg)  \nFigure 2: Distribution of Labor Supply Elasticities  \n\n![](images/8b1da65da71e54cd09638653e73d627624f4147f94395bb8d5b041bcbc03f468.jpg)  \nFigure 3: Empirical and Counterfactual Distributions  \n\n<html><body><table><tr><td colspan=\"3\">Table 1: Summary Statistics</td></tr><tr><td>Variable</td><td>Mean</td><td>Std Dev</td></tr><tr><td>Unit of Observation: Employment Spell</td><td></td><td></td></tr><tr><td rowspan=\"10\">Age Hispanic</td><td>38</td><td>15.2</td></tr><tr><td>Female 0.5</td><td>0.5</td></tr><tr><td>White</td><td>0.77 0.42</td></tr><tr><td>0.14</td><td>0.34</td></tr><tr><td>< High School 0.14</td><td>0.34</td></tr><tr><td>High School Diploma 0.29</td><td>0.45</td></tr><tr><td>Some College 0.32</td><td>0.47</td></tr><tr><td>College Degree+ 0.25</td><td>0.43</td></tr><tr><td>10.1</td><td>10.7</td></tr><tr><td>8.5</td><td>1</td></tr><tr><td>Log(Quarterly Earnings) Firm Concentration</td><td>0.01</td><td>0.02</td></tr><tr><td>Separation Rate</td><td>0.15</td><td>0.13</td></tr><tr><td>Recruited from Employment</td><td></td><td></td></tr><tr><td></td><td>0.64</td><td>0.48</td></tr><tr><td>Observations</td><td>267,310,000</td><td></td></tr><tr><td>Firm Industry-Concentration</td><td>Unit of Observation: Firm</td><td></td></tr><tr><td>Firm Hires per Quarter</td><td>0.09</td><td>0.16</td></tr><tr><td></td><td>493</td><td>1592</td></tr><tr><td>Firm Employment</td><td>2962</td><td>10772</td></tr><tr><td>Employment Growth Rate</td><td>1.01</td><td>0.15</td></tr><tr><td>Observations</td><td>340,000</td><td></td></tr></table></body></html>  \n\nTable 2: Impact of Firm Concentration on Earnings   \n\n\n<html><body><table><tr><td>Impact of a ten percentage point increase in concentration ratio on</td><td>0.0213</td><td>0.0053</td><td>0.0109</td><td>0.0066</td><td>0.0114</td></tr><tr><td>log(earnings) Demographic and human</td><td>No</td><td>Yes</td><td>Yes</td><td>Yes</td><td>Yes</td></tr><tr><td>capital controls Employer controls</td><td>No</td><td>No</td><td>Yes</td><td>Yes</td><td>Yes</td></tr><tr><td>Tenure Controls</td><td>No</td><td>No</td><td>No</td><td>Yes</td><td>Yes</td></tr><tr><td>Statefixed-effects</td><td>No</td><td>No</td><td>No</td><td>No</td><td>Yes</td></tr><tr><td>R-Squared</td><td>0.0013</td><td>0.2369</td><td>0.3300</td><td>0.3438</td><td>0.3502</td></tr><tr><td>Observations</td><td>325,630,000</td><td>325,630,000</td><td>325,630,0003</td><td>325,630,000</td><td>325,630,000</td></tr></table></body></html>  \n\n\\*A pooled national sample of all dominant employment spells is used in this set of regressions. The dependent variable is the natural log of quarterly earnings. Demographic and human capital controls include: age, age-squared, and indicator variables for gender, ethnicity, racial status, and education level. Employer controls include indicator variables for each of the 20 NAICS sectors and number of employees working at the firm. Tenure controls include the length (in quarters) of the employment spell, as well as its squared term. Year effects are included in all models. Standard errors are not reported because all t-statistics are greater than 50. Observation counts are rounded to the nearest 10,000 for confidentiallity reasons.  \n\nTable 3: Concentration Ratio Regressions by NAICS Sector   \n\n\n<html><body><table><tr><td>Industry</td><td>Impact of a ten percentage point increase in concentration ratio on log earnings</td></tr><tr><td>Agriculture</td><td>0.0055</td></tr><tr><td>Mining/Oil/Natural Gas</td><td>0.0071</td></tr><tr><td>Utilities</td><td>-0.0760</td></tr><tr><td>Construction</td><td>-0.0157</td></tr><tr><td>Manufacturing</td><td>0.0050</td></tr><tr><td>WholesaleTrade</td><td>-0.0142</td></tr><tr><td>Resale Trade</td><td>-0.0009</td></tr><tr><td>Transportation</td><td>0.0361</td></tr><tr><td>Information</td><td>-0.0308</td></tr><tr><td>Finance and Insurance</td><td>-0.015</td></tr><tr><td>Real Estate and Rental</td><td>0.022</td></tr><tr><td>Profession/Scientific/Technical Services</td><td>0.019</td></tr><tr><td>Management of Companies</td><td>0.056</td></tr><tr><td>Administrative Support</td><td>-0.01</td></tr><tr><td>Educational Services</td><td>-0.005</td></tr><tr><td>Health Care and Social Assistance</td><td>0.016</td></tr><tr><td></td><td></td></tr><tr><td>Arts and Entertainment</td><td>0.046</td></tr><tr><td>Accommodation and Food Services</td><td>0.021</td></tr><tr><td>Other Services</td><td>-0.129 -0.013</td></tr><tr><td>Public Administration</td><td>*A pooled national sample of all dominant employment spells is used in this</td></tr><tr><td colspan=\"2\">set of regressions. The dependent variable is the natural log of quarterly earnings. Demographic and human capital controls include: age, age-squared, and indicator variables for gender, ethnicity, racial status, and education level. Employer controls include the number of employees working at the firm. Tenure controls include the length (in quarters) of the employment</td></tr></table></body></html>  \n\n<html><body><table><tr><td colspan=\"3\">Table 4:Full-EconomyEstimate of the Labor SupplyElasticity to the Firm Full sample Full sample with Only firms with an</td></tr><tr><td>.76</td><td>firm FE .82</td><td>individually estimatedelasticity .81</td></tr><tr><td colspan=\"3\">*These labor supply elasticities were obtained by estimating equations (15)-(17), on a pooled sample of all (dominant) employment spells. Each model contained age, age-squared, along with indicator variables for female,</td></tr></table></body></html>  \n\nTable 5: Firm-Level Labor Supply Elasticities   \n\n\n<html><body><table><tr><td>Model</td><td>R</td><td></td><td></td><td>N3</td><td>E</td></tr><tr><td>Earnings Only</td><td>0.41</td><td>0.1</td><td>-0.41</td><td>-0.5</td><td>0.84</td></tr><tr><td>No Education Controls</td><td>0.43</td><td>0.3</td><td>-0.43</td><td>-0.52</td><td>0.89</td></tr><tr><td>Full Model</td><td>0.47</td><td>0.46</td><td>-0.47</td><td>-0.54</td><td>0.95</td></tr><tr><td>Full Model</td><td>0.6</td><td>0.59</td><td>-0.6</td><td>-0.67</td><td>1.08</td></tr><tr><td>(Time-Varying)</td><td></td><td></td><td></td><td></td><td></td></tr></table></body></html>  \n\nThe first row represents estimates from equations (15)-(17) where the only regressor in each model is log earnings. The second row estimates the same equations, and includes age, age-squared, along with indicator variables for female, nonwhite, Hispanic, and year effects. Employer controls include number of employees working at the firm and industry indicator variables. The third row adds indicator variables for completing a high school diploma, some college, and college degree or greater. The first four columns report the average firm-level elasticities of recruitment from employment and nonemployment, and the separation elasticities to employment and nonemployment respectively. The final column combines these elasticities, along with the calculated shares of separations/recruits to/from employment, separation rates, and growth rates to obtain the labor supply elasticity. The frst three rows report only the long-run elasticities, while the fourth row describes the elasticities when a steady-state is not assumed, and they are allowed to vary over time.  \n\n<html><body><table><tr><td colspan=\"6\">Table 6:Distribution of Estimated Firm-Level Labor Supply Elasticities</td></tr><tr><td colspan=\"6\">Percentiles</td></tr><tr><td>Mean</td><td>10th</td><td>25th</td><td>50th</td><td>75th</td><td>90th</td></tr><tr><td>1.08</td><td>0.22</td><td>0.44</td><td>0.75</td><td>1.13</td><td>1.73</td></tr><tr><td colspan=\"6\">*Three separate regressions, corresponding to equations (15)-(17), were estimated separatelyfor each firm in the data which met the conditions described in the data section. The coefficients on log earnings in each regression were combined, weighted by the share of recruits and separations to employment, separation rates, and growth rates according to equation (6) to obtain the estimate of the labor supply elasticity to the firm.</td></tr></table></body></html>  \n\n<html><body><table><tr><td colspan=\"2\">Table 7: Mean Labor Supply Elasticity by NAICS Sector</td></tr><tr><td>NAICS Sector</td><td>Mean Labor Supply Elasticity</td></tr><tr><td>Agriculture</td><td>1.43</td></tr><tr><td>Mining/Oil/Natural Gas</td><td>1.52</td></tr><tr><td>Utilities</td><td>1.18</td></tr><tr><td>Construction</td><td>1.42</td></tr><tr><td>Manufacturing</td><td>1.82</td></tr><tr><td>Wholesale Trade</td><td>1.48</td></tr><tr><td>Resale Trade</td><td>1.03</td></tr><tr><td>Transportation</td><td>1.47</td></tr><tr><td>Information</td><td>1.17</td></tr><tr><td>Finance and Insurance</td><td>1.27</td></tr><tr><td>Real Estate and Rental</td><td>1.01</td></tr><tr><td>Profession/Scientific/Technical Services</td><td>1.17</td></tr><tr><td>Management of Companies</td><td></td></tr><tr><td>Administrative Support</td><td>1.17</td></tr><tr><td></td><td>0.72</td></tr><tr><td>Educational Services</td><td>0.91</td></tr><tr><td>Health Care and Social Assistance</td><td>0.78</td></tr><tr><td>Arts and Entertainment</td><td>0.94</td></tr><tr><td>Accommodation and Food Services</td><td>0.85</td></tr><tr><td>Other Services</td><td>1.04</td></tr><tr><td>Public Administration</td><td>1.19</td></tr></table></body></html>  \n\n\\*The numbers in this table represent averages by NAICS sector of the estimated labor supply elasticity to the firm. Three separate regressions, corresponding to equations (15)-(17), were estimated separately for each firm in the data which met the conditions described in the data section. The coefficients on log earnings in each regression were combined, weighted by the share of recruits and separations to employment, separation rates, and growth rates according to equation (6) to obtain the estimate of the labor supply elasticity to the firm. Demographic and human capital controls include: age, age-squared, and indicator variables for gender, ethnicity, racial status, and education level. Employer controls include number of employees working at the firm. Year effects are included in all models.  \n\n<html><body><table><tr><td colspan=\"7\">Table 8: Impact of Firm Market Power on Earnings</td></tr><tr><td>Coefficientonlabor supply elasticity</td><td>0.13</td><td>0.11</td><td>0.05</td><td>0.05</td><td>0.09</td><td>0.15</td></tr><tr><td>Demographic controls</td><td>No</td><td>Yes</td><td>Yes</td><td>Yes</td><td>Yes</td><td>Yes</td></tr><tr><td>Employer controls</td><td>No</td><td>No</td><td>Yes</td><td>Yes</td><td>Yes</td><td>Yes</td></tr><tr><td>Person fixed-effects</td><td>No</td><td>No</td><td>No</td><td>Yes</td><td>No</td><td>Yes</td></tr><tr><td>Firm fixed-effects</td><td>No</td><td>No</td><td>No</td><td>No</td><td>Yes</td><td>Yes</td></tr><tr><td>R-Squared</td><td>0.005</td><td>0.238</td><td>0.312</td><td>0.784</td><td>0.90</td><td>0.95</td></tr></table></body></html>  \n\n\\*A pooled national sample of all dominant employment spells subject to the sample restriction described in the data section is used in this set of regressions. The dependent variable is the natural log of quarterly earnings. Demographic controls include: age, age-squared, and indicator variables for gender, ethnicity, racial status, and education level. Employer controls include the number of employees working at the firm, tenure (number of quarters employed at the firm), tenure-squared, and 20 industry indicator variables. Tenure controls include the length (in quarters) of the employment spell, as well as its squared term. Year effects are included in all models. These results are unweighted, however all models were also estimated with demographic weights constructed by the author. The model with both person and firm fixed effects is estimated using the two-way fixed effect methodology described in Abowd et al. (1999b). There were no significant differences between the weighted and unweighted models. Standard errors are not reported because the t-statistics range from 500-1000, but are available upon request along with all other estimated coefficients. There are 267,310,000 observations in each specification.  \n\n<html><body><table><tr><td colspan=\"6\">Table 9: Counterfactual Distribution Analysis</td></tr><tr><td colspan=\"6\">Change (log points) in Quantiles of the Earnings Distribution</td></tr><tr><td>Quantile</td><td>10th</td><td>25th</td><td>50th</td><td>75th</td><td>90th</td></tr><tr><td>Change in log(earnings)</td><td>0.09</td><td>0.05</td><td>0.04</td><td>0.01</td><td>0.00</td></tr><tr><td>Inequality measure</td><td>Variance</td><td>90-10</td><td>50-10</td><td>90-50</td><td></td></tr><tr><td>Earnings distribution</td><td>.94</td><td>1.32</td><td>1.18</td><td>1.12</td><td></td></tr><tr><td>Counterfactual distribution</td><td>.86</td><td>1.30</td><td>1.16</td><td>1.11</td><td></td></tr><tr><td colspan=\"6\">*The counterfactual distribution was constructed by estimating unconditional quantile regressions at every fifth quantile of the earnings distribution, and using the supply elasticity coefficient from each regression to simulate the effect at each quantile of a one-unit increase of the labor supply elasticity. Demographic and human capital controls include: age, age-squared, and indicator variables for gender, ethnicity, racial status, and education level. Employer controls include the number of employees working at the firm and industry indicator variables. Tenure controls include the length (in quarters) of the models</td></tr></table></body></html>  \n\nTable 10: Robustness Checks  \n\n<html><body><table><tr><td>*Panel A: NLSY comparisons</td><td>With versus without occupational effects</td><td>Full history versus partial history</td></tr><tr><td>Bootstrapped difference in labor supply elasticity Std Error</td><td>0.20 0.14</td><td>-.46 .76</td></tr><tr><td>**Panel B: Endogenous mobility corrections</td><td>Uncorrectedlabor supply elasticity</td><td>Earnings of job Control for changers adjusted Heckman selection downward correction</td></tr><tr><td>Median of distribution</td><td>.75 .74</td><td>.76</td></tr><tr><td>*Panel A: Equations (15)-(17) were estimated on a sample of employment spells from the NLSY79 from 1979-1996 (the last year for which detailed information on recruitment and separation dates are available). The specifications include the same variables available through the LEHD data: age, age-squared, year effects, along with gender, ethnicity, race, industry, and education indicators. The first column compares the labor supply elasticities with and without the inclusion of occupational fixed effects. The second column compares the labor supply elasticities with and without the assumption that only</td><td>the last third of every individual's work history is known.</td><td></td></tr><tr><td>workers current industry.</td><td>which workers who are recruited away from another job have their earnings adjusted downward by the average premium of moving from job n to job n+1. The third column represents a recalculation of the labor supply elasticity in which the inverse Mills ratio of a Heckman selection model for mobility is controlled for in each of Equations (15)-(17). The omitted category in the Heckman model is the number of new local jobs in each</td><td></td></tr></table></body></html>  "
  },
  "md_Woodbury - 1987 - Power in the Labor Market Institutionalist Approaches to Labor Problems": {
    "reference_markdown": "# Power in the Labor Market: Institutionalist Approaches to Labor Problems  \n\nStephen A. Woodbury  \n\nTo cite this article: Stephen A. Woodbury (1987) Power in the Labor Market: Institutionalist Approaches to Labor Problems, Journal of Economic Issues, 21:4, 1781-1807, DOl: 10.1080/00213624.1987.11504722  \n\nTo link to this article: http://dx.doi.0rg/10.1080/00213624.1987.11504722  \n\n# Power in the Labor Market: Institutionalist Approaches to Labor Problems  \n\nStephen A. Woodbury  \n\nThree features mark institutionalist work on labor problems and distinguish it from other approaches. First, institutional work generally starts with a perceived social problem and proceeds on the premise that the problem may be addressed usefully by public policy. Second, institutionalists often carry out much of their work by “looking and seeing\"-—by gaining a familiarity with the history of a problem, examining its legal foundations, and understanding its social and political aspects. Third, a cognizance of power in the labor marketan understanding that choice is proscribed by past choices, by factors beyond the control of economic agents, and by the structure of established legal and property rightsis the most telling aspect of the institutionalist approach. This last is related closely to the attention institutionalists pay to process, to the dynamics of political-economic circumstance, and to the way we got to where we are. Implicit is the understanding, unique to an institutionalist viewpoint, that the choice set of available alternatives is historical and evolutionary.  \n\nThese are, of course, generalities that do not exhaust what institutionalism means, and that must be clarified, supported, and illustrated. Two clarifications are worth making at the outset. The first assertion-- that the institutionalist proceeds on the premise that a problem may be addressed usefully by public policy—-would be rightly read as meaning that institutionalists tend to be activist and interventionist [Petr 1984]. The relevance of institutionalism to problem solving often implies revision or refinement of public policy—that is, institutional change. But it does not follow that institutionalists invariably agree on policy. To bastardize Marshall McLuhan, the methodology of institutionaism may well be the massage (in the sense that it conditions the questions posed and the way research is carried on) but it is surely not the message (that is, a prescription for action).  \n\nThe second assertionthat the institutional approach entails looking and seeing--is sometimes misconstrued to imply that institutionalism is nonanalytical. On the contrary, institutionalism can be both analytical and abstract. It is only the false identity of analysis with mathematics that has arisen in economics since the 1930s that obscures the underlying analytical nature of much institutional thought. The looking and seeing aspect of institutionalism implies a belief that much mainstream analysis has neglected important realities of situations being analyzed. Too often, the tradeoff between the clutter of institutional complexity and the limited applicability of abstraction has been resolved in favor of greater abstraction. Too often, the results of abstract theory have been inappropriately translated into practical maxims.1  \n\n## The Idea of Power  \n\nMy third assertion is that a recogition of the importance of power is the most telling aspect of the institutional approach to labor markets. The institutionalist preoccupation with power is difficult to describe to a noninstitutionalist, because the vocabulary to do so does not exist in the mainstream economic model, as Philip Klein has so well shown [Klein 1980]. The mainstream's traditional emphasis on a competitive labor market--one in which there are many agents trading a homogeneous grade of labor under conditions of full information and few barriers to movement -has inhibited consideration of power as a central component of the workings of the economy.2  \n\nIn the mainstream framework, power is treated as an aberration. In models current from the 1930s until the 1970s, it occurs only when few firms buy or sell a commodity or when there is product differentiation; that is, when there are oligopsonists, oligopolists, or monopolistic competitors [Robinson 1933; Chamberlin 1933]. In the model of perfectly contestable markets that has been ascendent since the mid-1970s, a market can perform “well\" even if there are only a few sellers [Baumol, Panzer, and Willig 1982]. Contestable market theory requires only that entry into a market be free and unimpeded--that a market be contestable\"-—-for efficient performance (prices at or near marginal cost) to occur. If the theory of contestable markets were representative, the mainstream would be moving further from a recognition of power, notcloser.3  \n\nBut to an institutionalist, power is an essential part of every market, transaction, and economic outcome. Power enters at a more basic stage of economic process: in the distribution of wealth (or “endowments\"), in the determination of tastes, in the evolution of technology, in the inherent heterogeneity of labor (which gives rise to the problem of impacted information, and to the potential for barriers to entering a labor market). Each is given or exogenous in the mainstream analysis. For many purposes, that is fine, just as for many engineering problems, Newtonian mechanics suffices, and to take account of the relativistic aspects ofa problem would be wasted effort.4Butinstitutionalists insist that in the most interesting problems, and also in many problems where mainstream economists neglect it, power plays a role.  \n\nA lasting problem in dealing with power-—-to the institutionalist and the mainstream economist alike—is that it is difficult to define or measure. Prices and quantities can be defined and measured with ease; focusing on such concepts and variables happens to be the strength of mainstream economics that makes it the envy of other social sciences. Power is different, and definitions of power are various. Some definitions focus on decision-making: Klein defines power as “disproportionate control over the decision-making process\"; and Don Kanel defines it as “a combination of responsibility and the capacity to coordinate and concentrate resources and foresee dangers and opportunities\" [Klein 1980, p. 873; Kanel 1974, p. 834]. Other definitions of power focus on control over others: William M. Dugger defines it as “\"the ability to tell other people what to do with some certainty that they will do it\"; and Warren J. Samuels defines it as “the means or capacity to coerce,” which in turn is the ability to affect \"the behavior and/or choices of others\" [Dugger 1980, p. 897; Samuels 1973, pp. 304-5]. The sources of power are various: Samuels lists “property rights, income, position, influence, and other rights of economic significance” as the bases of power [Samuels 1973, p. i].  \n\nIn the view of most mainstream economists, only fuzzy thinkers would try to handle so vague and unquantifiable a notion as power. But institutionalists insist on its importance, and they are hardly alone:  \n\nthe law, political science, psychology, and sociology all take the ideas of power and inequity as central. The importance of power in legal reasoning is especially clear and has special significance to institutional labor economics, as will become clearbelow.  \n\nThe remainder of this article is devoted to illustrating the importance of power in the institutional approach to labor problems. Collective bargaining and the character of labor markets are the two issues selected to make this illustration. They are treated in successive sections following a brief treatment of a prior question: How are we to decide what is an institutional approach?  \n\n### Is It Institutionalism?  \n\nDeciding whether a given treatment of a labor issue is institutionalist is far from simple, as existing discussions that entail the question show [Ramstad 1981; Segal 1986]. In fact, a continuum of positions on the question, “Is it institutionalism?\" can be imagined. At the exclusionist end of the continuum would be those who favor a tight definition of institutionalism and what it connotes. At the permissive end would be those who argue that any treatment purporting to be institutional is institutional.  \n\nThere are dangers in either position. The main objection to the exclusionist positionthat is, to drawing hard lines between institutionalists and others--is that it can only blind us to the elements that are shared by different approaches to similar problems. For example, Martin Segal, in a stimulating article, adopts a tight definition of institutionalism, and by so doing argues that post-World War II students of labor problems have virtually nothing in common with pre-World War II institutionalists such as John R. Commons, Selig Perlman, Richard T. Ely, and Robert F. Hoxie [Segal 1986]. This is a surprising conclusion because many of the postwar labor economists he views as noninstitutionalist have been widely viewed as institutionalist.5 Moreoever, by severing pre- and post-World War II labor economics from each other, Segal's tight definition of institutionalism has the disconcerting effect of leading one to ignore the contribution that institutionalism has made and can make to the current mainstream (and vice versa). The exercise of tightly defining institutionalism seems to lead to the unfortunate drawing of false lines, to the creation of camps where none exist, and to a failure to perceive common elements in work originating in different periods and places.  \n\nWhat about the permissive answer to the question, “Is it institutionalism?\" There are two dangers in adopting a permissive definition of institutionalism; that is, to say that anything purporting to be institutionalism is institutionalism. One is that some who have long regarded themselves as institutionalists and who have adopted a tight definition may object. The other is that we can no longer conveniently put work into neat categories. Neither of these is a great danger when set against the problems of oversimplification and stereotyping that can result from obsessive attempts to categorize and label.  \n\nAs it turns out, we need not choose one extreme answer or the other. We can note the origin and character of ideas and trace their infuence in contemporary work. Indeed, this seems the only reasonable solution. There are basic insights offered by institutionalists that need not remain in rarefied form to retain their power. They may play a role in analyses that draw on tools and insights that have been developed by noninstitutionalists. It follows that “Is it institutionalist?\" is not the best way to phrase the question. “Does it have institutional aspects?\" or “Does it draw its inspiration from institutionalism?\" might be better.6  \n\n## Unions and Collective Bargaining  \n\nThe study of unionism and collective bargaining has been one of the hallmarks of institutionalism. Many of the classics from the early days of institutionalism--Commons's essay on shoemakers, Perlman's History of Trade Unionism, and Hoxie's Trade Unionism in the United States--took as their subject the development of unions and labor institutions [Commons 1909; Perlman 1950; Hoxie 1923]. Further, it is in the study of unions that the approach of mainstream economics stands in sharpest contrast to work that draws on aspects of institutionalism.  \n\n### Mainstream and Institutional Views of Unions  \n\nThe view that unions represent a monopolistic seller of labor has been identified with mainstream economists in the postwar years. George Stigler's characteristically unequivocal statement of this position is that, “The major noncompetitive force on wages is the labor union. The labor union is for the labor market the equivalent of the cartel in the product market\" [Stigler 1966, p. 267]. The verdict, to Milton Friedman, is clear: \"Unions have . . . not only harmed the public at large and workers as a whole by distorting the use of labor; they have also made the incomes of the working class more unequal by reducing the opportunities available to the most disadvantaged workers\" [Friedman 1962, p. 124]. To a mainstream economist who believes that an unfettered labor market allocates resources efficiently, the union represents a wrench in an otherwise melifluously running machine, an unsightly weed to be extirpated.  \n\nThe institutional view is that a union is an organization of workers that seeks to further the interests of those workers. In the United States, unions have accomplished their objectives through the process of collective bargaining. But to institutionalists, collective bargaining is more than simply a process whereby workers improve their lot-a means of restricting the supply of labor and thereby improving wages and working conditions--as mainstream economists would have it. Rather, collective bargaining is one method of handling the problems that inevitably arise in relations between workers and management. Collective bargaining turns out to be the only method of handling labor-management relations that involves negotiating a mutually agreed upon package of wages, hours, and working conditions. Further, in collective bargaining, that agreement is backed up by a legally binding contract, the heart of which is the grievance procedure. The critical point is that collective bargaining is the only approach that permits the exercise of power by both parties to negotiation because it is the only approach that grants each side a sanction—-the strike or lockout—if agreement cannot be reached.7  \n\nIn the institutionalist's view, to repeat, collective bargaining is but one way of handling the relations between workers and employers. Indeed, to understand the institutional approach to labor-management relations, it is useful to imagine a continuum along which various mechanisms for handling labor-management relations can be placed. At the right extreme of the continuum is unilateral determination of the conditions of employment by management, the method most closely associated with Frederick Taylor and his “scientific management\" [Taylor 1967]. Although Taylor's views are no longer taught in the form Taylor propounded them, unilateral decision-making by management remains the most common method of determining the wages, hours, and working conditions of workers in the United States. Management unilateralism has two implications that are important for our purposes. First, and most clearly, it implies the possession by management of all power to make decisions about wages, hours, and the terms of employment. Second, adherence to management unilateralism implies the view that the interests of workers and those of management are wholly distinct, or nonintersecting. Hence, the terms of employment must be decidedby and resolvedinfavor of either management Or labor.  \n\nThe same view-that management and labor have no interests in common-also underlies the method of handling labor-management relations that lies at the left extreme of the continuum: worker management. Under worker management, all power to make decisions is assigned to workers, and the establishment is managed collectively by consensus of the workers. Worker management exists in name in Yugoslavia, and may be increasing in the United States with the rise of plans that allow workers to buy out establishments that management has decided to shut down [Hochner, Appelbaum, Goode, and Gramrose 1987; Kochan, Katz, and Mower 1984]. But it is widely agreed that worker management in Yugoslavia is limited, and the existing studies of worker buyouts in the United States suggest that the operation of employee-owned firms differs little from the operation of firms in which there is collective bargaining or consultation between labor and management.8  \n\nThe “human relations\" or “organization development\" approach to labor-management relations lies just to the left of unilateral decisionmaking by management on the continuum. Under a human relations approach, management remains in command, but there is greater sensitivity (or at least apparent sensitivity) to the needs of those who are part of the organization. The true goal of human relations is to “educate\" workers to view the company's goals as their own, and to act accordingly. Indeed, the basic view of the human relations approach is that the goals of the company and the worker are (or can be molded to be)identical.9  \n\nThe human relations approach can be viewed as a highly paternalistic form of management that robs the worker of dignity by denying his or her identity apart from the organization. It is a fundamentally contradictory approach in that it tries to view workers as human beings, but at the same time it denies the individuality of workers by identifying their goals with the company's and ignoring the complex psychological drives of workers.  \n\nCollective bargainingfalls between worker management and human relations on the continuum. The centerpiece of collective bargaining is negotiation of a binding agreement by management and the representatives of workers. What makes possible the negotiation of a mutually agreed upon package of wages, hours, and terms of employment is the possession of power by both labor and management. There are various types of collective bargaining--the types depend on the degree to which the terms of employment are subject to bargaining, and hence on the way power is distributed between management and labor. That is, the so-called scope of bargaining may be broad, as it is in Germany under codetermination, and may imply joint determination of most of the firm's activities (including not only conditions of employment but what, how, and how much to produce).  \n\nThe collective bargaining model differs from the others because, in it, workers and management are viewed as having some goals in common and others that conflict. The role of collective bargaining is to seek out the areas of common interest and to arrive at some compromise on issues where goals conflict. This view is based on the understanding that labor and management have more to gain in the end by compromising over certain issues where there is initial disagreement than to give up and break off the relationship. It follows that the collective bargaining model is essentially a problem-solving model in which each side possesses power and takes a meaningful part in decision-making. The problem solved by collective bargaining is that labor and management need each other but inevitably confict over the terms on which they should contract. The solution is a process that recognizes the complexities of both workers' and management's motives, and the multiplicity of issues that encompass the employment relation. The solution, in short, is a process that gives power to both management and workers.  \n\nAn important issue worth raising at this point is how the agreement struck under collective bargaining affects the welfare of the parties to the agreement and the general public. There are numerous concerns here: Can collective bargaining help unionized workers without harming nonunion workers and the public at large? To what degree do unions, by raising wages, cause resource misallocation and reduced total output? What part does collective bargaining play in generating inflation? How pervasive are union leaders who, although they purport to represent the workers, do little to benefit the membership but much to benefit themselves? As should be clear in the ensuing sections, the institutionalist's balance sheet on collective bargaining takes account of these concerns, but gives greater weight to the constructive role collective bargaining can play in bringing about greater industrial peace, in increasing workplace democracy, and in creating a distribution of power between labor and management that is consistent with the principle of freedom of contract.  \n\nTo summarize, the institutionalist's approach to unions differs fundamentally from the mainstream economist's approach. Where the mainstream economist sees in labor simply another factor of production,the institutionalist sees inlabor the onefactor of production that has a human being attached. Where the mainstream economist sees simply a union-an organization that restricts the supply of laborthe institutionalist sees a relationship between labor and management that is complex and can be handled through any of a variety of processes. Each of these various processes results in a different distribution of power between labor and management, and each stems from a different understanding of the degree to which the interests of labor and management are shared. The institutionalist's case for collective bargaining rests first, on the belief that it is the most realistic and workable model on which to base labor-management relations (in that collective bargaining is a process that recognizes and can handle the complexities of labor-management relations), and second, on legal reasoning to be pursuedbelow.  \n\n### Legal Underpinnings of Collective Bargaining in the United States  \n\nAlthough the arguments that carried the day for collective bargaining in the 1930s were essentially legal (as opposed to narrowly economic), before the 1930s, legal and political reasoning undermined the efforts of workers to organize. The doctrine of criminal conspiracy, dating from early nineteenth-century England, held that unions were a combination harmful to the social order, to employers, and to the public at large. For decades in the United States, striking workers, usually skilled craftsmen, were convicted under one or another variant of this doctrine as having conspired to usurp the property of owners or to harm the public.  \n\nUnions were also-indeed still are—-held to reduce the individual freedom of workers, and hence to act as an undemocratic force in society. Further, they are one-party governments, and as such may act not in the interest of their members, but corruptly so as to benefit their leaders [Kerr 1958]. The Landrum-Griffin Act of 1959-which includes a bill of rights for unionized workers, mandates reporting and disclosure of unions' finances, and requires election of union officials at threeto five-year intervals--is evidence that these concerns remain with us.  \n\nBut the doctrine of criminal conspiracy was laid to rest in 1932 by the Norris-La Guardia Act, which embodied a laissez-faire approach to labor relations based on the notion of freedom of contract. That is, Norris-La Guardia ordered the courts to stop enjoining strikes and to stop preventing workers from organizing. The act did not protect workers or encourage the existence of unions, but it did remove the main obstacles (which were judicial) to organizing and it did legalize the strike. The reasoning behind the act was that freedom of contract is just as important to the worker as to the employer, and that to deny workers the right to organize and strike is to deny them the right to dispose freely of their property, which is the ability to be productive.1o  \n\nIt is an understanding of unequal power in the labor market that permits one to go beyond a laissez-faire approach to collective bargaining toward a policy that actually fosters collective bargaining. This has, of course, happened in the United States: The Wagner Act of 1935 can be thought of as legislative action to protect workers in their efforts to organize and to require employers to bargain in good faith with the representatives of workers. The arguments in favor of such legislative action are four. The first is the argument of Sidney and Beatrice Webb that collective bargaining is the equivalent of democracy in the workplace. The dehumanizing aspects of industrial work--the destruction of creativity, the loss of control over work-—-can be mitigated, and some measure of dignity can be restored, by workers' participation in decisions that affect them. The second is that the existence of unions can actually strengthen democracy by giving political voice to groups that would otherwise be silent. The existence of many groups with different interests is essential to democracy; the presence of several strong groups makes it unlikely that any one group could ever dominate. The third argument is that collective bargaining, once established, can reduce the amount of industrial conflict and have a stabilizing effect on the economy and society. To see this argument, one must recall that the most disruptive and violent strikes in American history (those in railroads, longshoring, steel, and automobiles) occured because employers refused to recognize unions and bargain with them. Such recognition strikes have virtually vanished from the scene as a result of representation elections sanctioned by the Wagner Act and overseen by the National Labor Relations Board (NLRB).  \n\nThe fourth argument for legislative action in favor of collective bargaining is the most important, at least from the point of view of legal theorists [Wellington 1968, pp. 27-38]. In a nutshell, it is that there is a lack of equality between an individual worker and an individual employer because the employer has greater power to set wages, hours, and working conditions. The argument is worth elaborating.  \n\nOur law has a commitment to freedom of contract--the notion that people should be free to make agreements with a minimum of interference from government. This commitment comes from the belief that individuals usually know what is best for themselves, or at least they know better than the government. But if one person is in a position to set the terms of a contract without the other having much say, then freedom of contract becomes undesirable. The reason is that we generally believe that competition restrains parties from gaining too much power. In the absence of competition, the more powerful party may be able to exploit the situation and harm the other party. So in cases where the market fails, government inaction amounts to ruling in favor of the more powerful party.  \n\nThere is a mainstream economic counterpart to this argument: Employersmaybemonopsonists-theonlybuyersoflaborinagivenlabor marketin which case the employer is able to depress the wage (and employment) below the competitive level. Where legal theorists and institutionalists differ with mainstream economists is in their interpretation of monopsony. To the mainstream economist, monopsony is a theoretical curiosity  whose practical importance  is viewed as negligible-either because it is believed not to exist or because, if it did exist, its impact would be blunted over the long run by the ability of workers to move and seek alternatives [Bunting 1962]. Institutionalists and legal theorists view monopsony as important: Not only do they believe that evidence of monopsony's existence in certain labor markets is credible, but they believe that monopsony's adverse effects cannot be overcome by mobility because moving is costly and because the information required to make rational choices about moving in order to realize an alternative does not exist. Where the mainstream economist sees an effective market, theinstitutionalist sees a market rife with imperfection.  \n\nThe importance of unequal bargaining power in the institutional approach is clear. If workers had alternatives, then the power of the employer in making the wage bargain would be checked. But monopsony and other market imperfections rob the worker of the alternatives that could result in a mutually advantageous wage bargain, forcing the worker to accept employment on unfair terms or on no terms at all. The case in favor of legislation that protects the rights of workers to organize and bargain collectively rests squarely on a recognition of unequal bargaining power in the labor market.  \n\n### An Economic Case for Unions?  \n\nIn that they are based on process and power, the arguments in favor of collective bargaining just summarized, are purely institutionalist.  \n\nThey tend to neglect economic outcomes-the effect of unions on wages,employment,productivity,and profitability.But the assault on the probity of unions has been based at least in part on allegations that they create inefficiency. Responses to these allegations are the most exciting and controversial developments in the study of unions in recent years and are well represented by Richard B. Freeman and James L. Medoffs What Do Unions Do? [Freeman and Medoff 1984]. Freeman and Medoff's approach is based on a “collective voice-institutional response\" theory of unions, which is derived in turn from Albert Hirschman's work on the operation of social organizations [Hirschman 1970].  \n\nHirschman's argument, in brief, is that individuals who are associated with any social organization have open to them two ways of responding to decay and failure of that organization-exit and voice. That is, someone in a objectionable situation may either remove himself from the situation (exit) or try to change the situation (exercise voice). Someone who dislikes the food in a restaurant can either resolve to not return or can complain. Someone who has a disagreeable job may either quit or try to negotiate an improvement. Hirschman refers to exit and voice as “recuperative mechanisms\"--ways organizations can become aware of dissatisfaction and perhaps improve. Mainstream economists have tended to emphasize exit as the most important signalling mechanismthey see competition among many individuals and many firms as adequate to tell institutions when they are failing. Political scientists and institutionalists tend to emphasize voice-they count on an “alert, active, and vocal public\" for a properly functioning system [Hirschman 1970, pp. 31-32)].11 Exit and voice are nevertheless complementary in Hirschman's view. Both are useful and needed in that neither one is always superior.  \n\nThe importance of Hirschman's work to the functioning of unions (and to Freeman and Medoff) is that voice is the mechanism through which collective bargaining works. Indeed, without collective bargaining, exercise of voice in the labor market is precluded. Moreover, voice may be a mechanism that is superior to individual bargaining, not only because voice has intrinsic value (that is, it represents democracy in the workplace), but also because it results in outcomes that are preferred by both management and labor. Why should this be?  \n\nFreeman and Medoff give two reasons. First, they note that many aspects of the workplace are public goods-goods that, if provided to one worker, are provided to all. Safety conditions, lighting, heating, pace of work on a production line, the employer's layoff and recall policy, work-sharing, promotion policies, the retirement plan, and the grievance procedure are all workplace public goods. Well-known results of mainstream economic theory suggest that goods possessing some degree of publicness will be underprovided by the market. Freeman and Medoff argue that only through collective action-—-by banding together and bargaining collectively—-can a set of such working conditions be attained that is best from both workers' and managers' points of view.  \n\nSecond, Freeman and Medoff note that workers may fear reprisal or punishment if they express any criticism of their working conditions, since their criticisms will conflict with management's view of how the firm should be run. Only workers who are prepared to quit or exit anyway would be vocal about problems in the workplace. Such a state of affairs is bad because only the preferences of the marginal worker will be known; the preferences of the median worker, the more typical worker, will go unnoticed. Only a succession of worker departures, perhaps over a long time, will make management realize its errors. Without collective bargaining to protect workers from discrimination for expressing their views--without a grievance procedure that protects workersfromdischargewithoutcausevoicewillgounusedinthe workplace.  \n\nWhat, then, do unions do? It depends on management's response to the challenge of unionism. Management can respond constructively to the union, learning about the problems, concerns, and preferences of workers and the operation of the workplace. Management can also respond negatively, fighting the union and its suggestions, with deleterious results. Freeman and Medoff present copious evidence to support their predictions that constructive management response can lead to many improvements. First, management may use the information about workers’ preferences by collective bargaining to choose a mix of wages and fringe benefits and a set of personnel policies that are more appropriate to the firm's workforce. That is, the median worker's preferences will be known and acted upon, rather than the marginal worker's. Second, organizational changes made by management can bring about higher productivity through lower quit rates and improved morale and cooperation among workers. Third, collective bargaining may have a “shock effect\" on management, inducing adoption of more efficient technology and tighter job-production standards as part of an effort to maintain profits in the face of higher wages.12  \n\nAlthough widely hailed as a landmark analysis of unionism in the United States, the approach taken by Freeman and Medoff has been criticized by mainstream and institutional economists alike. Institutionalists have faulted Freeman and Medoff for basing their case in favor of unions on arguments that they improve economic outcomes such as productivity and efficiency and for neglecting the traditional arguments in favor of collective bargaining, such as freedom of contract and industrial democracy [Ulman and Sorensen 1984; Kochan 1986]. Somewhat curiously, one of the founders of contemporary mainstream labor economics, Melvin Reder, has leveled a similar criticism against Freeman and Medoff, noting that, “in basing their defense of union institutions upon unavoidably inadequate econometric analysis of their directly measurable effects, F&M have missed an opportunity to develop a case for the 'redeeming social value' of unionism\" [Reder 1985, p. 258].  \n\nIs one to conclude from these criticisms that Freeman and Medoff's approach should be eschewed by institutionalists? I do not think so. The critics are correct that Freeman and Medoff emphasize measurable economic outcomes, but perhaps forget that “voice\"and “institutional response\" are the mechanisms underlying Freeman and Medoff's understanding of how unions work. Theirs is clearly an approach that, although entailing empirical work that focuses on measurable outcomes, recognizes the importance of the processes that lead to those outcomes. From an institutionalist's standpoint, the worst that can be said about Freeman and Medoff is that their preoccupation with empirical work prevented them from recurring frequently enough to the framework that motivated the empirical work-—-that is, to the collective voice-institutional response theory of unions. This is hardly a damning criticism.  \n\n## The American Labor Movement Today  \n\nGiven the importance institutionalists have placed on collective bargaining-as a mechanism for handling labor-management relations that is both practical and based on a correct view of the importance of power in the labor market-institutionalists can only view with alarm the decline of unions and collective bargaining since the mid-1950s. Work on the direction of the labor movement in the United States once invariably included the words “union growth.\" Now, such work invariably includes the phrase “decline of unions.\" The reason, of course, is that the status and power of unions in the United States have, by nearly any measure, fallen in recent years. The most evident measures of union decline are union membership, which has dropped in absolute number since 1980, and the proportion of nonfarm workers covered by contracts, which has been in decline since the mid-1950s.  \n\nAlthough there is agreement that unions are in decline in the United States, there is considerable mystery surrounding the reasons why. To get a feel for the difficulties encountered in understanding the growth and decline of unions, it is useful to start with the so-called structural approach, which attempts to decompose changes in union coverage into various components. For example, demographic shifts in the composition of the labor force (more younger workers, better educated workers, more women), the decline of blue-collar occupations, the shrinkage of the manufacturing, construction, mining, and transportation industries, and the movement of jobs to the South and to less urban areas have all contributed to the decline of unions. Indeed, Freeman and Medoff as well as William T. Dickens and Jonathan S. Leonard have estimated that two-thirds to three-quarters of the shrinkage of union coverage can be attributed to these “structural\" changes-- that is, to the movement of jobs away from workers, industries, and regions that have been traditionally unionized [Freeman and Medoff 1984, Chap. 15; Dickens and Leonard 1986].  \n\nUseful as the structural approach may be, it is, as Freeman and Medoff note, a “technocratic\" explanation. Although straightforward and uncontroversial, it is rather unsatisfying because it offers no prescription for action. In addition, it poses important puzzles. First, it is incorrect and misleading to suppose that the proportion of workers in each industry (or of each sex) who are union members has been or will remain constant over time. Indeed, the most important development in collective bargaining in the last twenty years-the emergence of government unionism——-belies the supposition. Second, the same workers who have become more important in the labor force (and who are less likely to actually be union members) are the same workers who vote most heavily in favor of unions in NLRB representation elections. This fact has been noted by the few theorists of union growth, such as John Schmidman, who have argued that unions should not be on the decline at all, but rather should have a heightened role and importance in an economy that is primarily white-collar and post-industrial [Schmidman1979].13  \n\nThere are three ways of responding to these puzzles. The first is to recast the structural approach so that changes in union coverage can be understood as flows of workers into and out of unions. Such reconceptualization allows one to include changes in union organizing efforts, successes in representation elections, and attrition through decertification elections as explanations of changing union coverage. For exan!ple, Dickens and Leonard have taken such an approach and concluded that if the rate at which unions organized nonunion workers had not dropped, and if the proportion of representation elections won by unions had not fallen, then the union coverage ratio would have remained roughly constant since the mid-1950s [Dickens and Leonard 1985].  \n\nThis first way of responding to the puzzles still has limitations. As Freeman and Medof point out, other factors merit examination as possible causes of the decline of unions: the growth of management opposition to union organizing, the difficulty of bargaining a first contract once bargaining rights have been secured, and changes in how the federal collective bargaining laws have been interpreted and enforced. The problem is that these additional factors are far less susceptible to an empirical or quantitative approach. But it is in addressing just such issues that an institutionalist approach presents itself as a strong and sensible alternative. William Cooke's recent work is a fine example of how an eclectic approach can dig beneath the statistics and reveal how employer resistance and the legal process have stymied unions that have won bargaining rights from exercising those rights in a meaningful way [Co0ke1985].  \n\nThe third response to the puzzles is to look more deeply into the goals of the labor movement-to try to discern how the labor movement has used its political power and its exposure in the media—and to seek there an explanation of union decline. This is inherently a more speculative enterprise, but it is again the natural domain of the institutionalist. For example, David Brody has argued that the involvement of the labor movement in promoting the general social welfare (as opposed to its own narrower interests) was short-lived, lasting only from the 1930s until the mid-1960s [Brody 1980, pp. 215-57). The expansion of labor's public concerns came from an understanding that its wellbeing depended on the health of the rest of society and from its ability to identify its well-being with that of society at large. The subsequent contraction of labor's political interests, and its transformation back into a special interest group, coincided with what Brody calls the shattering of the liberal consensus over the Vietnam war, during which labor sided into the 1970s with those who supported the war. Labor's image as a special interest group has been enhanced by its responses to foreign competition (to wit, restrict imports) and technological change (forestall change). Labor's “short-sighted and unpromising economic policy positions\" have also been treated by Marvin Rozen, who has suggested an agenda of goals centering on work reorganization that could revitalize the labor movement [Rozen 1984]. Whether labor could be induced to adopt such an agenda is a question that, as Rozen points out, cannot easily be answered.  \n\n### The Character of Labor Markets  \n\nContemporary institutionalists espouse what has come to be known as “dual,” “segmented,” or “stratified\" labor market theory. The idea of stratified labor markets has its roots in J.S. Mill's and J.E. Cairnes's ideas of noncompeting groups, F.W. Taussig's discussions of social stratification, Clark Kerr's treatment of “Balkanized\" labor markets, and John Dunlop's notions of job clusters and wage contours.14 There are four central substantive features of the theory of dual or stratified labor markets. First, the labor market is divided into two or more reasonably well-defined segments or strata, each of which can be identified by a characteristic set of wages, working conditions, opportunities for advancement, level of turnover, and rules about supervision. Second, the process of wage and benefit determination differs across strata. Third, the relative size of each stratum is roughly fixed, so that the number of jobs in the most desirable (or primary) stratum is limited. And fourth, there exist barriers that inhibit workers in one stratum from moving to another more desirable one.15  \n\n### Opportunity and Power  \n\nThe institutional vision of the labor market, embodied in the theory of dual or stratified labor markets (hereafter, DSLM), implies a distinct understanding of howworkers'opportunties evolve or are determined. Specifically, the opportunities open to most workers are viewed not as infinite and expansive, but as meager and constraining. Jobs in the most desirable or primary stratum are in limited supply; moreover, those jobs are rationed arbitrarily by characteristics such as race or sex, rather than by ability. Proponents of the DSLM model would agree that Selig Perlman's “manualist psychology\"-in which pessimistic workers view themselves as part of a world of limited economic opportunity-- is a valid outlook for the majority of workers. It is not that most workers lack the intrinsic ability to attain their desired goals, it is that the system has arbitrarily thrown up roadblocks, has denied them the neededpower.  \n\nIt is useful to elaborate these points by contrasting DSLM theory with the mainstream theories of labor supply and human capital. The standard model of labor supply depicts an individual worker who chooses how much market labor to offer by maximizing a utility function subject to a given budget constraint. Although workers' choices are emphasized in this model,the model appears to make a placefor constraints faced by workers, in that the budget constraint seems beyond the control of the individual worker. That is,workers seem to face the rigors of a world of scarce opportunities, indeed, a world in which discrimination or poor educational opportunities could limit the options available to workers [Killingsworth 1983, pp. 18-19].  \n\nBut the appearance of constraints in the simple labor supply model is only a semblance. The budget constraint of the static labor supply decision is in turn the object of choice in the context of human capital theory. Human capital theory offers a picture of individuals who survey the lifetime opportunities open to them and make choices so as to optimize lifetime wealththat is, the present discounted value of the fow of net future earnings. Naturally, such a grand choice made at one time leads to opportunities--or lack of opportunity-in the future. Indeed, the budget constraint in each subsequent period is determined by the \"career\" choice depicted by the human capital model.  \n\nNow, one could argue that factors limiting opportunities, such as discrimination, could be superimposed on the human capital model. Indeed, mainstream labor economists occasionally offer such a suggestion, but it is fair to say that the suggestion remains undeveloped. At root, it is a matter of emphasis--whereas the DSLM model begins with a conception of the labor market in which workers' opportunities are limited, the mainstream model begins with a conception in which workers choose among many available alternatives.  \n\n## Policy  \n\nHence, the fundamental difference between the mainstream and institutional conceptions of the labor market is that the former envisions the choices available to workers as expansive, the latter as limiting. This basic difference implies in turn the basic difference between mainstream and orthodox labor economists on the role of government policy in the labor market. Whereas the mainstream economist tends to favor laissez-faire, the institutionalist sees problems that can be usefully addressed through government action. Indeed, institutionalists might well agree that, in a world of perfect capital markets and perfect foresight, the decision-making process envisioned in the human capital model would lead to outcomes that we would see as good. But of all markets, the labor market is the most ridden with imperfection. In a society that prohibits indentured servitude, educational loans will be greatly underprovided by private financial institutions. Youthful judgments about future income streams, even if not colored by wishful thinking, are likely to be quite wrong. It is all too likely that choices made early in life may be regretted, and suboptimal from a social standpoint. To the institutionalist, the scope for intervention is clear.16  \n\nPrecisely what action to take is, of course, another matter. During the 1960s and 1970s, many adherents of DSLM theory advocated socalled structural change in the labor market. Structural change simply refers to changing the kinds of jobs that exist. Certain low-skilled jobs might be obliterated by a sufficiently high minimum wage, the organization of production might be changed so that skilled occupations made up a greater proportion of all jobs, or technological change could be encouraged so that jobs in the lowest strata of the labor market became redundant. Accomplishing structural change would require policies such as an increased minimum wage, more stringent regulation of job hazards and other aspects of the workplace, or subsidies to upgrade jobs or to skew the distribution of jobs toward higher-skilled occupations. Any policy that attempts to change the job structure acts on the employer, who in the end demands labor and determines the structure ofjobs. Such intervention in the workplace has, of course, been resisted stridently by most employers and mainstream economists.  \n\nNot all institutional labor economists would advocate such uncompromising intervention in the labor market. Vernon Briggs has stated the institutionalist's case for the development of human resources through education, training, anti-discrimination, and job-creation policies [Briggs 1987]. An important part of this case is a recognition that basic changes in the economy--resulting from changing technology, competition from abroad, and changing demographic composition of the labor force--have resulted in higher levels of structural unemployment. Structural unemployment results from mismatches between the types of workers that employers demand and the types of workers who are available for work. If employers demand increasingly skilled labor, but the labor force is increasingly unskilled, then structural unemployment occurs.17 Pockets of unemployment among certain demographic groups or in certain regions are the result.  \n\nThe policies emphasized by Briggs aim to improve the employment prospects of workers afflicted with structural unemployment: Occupational training and work experience are ways of upgrading the skills of displaced workers. Voluntary relocation and anti-discrimination policies seek to break down barriers that hem workers into lower strata of the labor market. Job creation is a way of employing workers who are unable to find a match in the private labor market.  \n\nAll of these policies are predicated on an institutionalist view of the labor market--that is, a labor market that is stratified, and in which barriers exist between the strata. Briggs's structuralist emphasis differs from the strict DSLM approach in its greater optimism that barriers can be broken down either directly (through anti-discrimination policies or mobility) or indirectly (by giving workers the skills that are required to qualify them for jobs in the more desirable strata).18 Briggs, that is, emphasizes policies that operate on the supply side of the labor market, whereas a strict DSLM theorist might emphasize policies that operate on the demand side. But both sets of policies derive from an essentially similar conception of the labor market and how it operates.19  \n\n### Cross-fertilization?  \n\nThe DSLM theory poses an outstanding example of how an institutionalist conceptualization has had an impact on the thinking of mainstream economists and has blurred (in certain ways) the distinction between mainstream and institutional labor economics. In an important article, Dickens and Lang have used statistical techniques typically used by mainstream economists to test two of the most important implications of DsLM theory--that there are noneconomic barriers to entering the higher strata of the labor market, and that the returns to education differ markedly from stratum to stratum [Dickens and Lang 1985]. Their work provides convincing support for the idea that DSLM theory provides a correct characterization ofthe labor market that barriers do exist and that returns to education do differ greatly from stratum to stratum. Although the underlying hypotheses tested are old, the techniques used to examine them are new. If institutionalists want to offer evidence that convinces mainstream economists that their conceptualization is correct, such techniques may be an effective waytoproceed.  \n\nOther recent developments in the mainstream treatment of labor markets have their origin in institutionalist conceptions. The development of so-called efficiency wage theory is a clear attempt to expand mainstream economic theory from its narrow base so that it can accommodate behavior by firms that institutional labor economists have long observednamely, wage-setting with minimal regard to the market forces. Mainstream economists, of course, refer to the results of such behavior as “nonmarket-clearing\" or “disequilibrium\" wages, and somehavefelt compelled to come togripswith them.The ideabehind efficiency wage theory is that many workers-those in the upper strata of the labor market--are paid wages higher than would be consistent with a Walrasian equilibrium wage. They are paid the higher wage because transaction costs——costs of search, hiring, negotiation, and enforcement—all are especially significant in the case of labor. Paying the higher wage reduces turnover and creates an incentive for workers to work hard, reducing both search and hiring costs (by reducing turnover), and enforcement costs (by creating an incentive to work and not toshirk).2o  \n\nAgain the question arises, Should institutionalists eschew these transformations and uses of purer institutionalism by economists trained in the mainstream? There is a pure and a practical reason for answering, No. The pure reason is that nothing about mainstream statistical methods, or about mainstream mathematical methods, is naturally inimical to institutionalism. Indeed, Wesley Clair Mitchell's pioneering use of statistical methods is rightly claimed by institutionalists as among the triumphs of early institutionalism. Although institutionalists have been less avid users of mathematical methods, their use by Marxists demonstrates how footloose they can be. What matters is how statistical and mathematical methods are used. Although they have most often been used as part of (or in connection with) models that assume perfect markets and yield “ideal\" market-based outcomes, it need not be so. Such methods are equally amenable to testing the implications of institutionalist constructs against the evidence or to reaching an understanding of whose interests are served by an existing set of institutional arrangements.  \n\nThe practical reason is that only a handful of universities still grant a degree in economics with anything less than thorough indoctrination in mainstream models and techniques. To say that institutional work must be research that has the traditional institutionalist cast may be to consigninstitutionalism to extinction.  \n\nOne can only conclude that the marriage of institutionalism with more sophisticated theorizing (that is, modeling that relies less on simple maximizing) will be increasingly fruitful.  \n\n### Reprise  \n\nI am prepared to predict that research on labor markets and labor problems-whether or not institutionalistinnamewill have anincreasingly institutionalist cast in the future. Indeed, labor economics has, despite the best efforts of some, never strayed far from its institutionalist roots. There is far more continuity than discontinuity in the history of labor economics, as Paul J. McNulty has so well demonstrated in his definitive treatment of the development of labor economics [McNulty 1980].  \n\nMy prediction, I am sorry to say, does not imply that labor economists will increasingly hark back to Commons, Veblen, and Perlman for their inspiration--at least not explicitly. Nor does it mean that institutionalism will become recognized as the preeminent framework within which to conduct labor research. But labor economists will increasingly address the so-called imperfections of the labor market as we are forced by the data and events to recognize their importance. We will become increasingly familiar with the complexity of the labor market and its institutions as our demands for more rigorous tests of hypotheses force us to resort to methods, such as social experimentation, that require us in turn to get our hands dirty in the real world and its institutions. In the end, I am convinced, we will have to recognize the importance of power in the labor market-such recognition follows too obviously from attention to the data and institutions of the labor market.  \n\n#### Notes  \n\n1. The choice between greater institutional complexity and greater abstraction must of course be made with an eye to the purposes at hand. Although greater attention to institutional complexity may make an analysis more realistic and useful in practical contexts, it may also make an analysis more difficult to execute and less general. But mainstream economists are coming to agree with institutionalists that mainstream economists have often usedpoorjudgmentinchoosinghowfartopushabstraction,andthatthe result hasbeen analysis withlittle practical application.As Andrew Oswald hasput it inhisreviewof recentmainstreamresearch on unions andlabor markets:  \n\nMost of the new theories have been derived by economists who would probably admit that they know little of the institutional features of real labor markets. To some limited extent this may be acceptable. Yet there are reasons to believe that it has now gone too far in this field of economics, and it seems partly up to industrial relations researchers to pull economic theorists around, and to point them in theright direction....Onerather obviouslessonfrom all thisit is unfortunate that it needs to be saidis that theoretical models ought to be consistent with the stylized facts. The industrial relations literatureprovides an abundantsource ofsuch information;few otherareas of economics have the benefit of this kind of parallel field. Up to now, however, economists have not made the most of this advantage. It may be time for economic theorists and industrial relations researchers to combine forces [Oswald 1986, pp. 14-15].  \n\nI am grateful to Marvin Rozen for these points.   \n2. It would be unfair to say that all mainstream work has assumed a competitive labor market. Indeed, many contributions to the mainstream literature of the last twentyyears have attempted to relax one or more of the competitive assumptions. The labor demand literature has attempted to measure how well or poorly different types of labor substitute for each other. The job search literature has introduced imperfect information. And some attempts have been made to introduce discriminatory wage differentials and other barriers, although the attempts to measure discriminatory differentials have been more successful than the attempts to explain those differentials within the mainstream framework.   \n3. In fact, the increased attention some theorists have paid to game theory and uncertainty in recent years suggests an opposite trend—that some within the mainstream would like to consider power and imperfections. Whether they can succeed on the turf they have chosen is another issue.   \n4. As John S. Gambs has noted, “Institutionalists accept much that standard economists believe; on the whole they seem to think that what standard theory has to offer is rather elementary and only the beginning of wisdom\" [Gambs 1946, p. 4].   \n5. Segal discusses in detail four prominent labor economists of the 1940s and 1950sJohn Dunlop, Richard Lester, Charles Myers, and Lloyd Reynolds-who he labels “post-institutionalists.\" He argues that these post-institutionalists share much with current orthodox labor economics and little with early institutionalists such as Commons. But this interpretation is at odds with the views of mainstream and institutionalist labor economists alike [Cain 1976, p. 1227; McNulty 1980, Chapters 7 and 8; Ramstad 1981, p. 339].   \n6. If this discussion suggests that institutional labor economics has been experiencing a crisis of identity, then so be it. Labor economics, from the time it was called “Labor Problems\" to the present, has been the most eclectic of enterprises. It has drawn on fields as far-flung as social work, history, law, mathematics, and statistics. The urge to create tidy compartments into which various work can be placed is understandable in such a seeming morass. But again, the dangers of oversimplification and stereotyping--of labelingA aninstitutionalist andB something else-are great.   \n7. This sketch of institutional views of collective bargaining derives mainly from the lectures and published work of Jack Barbash [1964; 1977a; 1977b].   \n8. Perhaps the most important shortcoming of worker management, from the  \n\ninstitutionalist viewpoint, is that it lacks an intrinsic way of dealing with the politics of a worker organization, or of mediating the conficting interests of different workers within an establishment. Indeed, proponents of worker management have rarely recognized these organizational issues. The result is that worker management in its pure form tends to be an imaginary notion of the radical utopian mind.  \n\n9. Mild forms of human relations would be the so-called consultation that occurs in Europe, or the “meet-and-confer” arrangements that have arisen in the public sector in the United States. Thefull-fledged human relations approach referred to in the text is an ideal or stereotype that is often used to characterize large corporations such asIBM.  \n\n10. Indeed, this argument is so obvious to contemporary legal scholars such as Wellington [1968] and Gregory and Katz [1979] that they are puzzled as to how the doctrine of criminal conspiracy ever held up.  \n\n11. The association of political scientists with institutionalists seems warranted in view of Philip Klein's work [Klein 1980].  \n\n12. Freeman and Medoff note several other effects of unions. They tend to reduce the inequality of earnings within a firm or industry. They limit the scope for arbitrary action against workers by management. They often represent the interests of groups who are disadvantaged, discriminated against, or who have lower incomes. These effects of unions have long been recognized in the institutionalist literature.  \n\n13. There is in fact a third puzzle: The same structural changes that have occurred in the United States have occurred in other western countries, but without the accompanying decline in unionism.  \n\n14. For a full set of references, see Woodbury [1979].  \n\n15. The dual or segmented labor market theory has other features as well: Its hypotheses are derived from a participant-observer approach, its impetus is perceived social problems such as poverty and unequal distribution of income, and it can be adapted to study broad issues such as the sources of labor institutions.  \n\n16. Especially germane is the debate, which has enduring significance and value, between Simon Rottenberg and Robert J. Lampman over choice in thelabor market [Rottenberg 1956; Lampman 1956].  \n\n17. Note that structural unemployment is distinct from two other types of unemployment:frictional unemployment,which occurs as workerssearchfor jobs, and demand deficiency unemployment, which occurs when aggregate demandisbelowthelevel consistentwithfull employment.  \n\n18. Implicitly, Briggs supposes that jobs requiring a high level of skill are waiting for workers who possess the needed skills. A strict DSLM theorist, on the other hand, believes that the number of jobs in the higher strata of the labor market are kept arbitrarily few.  \n\n19. It is worth noting that Briggs's work and views are representative of a large group of institutional labor economists who, during the 1960s and 1970s succeeded admirably both in bringing the problem of structural unemployment to the attention of policy-makers and in seeing that the problem was addressed effectively through public policy. For reviews and evaluations of the training and job-creation policies that reached their zenith during the late 1970s, see Levitan and Mangum [1981] and Cook, Adams, Rawlins, and Associates [1985].  \n\n20. George Akerlof and Janet Yellen present several efficiency wage models [Akerlof and Yellen 1986]. The efficiency wage theorists have tended to neglect an important group of less-mathematical treatments of labor institutions that focus on property rights and transaction costs. These latter contributions are well represented by Eirik G.Furubotn and Svetozar Pejovich [1974], and Williamson [1975]. Carl J. Dahlman [1980, Chap. 3] offers an excellent synthesis of the property rights literature, with some applicationsandextensions.  \n\n#### References  \n\nAkerlof, George, and Janet Yellen, eds. 1986. Efficiency Wage Models of the Labor Market. New York: Cambridge University Press.   \nBarbash, Jack. 1964.“The Elements of Industrial Relations.\" British Journal of Industrial Relations 21 (March): 66-77.   \nBarbash, Jack. 1977a. \"Collective Bargaining as an Institution-A Long View.\" In Proceedings of the 29th Annual Meeting, Industrial Relations Research Association. Madison, Wisc.: IRRA. Pp. 303-10.   \nBarbash, Jack. 1977b. “Price and Power in Collective Bargaining.\" Journal of Economic Issues 11 (December): 847-59.   \nBaumol, William J., John C. Panzar, and Robert D. Willig. 1982. Contestable Markets and the Theory of Industry Structure. New York: Harcourt Brace Jovanovich.   \nBriggs, Vernon M., Jr. 1987. “Human Resources.\" Journal of Economic Issues 21 (September): 1207-40.   \nBrody, David. 1980. Workers in Industrial America. New York: Oxford University Press.   \nBunting, Robert L. 1962. Employer Concentration in Local Labor Markets. Chapel Hill, N.C.: University of North Carolina Press.   \nCain, Glen G. 1976. “The Challenge of Segmented Labor Market Theories to Orthodox Theories.\" Journal of Economic Literature 14 (December): 1215-57.   \nChamberlin, Edward H. 1933. The Theory of Monopolistic Competition. Cambridge, Mass.: Harvard University Press.   \nCommons,John R.1909.“American Shoemakers, 1648-1895: A Sketch of Industrial Evolution.\" Quarterly Journal of Economics 24 (November): 39-84.   \nCook, Robert F., Charles F. Adams, V. Lane Rawlins, and Associates. 1985. Public Service Employment. Kalamazoo, Mich.: W. E. Upjohn Institute for Employment Research.   \nCooke, William N. 1985. Union Organizing and Public Policy. Kalamazo0, Mich.: W. E. Upjohn Institute for Employment Research.   \nDahlman, Carl J. 1980. The Open Field System and Beyond. New York: Cambridge University Press.   \nDickens, William T., and Kevin Lang. 1985. “A Test of Dual Labor Market Theory.\"American Economic Review 75 (September): 792-805.   \nDickens, William T., and Johnathan S. Leonard. 1985.“Accounting for the Decnei m Umon mempersnip. inaustriat ana Laoor Kelanons Keview 58 (April): 323-34. -.1986. “Structural Changes in Unionization: 1973-1981.\" Working Paper No. 1882, National Bureau of Economic Research, Cambridge, Mass., April.   \nDugger, William M. 1980. “Power: An Institutional Framework of Analysis.\" Journal of Economic Issues (December): 897-907.   \nFreeman, Richard B., and James L. Medoff. 1984. What Do Unions Do? New York: Basic Books.   \nFriedman, Milton. 1962. Capitalism and Freedom. Chicago,Ill: University of Chicago Press.   \nFurubotn, Eirik G., and Svetozar Pejovich, eds. 1974. The Economics of Property Rights. Cambridge, Mas.: Ballinger.   \nGambs, John S. 1946. Beyond Supply and Demand. New York: Columbia University Press.   \nGregory, Charles O., and Harold A. Katz. 1979. Labor and the Law, 3d. ed. New York: W.W. Norton.   \nHirschman, Albert O. 1970. Exit, Voice, and Loyalty. Cambridge, Mass.: Harvard University Press.   \nHockner, Arthur, Eiken Appelbaum, Judith Goode, and Cherlyn Granrose. 1987. Worker Buyouts. Kalamazoo, Mich.: W. E. Upjohn Institute for Employment Research.   \nHoxie, Robert F. 1923. Trade Unionism in the United States. New York: D. Appleton.   \nKanel, Don. 1974. “Property and Economic Power as Issues in Institutional Economics.\" Journal of Economic Issues 8 (December): 827-40.   \nKerr, Clark. 1958. Unions and Union Leaders of Their Own Choosing. Santa Barbara, Calif. Center for the Study of Democratic Institutions.   \nKillingsworth, Mark R. 1983. Labor Supply. New York: Cambridge University Press.   \nKlein, Philip A. 1980. “Confronting Power in Economics: A Pragmatic Evaluation.\" Journal of Economic Issues 14 (December): 871-96. _.1987. “Power and Economic Performance: The Institutionalist View.\" Journal of Economic Issues 21 (September): 1341-77.   \nKochan, Thomas A. 1986. “Comments on What Do Unions Do?\" In Proceedings of the 38th Annual Meeting, Industrial Relations Research Association. Madison, Wisc.: IRRA. Pp. 364-68.   \nKochan, Thomas A., Harry C. Katz, and Nancy Mower. 1984. Worker Participation and American Unions. Kalamazoo, Mich.: W. E. Upjohn Institute for Employment Research.   \nLampman, Robert J. 1956. \"On Choice in Labor Markets: Comment.\" Industrial and Labor Relations Review 9 (July): 629-36.   \nLevitan, Sar A., and Garth L. Mangum, eds. 1981. The T in CETA. Kalamazoo, Mich.: W. E. Upjohn Institute for Employment Research.   \nMcNulty, Paul J. 1980. The Origins and Development of Labor Economics. Cambridge, Mass.: MIT Press.   \nOswald, Andrew. 1986. \"New Research on the Economics of Trade Unions and Labor Contracts.\" Discussion Paper No. 261, Center for Labor Economics. London School of Economics. London. England. November.   \nPerlman, Selig. 1950 [1922]. A History of Trade Unionism in the United States. New York: Augustus M. Kelley.   \nPetr, Jerry L. 1984. “Fundamentals of an Institutionalist Perspective on Economic Policy.\" Journal of Economic Issues 18 (March): 1-17.   \nRamstad, Yngve. 1981. “Institutional Economics: How Prevalent in the Labor Literature?\" Journal of Economic Issues 15 (June): 339-50.   \nReder, Melvin W. 1985. \"Comment on What Do Unions Do?\" Industrial and Labor Relations Review 38 (January): 256-58.   \nRobinson, Joan. 1933. The Economics of Imperfect Competition. London: Macmillan.   \nRottenberg, Simon. 1956. \"On Choice in Labor Markets.\" Industrial and Labor Relations Review 9 (January): 183-99.   \nRozen, Marvin E. 1984. \"Work Reorganization and Labor's Future: New Directions for Unions.\" Working Paper, Department of Economics, Pennsylvania State University, University Park, Penn., September.   \nSamuels, Warren J. 1973. “The Economy as a System of Power and Its Legal Bases: The Legal Economics of Robert Lee Hale.\" University of Miami Law Review 27 (Spring and Summer): 261-371.   \nSamuels, Warren J. 1979. “Introduction.\" In The Economy as a System of Power, p i-xii, ed. Warren J. Samuels. New Brunswick, N.J.: Transaction Books.   \nSchmidman, John. 1979. Unions in Postindustrial Society. University Park, Penn.: Pennsylvania State University Press.   \nSegal, Martin. 1986. “Post-Institutionalism in Labor Economics: The Forties and Fifties Revisited.\" Industrial and Labor Relations Review 39 (April): 388-403.   \nStigler, George J. 1966. The Theory of Price, 3d ed. New York: Macmillan.   \nTaylor, Frederick Winslow. 1967 [1911]. The Principles of Scientijfic Management. New York: W.W. Norton.   \nUlman, Lloyd and Elaine Sorensen. 1984. “Exit, Voice, and Muscle: A Note.\" Industrial Relations 23 (Fall): 424-28.   \nWellington, Harry G. 1968. Labor and the Legal Process. New Haven: Yale University Press.   \nWilliamson, Oliver E. 1975. Markets and Hierarchies. New York: The Free Press.   \nWoodbury, Stephen A. 1979. “Methodological Controversy in Labor Economics.\" Journal of Economic Issues 13 (December): 933-55.  "
  },
  "md_aggarwalEvaluatingVentureTechnical2015": {
    "reference_markdown": "This article was downloaded by: [132.239.1.230] On: 02 December 2015, At: 02:50 Publisher: Institute for Operations Research and the Management Sciences (INFORMS) INFORMS is located in Maryland, USA  \n\n# Management Science  \n\nPublication details, including instructions for authors and subscription information: http: //pubsonline.informs.org  \n\n# Evaluating Venture Technical Competence in Venture Capitalist Investment Decisions  \n\nRohit Aggarwal, David Kryscynski, Harpreet Singh  \n\n# To cite this article:  \n\nRohit Aggarwal, David Kryscynski, Harpreet Singh (2015) Evaluating Venture Technical Competence in Venture Capitalist nvestment Decisions. Management Science 61(11):2685-2706. http://dx.doi.org/10.1287/mnsc.2014.2117  \n\nFull terms and conditions of use: http: //pubsonline.informs.org/page/terms-and-conditions  \n\nThis article may be used only for the purposes of research, teaching, and/or private study. Commercial use or systematic downloading (by robots or other automatic processes) is prohibited without explicit Publisher approval, unless otherwise noted. For more information, contact permissions@informs.org.  \n\nThe Publisher does not warrant or guarantee the article's accuracy, completeness, merchantability, fitness for a particular purpose, or non-infringement. Descriptions of, or references to, products or publications, or inclusion of an advertisement in this article, neither constitutes nor implies a guarantee, endorsement, or support of claims made of that product, publication, or service.  \n\nCopyright @ 2015, INFORMS  \n\n# Please scroll down for article-it is on subsequent pages  \n\n![](images/8b56627fafd1a2a44662531e08585843af3ed196945ca9fad212dfc3fe007787.jpg)  \n\nINFORMS is the largest professional society in the world for professionals in the fields of operations research, management science, and analytics. For more information on INFORMS, its publications, membership, or meetings visit http:/ /www.informs.org  \n\n# Evaluating Venture Technical Competence in Venture Capitalist Investment Decisions  \n\nRohit Aggarwal The University of Utah, Salt Lake City, Utah 84112, rohit.aggarwal@business.utah.edu  \n\nDavid Kryscynski Brigham Young University, Provo, Utah 84602, dk@byu.edu  \n\nHarpreet Singh University of Texas at Dallas, Richardson, Texas 75080, harpreet@utdallas.edu  \n\nA Ithough much research emphasizes the importance of venture technical competence for venture success and, therefore, the importance of venture technical competence in venture capitalist (VC) investment decisions, We know little about why some VCs may be better than others at assessing the technical competence of ventures. We gathered unique and proprietary data from 33 VCs and 308 ventures that sought Series A funding from those VCs. We show that VC assessment of ventures predicts VC investment, and venture technical competence predicts subsequent venture failure. This means that VCs that overassess ventures are more likely to invest in firms that are more likely to fail. We then show that higher VC technical competence leads to lower errors in assessment, but that greater similarity between the VC and venture in technical competence leads to higher assessments, ceteris paribus. We thus conclude that VC competence enhances the accuracy of VC assessments, but similarity in technical competence between VCs and ventures may lead to positive assessment bias.  \n\nKeywords: econometrics; VC funding; technical competence, VC assessment   \nHistory: Received October 25, 2013; accepted June 28, 2014, by Sandra Slaughter, information systems. Published online in Articles in Advance May 15, 2015.  \n\n## 1. Introduction  \n\nI don't know about Techstars, but we would have a hard time funding a startup without a strong technical founder. I'd go so far as to say that it is irresponsible to start a technology company without a technical founder. (Andreessen 2011)  \n\nWe reject teams for a variety of reasons, and lack of tech expertise is one of the big ones.... Imagine going on a transatlantic voyage without a ship. Without software engineering knowledge, we will fare no better. We need good IT knowledge to correctly judge a team's tech expertise.  \n\n—A reputed venture capitalist in the IT domain  \n\nSince a venture's human capital has a significant impact on future growth and performance (Colombo and Grilli 2005, Cooper et al. 1994, Haber and Reichel 2007, Shrader and Siegel 2007), the ability of a venture capitalist (VC) to accurately evaluate the venture's human capital should have a strong impact on the quality of the VC's funding decision (Baum and Silverman 2004, Patzelt 2010). In the technology domain, one of the most important aspects of venture human capital is technical competence—i.e., a venture's ability to effectively address technology-related challenges such as programming, data access, data development, information technology (IT) architecture, and so forth (Lee et al. 1995, Trauth et al. 1993). The leading quotations above illustrate the clear preference of VCs for investing in technology ventures with strong technical competence.  \n\nAlthough technical competence may be an important predictor of technology-venture success and an important component of VC investment decisions, we know surprisingly little about the underlying abilities of VCs to evaluate the technical competence of ventures. As we shall see, research seems to have taken for granted that VCs are fully capable of evaluating the technical competence of venture teams when making investment decisions. If all VCs are equally able to evaluate the technical competence of technology ventures, then the lack of research should not be concerning. However, if VCs systematically vary in their abilities to evaluate the technical competence of ventures, then some VCs may be better situated to assess the likelihood of venture survival and performance. Similarly, VCs with poor abilities to assess venture technical competence may consistently invest in ventures with poor performance prospects. Accordingly, understanding why and how VCs evaluate the technical competence of technology ventures may help to explain performance differences among technology VCs.  \n\nWe argue that VCs do vary in their abilities to assess the technical competence of venture teams and that two factors predicting that variance are the VC's own technical competence and the similarity in technical competence between the VC and venture. We thus ask two tightly coupled research questions: (1) Does VC technical competence improve assessment accuracy when evaluating the technical competence of ventures and the quality of subsequent investment decisions? And (2) does similarity in technical competence between VCs and ventures positively bias assessments and affect the quality of subsequent investment decisions? We leverage a unique and proprietary data set of 33 VCs and 308 ventures that those VCs considered for investment. The VCs and technology heads at the ventures both took validated quizzes to test their own technical competence, and, in addition, each VC evaluated the technical competence of each venture it considered. Our data are uniquely positioned to allow us to explore the effect of VC technical competence on accuracy when evaluating venture technical competence, the effect of similarity in technical competence on VC evaluations of venture competence, investment decisions and venture performance outcomes.  \n\nWe thus contribute to the VC investment decision literature both theoretically and empirically. From a theory_ perspective, we first partially explain why some VCs may be better able to assess the technical competence of ventures than others and directly challenge the implicit assumption that VCs are similar in their abilities to evaluate venture technical competence. From an empirical perspective, we provide a unique empirical setting that allows us to observe VC technical competence, VC assessments of venture technical competence, actual venture technical competence, actual VC investment decisions, and real venture performance outcomes. Prior studies have lacked the data depth to explore all of these factors in the same models.  \n\nIn the next section we establish the baseline expectations that (1) VC assessments of venture technical competence predict VC investments and (2) venture technical  competence predicts  the likelihood of venture failure. The clear implication of these expectations is that overassessing venture technical competence can lead to investing in ventures that may be more likely to fail. In $\\S3$ we then show that VC technical competence leads to lower error magnitudes when assessing ventures, and that greater similarity between VC and venture technical competence leads to higher assessments, ceteris paribus. Thus, increased VC technical competence increases assessment accuracy, but similarity between the VC and venture can lead to positive bias in assessments. We then describe our data and results and finally conclude with impli cations for future research.  \n\n## 2. Why Assessments Matter for VC Outcomes  \n\nA baseline expectation from prior VC investment research is that the probability of investment should increase with the VC's assessment of the venture's technical competence and that the likelihood of venture failure should decrease with increased actual technical competence. Before developing these expectations in detail, however, it is useful to clarify what we mean by technical competence and why technical competence is important in VC investment decisions.  \n\nAs mentioned in the introduction, technical competence is a venture's ability to effectively address ITrelated challenges such as programming, data access, data development, IT architecture, and so forth (Lee et al. 1995, Trauth et al. 1993). Both Marc Andreessen and the unnamed venture capitalist in the second introductory quotation consider carefully the technical expertise and competence of the ventures' key workers. Their emphasis on venture technical competence seems well founded in the academic literature (e.g., Baum and Silverman 2004, Zacharakis and Meyer 2000). Shepherd (1999), for example, finds that the industry expertise of the founding team is one of the most important factors in predicting venture survival. Similarly, a host of studies show that the industry expertise of a venture's key workers significantly predicts the future performance of the venture (Colombo and Grilli 2005, Crook et al. 2008, Haber and Reichel 2007, Shrader and Siegel 2007). Accordingly, if the venture seeks to grow and survive as a technology-intensive enterprise, then the technical competence of its key workers should be a critical predictor of its future success. Indeed, some scholars have shown that technical competence can be a source of sustained competitive advantage for the firm (Bharadwaj 2000, Mata et al. 1995, Pavlou and El Sawy 2006, Tambe et al. 2012, Tippins and Sohi 2003).  \n\nAlthough venture technical competence is important for venture performance (Colombo and Grilli 2005, Haber and Reichel 2007, Shrader and Siegel 2007) and VC decisions to invest (Baum and Silverman 2004, Zacharakis and Meyer 2000), it may be quite difficult for the VC to evaluate the technical competence of a venture, even when the venture opens its doors to the VC. The venture may project high levels of technical competence, even if its true competence is low. Entrepreneurs are notoriously overconfident, so they may believe that they are far more competent than they actually are (Busenitz and Barney 1997, Forbes 2005, Lowe and Ziedonis 2006). If they believe that they are highly competent, then they will project that competence to potential VCs, even if they are not. Also, VCs face a moral hazard problem when investing in ventures (Bergemann and Hege 1998, Wang and Zhou 2004). In other words, there is great uncertainty about the future success of the venture, and the venture has incentive to convince the VC that there is a high probability of future success even if the venture has private information to the contrary. Accordingly, the venture may try to project a high level of technical competence even if it does not have it, to secure funding. Thus, whether the venture is honest and overconfident or dishonest, the venture still may project a higher level of technical competence than it really has. It may be very difficult for the VC to cut through those projected signals to evaluate the true technical competence of the venture. In other words, there may be a gap between the venture's true technical competence and the VC's assessment of the venture's technical competence.  \n\nThe fairly straightforward concern with the gap between VC assessments and actual venture competence is that the decision makers act on their perceptions of reality rather than on the unknown objective reality (March 1994). From the VC's perspective, the assessment is the best indicator of the true venture technical competence, and, therefore, investment decisions are likely based on the assessment. Accordingly, we should expect the probability of VC investment to increase with the VC's assessment of venture technical competence. Stated formally:  \n\nHYPOTHEsIs 1A (H1A). The probability of VC investment increases as the VC's assessment of a venture's technical competence increases, ceteris paribus.  \n\nWhereas the VC's assessment of venture technical competence may drive the VC's investment decisions, the actual venture technical competence is likely to drive venture performance outcomes. Based on the logic described above (e.g., Colombo and Grilli 2005, Kor 2003), higher venture technical competence likely leads to higher venture performance. In particular, higher venture technical competence likely leads to lower failure rates among new ventures because technically competent teams are better positioned to deal with the technical challenges required to successfully bring new products and services to market. Thus:  \n\nHYPOTHESIs 1B (H1B). The probability of venture failuredecreases as the venture's technical competenceincreases,ceterisparibus.  \n\nThe hypotheses above may seem straightforward initially. Extant research on VC decision making certainly supports the logic that VCs will be more likely to invest in ventures that they believe are more competent and that ventures that are more competent are more likely to succeed. These hypotheses taken together, however, reveal an important implicit assumption in extant models. Specifically, prior models implicitly assume that VCs are similarly able to assess venture technical competence. Consider, for example, Colombo and Grilli's (2005) rich study exploring the impact of founding team human capital on the growth of new technology firms. Their theory and empirical design leverage founders' years of education, years of industry experience, managerial experience, and prior entrepreneurial experience as indicators of the competence of the founding team. Colombo and Grilli's (2005) approach is representative of other research on venture team competence and/or experience (e.g., Baum and Silverman 2004, Kor 2003, Zacharakis and Meyer 2000). The logic underlying the use of demographic experience variables is that that experience is the best observable proxy for true competence. Thus, if these easy-toobserve measures are the key competence indicators, then we should not expect variance in ${\\mathrm{VCs^{\\prime}}}$ abilities to assess venture technical competence. VCs should be similarly able to assess venture teams.  \n\nBut although data availability for demographic experience measures has made such measures standard in VC decision making and venture performance studies, even the scholars using these indicators recognize the potential limitations of using experience to proxy for competence (e.g., Kor 2003). Competence does not necessarily follow experience, and experience is not necessarily required for competence. BusinessWeek's annual survey of young tech entrepreneurs, for example, illustrates many highly successful and competent tech founders who lacked experience at the time of founding. Accordingly, when it comes to actual investment decisions, VCs may be more likely to rely on their own subjective assessments of venture technical competence than the objective measures of experience typically invoked in prior research. Our qualitative conversations with VCs in the research process seem to support this notion. If these subjective assessments are important, then explaining why some VCs have superior assessment abilities is critical for improving models of VC decision making and subsequent outcomes. Constructing such a model is the primary purpose of the nextsection.  \n\n## 3. Predicting VC Assessments of Venture Technical Competence  \n\n3.1. VC Technical Competence Increases Assessment Accuracy  \n\nTheories of expert knowledge suggest that VCs with higher technical competence should be better able to accurately assess the technical competence of ventures (Castanias and Helfat 2001, Eisenhardt and Schoonhoven 1990, Kor 2003, Shepherd et al. 2003). Research supports that highly competent individuals in a specific domain are better able to discern nuances within that domain. Historical research on chess experts shows that these experts have deeper understanding of the game, but also have greater recall related to the game (Chase and Simon 1973). Their more advanced cognitive structures related to the many different problems and possibilities in chess help them to more quickly diagnose a specific chess situation. Accordingly, experts are better able to quickly evaluate situations in their domains because of their deep technical knowledge and experience (Gladwell 2007, Sternberg and Grigorenko 2003).  \n\nFor the reasons mentioned above, deep contextspecific knowledge is particularly valuable in the business domain where firms may need to quickly evaluate shifting external environments and make decisions accordingly. Kor (2003) finds that management competence in specific domains enhances the rate of entrepreneurial growth. She argues that this is because competent management teams are better able to synthesize the nuances in their situations and contexts and make appropriate decisions. Other research also supports the positive relationship between domain-specific managerial competence and venture performance (e.g., Castanias and Helfat 2001, Eisenhardt and Schoonhoven 1990).  \n\nThe same principles underlying theories of expert knowledge also likely apply in the context of VCs investing in technology ventures (Shepherd et al. 2003). Specifically, as a VC's technical competence increases, that VC should be better able to observe the nuances in venture technical knowledge and, therefore, determine the extent to which the venture also has technical competence. Highly competent VCs should know what questions to ask to validate the technical claims made by ventures, and they should be better able to recognize any technical constraints or difficulties the venture may face moving forward. These VCs can comprehend any technical uncertainties and complexities and they can carefully evaluate how ventures respond to their various questions. This is emphasized in the second leading quotation of the article when the VC mentions that he needs technical knowledge to assess the technical competence of a venture's human capital. Thus, VCs with high levels of technical competence both know what questions to ask as Well as how to evaluate the quality of the answers they receive.  \n\nThe value of VC technical competence can be illustrated by a hypothetical example based on rich interviews conducted by one of the authors. A particular venture with a low level of technical competence (loventure, for short) pitches its business model to both a VC with high technical competence (hi-VC, for short) and a VC with low technical competence (lo-VC, for short). One major challenge for the venture is the need to quickly scale up operations in the face of an exponential increase in traffic load. Both VCs ask the venture about how to deal with this challenge, and the venture replies that they will move their application to the distributed environment of Amazon Web Services when necessary. The lo-VC is satisfied with this response, but the hi-VC follows up with additional questions such as whether the application is built around a shared database, what kind of abstraction they have created to scale the catching layer, what they have done to make their process asynchronous, and so forth. The venture is still struggling to get the application running on a single server system and, therefore, does not have satisfactory answers to the hi-VC's questions. Accordingly, the hi-VC is far better prepared to determine the true technical competence of the venture.  \n\nThus, we expect VCs with high technical competence to be more accurate in their assessments of venture technical competence. Formally:  \n\nHYPOTHEs1s 2 (H2). VCs with higher technical competence will have lower error magnitudes when assessing the technical competence of ventures.  \n\n### 3.2. Similarity in VC and Venture Technical Competence Leads to Positive Assessment Bias  \n\nWhereas the accuracy of VC assessments may increase with VC technical competence, accuracy may decrease with greater similarity between VCs and ventures. Franke et al. (2006) apply this similarity logic to the VC context and show that VCs evaluate venture teams more positively when they have similar training and professional experience. Although we do not dispute their findings, we also note that their study has at least two important limitations. First, like most similarity bias research, their work focuses on easy-to-observe demographic similarities between VCs and venture teams. Second, their research explores ex ante evaluations that do not involve social interactions between the VCs and the venture teams.  \n\nOne of the key findings in social judgments research is that assessments of others are reciprocally updated over time and through interactions (Klimoski and Donahue 2001). In other words, evaluators make initial evaluations that they then update as they receive additional relevant information. With this reciprocal updating process in mind, it is important to note that the VC investment decision process occurs through multiple interactions between the VCs and the ventures. For simplification purposes, we can consider at least two important stages, namely, prescreening potential ventures for presentations and selecting ventures for investments from among those invited to give presentations.  \n\nPrior similarity bias research in the VC context has explained such bias for the prescreening stage, but not for the investment decision stage. Franke et al. (2006) use a creative conjoint method that effectively reveals VC preferences based on different scenarios. Their work provides high-level demographic information about venture teams and then observes VC preferences for venture teams based on demographic similarities. Their approach seems to match the real process of VC prescreening well; i.e., VCs have access to business plans and high-level demographic information about venture teams before deciding whether or not to invite them to give presentations.  \n\nUsing demographic similarity as a signal of underlying competence may occur at the prescreening level, but these demographic factors may be too high level to be useful during the investment decision stage when VCs and ventures interact, and, therefore, when VCs have greater opportunities to personally evaluate competence. Once the VC and the venture team start interacting in the intense presentation environment, the VC can ask detailed and probing questions to determine the extent to which the venture team possesses the desired competence. In the face of these more detailed interactions, the demographic characteristics may become less important in the social judgments of the VC, and the social experience may become more important (London 2001).  \n\nWe argue that in situations where the social experience is important for social judgments, the similarity in actual technical competence may explain positive bias in competency assessments. The logic for our theory comes from foundational work in organizational theory suggesting that the frequency and positivity of interpersonal interactions between two actors increases with the ease of communication between those two actors (March and Simon 1958). As Zenger and Lawrence (1989) review and discuss in detail, the ease of communication between two actors increases when they have common vocabularies and common interpretations of environmental stimuli— i.e., a shared language. They argue that shared language between individuals \"reflects similarities in how they interpret, understand, and respond to information\" (Zenger and Lawrence 1989, p. 355). Thus, two individuals with a shared language prior to an initial social interaction are more likely to connect and understand each other (Murnieks et al. 2011). They are more likely to interpret situations and approach problems in similar ways. Ultimately, coordination and communication will be much easier between two people with a shared language, ceteris paribus (Katz and Kahn 1966, March and Simon 1958). When communication and coordination increase, then the positive energy in interactions increases (Quinn and Dutton 2005), and that positive energy increases the positive affect within relationships (Quinn 2007). As the positive affect within relationships increases, individuals are more likely to assess each other positively in all dimensions, including intelligence and competence (Nathan and Lord 1983, Nisbett and Wilson 1977, Tsui and Barry 1986).  \n\nTechnical competence can be a shared language between VCs and ventures when their levels of technical competence are similar. As an individual's technical competence increases, the complexity of that individual's mental models and schemas for addressing technical challenges increases (JohnsonLaird 1983). This increased complexity makes it easier for the individual to diagnose technical problems and identify creative solutions to those problems. Thus, two people with similar levels of technical competence likely have similar levels of complexity in their mental models and schemas. As they begin to communicate with each other, they are likely to find that this common level of competency allows them to communicate more quickly and easily with one another. Each party finds that the other quickly and readily understands technical comments and ideas at similar levels without a need for detailed explanation and discussion (Biernat et al. 1997).  \n\nApplying this logic to the VC context, then, when VCs and venture teams have similar levels of technical competence, they are more likely to communicate effectively, efficiently and smoothly through the shared language of technical competence. Accordingly, the VC is more likely to experience positive affect in the interpersonal interactions with the venture team, and this positive affect is likely to lead to positive evaluations of the venture's skills, abilities, and performance potential. We thus expect that VCs will rate ventures higher on technical competence when VCs and ventures are more similar in technical competence. Formally:  \n\nHyPoTHEsIs 3 (H3).The more similar the venture is to the VC in technical competence, the greater the VC's assessment of the venture's technical competence.  \n\nAn interesting consequence of Hypothesis 3 is that it contradicts the statistical regression to the mean phenomenon. Consider a rating scale of very low, low, average, high, and very high technical competence, and a case of a hi-VC evaluating a hiventure. Regression to the mean suggests that the hi-VC should err on the side of underassessing the hi-venture, because in Hypothesis 3 we argued that when VCs and venture teams have similar levels of technical competence, they are likely to assess ventures' technical competence to be high. We thus expect that the hi-VC should evaluate the hi-venture as having high or very high technical competence. This scenario of hypothesis is theoretically interesting because it contradicts the statistical expectation from regression to the mean.  \n\n## 4. Data  \n\nThe ideal test of our theory requires data on the actual technical competence of VCs, the actual technical competence of ventures, and the ${\\mathrm{VCs^{\\prime}}}$ perceptions of the ventures′ technical competence along with investment choices, subsequent performance outcomes, and a host of control variables. Since such a database does not exist in a secondary source, we approached VCs and ventures directly to collect the data for our study. We began by identifying a random sample of 200 VCs that invest in early-stage IT ventures from the VentureXpert database. Of these 200, 47 VCs chose to participate in our study, for a $23.5\\%$ participation rate. As part of their participation, they completed an instrument to evaluate their technical competence. We statistically compared the VCs who chose to participate with those that did not using unpaired twosample $t$ -tests on the dimensions of VC age and fund size, two of the variables available to us for all VCs in the original sample. Our tests failed to reject the null hypothesis that the groups have similar average ages ( $\\mathrm{\\Delta}p$ -value $=0.26$ $t.$ -statistic $=1.14\\$ ) and similar average fund sizes ( $\\mathrm{\\Delta}p$ -value $=0.24$ $t.$ -statistic $=-1.18\\mathrm{`}$ Accordingly, we find no evidence to suggest that participating VCs are systematically different from the nonparticipating VCs in any observable way that may threaten the validity of our findings.  \n\nOf the 47 VCs who chose to participate in our initial data collection, 33 chose to participate further by providing information about the ventures that they invited to give presentations in the year 2008. To control for funding stage through sample selection, we only asked for ventures that were seeking Series A funding requests. The VCs invited 689 such ventures for presentations in 2008.1 Since some VCs invited the same ventures, these 689 total invitations represented 530 unique ventures. The VCs subsequently offered 215 ventures term sheets for funding. The average fund size of the VCs was $\\$123.02$ million, and the average valuation that the VCs offered ventures was $\\$14.67$ million. The VCs completed an instrument for each venture that included the VC's assessment of the venture's technical competence. We statistically compared the 33 VCs who chose to participate further by providing venture information with the 14 that did not. We conducted unpaired two-sample $t.$ -tests on the dimensions of VC age, fund size, and technical competence. Both groups have a similar mean age $\\dot{p}$ -value $=0.92$ $t.$ -statistic $=0.0966;$ , similar fund size $\\boldsymbol{\\Tilde{p}}$ -value $=0.2687$ $t.$ -statistic $=-1.199;$ , and similar technical competence $(p\\mathrm{-value}=0.6566,$ $t.$ -statistic $=$ 0.4476). We find no evidence to suggest that the VCs who chose to participate further are systematically different from the VCs who chose not to participate further in any observable way that may threaten the validity of our findings.  \n\nWe approached all 530 unique ventures that the 33 VCs invited to give presentations in 2008 and requested that their technology heads participate in our study. Out of these, 308 technology heads chose to participate in the first quarter of 2009. These ventures completed an instrument that measured the actual technical competence of the technology heads. We statistically compared the 308 ventures who chose to participate with the 222 that chose not to participate. Both groups have similar mean values for the amount of funding raised $(p\\mathrm{-value}=0.27$ $t.$ -statistic $=$ 1.103), founder reputation ( $\\boldsymbol{\\cdot}p$ -value $=0.71$ $t.$ -statistic $=$ $-0.3680)$ ， and founder experience ( $\\mathrm{\\Delta}p\\cdot\\mathrm{\\Delta}$ -value $=0.86,$ $t$ -statistic $=0.3896^{\\cdot}$ 0. We find no evidence to suggest that the ventures that chose to participate are systematically different from the ventures who chose not to participate in our study in any observable way that may threaten the validity of our findings. The participating ventures received a total of 396 invitations from VCs and 123 funding term sheets.  \n\n### 4.1. Key Variables  \n\n4.1.1. Technical Competence. Following best practices in the organizational literature on individual competence measurement (Ehrlinger et al. 2008, Kruger and Dunning 1999), we used an objective quiz to evaluate the technical competence of VCs and ventures. The VC responsible? for deciding whether or not to invest in a technology venture took the quiz to determine VC technical competence. The technology head3 for each venture took the quiz to determine venture technical competence. This quiz was created through in-depth interviews with the chief technology officers (CTOs) of 11 IT and software companies. These CTOs used this quiz as one of their hiring exams for a total of 57 software professionals as a pretest. Based on this testing, the quiz was improved to make it clearer and more robust. The CTOs agreed that the quiz provides a reliable measure of an individual's technical competence. Accordingly, the number of correct answers on the quiz provides a numerical indicator of the technical competence of the person taking the quiz.4  \n\nTo validate the quiz for the present research, we partnered with an IT venture that was actively recruiting recent IT graduates from universities. This venture was growing quickly and finding it difficult to divert its resources toward hiring. They agreed to use the quiz to test candidates on their technical competence and provided the grade point averages (GPAs) of all applicants who took the quiz. Ninetyeight graduating job candidates took the quiz. For these 98 job candidates, we found a positive and significant correlation between GPA and quiz score $(\\rho=0.81$ $p$ -value $<0.000^{}$ 0. Of the 98 candidates,63 did not have any prior work experience, whereas the rest had one to three years of prior work experience. The correlation for these 63 candidates was $\\rho=0.86$ With $p<0.000,$ and the correlation for the remaining 35 candidates was $\\rho=0.78$ With $p<0.000$ . These high and statistically significant correlations between GPA and quiz score provide a strong independent test of the validity of the quiz for assessing technical competence.  \n\nIn addition to testing the quiz with job candidates as described above, we also asked participating ventures and VCs to rate how effectively this quiz measured technical competence on a Likerttype scale of 1 to 5. These survey results strongly suggest that the quiz effectively measures technical competence. A histogram showing these responses is included in Figure EC.1 in the e-companion (available as supplemental material at http: //dx.doi.org/ 10.1287/mnsc.2014.2117).  \n\n3 One concern raised in the review process is whether the technology head may have delegated the completion of the quiz. We do not think this is a concern for at least two reasons: (1) there were no incentives to participate, so it would be easier to not participate than to delegate if the head did not want to fill out the quiz; and (2) even if delegation did occur, it would likely bias the score upward because of social desirability bias; i.e., the technology head would delegate to someone equally or more competent than himorherself.  \n\n4 Although we cannot share the actual instrument in publication because of its proprietary nature, we made the instrument accessible to the editors and reviewers during the peer review process.  \n\nTo test the consistency of the measurement of technical competence using quiz scores, we used the splithalf method (Bollen 1989). In this method, a quiz is first divided into two parts, and the correlation between the quiz score of the two halves is calculated. The Spearman-Brown Prophecy formula is then applied to the correlation to calculate the reliability of the full quiz, which is given by $2*\\rho/(1+\\rho)$ where $\\rho$ is the correlation between the quiz scores of the two halves. The split-half reliability for our quiz is 0.887, which is substantially higher than the threshold value of 0.7 (Bollen 1989) and indicates that the quiz is reliable. We also replicated our analyses using scores from quiz halves. Results from these split halves were qualitatively similar to the results from the total score.  \n\n4.1.2. Assessment. Assessment is operationalized as the VC's assessment of venture technical competence. The VC's assessment of venture technical competence was obtained after each VC took the quiz. After taking the quiz, the VC answered the question, \"how many questions (out of 40) do you think the technology heads of the following ventures would answer correctly?\"  \n\n4.1.3. Assessment Error Magnitude. The VC's assessment error magnitude is calculated as the absolute value of the difference between the VC's assessment of venture technical competence and actual venture technical competence. Accordingly, the error magnitude is the absolute value of the difference between the VC's estimate of the technology head's quiz score and the actual quiz score for that technology head.  \n\n4.1.4. Dissimilarity. The hypothesis development focuses on similarity in technical competence between the VC and the venture, but we empirically use a measure of dissimilarity to aid interpretation. Dissimilarity is the absolute value of the difference between actual VC technical competence and actual venture technical competence. Accordingly, larger differences represent greater dissimilarity between the VC and the venture.  \n\n4.1.5. Investment Decision. Investment decision is a dummy variable coded 1 if the VC chose to offer a term sheet to the venture. This indicates that the VC saw enough promise in the venture to offer funding.  \n\n4.1.6. Venture Failure. Venture failure is a dummy variable coded 1 if a venture failed. We considered ventures as failed if they filed for bankruptcy or they ceased their operations during the three year window following 2008. Although it is possible that VCs may recover their investments by selling off ventures' assets even if ventures cease to operate, in our sample, none of the VCs were fortunate enough to recoup their investments by liquidating ventures' assets.  \n\n### 4.2. Control Variables  \n\nPrior research suggests at least four different categories of factors that likely  affect  VC  funding decisions: aspects of the venture's environment, characteristics of the venture, characteristics of the VC, and characteristics of the VC-venture dyad (Baum and Silverman 2004; Franke et al. 2006, 2008; Zacharakis and Meyer 2000).  \n\n4.2.1. Environment Controls. VC  assessments and funding decisions may differ by industry category. All firms in our sample come from the Software and Services category of the Venture Economics Primary Industry Minor Group classification of industries. This category has two subcategories: software and IT services. To control for different industry subcategories, we coded a dummy variable with a value of 1 if the firm was in the software subcategory and a value of O if the firm was in the IT services subcategory. Our data do not allow finer-grained measures of industry, but all companies fall strictly into one or the other subgroup. None of these firms include hardware- or equipment-related categories.  \n\nThe amount of competition for VCs when choosing to invest in a venture may also influence VC assessments and subsequent decisions. The level of competition may raise the bar on the VCs' expectations for venture technical competence and may also affect the ${\\mathrm{VCs^{\\prime}}}$ willingness to invest. To control for potential competition that VCs faced, we used the number of VCs that were interested in a venture. The VCs provided the number of VCs interested in each venture.  \n\n4.2.2. Venture Characteristics. Macmillan et al. (1985) investigated important criteria used by VCs to make funding decisions. Their findings helped us identify controls related to the characteristics of the founders such as founders' experience, founders’ reputation, and founders’ communication skills. Founders' reputation was operationalized by the average number of successful exits (initial public offerings and acquisitions) led by the founders of a venture. Founders’ industry experience was measured by the average industry experience (in years) of the founders of a venture. Founding team project management experience was the average years of managing projects of the founding team. Venture team size was measured as the total number of team members on the venture team.  \n\nHall and Hofer (1993) also examined VC decision making in a similar vein and indicated that, in addition to the above characteristics, factors related to the venture's financial situation such as amount raised, amount requested, and revenue can also influence VCs’ decision making. Amount of funding raised was the actual amount of funding the venture received prior to the VC funding request. Amount of funding requested was the amount of funding the venture was requesting from the VC. Projected revenue was operationalized as a venture's assessment of its revenue in three years.  \n\nPrior literature indicates that the following additional venture characteristics can also influence VCs' decision making—venture age, venture size, and number of patents (MacMillan et al. 1985, Tyebjee and Bruno 1984). Venture age was measured as the difference in months between the date when the venture was incorporated and the date when the funding request was made. Venture size was measured as the 2008 U.S. market value of the business in dollars. Number of patents was measured by the count of patents a venture had applied for at the United States Patent Office.  \n\n4.2.3.  VC Characteristics. $V C s^{\\prime}I T$ experiencewas calculated as the number of years of experience the VCs had in the IT industry. The $V C s^{\\prime}$ overall experience was operationalized as the total number of years of experience as a VC. Total investments were measured as the total number of investments that VCs made. $V C s^{\\prime}$ successes was measured as the number of successful exits for the ventures that they funded (Shane and Stuart 2002, Tyebjee and Bruno 1984). $V C s^{\\prime}$ failures were defined as the number of defaulted ventures that they funded. We considered a company as defaulted if it had filed for bankruptcy or had ceased its operations. The fund size was operationalized as total funds raised by VCs. It is also possible that VC ethnicity may affect decisions. Accordingly, VC ethnicity was coded using a dummy variable for Asian and a dummy variable for Hispanic. Both variables took a value of 1 if the VC was that ethnicity, or a value of O if the VC was Caucasian. VC age was measured in years.  \n\n4.2.4. VC-Venture Dyad Characteristics. Since dyad-specific factors may also affect VC investment decisions and subsequent outcomes, we controlled for the extent to which the venture comes to the VC through a trusted referral (Shepherd 1999). Trusted referral was measured if the venture was recommended to the VC from one of its trusted affiliates. This was coded using a dummy variable with a value of 1 if the venture came through a trusted referral and 0 otherwise. We also controlled for ${\\mathrm{VCs^{\\prime}}}$ assessment of ventures' communication skills and management capability. Communication was measured as the VC's assessment of the venture technology head's communication skills on a Likert-type scale from 1 to 10 with higher scores representing better communication skills. Management capability was similarly measured as the VC's assessment of the managerial capabilities of the founding team on a Likert-type scale from 1 to 10, with higher scores representing better management skills.  \n\nTable 1 Descriptive Statistics   \n\n\n<html><body><table><tr><td>Variable</td><td>Mean</td><td>Std. dev.</td><td>Min</td><td>Max</td></tr><tr><td>Fundingreceived</td><td>0.31</td><td>0.46</td><td>0</td><td>1</td></tr><tr><td>Venturefailure</td><td>0.57</td><td>0.50</td><td>0</td><td>1</td></tr><tr><td>Assessmenterrormagnitude</td><td>6.76</td><td>5.08</td><td>0</td><td>26</td></tr><tr><td>Assessment (out of 40)</td><td>23.79</td><td>6.50</td><td>4</td><td>40</td></tr><tr><td>Dissimilarity</td><td>8.06</td><td>5.56</td><td>0</td><td>26</td></tr><tr><td>VCs'technical competence (out of 40)</td><td>18.83</td><td>4.82</td><td>10</td><td>28</td></tr><tr><td>Ventures'technical competence (out of 40)</td><td>23.76</td><td>7.14</td><td>10</td><td>36</td></tr><tr><td>Dummyreference</td><td>0.32</td><td>0.47</td><td>0</td><td>1</td></tr><tr><td>Numberofpatents</td><td>1.22</td><td>2.22</td><td>0</td><td>10</td></tr><tr><td>Team size</td><td>2.78</td><td>1.31</td><td>1</td><td>6</td></tr><tr><td>Market size ($ billion)</td><td>6.77</td><td>3.71</td><td>0.04</td><td>17.74</td></tr><tr><td>Competition</td><td>1.95</td><td>1.91</td><td>0</td><td>7</td></tr><tr><td>Founderreputation</td><td>2.27</td><td>0.92</td><td>0</td><td>4</td></tr><tr><td>Founderexperience(years)</td><td>8.50</td><td>2.78</td><td>1</td><td>16</td></tr><tr><td>Ageof a venture(months)</td><td>13.11</td><td>1.75</td><td>8</td><td>18</td></tr><tr><td>Projectedrevenue($million)</td><td>5.30</td><td>1.10</td><td>2.32</td><td>8.69</td></tr><tr><td>Dummysoftware</td><td>0.37</td><td>0.48</td><td>0</td><td>1</td></tr><tr><td>Amount raised($103)</td><td>476.62</td><td>197.30</td><td>100.45</td><td>930.49</td></tr><tr><td>Amount requested ($ million)</td><td>4.34</td><td>1.15</td><td>1.50</td><td>7.61</td></tr><tr><td>Projectmanagementexperience (years)</td><td>3.39</td><td>1.48</td><td>0</td><td>8</td></tr><tr><td>Communication(scale of 1-10)</td><td>5.59</td><td>2.91</td><td>1</td><td>10</td></tr><tr><td>Managementcapability</td><td>3.94</td><td>1.32</td><td>1</td><td>10</td></tr><tr><td>VCs'failures</td><td>8.38</td><td>3.39</td><td>2</td><td>15</td></tr><tr><td>VCs'successes</td><td>2.58</td><td>1.44</td><td>1</td><td>6</td></tr><tr><td>Fund size($ million)</td><td>129.11</td><td>70.02</td><td>36</td><td>245</td></tr><tr><td>VCs'experience(years)</td><td>7.95</td><td>2.73</td><td>5</td><td>16</td></tr><tr><td>Totalinvestments</td><td>16.08</td><td>3.84</td><td>5</td><td>24</td></tr><tr><td>VCs'ITexperience(years)</td><td>16.93</td><td>4.27</td><td>10</td><td>25</td></tr><tr><td>DummyAsianVC</td><td>0.36</td><td>0.48</td><td>0</td><td>1</td></tr><tr><td>DummyHispanicVC</td><td>0.04</td><td>0.18</td><td>0</td><td>1</td></tr><tr><td>VC age</td><td>45.51</td><td>4.68</td><td>38</td><td>53</td></tr></table></body></html>  \n\nDescriptive statistics for all variables are provided in Table 1, and a correlation matrix is reported in Table EC.2 in the e-companion.  \n\n## 5. Empirical Analysis  \n\n### 5.1. Model for Predicting VC Investment Based onVC Assessment  \n\nHypothesis 1A predicts that the probability of VC investment increases as the VC's assessment of venture technical competence increases. We used a logit random effects (RE) model to examine the probability that a VC will invest in a venture as a function of the VC's assessment and control variables. It is plausible that VC and venture unobserved effects might also influence ${\\mathrm{VCs^{\\prime}}}$ investment decisions. Therefore, we account for potential unobserved effects with the random effects model.  \n\nThe general specification of our model is $P(I n v e s t_{i j}=$ $1\\mid A s s e s s_{i j},X_{i j},\\mu_{i},\\delta_{j})=F(A s s e s s_{i j}\\alpha+X_{i j}\\beta+\\mu_{i}+\\hat{\\delta}_{j}),$ where $P(I n v e s t_{i j}=1\\mid A s s e s s_{i j},X_{i j},\\mu_{i},\\delta_{j})$ refers to the probability that a VC $i$ will invest in a venture $j$ for the given data, $F(\\cdot)$ is the logit function, $A s s e s s_{i j}$ is the assessment of VC $i$ of technical competence of venture $j,X_{i j}$ is a vector of exogenous variables comprising controls, $\\mu_{i}$ captures the unobserved effects for a VC $i,$ and $\\delta_{j}$ captures the unobserved effects for the venture $j$ . The results are shown as Model 1 in Table 2. As predicted, the coefficient on the assessment is positive and significant, providing strong support for Hypothesis 1A.  \n\n### 5.2. Model for Predicting the Probability of  \n\nVenture Failure Based on VC Overassessment Hypothesis 1B predicts that the probability of venture failure decreases as the technical competence of the venture increases. Just as above, we use a logit random effects model (that accounts for both VC and venture unobserved effects) to examine the probability of venture failure as a function of venture technical competence and control variables.  \n\nThe general specification of the model is $P(F a i l_{j}=$ 1 I Ventcomp; $X_{i j},\\mu_{i},\\delta_{j})=F(V e n t c o m p_{i}\\alpha+X_{i j}\\beta+\\mu_{i}+$ $\\delta_{j})$ ,where $^P({\\dot{F}}a i l_{j}=1\\mid{\\mathit{V e n t c o m p}}_{j},{\\dot{X}}_{i j},\\mu_{i},{\\dot{\\delta}}_{j})$ refers to the probability of failure of a'venture $j,F(\\cdot)$ is the logit function, Ventcomp; is the technical competence of venture $j,X_{i j}$ is a vector of exogenous variables comprising controls, $\\mu_{i}$ captures the unobserved effects for a VC $i,$ and $\\delta_{j}$ captures the unobserved effects for the venture $j$  \n\nThe results are shown in Model 2 in Table 2. As predicted, the extent of venture technical competence negatively and significantly correlates with subsequent venture failure, providing strong support for Hypothesis 1B.  \n\n### 5.3. Model for Predicting VC Assessment Error Magnitudes Based on VC Technical Competence  \n\nHypothesis 2 predicts that VCs with higher technical competence will have lower error magnitudes. We use a random effects model (that accounts for both VC and venture unobserved effects) to examine the influence of VC technical competence on assessment error magnitudes.  \n\nThe   general  specification  of  the   model  is $E r r A s s V e n_{i j}=V C C o m p_{i}\\alpha+Z_{i j}\\beta+\\mu_{i}+\\delta_{j}+\\varepsilon_{i j},$ where $E r r A s s V e n_{i j}$ is the magnitude of assessment error of a VC $i$ for a venture $j,V C C o m p_{i}$ is the technical competence of VC i, $Z_{i j}$ is a vector of exogenous variables comprising controls, $\\varepsilon_{i j}$ is an idiosyncratic error, $\\mu_{i}$ captures the unobserved effects for a VC $i,$ and $\\delta_{j}$ captures the unobserved effects for the venture $j$  \n\nThe results are shown in Model 3 in Table 2. As predicted, the coefficient on VC technical competence is negative and significant, suggesting that the higher the VC technical competence, the lower the VC's error magnitudes when assessing the technical competence of the venture. These results suggest strong support for Hypothesis 2.  \n\nTable 2 Analyses for Hypotheses Testing   \n\n\n<html><body><table><tr><td rowspan=\"5\"></td><td>Model 1 (for H1A)</td><td>Model 2 (for H1B)</td><td>Model 3 (for H2)</td><td>Model 4(for H3</td></tr><tr><td colspan=\"3\">Dependent variables</td><td></td></tr><tr><td colspan=\"3\"></td><td></td></tr><tr><td>Fundingreceived</td><td>Venturefailure</td><td>Absoluteerrorin assessing ventures'technical competence</td><td>Assessment</td></tr><tr><td>All observations</td><td>Only those ventures that were funded</td><td>All observations</td><td>All observations</td></tr><tr><td>Assessment</td><td>0.1838** (0.0448)</td><td></td><td></td><td></td></tr><tr><td rowspan=\"2\">Ventures'technicalcompetence</td><td></td><td>-0.3825***</td><td>-0.0324</td><td>0.3995***</td></tr><tr><td></td><td>(0.0895)</td><td>(0.0365)</td><td>(0.0554)</td></tr><tr><td rowspan=\"2\">VCs'technicalcompetence</td><td>-0.012</td><td>0.0599</td><td>--0.6246***</td><td>-0.3317***</td></tr><tr><td>(0.0377)</td><td>(0.0716)</td><td>(0.0360)</td><td>(0.0495)</td></tr><tr><td rowspan=\"2\">Dissimilarity</td><td></td><td></td><td></td><td>-0.5707***</td></tr><tr><td></td><td></td><td></td><td>(0.0675)</td></tr><tr><td rowspan=\"2\">Dummyreference</td><td>1.1276***</td><td>-0.2719</td><td>1.1228***</td><td>0.3178</td></tr><tr><td>(0.3317)</td><td>(0.5977)</td><td>(0.3441)</td><td>(0.3925)</td></tr><tr><td rowspan=\"2\">Numberofpatents</td><td>0.1812**</td><td>0.071</td><td>0.0449</td><td>0.2269***</td></tr><tr><td>(0.0716)</td><td>(0.1303)</td><td>(0.0881)</td><td>(0.0834)</td></tr><tr><td rowspan=\"2\">Ventureteamsize</td><td>0.303**</td><td>0.2685</td><td>-0.0555</td><td>0.4797***</td></tr><tr><td>(0.1415)</td><td>(0.3706)</td><td>(0.1640)</td><td>(0.1442)</td></tr><tr><td rowspan=\"2\">Marketsize</td><td>0.1302***</td><td>-0.2082**</td><td>0.0161</td><td>0.0517</td></tr><tr><td>(0.0488)</td><td>(0.1001)</td><td>(0.0566)</td><td>(0.0452)</td></tr><tr><td rowspan=\"2\">Competition</td><td>0.1059</td><td>0.2486</td><td>0.0368</td><td>0.0467</td></tr><tr><td>(0.0883)</td><td>(0.2125)</td><td>(0.1147)</td><td>(0.1008)</td></tr><tr><td rowspan=\"2\">Founderreputation</td><td>-0.0696</td><td>0.2253</td><td>-0.0998</td><td>-0.1113</td></tr><tr><td>(0.1839)</td><td>(0.5719)</td><td>(0.2337)</td><td>(0.2259)</td></tr><tr><td rowspan=\"2\">Founderexperience</td><td>-0.0392</td><td>-0.2867**</td><td>-0.0044</td><td></td></tr><tr><td>(0.0721)</td><td>(0.1358)</td><td>(0.0811)</td><td>-0.0025</td></tr><tr><td rowspan=\"2\">Ageofaventure</td><td>0.0128</td><td>0.1621</td><td></td><td>(0.0860)</td></tr><tr><td>(0.1036)</td><td>(0.2573)</td><td>-0.1443</td><td>-0.0988</td></tr><tr><td rowspan=\"2\">Revenue</td><td>-0.0423</td><td>0.1706</td><td>(0.1128)</td><td>(0.1146)</td></tr><tr><td>(0.1775)</td><td></td><td>0.068</td><td>0.0025</td></tr><tr><td rowspan=\"2\">Dummysoftware</td><td>-0.4216</td><td>(0.3787)</td><td>(0.2072)</td><td>(0.2114)</td></tr><tr><td>(0.3101)</td><td>0.394</td><td>-0.2639</td><td>-0.1802</td></tr><tr><td rowspan=\"2\">Amountraised</td><td>0.002*</td><td>(0.9777) -0.0006</td><td>(0.3966)</td><td>(0.4144)</td></tr><tr><td>(0.0011)</td><td>(0.0022)</td><td>-0.0005</td><td>0.001</td></tr><tr><td rowspan=\"2\">Amountrequested</td><td>0.1564</td><td>0.1999</td><td>(0.0010) 0.6861***</td><td>(0.0013)</td></tr><tr><td>(0.1765)</td><td></td><td></td><td>0.0312</td></tr><tr><td rowspan=\"2\">Projectmanagementexperience</td><td>0.0413</td><td>(0.3520)</td><td>(0.2065)</td><td>(0.1546)</td></tr><tr><td>(0.1431)</td><td>0.7641</td><td>-0.0487</td><td>2.1638***</td></tr><tr><td rowspan=\"2\">Communication</td><td>-0.0361</td><td>(0.1976)</td><td>(0.1686)</td><td>(0.2023)</td></tr><tr><td>(0.0563)</td><td>-0.1125</td><td>0.2197**</td><td>0.159*</td></tr><tr><td rowspan=\"2\">Managementcapability</td><td>0.2729*</td><td>(0.0962)</td><td>(0.0910)</td><td>(0.0842)</td></tr><tr><td>(0.1435)</td><td>0.2538</td><td>0.2803*</td><td>0.4146***</td></tr><tr><td rowspan=\"2\">VCs'failures</td><td></td><td>(0.1701)</td><td>(0.1482)</td><td>(0.1579)</td></tr><tr><td>-0.0902**</td><td>0.2832**</td><td>-0.045</td><td>-0.0796</td></tr><tr><td rowspan=\"2\">VCs'successes</td><td>(0.0422)</td><td>(0.1373)</td><td>(0.0505)</td><td>(0.0634)</td></tr><tr><td>0.4683***</td><td>-0.251</td><td>0.125</td><td>0.0308</td></tr><tr><td rowspan=\"2\">Fundsize</td><td>(0.1143)</td><td>(0.3496)</td><td>(0.1104)</td><td>(0.1395)</td></tr><tr><td>-0.0023</td><td>-0.0081**</td><td>-0.0012</td><td>-0.0033*</td></tr><tr><td rowspan=\"2\">VCs'experience</td><td>(0.0019)</td><td>(0.0041)</td><td>(0.0018)</td><td>(0.0019)</td></tr><tr><td>0.0558*</td><td>0.1131</td><td>0.0755*</td><td>0.1041**</td></tr><tr><td rowspan=\"2\">Total investments</td><td>(0.0316)</td><td>(0.1585)</td><td>(0.0446)</td><td>(0.0468)</td></tr><tr><td>-0.0389</td><td>-0.0693</td><td>0.0259</td><td>0.0352</td></tr><tr><td rowspan=\"2\">VCs'IT experience</td><td>(0.0418)</td><td>(0.0623)</td><td>(0.0470)</td><td>(0.0436)</td></tr><tr><td>-0.0105</td><td>-0.1483</td><td>-0.015</td><td>-0.0677*</td></tr><tr><td rowspan=\"2\"></td><td></td><td></td><td></td><td></td></tr><tr><td>(0.0293)</td><td>(0.0922)</td><td>(0.0290)</td><td>(0.0353)</td></tr></table></body></html>  \n\nTable 2 (Continued)   \n\n\n<html><body><table><tr><td rowspan=\"5\"></td><td>Model 1 (for H1A)</td><td>Model 2 (for H1B)</td><td>Model 3 (for H2)</td><td>Model 4 (for H3)</td></tr><tr><td colspan=\"4\">Dependent variables</td></tr><tr><td colspan=\"3\">Absoluteerrorinassessing</td><td></td></tr><tr><td>Fundingreceived</td><td>Venturefailure</td><td>ventures'technicalcompetence</td><td>Assessment</td></tr><tr><td>All observations</td><td>Only those ventures that were funded</td><td>All observations</td><td>Allobservations</td></tr><tr><td rowspan=\"2\">DummyAsianVC</td><td>0.0725</td><td>0.5301</td><td>0.5489**</td><td>0.1402</td></tr><tr><td>(0.2622)</td><td>(0.5360)</td><td>(0.2799)</td><td>(0.3154)</td></tr><tr><td rowspan=\"2\">DummyHispanicVC</td><td>0.2968</td><td>-1.5564</td><td>0.2247</td><td>-1.7028***</td></tr><tr><td>(0.4263)</td><td>(1.5700)</td><td>(0.4603)</td><td>(0.5321)</td></tr><tr><td rowspan=\"2\">VC age</td><td>-0.0239</td><td>0.114</td><td>-0.0408**</td><td>-0.0296</td></tr><tr><td>(0.0290)</td><td>(0.0759)</td><td>(0.0193)</td><td>(0.0369)</td></tr><tr><td rowspan=\"2\">Constant</td><td>-8.6958***</td><td>-0.5792</td><td>16.9357***</td><td>16.2812***</td></tr><tr><td>(2.4544)</td><td>(5.0957)</td><td>(2.8504)</td><td>(3.0674)</td></tr><tr><td>Log likelihood</td><td>-158.4443</td><td>-39.6523</td><td>-1,101.7523</td><td>-1,089.2725</td></tr><tr><td>N</td><td>396</td><td>120</td><td>396</td><td>396</td></tr></table></body></html>\n\nNotes. VC and venture random effects are used in all of the models. In Model 1, ventures' technical competence is not included to see the independent effect of assessment on funding received. We thank an anonymous reviewer for suggesting this. It should be noted that including ventures'technical competence in Model 1 does not change coefficients substantially. Including dissimilaity in Models 1, 2, and 3 also does not change the results. Robust standard errors are inparentheses.  \n\n### 5.4. Model for Predicting VC Assessment Based on Dissimilarity  \n\nHypothesis 3 predicts that greater similarity (dissimilarity) between the VC technical competence and the venture technical competence leads to higher (lower) assessment of venture technical competence.  \n\nThe general specification of the model is $A s s e s s_{i j}=$ $D i s s i m_{i j}\\alpha+X_{i j}\\beta+\\mu_{i}+\\delta_{j}+\\varepsilon_{i j},$ where $A s s e s s_{i j}$ is assessment of VC $i$ of the technical competence of venture $j,D i s s i m_{i j}$ is the dissimilarity between technical competence of VC $i$ and venture $j,X_{i j}$ is a vector of exogenous variables comprising controls, $\\varepsilon_{i j}$ is an idiosyncratic error, $\\mu_{i}$ captures the unobserved effects for a VC $i,$ and $\\delta_{j}$ captures the unobserved effects for the venture $j$  \n\nModel 4 in Table 2 shows a negative and significant coefficient on the extent of dissimilarity, suggesting that the more dissimilar the VC and the venture are, the lower the assessment. This means that as similarity increases, assessment also increases. This lends strong support for Hypothesis 3.  \n\n### 5.5. Robustness Checks  \n\n5.5.1. Robustness Checks for Endogeneity. In our main analyses, we used VC and venture RE models to control for potential unobserved endogeneity. Next, two additional model specifications—the simultaneous equation model and fixed effects (FE) model—are reported to control for potential endogeneity and further check the robustness of our results. It is possible that the VC assessments could be endogenously determined since they are measured after the investment decision, and it is also possible that unobserved effects are correlated with the independent variables, making the random effects model inappropriate. We present a simultaneous equations model to address the first concern and a set of fixed effects models to address the second.  \n\nSimultaneous Equation Model. Earlier we argued that higher assessments lead to a higher probability of venture investment. Given the way our data were collected, however, it is possible that VCs were evaluating venture technical competence after making investment decisions. If so, then a standard confirmation bias effect would lead VCs to give more positive assessments to the ventures in which they chose to invest. In other words, the investment decision may drive the assessment rather than the other way around, as we have argued. To account for this potential reverse causality, we model this problem as a system of equations with instruments to assist in identifying the joint model. The general specification of the model with instruments is as follows:  \n\n$$\n\\begin{array}{r}{A s s e s s_{i j}=\\alpha_{0}^{1}+\\beta^{1}X_{i j}+\\delta I n v e s t_{i j}^{*}+\\varepsilon_{1},}\\ {I n v e s t_{i j}^{*}=\\alpha_{0}^{2}+\\beta^{2}Y_{i j}+\\eta A s s e s s_{i j}+\\varepsilon_{2},}\\end{array}\n$$  \n\nwhere $A s s e s s_{i j}$ is VC i's assessment of the technical competence of venture $j,X_{i j}$ and $Y_{i j}$ are vectors of exogenous variables, and Inves $t_{i j}^{*}$ is a latent variable that is not observable. We can observe the VC's decision to invest $(I n v e s t_{i j})$ , which can be viewed as indicator variable for which the latent variable is positive, i.e., $I n v e s t_{i j}=1$ if $I n v e s t_{i j}^{*}>0.$ and $I n v e s t_{i j}=0$ otherwise. Since one dependent variable is continuous and the other is discrete in the above system of equations, we use two-stage probit least squares estimation (Alvarez and Glasgow 1999, Maddala 1983).  \n\nTo identify the assessment equation, we needed an instrument that is correlated with Inves $t_{i j}^{*}$ but not with $\\varepsilon_{1}$ . Two such instruments are the stock market index for technology companies (tech index) and the distance between the VC and venture (distance). We used the Morgan Stanley high technology ticker (MSH) listed on the New York Stock Exchange and used the index value at market close on the day5 before the funding sheet was issued as the tech index. The tech index is a proxy for how positive investors feel about investing in the tech sector at that point in time. Higher index values indicate a high level of confidence in the future of the technology sector. All else being equal, as the tech index increases, VCs should be more likely to invest in technology startups. At the same time, however, we should not expect a higher tech index to correlate with ${\\mathrm{VCs^{\\prime}}}$ assessments of any specific ventures. To calculate the distance between the VC and venture, the Haversine formula was used. This formula calculates the distance between two geographical coordinates accounting for the curvature of the Earth. The greater the distance between VCs and ventures, the less likely VCs should be to invest in ventures (Sorenson and Stuart 2001). However, there does not seem to be much reason to believe that the tech index and distance affect assessments of venture technical competence. Thus, the distance between the VC and the venture provides a second strong instrument for the assessment equation.  \n\nSimilarly, to identify the investment equation, we needed an instrument that is correlated with $A s s e s s_{i j}$ but is not correlated with $\\varepsilon_{2}$ . One such instrument is the number of IT certificates (such as Oracle or Microsoft certifications) completed by technical leads of ventures (nitcert). IT certificates may be a clearly visible and easy-to-evaluate signal of venture technical competence. Accordingly, VCs may use certifications as part of their assessment—i.e., more certifications likely indicates higher competence. At the same time, however, VCs are not likely to view the certifications on their own as reason to invest in a venture. The VC will want to carefully evaluate the extent to which the venture has the unique and focused competence required to bring its specific product or service to market. A generic certification may not be sufficient to signal that type of competence. Thus, certifications likely correlate with the VC's assessment of the venture's technical competence, but probably not with a VC's decision to invest.  \n\nFurthermore, we statistically confirm the relevance and validity of instruments by using $F$ -statisticvalues and the Sargan test. To ensure that instruments are not weakly identified, we checked the $F\\cdot$ -statistic value for the first stage regression. $F\\cdot$ -statistic values were much larger than the suggested value of 10 (Staiger and Stock 1997), which suggests that instruments were not weakly identified. The Sargan test for overidentification is used to examine the orthogonality of instruments in the simultaneous model (Baum et al. 2003). The null hypothesis is that instruments are uncorrelated to errors in the model. Sargan tests failed to reject the null hypothesis $(p=0.17)$ ,suggesting that instruments are not highly correlated with the error term and hence satisfy the required orthogonality condition.  \n\nThe results of the simultaneous equation model are shown in Model 5 of Table 3. As expected, distance negatively predicts funding, and the tech index positively predicts funding. The VC's assessment of the venture is still positive and significant. Also as expected, the number of IT certificates positively and significantly predicts the VC's assessment of the venture. The funding decision, however, does not significantly predict assessment. Thus, the simultaneous equation model lends additional support to the prior result that assessments seem to have an independent effect on the funding decision.  \n\nFixed Effects Model. In our main analysis, we used VC and venture RE models to control for potential unobserved endogeneity. Random effects models assume that the unobserved effects are not correlated with the independent variables. To do away with this assumption, we report the results using VC and venture and FE models also. The results of the FE models are reported in Table 4 and are qualitatively similar to results of the RE models. We used both VC and venture fixed effects for Models 6 and 9 in Table 4. Model 7 provides the results of influence of venture technical competence on probability of venture failing. Since the value of the dependent variable (a dummy variable that takes the value of 1 if the venture has failed and O otherwise) does not change for a given venture, we cannot estimate venture fixed effects for this model. Hence, we estimate Model 7 using VC fixed effects only. Model 8 provides the results of the influence of ${\\mathrm{VCs^{\\prime}}}$ technical competence on absolute error in assessing ventures' technical competence. If we use VC fixed effects for this model, we cannot estimate the influence of ${\\mathrm{VCs^{\\prime}}}$ technical competence (as it does not vary for a given VC). Hence, we estimate Model 8 using venture fixed effects only.  \n\n5.5.2. Overfitting. Given the substantial controls used in the present study, we may be concerned that the statistical relationships demonstrated previously are artifacts of the highly constrained context studied here. To allay concerns with overfitting, we repeated the analyses described above using stripped-down models containing only the key explanatory variables  \n\nTable 3 Simultaneous Equation Model   \n\n\n<html><body><table><tr><td rowspan=\"2\"></td><td colspan=\"2\">Model5</td></tr><tr><td>Dependent variables</td><td></td></tr><tr><td>NumberofITcertificates</td><td>Fundingreceived</td><td>Assessment 1.2262***</td></tr><tr><td></td><td></td><td>(0.4095)</td></tr><tr><td>Distance</td><td>-0.0014*** (0.0003)</td><td></td></tr><tr><td>Techindex</td><td>0.0034*** (0.0007)</td><td>0.2205</td></tr><tr><td>Fundingreceived Assessment</td><td>0.1237***</td><td>(0.183)</td></tr><tr><td>Ventures'technicalcompetence</td><td>(0.023)</td><td>0.3791***</td></tr><tr><td>VCs'technicalcompetence</td><td>-0.018</td><td>(0.0317) -0.3138***</td></tr><tr><td>Dissimilarity</td><td>(0.0144)</td><td>(0.0584) -0.5447***</td></tr><tr><td></td><td>0.6285***</td><td>(0.0444) 0.0987</td></tr><tr><td>Dummyreference</td><td>(0.0992)</td><td>(0.4132) 0.181**</td></tr><tr><td>Numberofpatents</td><td>0.0517** (0.0213)</td><td>(0.0881) 0.3582**</td></tr><tr><td>Ventureteamsize</td><td>0.1042** (0.0418)</td><td>(0.1444) 0.0283</td></tr><tr><td>Marketsize</td><td>0.045*** (0.0153)</td><td>(0.0506)</td></tr><tr><td>Competition</td><td>0.0514* (0.0279)</td><td>0.0393 (0.0953)</td></tr><tr><td>Founderreputation</td><td>-0.0891 (0.0663)</td><td>-0.043 (0.2077)</td></tr><tr><td>Founderexperience</td><td>-0.0228 (0.0196)</td><td>0.0007 (0.069)</td></tr><tr><td>Ageofaventure</td><td>0.0131 (0.0318)</td><td>-0.1439 (0.1075)</td></tr><tr><td>Revenue</td><td>-0.0611 (0.0451)</td><td>0.0312 (0.169)</td></tr><tr><td>Dummy software</td><td>-0.2729** (0.1188)</td><td>-0.0522 (0.3726)</td></tr><tr><td>Amountraised</td><td>0.0006* (0.0003)</td><td>0.0005 (0.001)</td></tr><tr><td>Amountrequested</td><td>0.1084** (0.0521)</td><td>0.0504 (0.1753)</td></tr><tr><td>Projectmanagementexperience</td><td>-0.0379 (0.0695)</td><td>1.8605*** (0.1554)</td></tr><tr><td>Communication</td><td>0.0039 (0.0194)</td><td>0.1687*** (0.0646)</td></tr><tr><td>Managementcapability</td><td>0.1292*** (0.0439)</td><td>0.3275** (0.1403)</td></tr><tr><td>VCs'failures</td><td>-0.0669*** (0.0223)</td><td>-0.0672 (0.0695)</td></tr><tr><td>VCs'successes</td><td>0.2605***</td><td>-0.0565</td></tr><tr><td>Fund size</td><td>(0.0536) -0.0007</td><td>(0.182) -0.003</td></tr><tr><td></td><td>(0.0009)</td><td>(0.0029)</td></tr><tr><td>VCs'experience</td><td>0.0092 (0.0168)</td><td>0.1232* (0.0732)</td></tr></table></body></html>  \n\nTable 3 (Continued)   \n\n\n<html><body><table><tr><td rowspan=\"2\"></td><td colspan=\"2\">Model5</td></tr><tr><td colspan=\"2\">Dependentvariables</td></tr><tr><td>Totalinvestments</td><td>Fundingreceived 0.0042</td><td>Assessment 0.0364</td></tr><tr><td></td><td>(0.018)</td><td>(0.058)</td></tr><tr><td>VCs'ITexperience DummyAsianVC</td><td>-0.0149 (0.0142)</td><td>-0.0695 (0.0508)</td></tr><tr><td></td><td>0.0078 (0.1136)</td><td>0.1284 (0.3878)</td></tr><tr><td>DummyHispanicVC</td><td>0.1336 (0.4031)</td><td>1.7374 (1.1509)</td></tr><tr><td>VC age</td><td>-0.0094 (0.0139)</td><td>-0.0347 (0.0437)</td></tr><tr><td>Constant</td><td>-5.2873*** (1.0063)</td><td>16.0672*** (3.1869)</td></tr><tr><td>Log likelihood/R2 N</td><td>-146.54368 396</td><td>0.6704 396</td></tr></table></body></html>  \n\nNotes. In the funding equation, ventures' technical competence is not included to see the independent effect of assessment. We thank an anonymous reviewer for suggesting this. It should be noted that including ventures' technical competence in the funding equation does not change coefficients substantialy. Including dissimilarity in the funding equation also does not change results. Standard errors are in parentheses.  \n\nand relevant interactions. These results are shown in Table 5. The predicted relationships still hold in these stripped-down models, suggesting that overfitting should not be a concern for our findings.  \n\n5.5.3. Connecting Dissimilarity to Investment Decisions. The logic presented in the arguments of this paper suggests that similarity may lead to higher assessment, which may subsequently lead to a higher likelihood of VC investment. Although not explicitly hypothesized in this way, we also tested the mediation hypothesis that the extent of assessment mediates the relationship between  VC-venture dissimilarity and the probability of VC investment. Table 6 shows the results of this analysis. To analyze the possible complete mediation effect, four conditions need to be met (Baron and Kenny 1986). The first condition pertains to checking the association between the independent variable (VC-venture dissimilarity) and the dependent variable (probability of VC investment) without controlling for the mediator variable (assessment). We found that the VC-venture dissimilarity had a significant influence on the probability of VC investment without controlling for the assessment (see Model 14 in Table 6). The second condition refers to checking the association between the independent variable and the mediator variable. We found that VC-venture dissimilarity had significant influence on assessment (see Model 4 in Table 2). The third condition pertains to checking the association between the mediator variable and the dependent variable after controlling for the independent variable. We found that the assessment had significant influence on the probability of VC investment (see Model 15 in Table 6). The fourth condition refers to checking the association between the independent variable and the dependent variable after controlling for the mediator variable. We found that the VC-venture dissimilarity does not influence the probability of VC investment after controlling for assessment (see Model 15 in Table 6). These results from these four conditions lend strong support to the logic that the extent of similarity between the VC and the venture affects the likelihood of investment through the mediating process of assessment. In addition, we did a statistical test suggested by Preacher and Hayes (2004) to check the significance of the indirect effect of dissimilarity. We found that the indirect effect is statistically significant $(p={\\mathrm{value}}<0.05)$ , indicating that assessment mediates the effect of dissimilarity.  \n\n<html><body><table><tr><td colspan=\"5\">Table 4 FixedEffectsModels</td></tr><tr><td></td><td></td><td>Model 6 (for H1A) Model 7 (for H1B)</td><td>Model 8 (for H2)</td><td>Model 9 (for H3)</td></tr><tr><td colspan=\"3\"></td><td>Dependent variables</td><td></td></tr><tr><td colspan=\"3\">Fundingreceived Venturefailure</td><td>Absoluteerrorinassessing ventures'technicalcompetence</td><td>Assessment</td></tr><tr><td colspan=\"3\">All observations</td><td>Only those ventures that were funded All observations</td><td>All observations</td></tr><tr><td colspan=\"3\">Assessment 0.3546***</td><td></td><td></td></tr><tr><td colspan=\"3\">(0.0798) Ventures'technicalcompetence</td><td></td><td></td></tr><tr><td colspan=\"3\"></td><td></td><td></td></tr><tr><td colspan=\"3\">VCs'technicalcompetence</td><td>-0.6361*** (0.0904)</td><td></td></tr><tr><td colspan=\"3\">Dissimilarity</td><td></td><td>-1.3155*** (0.1196)</td></tr><tr><td colspan=\"3\">Dummyreference</td><td>0.1281 (0.7606)</td><td>1.9279 (1.5060)</td></tr><tr><td colspan=\"3\">Number of patents</td><td></td><td></td></tr><tr><td colspan=\"3\">Ventureteamsize</td><td></td><td></td></tr><tr><td colspan=\"3\">Marketsize</td><td></td><td></td></tr><tr><td colspan=\"3\"></td><td></td><td></td></tr><tr><td colspan=\"3\">Competition</td><td></td><td></td></tr><tr><td colspan=\"3\">Founderreputation</td><td></td><td></td></tr><tr><td colspan=\"3\">Founderexperience</td><td></td><td></td></tr><tr><td colspan=\"3\">Age of aventure</td><td></td><td></td></tr><tr><td colspan=\"3\"></td><td></td><td></td></tr><tr><td colspan=\"3\">Revenue</td><td></td><td></td></tr><tr><td colspan=\"3\">Dummy software</td><td></td><td></td></tr><tr><td colspan=\"3\"></td><td></td><td></td></tr><tr><td colspan=\"3\">Amountraised</td><td></td><td></td></tr><tr><td colspan=\"3\">Amountrequested</td><td></td><td></td></tr><tr><td colspan=\"3\"></td><td></td><td></td></tr><tr><td colspan=\"3\">Projectmanagementexperience</td><td></td><td></td></tr><tr><td colspan=\"3\">Communication -0.6781* (0.3600)</td><td>0.2823* (0.1578)</td><td>0.1908 (0.2099)</td></tr><tr><td colspan=\"3\">Managementcapability</td><td>-0.4666*</td><td>0.3628</td></tr><tr><td colspan=\"3\"></td><td>(0.2524) 0.1001</td><td>(0.4879)</td></tr><tr><td colspan=\"3\">VCs'failures</td><td>(0.1513)</td><td></td></tr><tr><td colspan=\"3\">VCs'successes</td><td>-0.386 (0.4735)</td><td></td></tr><tr><td colspan=\"3\"></td><td>-0.0041</td><td></td></tr><tr><td colspan=\"3\">Fund size</td><td>(0.0065)</td><td></td></tr><tr><td colspan=\"3\"></td><td></td><td></td></tr><tr><td colspan=\"3\">VCs'experience</td><td>-0.043</td><td></td></tr><tr><td colspan=\"3\"></td><td>(0.1142)</td><td></td></tr><tr><td colspan=\"3\"></td><td></td><td></td></tr><tr><td colspan=\"3\">Total investments</td><td>0.1543</td><td></td></tr><tr><td colspan=\"3\"></td><td>(0.1385)</td><td></td></tr><tr><td colspan=\"3\"></td><td></td><td></td></tr><tr><td colspan=\"3\"></td><td>-0.0193</td><td></td></tr><tr><td colspan=\"3\">VCs'IT experience</td><td></td><td></td></tr><tr><td colspan=\"3\"></td><td></td><td></td></tr><tr><td colspan=\"3\"></td><td>(0.1218)</td><td></td></tr></table></body></html>  \n\nTable 4 (Continued)   \n\n\n<html><body><table><tr><td rowspan=\"5\"></td><td>Model 6 (for H1A)</td><td>Model 7 (for H1B)</td><td>Model 8 (for H2)</td><td>Model 9 (for H3)</td></tr><tr><td colspan=\"4\">Dependentvariables</td></tr><tr><td>Fundingreceived</td><td>Venturefailure</td><td>Absoluteerrorinassessing ventures'technical competence</td><td>Assessment</td></tr><tr><td>Allobservations</td><td>Only those ventures that were funded</td><td>Allobservations</td><td>Allobservations</td></tr><tr><td>DummyAsianVC</td><td></td><td></td><td>-0.1785</td><td></td></tr><tr><td></td><td></td><td></td><td>(0.7689)</td><td></td></tr><tr><td>DummyHispanicVC</td><td></td><td></td><td>-0.1964 (2.4343)</td><td></td></tr><tr><td rowspan=\"2\">VC age</td><td></td><td></td><td>0.0875</td><td></td></tr><tr><td></td><td></td><td>(0.1289)</td><td></td></tr><tr><td>Constant</td><td></td><td></td><td>13.9928** (6.1317)</td><td></td></tr><tr><td>Log likelihood/R2</td><td></td><td>17.302</td><td></td><td></td></tr><tr><td></td><td>-6.8811</td><td></td><td>0.6428</td><td>0.8424</td></tr></table></body></html>\n\nNotes. Including dissimilarity in Models 6, 7, and 8 also does not change results. Robust standard errors are in parentheses. $^{*}p<0.1$ $^{**}p<0.05$ $^{***}p<0.01$  \n\n5.5.4. Lo-VCs Driving Results. A logical conclusion from Hypothesis 2 is that lo-VCs are simply worse  \n\nTable5 Stripped Down Models to Test Overfitting   \n\n\n<html><body><table><tr><td rowspan=\"5\"></td><td>Model 10 (for H1A)</td><td>Model 11 (for H1B)</td><td>Model 12 (for H2)</td><td>Model 13 (for H3)</td></tr><tr><td colspan=\"4\">Dependent variables</td></tr><tr><td>Funding received</td><td>Venture failure</td><td>Absolute error in assessing ventures'technical competence</td><td>Assessment</td></tr><tr><td>All observations</td><td>Only those ventures that were funded</td><td>Allobservations</td><td>Allobservations</td></tr><tr><td>Assessment</td><td>0.1996*** (0.0328)</td><td></td><td></td><td></td></tr><tr><td>Ventures'technicalcompetence</td><td></td><td>-0.2283***</td><td>-0.0202</td><td>0.5351***</td></tr><tr><td rowspan=\"2\">VCs'technicalcompetence</td><td>0.0416</td><td>(0.0574) -0.0396</td><td>(0.0328)</td><td>(0.0643)</td></tr><tr><td>(0.0335)</td><td>(0.0397)</td><td>-0.608*** (0.0368)</td><td>-0.395*** (0.0740)</td></tr><tr><td>Dissimilarity</td><td></td><td></td><td></td><td>-0.7862***</td></tr><tr><td>Constant</td><td>-6.6514***</td><td>6.0023***</td><td>18.6862***</td><td>(0.0806) 24.8493***</td></tr><tr><td></td><td>(1.1352)</td><td>(1.5505)</td><td>(1.2300)</td><td>(2.7832)</td></tr><tr><td>Log likelihood N</td><td>-200.2723 396</td><td>-55.3685 120</td><td>-1,124.2671 396</td><td>-1,219.7093 396</td></tr></table></body></html>\n\nNotes. VC and venture random effects are used in all of the models. In Model 10, ventures' technical competence is not included to see the independent effect of assessment on funding received. We thank an anonymous reviewer for suggesting this. It should be noted that including ventures' technical competence in Model 10 does not change coefficients substantially. Including dissimilaity in Models 10, 11, and 12 also does not change results. Robust standard errors are inparentheses.  \n\nTable6 Overassessment Mediating the Relationship Between Dissimilarity and Funding Probabilities   \n\n\n<html><body><table><tr><td colspan=\"2\">Model 14: dissimilarity only</td><td colspan=\"2\">Model15:both overassessr and dissimilarity</td></tr><tr><td></td><td colspan=\"2\">Dependent variable: Funding received</td><td></td></tr><tr><td rowspan=\"2\">Assessment</td><td></td><td></td><td>0.1756***</td></tr><tr><td></td><td></td><td>(0.0448)</td></tr><tr><td>Dissimilarity</td><td>-0.0732*</td><td>-0.025 (0.0417)</td><td></td></tr><tr><td></td><td>(0.0402) -0.0639*</td><td></td><td>-0.0239</td></tr><tr><td>VCs'technical competence</td><td>(0.0369)</td><td></td><td>(0.0419)</td></tr><tr><td>Dummyreference</td><td>1.2024***</td><td></td><td>1.1642***</td></tr><tr><td>Numberofpatents</td><td>(0.3382) 0.1715**</td><td></td><td>(0.3372) 0.1789**</td></tr><tr><td>Ventureteamsize</td><td>(0.0679) 0.3882***</td><td></td><td>(0.0702) 0.3127**</td></tr><tr><td>Marketsize</td><td>(0.1269) 0.1467***</td><td></td><td>(0.1404) 0.1327***</td></tr><tr><td>Competition</td><td>(0.0476) 0.1078</td><td></td><td>(0.0491) 0.1124</td></tr><tr><td>Founderreputation</td><td>(0.0886) -0.0782</td><td></td><td>(0.0908) -0.0619</td></tr><tr><td>Founderexperience</td><td>(0.1726) -0.0353</td><td></td><td>(0.1839) -0.0354</td></tr><tr><td>Ageofaventure</td><td>(0.0770) 0.0274</td><td></td><td>(0.0721) 0.0117</td></tr><tr><td>Revenue</td><td>(0.1007) -0.0206</td><td></td><td>(0.1047) -0.0299</td></tr><tr><td>Dummysoftware</td><td>(0.1899) -0.4381</td><td></td><td>(0.1791) -0.4015</td></tr><tr><td>Amountraised</td><td>(0.3392) 0.0022**</td><td></td><td>(0.3122) 0.002*</td></tr><tr><td>Amountrequested</td><td>(0.0011) 0.1757</td><td></td><td>(0.0011) 0.1643</td></tr><tr><td>Project management</td><td>(0.1566) 0.4537***</td><td></td><td>(0.1772) 0.0419</td></tr><tr><td>experience Communication</td><td>(0.0852) 0.003</td><td></td><td>(0.1402) -0.0359</td></tr><tr><td>Managementcapability</td><td>(0.0529) 0.2851**</td><td></td><td>(0.0561) 0.2575*</td></tr><tr><td>VCs'failures</td><td>(0.1387) -0.0984**</td><td></td><td>(0.1426) -0.0916**</td></tr><tr><td>VCs'successes</td><td>(0.0387) 0.4417***</td><td></td><td>(0.0413) 0.4704*** (0.1125)</td></tr><tr><td>Fund size</td><td>(0.1061) -0.0021 (0.0018)</td><td></td><td>-0.0022 (0.0019)</td></tr><tr><td>VCs'experience</td><td>0.0694** (0.0315)</td><td></td><td>0.0599* (0.0339)</td></tr><tr><td>Totalinvestments</td><td>-0.0414 (0.0390)</td><td>0.0408</td><td></td></tr><tr><td>VCs'ITexperience</td><td>-0.036</td><td>-0.0143</td><td>(0.0416)</td></tr><tr><td></td><td>(0.0263) 0.2325</td><td></td><td>(0.0296)</td></tr><tr><td>Dummy AsianVC</td><td>(0.2044)</td><td></td><td>0.0864 (0.2590)</td></tr></table></body></html>  \n\nTable 6 (Continued)   \n\n\n<html><body><table><tr><td rowspan=\"2\"></td><td>Model 14: dissimilarityonly</td><td>Model15:bothoverassessment anddissimilarity</td></tr><tr><td></td><td>Dependentvariable:Fundingreceived</td></tr><tr><td>VC age</td><td>-0.0263</td><td>-0.0243</td></tr><tr><td rowspan=\"2\">Constant</td><td>(0.0279)</td><td>(0.0288)</td></tr><tr><td>-4.6524**</td><td>-8.1715***</td></tr><tr><td></td><td>(2.2985)</td><td>(2.3066)</td></tr><tr><td>Loglikelihood</td><td>-170.5422</td><td>-158.1698</td></tr><tr><td>N</td><td>396</td><td>396</td></tr></table></body></html>  \n\nNotes. VC and venture random effects are used in all the models. In Models 14 and 15, ventures’ technical competence is not included to see the independent effect of assessment on funding received. We thank an anonymous reviewer for suggesting this. It should be noted that including ventures' technical competence in Models 14 and 15 does not change coefficients substantially. Robust standard errors are in parentheses.  \n\nat evaluating technical competence than hi-VCs. If lo-VCs are purely random in their errors, then this should not threaten the results presented previously. However, it is possible that lo-VCs have a cognitive anchor around medium levels of technical competency that serves as their default assessment of venture technical competence. Thus, rather than assessing ventures randomly throughout the competency spectrum, they may cluster their assessments around some medium competence level. If so, then lo-VCs will systematically overassess lo-ventures, because their true technical competence falls below the medium competency anchor, and  they will systematically underassess hi-ventures, because their true technical competence is above the medium competency anchor. Thus, if lo-VCs anchor their bad assessments around a medium level of technical competency, we can logically deduce the results of H3. In other words, the apparent dissimilarity between lo-VCs and hi-ventures correlates with underassessment, and apparent similarity between lo-VCs and lo-ventures correlates with overassessment. Thus, the results observed in H3 could be artifacts of the data driven by variance in lo-VC assessments rather than a true similarity effect.  \n\nTo refute this possibility, we recreated our analysis by using only the top third of VCs in technical competence. If we include only hi-VCs, then the logic described above no longer holds. As shown in Table 7, the results are qualitatively similar, suggesting that the variance in lo-VC ratings are not driving the supportive results for H3.  \n\n5.5.5. Similarity Between the VC and Venture in Other Dimensions. It is also plausible that similarity between the VC and technology head in aspects other than technical competence can also have significant influence on the VC's assessment. Following this literature, we added age similarity and education background similarity as controls and redid our analysis (Franke et al. 2006). These data were available for only $74\\%$ of VC-venture pairs. Age similarity is defined as the absolute difference in ages of the VC and the technical lead. Educational background (management or technology) similarity is operationalized as a dummy variable, which is coded as 1 if the technical lead and VC have similar educational training and O otherwise. The results of this analysis are reported in Table 8 and are qualitatively similar to results reported earlier. It is also important to note that these other similarity measures do not significantly predict a VC's funding decision. They may have predicted the decision to invite ventures for presentations, but our data do not allow that analysis.  \n\n<html><body><table><tr><td colspan=\"2\">Table7 Analysis with High-Technical-Competence VCs</td><td colspan=\"2\"></td></tr><tr><td></td><td>Model 16 (for H1A)</td><td>Model 17 (for H2)</td><td>Model 18 (for H3)</td></tr><tr><td></td><td></td><td>Absoluteerrorin assessing</td><td></td></tr><tr><td rowspan=\"2\"></td><td>Fundingreceived</td><td>ventures'technicalcompetence</td><td>Assessment</td></tr><tr><td>0.2266***</td><td></td><td></td></tr><tr><td></td><td>(0.0593)</td><td></td><td></td></tr><tr><td rowspan=\"2\">Ventures'technicalcompetence</td><td></td><td>0.0109</td><td>0.7630*** (0.0470)</td></tr><tr><td></td><td>(0.0308)</td><td></td></tr><tr><td>VCs'technicalcompetence</td><td>0.7155*** (0.2103)</td><td>-0.2514*** (0.0912)</td><td>-0.2041 (0.3385)</td></tr><tr><td rowspan=\"2\">Dissimilarity</td><td></td><td></td><td>-0.2062***</td></tr><tr><td></td><td></td><td>(0.0679)</td></tr><tr><td>Dummyreference</td><td>0.9558</td><td>0.2003</td><td>-0.9697</td></tr><tr><td rowspan=\"2\"></td><td>(0.7473)</td><td>(0.3883)</td><td>(0.6281)</td></tr><tr><td>0.2699**</td><td>0.1031*</td><td>0.3366***</td></tr><tr><td rowspan=\"2\">Numberofpatents</td><td>(0.1329)</td><td>(0.0551)</td><td>(0.1299)</td></tr><tr><td>0.3613</td><td>-0.0179</td><td>0.2126</td></tr><tr><td rowspan=\"2\">Ventureteamsize</td><td>(0.3223)</td><td>(0.1196)</td><td>(0.2162)</td></tr><tr><td>0.2420*</td><td>0.0319</td><td>-0.0648</td></tr><tr><td rowspan=\"2\">Marketsize</td><td>(0.1354)</td><td>(0.0445)</td><td>(0.0848)</td></tr><tr><td>0.3895</td><td>0.0936</td><td>0.0182</td></tr><tr><td rowspan=\"2\">Competition</td><td>(0.2412)</td><td>(0.0911)</td><td>(0.1650)</td></tr><tr><td>0.1852</td><td>-0.223</td><td>-0.0542</td></tr><tr><td rowspan=\"2\">Founderreputation</td><td>(0.5421)</td><td>(0.2499)</td><td>(0.3514)</td></tr><tr><td>-0.1468</td><td>-0.0618</td><td>0.1273</td></tr><tr><td rowspan=\"2\">Founderexperience</td><td>(0.1853)</td><td>(0.0880)</td><td>(0.1203)</td></tr><tr><td>-0.1125</td><td>-0.1185</td><td>0.0397</td></tr><tr><td rowspan=\"2\">Age of a venture</td><td>(0.1624)</td><td>(0.1072)</td><td>(0.1956)</td></tr><tr><td>-0.7319*</td><td>-0.156</td><td>-0.4517</td></tr><tr><td rowspan=\"2\">Revenue Dummysoftware</td><td>(0.4219)</td><td>(0.2554)</td><td>(0.3118)</td></tr><tr><td>0.2965</td><td>0.0363</td><td>0.6562</td></tr><tr><td rowspan=\"2\">Amountraised</td><td>(0.6283)</td><td>(0.2291)</td><td>(0.5837)</td></tr><tr><td>0.0017</td><td>-0.001</td><td>0.0028*</td></tr><tr><td rowspan=\"2\">Amountrequested</td><td>(0.0020)</td><td>(0.0009)</td><td>(0.0017)</td></tr><tr><td>1.0610***</td><td>0.4355***</td><td>-0.2347</td></tr><tr><td rowspan=\"2\"></td><td>(0.3671)</td><td>(0.1195)</td><td>(0.2752)</td></tr><tr><td>0.1432</td><td>0.1433</td><td>1.4372***</td></tr><tr><td rowspan=\"2\">Projectmanagementexperience</td><td>(0.2664)</td><td>(0.1134)</td><td>(0.2034)</td></tr><tr><td>-0.2592**</td><td>-0.0382</td><td>0.2046*</td></tr><tr><td rowspan=\"2\">Communication</td><td>(0.1242)</td><td>(0.0554)</td><td>(0.1072)</td></tr><tr><td>0.2787</td><td>-0.0147</td><td>0.2879</td></tr><tr><td rowspan=\"2\">Managementcapability</td><td>(0.2988)</td><td>(0.1250)</td><td>(0.1960)</td></tr><tr><td>-0.1785</td><td></td><td>0.0088</td></tr><tr><td rowspan=\"2\">VCs'failures</td><td>(0.3848)</td><td>0.2916** (0.1155)</td><td></td></tr><tr><td>-0.8418***</td><td></td><td>(0.4656)</td></tr><tr><td rowspan=\"2\">VCs'successes</td><td>(0.2995)</td><td>0.2537***</td><td>-0.1277</td></tr><tr><td></td><td>(0.0903)</td><td>(0.4805)</td></tr><tr><td rowspan=\"2\">Fundsize</td><td>-0.0192** (0.0086)</td><td>0.0051***</td><td>-0.0009</td></tr><tr><td></td><td>(0.0020)</td><td>(0.0099)</td></tr><tr><td rowspan=\"2\">VCs'experience</td><td>-0.6298*</td><td>0.1225</td><td>0.0465</td></tr><tr><td>(0.3362)</td><td>(0.0825)</td><td>(0.4366)</td></tr><tr><td rowspan=\"2\">Totalinvestments</td><td>0.2472**</td><td>-0.0929***</td><td>-0.002</td></tr><tr><td>(0.0999)</td><td>(0.0270)</td><td>(0.1579)</td></tr><tr><td rowspan=\"2\">VCs'ITexperience</td><td>0.2936**</td><td>0.0087</td><td>-0.1669</td></tr><tr><td>(0.1278)</td><td>(0.0259)</td><td>(0.1509)</td></tr><tr><td rowspan=\"2\">Dummy AsianVC</td><td>0.2669</td><td>-0.4529*</td><td>0.2139</td></tr><tr><td>(0.9091)</td><td>(0.2612)</td><td>(0.9717)</td></tr><tr><td rowspan=\"2\">Dummy Hispanic VC</td><td>4.3965*</td><td>-0.6055</td><td>-1.3581</td></tr><tr><td>(2.4121)</td><td>(0.3741)</td><td>(2.6917)</td></tr></table></body></html>  \n\nTable 7 (Continued)   \n\n\n<html><body><table><tr><td></td><td>Model16(forH1A)</td><td>Model 17 (for H2)</td><td>Model18(forH3)</td></tr><tr><td></td><td>Fundingreceived</td><td>Absoluteerrorinassessing ventures'technicalcompetence</td><td>Assessment</td></tr><tr><td>VC age</td><td>0.0966 (0.0845)</td><td>0.0147 (0.0270)</td><td>-0.077 (0.1295)</td></tr><tr><td>Constant</td><td>-27.9632**</td><td>6.5447</td><td>10.5799</td></tr><tr><td></td><td>(12.4178)</td><td>(4.1542)</td><td>(15.0880)</td></tr><tr><td>Log likelihood</td><td>-52.8405</td><td>-266.6231</td><td>-344.3975</td></tr><tr><td></td><td>137</td><td></td><td>137</td></tr><tr><td>N</td><td></td><td>137</td><td></td></tr></table></body></html>\n\nNotes. VC and venture random effects are used in all of the models. In Model 16, ventures' technical competence is not included to see the independent effect of assessment on funding received. We thank an anonymous reviewer for suggesting this. It should be noted that including ventures' technical competence in Model 16 does not change coefficients substantialy. Including dissimilarity in Models 16 and 17 also does not change results. Robust standard errors are in parentheses.  \n\n### 5.6. Results Summary  \n\nAs expected, we find that VC assessments of venture competence strongly correlate with VC investment decisions, that venture technical competence strongly correlates with venture failure, that VC technical competence strongly correlates with assessment accuracy, and that similarity in technical competence strongly predicts positive assessment bias. These findings are robust to multiple specifications and numerous robustness checks.  \n\n## 6.  Discussion and Conclusion  \n\n6.1. Implications for Theory and Future Research Using a unique and proprietary data set, we have shown that higher VC technical competence predicts higher accuracy in evaluating the technical competence of ventures, and that higher similarity between the VC and venture in technical competence leads to higher assessments by the VC. We also show that this higher assessment leads to a greater likelihood of VC investment. Accordingly, greater similarity between the VC and the venture in technical competence may lead to the VC being more likely to invest in ventures that are more likely to fail. Our work, therefore, joins the growing conversation exploring potential shortcomings in VC investment decisions (e.g., Franke et al. 2006, 2008; Guler 2007).  \n\nOne important way our work differs, however, is by exploring a deeper form of similarity than has been explored previously. Rather than testing whether similarity in high-level demographic factors leads to ex ante bias, we explore the extent to which actual similarity in technical competence leads to positive bias through real social interactions. We have argued that decision makers may update their initial assessments through actual social interactions and that those decision makers may be more attuned to deeper similarities in social interactions than simple demographics. We have shown that similarity in technical competence does lead to positive assessment bias, and our results lend support to our proposed mechanisms. Specifically, our results support the notion that similarity in technical competence creates a shared language between the VC and the venture that helps to smooth interpersonal interactions and create more positive relationships. This positivity likely drives the positive assessment bias. Thus, whereas prior work explores the effects of apparent similarity on ex ante decisions (Franke et al. 2006), our research focuses on the effects of actual similarity on social interactions and subsequent decision outcomes.  \n\nWe have examined similarity in technical competence because it is a centrally important factor in VC investment decisions for technology ventures, but it is possible that other kinds of similarity may have similar or related effects. We have controlled, for example, for managerial capability in our empirical models. Given the importance of business acumen for actually brining technical innovation to market, it is possible that similar managerial capabilities may also lead to positive bias. Future research may more carefully explore the extent to which similarities in other kinds of competence may lead to biased judgments.  \n\n<html><body><table><tr><td rowspan=\"5\">Table8 RobustnessCheckControllingforVCandVentureSimilarity</td><td>Model 19 (for H1A)</td><td>Model 20 (for H1B)</td><td>Model 21 (for H2)</td><td>Model 22(for H3)</td></tr><tr><td></td><td>Dependent variables</td><td></td><td></td></tr><tr><td colspan=\"4\"></td></tr><tr><td>Funding received</td><td>Venturefailure</td><td>Absoluteerrorinassessing ventures'technicalcompetence</td><td>Assessment</td></tr><tr><td>Allobservations</td><td>Only those ventures that were funded</td><td>Allobservations</td><td>Allobservations</td></tr><tr><td></td><td></td><td></td><td></td><td></td></tr><tr><td rowspan=\"2\">Assessment</td><td>0.1919*** (0.0433)</td><td></td><td></td><td></td></tr><tr><td></td><td>-0.4685***</td><td>-0.0332</td><td>0.3759***</td></tr><tr><td rowspan=\"2\">Ventures'technicalcompetence</td><td></td><td>(0.0890)</td><td>(0.0381)</td><td>(0.0642)</td></tr><tr><td></td><td>0.065</td><td>-0.6769***</td><td>--0.3336***</td></tr><tr><td rowspan=\"2\">VCs'technicalcompetence</td><td>-0.0376</td><td>(0.0987)</td><td>(0.0571)</td><td>(0.0558)</td></tr><tr><td>(0.0532)</td><td></td><td></td><td></td></tr><tr><td rowspan=\"2\">Dissimilarity</td><td></td><td></td><td></td><td>-0.5239***</td></tr><tr><td></td><td></td><td></td><td>(0.0822)</td></tr><tr><td rowspan=\"2\">Age similarity</td><td>-0.0046</td><td>-0.0263 (0.0638)</td><td>-0.0377</td><td>0.0228</td></tr><tr><td>(0.0332)</td><td>-1.9495***</td><td>(0.0476)</td><td>(0.0383)</td></tr><tr><td rowspan=\"2\">Educationsimilarity</td><td>0.0366</td><td>(0.7223)</td><td>-0.4461</td><td>-0.3949</td></tr><tr><td>(0.3396)</td><td>-0.7279</td><td>(0.5124)</td><td>(0.5134)</td></tr><tr><td rowspan=\"2\">Dummyreference</td><td>0.8621**</td><td>(0.6866)</td><td>0.9765*** (0.3489)</td><td>0.4374</td></tr><tr><td>(0.3784)</td><td>0.0691</td><td>0.0233</td><td>(0.4289)</td></tr><tr><td rowspan=\"2\">Numberofpatents</td><td>0.177*</td><td>(0.1523)</td><td>(0.0974)</td><td>0.1441</td></tr><tr><td>(0.0952)</td><td>0.4826</td><td></td><td>(0.0940)</td></tr><tr><td rowspan=\"2\">Ventureteamsize</td><td>0.4525***</td><td>(0.3668)</td><td>-0.0718</td><td>0.1423</td></tr><tr><td>(0.1450)</td><td></td><td>(0.1887)</td><td>(0.1899)</td></tr><tr><td rowspan=\"2\">Marketsize</td><td>0.1388***</td><td>-0.2214* (0.1221)</td><td>0.0152</td><td>0.1**</td></tr><tr><td>(0.0507)</td><td></td><td>(0.0762)</td><td>(0.0445)</td></tr><tr><td rowspan=\"2\">Competition</td><td>0.1076</td><td>0.2185 (0.2017)</td><td>-0.054</td><td>0.1153</td></tr><tr><td>(0.0953)</td><td></td><td>(0.1162)</td><td>(0.1154)</td></tr><tr><td rowspan=\"2\">Founderreputation</td><td>-0.0819</td><td>-0.1735</td><td>-0.1036</td><td>-0.2071</td></tr><tr><td>(0.2043)</td><td>(0.6058)</td><td>(0.2329)</td><td>(0.2864)</td></tr><tr><td rowspan=\"2\">Founderexperience</td><td>-0.0358</td><td>-0.3366**</td><td>-0.0383</td><td>-0.0589</td></tr><tr><td>(0.0629)</td><td>(0.1378)</td><td>(0.0908)</td><td>(0.1200)</td></tr><tr><td rowspan=\"2\">Ageofaventure</td><td>0.0331</td><td>0.3214</td><td>-0.1085</td><td>-0.1041</td></tr><tr><td>(0.1054)</td><td>(0.3523)</td><td>(0.1280)</td><td>(0.1232)</td></tr><tr><td rowspan=\"2\">Revenue</td><td>-0.1337</td><td>0.4595</td><td>0.0011</td><td>-0.0224</td></tr><tr><td>(0.2004)</td><td>(0.4215)</td><td>(0.2128)</td><td>(0.2639)</td></tr><tr><td rowspan=\"2\">Dummysoftware</td><td>-0.3935</td><td>0.8308</td><td>-0.8478*</td><td>-0.0283</td></tr><tr><td>(0.4064)</td><td>(0.9861)</td><td>(0.4895)</td><td>(0.5814)</td></tr><tr><td rowspan=\"2\">Amountraised</td><td>0.0023*</td><td>0.0004</td><td>-0.0013</td><td>0.0016</td></tr><tr><td>(0.0013)</td><td>(0.0022)</td><td>(0.0012)</td><td>(0.0015)</td></tr><tr><td rowspan=\"2\">Amountrequested</td><td>0.0732</td><td>0.1317</td><td>0.7543***</td><td>0.0955</td></tr><tr><td>(0.1873)</td><td>(0.3789)</td><td>(0.2325)</td><td>(0.1766)</td></tr><tr><td rowspan=\"2\">Projectmanagementexperience</td><td>-0.042</td><td>0.6576</td><td>-0.1298</td><td>2.4079***</td></tr><tr><td>(0.1406)</td><td>(0.2684)</td><td>(0.1973)</td><td>(0.2171)</td></tr><tr><td rowspan=\"2\">Communication</td><td>-0.0579</td><td>-0.0336</td><td>0.2409**</td><td>0.1317</td></tr><tr><td>(0.0443)</td><td>(0.1221)</td><td>(0.1130)</td><td>(0.1177)</td></tr><tr><td rowspan=\"2\">Managementcapability</td><td>0.18</td><td>0.0755</td><td>0.3766**</td><td>0.4433**</td></tr><tr><td>(0.1572)</td><td>(0.2031)</td><td>(0.1817)</td><td>(0.1911)</td></tr><tr><td rowspan=\"2\">VCs'failures</td><td>-0.0879</td><td>0.437**</td><td>-0.1651**</td><td>0.0868</td></tr><tr><td>(0.0613)</td><td>(0.1836)</td><td>(0.0823)</td><td>(0.0782)</td></tr><tr><td rowspan=\"2\">VCs'successes</td><td>0.5664***</td><td>-0.3571</td><td>0.2296</td><td>-0.0265</td></tr><tr><td>(0.1432)</td><td>(0.4051)</td><td>(0.1433)</td><td>(0.1416)</td></tr><tr><td rowspan=\"2\">Fundsize</td><td>-0.001</td><td>-0.0039</td><td>0.0017</td><td>-0.0024</td></tr><tr><td>(0.0031)</td><td>(0.0045)</td><td>(0.0033)</td><td>(0.0024)</td></tr><tr><td rowspan=\"2\">VCs'experience</td><td>0.0686</td><td>0.2341</td><td>0.039</td><td>0.1012</td></tr><tr><td>(0.0513)</td><td>(0.1944)</td><td>(0.0805)</td><td>(0.0689)</td></tr><tr><td rowspan=\"2\">Totalinvestments</td><td>-0.0401</td><td>-0.1168*</td><td>0.0919</td><td></td></tr><tr><td>(0.0552)</td><td>(0.0704)</td><td>(0.0685)</td><td>0.0214 (0.0493)</td></tr></table></body></html>  \n\nTable 8 (Continued)   \n\n\n<html><body><table><tr><td rowspan=\"5\"></td><td>Model 19 (for H1A)</td><td>Model 20 (for H1B)</td><td>Model 21 (for H2)</td><td>Model 22 (for H3)</td></tr><tr><td colspan=\"4\">Dependent variables</td></tr><tr><td>Fundingreceived</td><td>Venturefailure</td><td>Absoluteerrorinassessing ventures'technicalcompetence</td><td>Assessment</td></tr><tr><td>Allobservations</td><td>Only those ventures that were funded</td><td>Allobservations</td><td>Allobservations</td></tr><tr><td rowspan=\"2\">VCs'ITexperience</td><td>-0.0299</td><td>-0.1694*</td><td>0.0624</td><td>-0.1202***</td></tr><tr><td>(0.0406)</td><td>(0.1008)</td><td>(0.0439)</td><td>(0.0289)</td></tr><tr><td rowspan=\"2\">DummyAsianVC</td><td>0.2221</td><td>1.1548*</td><td>0.8563*</td><td>0.5821*</td></tr><tr><td>(0.4106)</td><td>(0.6283)</td><td>(0.4788)</td><td>(0.3360)</td></tr><tr><td rowspan=\"2\">Dummy Hispanic VC</td><td>0.5117</td><td>-2.0273</td><td>-0.8906</td><td>-2.0755**</td></tr><tr><td>(0.5703)</td><td>(1.9093)</td><td>(0.8203)</td><td>(1.0082)</td></tr><tr><td rowspan=\"2\">VC age</td><td>-0.0008</td><td>0.1362</td><td>-0.0718</td><td>-0.0511</td></tr><tr><td>(0.0452)</td><td>(0.1055)</td><td>(0.0561)</td><td>(0.0533)</td></tr><tr><td rowspan=\"2\">Constant</td><td>-8.3211**</td><td>-2.7797</td><td>18.8001***</td><td>18.4445***</td></tr><tr><td>(3.3841)</td><td>(5.9553)</td><td>(3.6468)</td><td>(3.1093)</td></tr><tr><td>Log likelihood</td><td>-126.8814</td><td>-34.8776</td><td>-803.2231</td><td>-805.7582</td></tr><tr><td>N</td><td>293</td><td>119</td><td>293</td><td>293</td></tr></table></body></html>\n\nNotes. VC and venture random effects are used in all of the models. In Model 19, ventures' technical competence is not included to see the independent effect of assessment on funding received. We thank an anonymous reviewer for suggesting this.It should be noted that including ventures'technical competence in Model 19 does not change coefficients substantialy. Including dissimilarity in Models 19, 20, and 21 also does not change the results. Robust standard errors areinparentheses.  \n\nWe also contribute theoretically to the VC investment decision literature by partially explaining why some VCs may be better able to assess the technical competence of ventures than others. By so doing we directly challenge the implicit assumption in prior work that VCs are similar in their abilities to evaluate venture technical competence. Thus, although prior research has clearly established the theoretical importance of venture technical competence for venture performance outcomes (e.g., Colombo and Grilli 2005, Kor 2003), our work suggests that measures of venture technical competence are not sufficient for explaining VC investment decisions. Instead, we must more carefully explore why some VCs are better able to evaluate and predict venture technical competence. Thus, the ability to assess accurately may be an important factor explaining why some VCs systematically outperform others in their investment decisions.  \n\n### 6.2. Managerial Implications  \n\nOur findings are also substantively important for practicing managers given the significance of these ventures for economic growth and development. Eleven percent of private-sector jobs come from venture-backed companies, and venture-backed revenue accounts for $21\\%$ of U.S. gross domestic product (National Venture Capital Association 2011). The VC domain has a substantial footprint (National Venture Capital Association 2011), roughly equal to the combined size of three widely researched industry domains—the online book domain (Publishers  \n\nWeekly 2011), the box-office domain (Motion Pictures Association of America 2011), and the music domain (Friedlander 2011). One VC-industry-specific implication of this study is that there may be a need to structure the evaluation of ventures′ technical competence so that VCs can rely on actual assessments, rather than their own imperfect approximations. The VC industry traditionally relies on VCs to evaluate ventures' technical competence using their own idiosyncratic methods, but this may not be the best solution. Introducing somewhat standard and objective assessments of technical competence within certain domains may help VCs reduce their reliance on potential decision biases when determining the ventures in which toinvest.  \n\nOur work also implies that founders of technology ventures would benefit from ensuring a high level of technical competence on the venture team. Our findings are consistent with prior research suggesting that technical competence enhances venture survival. Where our work adds to prior implications, however, is by showing that a highly competent technology head can facilitate more positive social interactions with competent VCs. In addition to having a positive effect on VC funding decisions, these positive relationships may also affect the VC's propensity to invest time and other resources into the venture's survival. Future research may also explore the extent to which similarity in technical competence affects the VCs level of nonmonetary investment in the venture.  \n\n### 6.3. Limitations  \n\nAlthough we have included many controls and tested multiple specifications, our empirical design nevertheless suffers from several important limitations. First, there are several omitted controls, due to data availability, that may have improved the robustness of our work. Specifically, we may have benefited from a measure of the number of ventures started by founders before the current ventures. This control would have helped to alleviate the potential concern that serial entrepreneurs may be more likely to receive funding, ceteris paribus.  \n\nSecond, despite our efforts to deal with endogeneity through a simultaneous equation model, there is still a flaw in the timing of our data collection that empirical tests cannot fully rectify. Specifically, we gathered VC assessments after VCs made investment decisions. A superior design would have measured assessments of technical competence at the time of the venture presentation so that the temporal ordering of data collection would have made clear the independent effect of the assessment on subsequent decision outcomes. Although this may have been a superior approach, it was not possible in this case. Despite this shortcoming, however, we note that the strong independent effect of assessment on subsequent investment decisions persisted even in the simultaneous equation model. Accordingly, we believe our data and results lend positive support to our core hypotheses.  \n\nSupplemental material to this paper is available at http: //dx .doi.org/10.1287 /mnsc.2014.2117.  \n\n# Supplemental Material  \n\nBusenitz LW, Barney JB (1997) Differences between entrepreneurs and managers in large organizations: Biases and heuristics in strategic decision-making. J. Bus. Venturing 12(1):9-30.   \nCastanias RP, Helfat CE (2001) Themanagerial rents model: Thory and empirical analysis. J. Management 27(6):661-678.   \nChase WG, Simon HA (1973) Perception in chess. Cognitive Psych. 4(1):55-81.   \nColombo MG, Grilli L (2005) Founders' human capital and the growth of new technology-based firms: A competence-based view. Res. Policy 34(6):795-816.   \nCooper AC, Gimeno-Gascon FJ, Woo CY (1994) Initial human and financial capital aspreditors of nwventure performance. J. Bus. Venturing 9(5):371-395.   \nCrook TR, Ketchen DJ, Combs JG, Todd SY (2008) Strategic resourcesand performancemetanalysisStrategicMage ment J. 29(11):1141-1154.   \nEhrlinger J Johnson K, Baner M, Dunning D, Kruger J (2008Why the unskilled are unaware: Further explorations of (absent) selfinsigt amng the incmpetet. Oran ehHman Dc sion Processs 105(1):98-121.   \nEisenhardt KM, Schoonhoven CB (1990) Organizational growth: Linking founding team, strategy, environment, and growth among us semiconductor ventures, 1978-1988. Admin. Sci. Quart. 35(3):504-529.   \nForbes DP (2005) Are some entrepreneurs more overconfident than others? J. Bus. Venturing 20(5):623-640.   \nFranke N, Gruber M, Harhoff D, Henkel J (2006) What you are is what you like similarity biases in venture capitalists' evaluations of start-up teams. J. Bus. Venturing 21(6):802-826.   \nFranke N, Gruber M, Harhoff D, Henkel J (2008) Venture capitalists' evaluations of start-up teams: Trade-offs, knock-out criteria, and the impact of VC experience. Entrepreneurship Theory and Practice 32(3):459-483.   \nFriedlander JP (2011) 2010 year-end shipment statistics. Report, Recording Industry Association of America, Washington, DC. Accessed April 24, 2015, http://riaa.com/media/548C3F4C6B6D-F702-384C-D25E2AB93610.pdf.   \nGladwell M (2007) Blink: The Power of Thinking Without Thinking (Bay Back Books, New York).   \nGuler I 2007) Throwing good money afer bad? Political and institutional influences on sequential decision making in the venture capital industry. Admin. Sci. Quart. 52(2):248-285.   \nHaber S, Reichel A (2007) The cumulative nature of the entrepreneurial process: The contribution of human capital, planning and environment resources to small venture performance. J. Bus. Venturing 22(1):119-145.   \nHall J, Hofer CW (1993) Venture capitalists' decision criteria in neW venture evaluation. J. Bus. Venturing 8(1):25-42.   \nJohnson-Laird PN (1983) Mental Models: Towards a Cognitive Science of Language, Inference, and Consciousness (Harvard University Press, Cambridge, MA).   \nKatz D, Kahn RL (1966) Organizations and the system concept. Katz D, Kahn RL, eds. The Social Psychology of Organizations John Wiley & Sons, New York), 14-29.   \nKlimoski RJ, Donahue LM (2001) Person perception in organizations: An overview of the field. London M, ed. How People Eoaluate Others in Organizations (Lawrence Erlbaum Associates, Mahwah, NJ), 5-43.   \nKor YY (2003) Experience-based top management team competence and sustained growth. Organ. Sci. 14(6):707-719.   \nKruger J, Dunning D (1999) Unskilled and unaware of it: How difficulties in recognizing one's own incompetence lead to inflated self-assessments. J. Personality Soc. Psych. 77(6):1121-1134.  \n\n# References  \n\nAlvarez RM, Glasgow G (1999) Two-stage estimation of nonrecursive choice models. Political Anal. 8(2):147-165.   \nAndreessen M (2011） How important is it to have a technical cofounder, in order to get funding from a VC or an incubator/ seed program? Accessed April 24, 2015, http://qr.ae /L5VRW.   \nBaron RM, Kenny DA (1986) The moderator-mediator variable distinction in social psychological research: Conceptual, strategic, and statistical considerations. J. Personality Soc. Psych. 51(6): 1173-1182.   \nBaum CF, Schaffer ME, Stillman S (2003) Instrumental variables and GMM: Estimation and testing. Stata J. 3(1):1-31.   \nBaum JAC, Silverman BS (2004) Picking winners or building them? Alliance, intellectual, and human capital as selection criteria in venture financing and performance of biotechnology startups. J. Bus. Venturing 19(3):411-436.   \nBergemann D, Hege U (1998) Venture capital financing, moral hazard, and learning. J. Banking Finance 22(6):703-735.   \nBharadwaj AS (2000) A resource-based perspective on information technology capability and firm performance: An empirical investigation. MIS Quart. 24(1):169-196.   \nBiernat M, Manis M, Kobrynowicz D (1997) Simultaneous assimilation and contrast effects in judgments of self and others. J. Personality Soc.Psych. 73(2):254-269.   \nBollen KA (1989） Structural Equations with Latent Variables (John Wiley & Sons, New York).   \nLee DMS, Trauth EM, Farwell D (1995) Critical skills and knowledge requirements of is professionals: A joint academic/industry investigation. MIS Quart. 19(3):313-340.   \nLondon M (2001) How People Evaluate Others in Organizations (Lawrence Erlbaum Associates, Mahwah, NJ).   \nLowe RA, Ziedonis AA (2006) Overoptimism and the _performance of entrepreneurial firms. Management Sci. 52(2): 173-186.   \nMacMillan IC, Siegel R, Subba Narasimha PN (1985) Criteria used by venture capitalists to evaluate new venture proposals. J. Bus. Venturing 1(1):119-128.   \nMaddala GS (1983) Limited-Dependent and Qualitative Variables in Econometrics (Cambridge University Press, Cambridge, UK).   \nMarch JG (1994) Primer on Decision Making: How Decisions Happen (The Free Press, New York).   \nMarch JG, Simon HA (1958) Organizations (John Wiley & Sons, New York).   \nMata FJ, Fuerst WL, Barney JB (1995) Information technology and sustained competitive advantage: A resource-based analysis. MIS Quart. 19(4):487-505.   \nMotion Pictures Association of America (2011) Theatrical market statistics. Motion Pictures Association of America, Washington, DC.   \nMurnieks CY, Haynie JM, Wiltbank RE, Harting T (2011) \"I like how you think\": Similarity as an interaction bias in the investorentrepreneur dyad. J. Management Stud. 48(7):1533-1561.   \nNathan BR, Lord RG (1983) Cognitive categorization and dimensional schemata: A process approach to the study of halo in performance ratings. J. Appl. Psych. 68(1):102-114.   \nNational Venture Capital Association (2011) Venture impact: The economic importance of venture capital-backed companies to the U.S. economy. Report, National Venture Capital Association, Arlington, VA. Accessed April 24, 2015, http://www jumpstartinc.org/companies/dl/ \\~ /media/JumpStartlnc/Images/ Results-Page/2011-NVCA-VenturelmpactReport.ashx.   \nNisbett RE, Wilson TD (1977) The halo effect: Evidence for unconscious alteration of judgments. J. Personality Soc. Psych. 35(4):250-256.   \nPatzelt H (2010) CEO human capital, top management teams, and the acquisition of venture capital in new technology ventures: An empirical analysis. J. Engrg. Tech. Management 27(3): 131-147.   \nPavlou PA, El Sawy OA (2006) From it leveraging competence to competitive advantage in turbulent environments: The case of new product development. Inform. Systems Res. 17(3):198-227.   \nPreacher KJ, Hayes AF (2004) SPSS and’ SAS procedures for estimating indirect effects in simple mediation models. Behav. Res. Methods, Instruments, Comput. 36(4):717-731.   \nPublishers Weekly (2011) Industry sales rose $3.1\\%$ in 2010; trade e-book sales the big winner. Publishers Weekly (August 9), http://www.publishersweekly.com/pw/by-topic/industry -news /financial-reporting/article/48280-industry-sales-rose-3 -1-in-2010-trade-e-book-sales-the-big-winner.html.   \nQuinn RW (2007) Energizing others in work connections. Dutton JE, RaginsBR,eds.Exploring Positive Relationships at Work:Building a Theoretical and Research Foundation (Lawrence Erlbaum Associates, Mahwah, NJ), 73-90.   \nQuinn RW, Dutton JE (2005) Coordination as energy-inconversation. Acad. Management Rev. 30(1):36-57.   \nShane S, Stuart T (2002) Organizational endowments and the performance of university start-ups. Management Sci. 48(1): 154-170.   \nShepherd DA (1999) Venture capitalists' assessment of new venture survival. Management Sci. 45(5):621-632.   \nShepherd DA, Zacharakis A, Baron RA (2003) VCs' decision processes: Evidence suggesting more experience may not always be better. J. Bus. Venturing 18(3):381-401.   \nShrader R, Siegel DS (2007) Assessing the relationship between human capital and firm performance: Evidence from technology-based new ventures. Entrepreneurship Theory and Practice 31(6):893-908.   \nSorenson O, Stuart TE (2001) Syndication networks and the spatial distribution of venture capital investments. Amer. J. Sociol. 106(6):1546-1588.   \nStaiger D, Stock JH (1997) Instrumental variables regression with weak instruments. Econometrica 65(3):557-586.   \nSternberg RJ, Grigorenko EL (2003) The Psychology of Abilities, Competencies, and Expertise (Cambridge University Press, Cambridge, UK).   \nTambe P, Hitt LM, Brynjolfsson E (2012) The extroverted firm: How external information practices affect innovation and productivity. Management Sci. 58(5):843-859.   \nTippins MJ, Sohi RS (2003) IT competency and firm performance: Is organizational learning a missing link? Strategic Management J. 24(8):745-761.   \nTrauth EM, Farwell DW, Lee D (1993) The is expectation gap: Industry expectations versus academic preparation. MIS Quart. 17(3):293-307.   \nTsui AS, Barry B (1986) Research notes: Interpersonal affect and rating errors. Acad. Management J. 29(3):586-599.   \nTyebjee TT, Bruno AV (1984) A model of venture capitalist investment activity. Management Sci. 30(9):1051-1066.   \nWang S, Zhou H (2004) Staged financing in venture capital: Moral hazard and risks. J. Corporate Finance 10(1):131-155.   \nZacharakis AL, Meyer GD (2000) The potential of actuarial decision models: Can they improve the venture capital investment decision? J. Bus. Venturing 15(4):323-346.   \nZenger TR, Lawrence BS (1989) Organizational demography: The differential effects of age and tenure distributions on technical communication. Acad. Management J. 32(2):353-376.  "
  },
  "md_alperovychHowDoesGovernmental2015": {
    "reference_markdown": "# How does governmental versus private venture capital backing affect a firm's efficiency? Evidence from Belgium  \n\nYan Alperovycha\\*, Georges Hubnerbc.d, Fabrice Lobet  \n\na EMLYON Business School   \nHCMangemntchiversityf   \nMastricht University   \nd Gambit Financial Solutions   \ne Free Universty of Brussels  \n\n# ARTICLEINFO  \n\n# ABSTRACT  \n\nArticlehistory:   \nReceived 13March 2014   \nReceived in revised form 18 November 2014   \nAccepted 19 November 2014   \nAvailable online xxxx  \n\nField Editor: S. Venkataraman  \n\nKeywords:   \nVenture capital   \nEfficiency   \nData envelopment analysis   \nFund type   \nPublic investor  \n\nWe investigate the implications of venture capital (VC) investor type (government or private) on the operating efficiency of a sample of 515 Belgian portfolio firms up to 3 years after the investment. We find that the government VC-backed firms display significant reductions in productivity. No significant differences in efficiency are found in firms backed by private VC compared with their non-VC-backed peers. Finally, significant reductions in efficiency exist in targets of government VC compared to their non-VC-backed peers.  \n\n$\\circledcirc$ 2014 Elsevier Inc. All rights reserved.  \n\nstudies do not address the source of these inferior achievements and there is a lack of academic understanding of the implications of GVC funding on the link between inputs and outputs, namely efficiency.  \n\nIn this paper we tackle this issue by investigating explicitly the relationship between VC sponsor type and the efficiency of the recipient firms. Our intended contribution is twofold. Firstly, this study strengthens the distinction between purely financial support and the value added by GVC and PVC investors. This result is important as the efficiency itself is one of the fundamental drivers of a firm's growth, job creation, and performance (Bottazzi et al., 2008a; Jovanovic, 1982). Secondly, our measures of each firm's efciency span from the year before the first investment to 3 years post-investment. We are able to observe the evolution of productivity in firms funded by distinct VC sponsors and thus the contribution of this typology to the dynamic improvements in efficiency.  \n\nThe empirical part of the paper uses a sample set of 515 Belgian VC-backed firms observed from 1998 to 2007. We use a matching procedure before the first financing round to identify a control sample of comparable non-VC-backed firm from the entire population of Belgian firms. Two reasons exist for using Belgium as a testing ground. Firstly, several important Belgian GVC players account for approximately half of the country's VC investments over the period under study. Some of these funds have existed in the industry for more than 30 years and all are still \"technically\" influenced by the policy makers. Secondly, being particularly open, the Belgian economy is representative of major European economic trends.  \n\nOur analyses show no significant differences between the future targets of PVC and GVC funds before a first investment round. Once these firms obtain funding, PVC-backed firms demonstrate statistically significantly superior productivity in all three posttransaction years compared with their GVC-backed peers. The difference is also significant in the overall (global) efficiency level. This result is more in line with Croce et al. (2013), rather than Chemmanur et al. (2011). We also find that funding by a set of specific GVC funds destroys target productivity compared with PVC- and even non-VC-backed firms. Finally, we find no significant differences in productivity levels and changes in PVC-backed firms compared with their non-VC-backed peers. All results are robust to changes in the time frame, estimation methods, and endogeneity concerns.  \n\nThis study therefore sheds new light on existing evidence of the impact of VC financing on efficiency. Our results are also potentially useful for Belgian policy makers. Although we cannot conclude whether their funds are incrementally harmful to the national economy, we believe that serious failures exist in the design of the GVC program studied, which may require a reexamination of theirstructures.  \n\n## 2. Introduction  \n\nDespite the seemingly modest volumes of VC investments compared with the rest of capital flows, the consequences of such financing are quite substantial (Lerner, 1999, 2002b, 2009). In terms of innovation, Kortum and Lerner (2000) show that VC-backed firms are characterized by significantly higher patenting rates compared with their non-VC-backed peers. Davila et al. (2003) find that a positive relationship between the growth of start-ups, as measured by labor growth, and VC funding. At the macroeconomic level, Samila and Sorenson (2011) document a highly positive impact of VC supply on business creation, employment, and aggregate income in the USA. In terms of performance, VC-backed firms display better chances of IPO and survival rates after an IPO (Hochberg et al., 2007; Puri and Zarutskie, 2012). The operating performance of VC-backed firms also seems to be superior to that of comparable non-VC-backed companies (Alperovych and Huibner, 2013). These arguments outline the added value of VC financing.  \n\nMany governments sharing this conviction about the benefits of VC activity have introduced programs to foster VC financing. These initiatives may take three general forms: regulatory framework (\"law\"), indirect framework, and direct investment schemes (Cumming, 2007; Cumming and Li, 2013; Keuschnigg and Bo Nielsen, 2001). The “law\" mainly relates to taxation and institutional frameworks in which venture capitalists and entrepreneurial firms operate. Indirect frameworks include programs that favor technology transfers from universities to business, creation and support of business incubators, and structuring industrial sectors in clusters. Finally, the “direct investment schemes\" focus mainly on the supply side of the market. These schemes may be classified into three types: (i) the guarantee system, in which the government commits to covering, totally or partially, potential losses of private VC funds, (i) the fund-of-funds system, where the government co-invests with private VC funds, and (ii) the direct investments in small and medium enterprises (SMEs) by GVC investment funds. In this paper, we focus on this third vector of public influence in theVCworld.1  \n\nVarious studies have investigated country-specific settings of different forms of government-sponsored VC, such as in the USA (Cumming and Li, 2013; Lerner, 1999), Canada (Cumming and Maclntosh, 2003, 2006, 2007), UK and Germany (Bascha and Walz, 2006; Cumming, 2003; Heger et al., 2005; Sunley et al., 2005), Australia (Cumming, 2007; Cumming and Johan, 2009, forthcoming; Lerner and Watson, 2008), Finland (Maula et al., 2007), and on a pan-European basis (Da Rin et al., 2006; Leleux and Surlemont, 2003). International evidence on the effects of GVC on investment patterns and exit performance is documented by Cumming et al. (forthcoming) and Brander et al. (forthcoming).  \n\nNone of this literature investigates the transformation process of inputs into outputs (i.e. the firm's operating efficiency). Rather, they focus on GVC-funded firms' output levels such as growth in sales revenues and/or labor, patents, returns, or exit patterns. However, efficiency is a substantial determinant of firm performance (Bottazzi et al., 2008a), and there is recent evidence that it is impacted positively by VC backing (Chemmanur et al., 2011; Croce et al., 2013). One may thus wonder where the source of this impact comes from. Our paper contributes to answer this question. Using Belgium, we investigate whether the impact of investor type can be observed upstream from the output, directly in firm productivity. Specifically, we use operating effciency as a metric to contribute to the debate on the impact of the origin of the VC funds - government or private - on firm performance.  \n\nGVC funds, like private VC investors, face the issues of the selection of the right targets, and coaching portfolio firms in growth and development. Even though their global objective is probably not only profit maximization, but also job creation and stabilization of regional economic activity, ensuring that the provided funds are properly allocated and used efficiently by their portfolio firms is still incumbent upon the management of such funds. In light of the recent criticism that governments often fail in this task (Shane, 2009), a thorough analysis of the implications of GVC financing on efficiency becomes worthwhile and instructive. Our general research question is therefore formulated as follows: How do differences in types of VC investors (GVC/PVC) affect the postinvestment efficiency of their portfolio firms?  \n\nTo address this question, we gathered data on 515 Belgian VC deals from 1998 to 2007. To enhance our analysis, we investigated whether VC-backed firms in Belgium are more or less efficient than their comparable non-VC-backed (NVC) peers, again focusing on the GVC-PVC investor dichotomy. For this purpose, we constructed a control group of similar firms without any form of VC financing from the entire population of Belgian firms.  \n\nTo estimate efficiency, we rely on Dynamic Data Envelopment Analysis (DDEA) models (Fare and Grosskopf, 1996; Tone and Tsutsui, 2010). These models are rooted in the DEA literature, and draw on the microeconomic theory of firms' optimizing behavior. In this sense, this analysis has a stronger theoretical foundation than accounting ratios (Cook and Seiford, 2009). Practically speaking, for each VC-backed or comparable firm, we estimate a global effciency score between O and 1 over the 4-year time window from the pre-transaction2 year to 3 years post-transaction. A higher score indicates that a firm has used its inputs more efficiently to produce outputs. The global efficiency score is then decomposed into term efficiencies, which show the evolution of efficiency with time. Next, we use the estimated scores in a regression setting to assess the impact of VC investor type on firm efficiency.  \n\nOur findings indicate that within the cohort of VC-backed firms, efficiency increases after the VC injection. This result, however, is not split uniformly between the GVC- and PVC-backed portfolio firms. The univariate global and term efficiency scores show that the Belgian GVC-backed firms lag behind their privately-backed peers in terms of productivity. The existence of a GVC investor in the firms' equity results in substantial reductions in global efficiency over the 4-year study window. Factoring comparable NVC-backed firms into the analysis suggests that GVC-backed portfolio companies lag even behind these comparable peers. We also find no effect of PVC funding on productivity compared with the NVC-backed firms.3  \n\nThese results provide new evidence on the impact of VC financing on efficiency, and sometimes contradict existing evidence. The study by Chemmanur et al. (2011) suggests that VC-backed firms are more efficient than non-VC-backed firms before and after VC financing. Our results show that the differential effect of VC backing in Belgium results mostly from the destruction of productivity from GVC rather than an improvement because of PVC. We also confirm the documented findings that VC improves the productivity of the targets after the first financing event, a result that is consistent with Croce et al. (2013). The type of VC clearly also matters. GVC fund financing seems to hinder the improvement in productivity, as the firm's efficiency remains below even that of NvC-backed firms.  \n\nThe remainder of the paper is organized as follws. Section 3 presents the theoretical design. Section 4 outlines the methodology and data used in the analyses. Section 5 presents the results and we provide conclusions in Section 6.  \n\n## 3. Background and theoretical design  \n\n### 3.1. VC financing and effciency  \n\nA large body of the literature indicates that besides returns (Cochrane, 2005; Hand, 2007; Korteweg and Sorensen, 2010), VC also stimulates growth, spurs innovation, and creates jobs at firm and economy levels (Kortum and Lerner, 2ooo), (Puri and Zarutskie, 2012; Samila and Sorenson, 2011). The mechanisms through which VC financiers produce value are selection and value adding (Alperovych and Hibner, 2013). VC investors pick their targets using stringent screening criteria Tyebjee and Bruno (1984), Macmillan et al. (1985, 1987) and scrutiny in the selection process. This allows them to reduce the information asymmetries around potential qualifiers prior to the initial investment (Knockaert et al., 2006; Lerner, 2002b). VC investors then monitor closely, control, and involve themselves actively in their portfolio firms after financing (Sapienza et al., 1994; Bottazzi et al., 2008b). Monitoring and control efforts by VC investors include (but are not limited to) board representation (Lerner, 1995), staging of capital infusions (Cornelli and Yosha, 2003; Lerner, 1995), and the use of convertible securities to name but a few (Hellmann, 1998, 2006). Similarly, advisory and involvement services could be the internal restructuring of the management teams and their compensation structures (Sapienza, 1992), assistance in strategic and operational management (Hellmann and Puri, 2000), professionalization, headhunting, and additional fundraising (Hellmann and Puri, 2002). VC investors also capitalize extensively on their network of contacts to enhance the scale and empower the growth of ventures that they fund (Davila et al., 2003; Hochberg et al., 2007; Hsu, 2000). Finally, the reputation and experience of VC sponsors play a critical role in facilitating growth and certifying the quality of a venture (Gompers, 1996;  \n\nSorensen, 2007). A combination of these effects results in the more efficient allocation of resources, which implies improvements in a firm-level productivity and thus the superior efficiency of VC-backed firms (Chemmanur et al., 2011; Croce et al., 2013).  \n\n### 3.2. VC investor type and effciency  \n\nImprovements in productivity (as well as other benefits) can only be achieved if screening and value-added mechanisms are implemented and enforced properly. This is related to constraints that VC funds are subject to. These, however, may vary depending on the type of VC investor (Lerner, 2002b).  \n\nPVC investors are subject to strong contractual, financial, and reputational constraints from the institutions (termed limited partners, LPs) that VC firms raise money from (Bottazzi et al., 2008b; Florin, 2005). Contractual pressure is related to complex partnership agreements, which govern business relations between LPs and VC fund managers. Gompers and Lerner (1996) characterize three broad classes of restrictions (covenants) pertaining to overall fund management, to the activities of fund managers, and to the types of targets in which the fund is allowed to invest. Violation of these clauses results in penalties applied to PVC fund managers, which limits the potential for agency conflicts and costs associated with them.  \n\nFinancial pressure is related to the strong return requirements and compensation structures. Return hurdles, coupled with a fund's limited lifetime forces fund managers to discontinue the financing of underperforming investments and adopt a clearly observable exit-oriented investment strategy (Gompers and Lerner, 2004; Lerner et al., 2007). The compensation structures of PVC funds (management fees and carried interest) are linked closely to the outcomes of their investments policies (Gompers and Lerner, 1999; Jensen, 1986; Metrick and Yasuda, 2010). This should force fund managers to exert a considerable effort in selection, monitoring, and valueadding activities (Bottazzi et al., 2008b; Sapienza, 1992; Sapienza et al., 1996).  \n\nReputation pressure is related to violations in contractual agreements and failure to deliver sufficient financial returns to LPs. Since VC investors raise funds recursively as part of their business activity, LPs are unlikely to commit their capital to a VC firm with a poor track record (Gompers, 1996; Gompers and Lerner, 1999). Such constraints force PVC managers with limited financial and overseeing resources to ensure that the funds that they provide to entrepreneurial firms are properly allocated, and that moral hazard problems at the investee level are addressed, to maximize the overall exit value of their portfolios (de Clercq and Manigart, 2007).  \n\nGVC funds are largely exempt from such pressures. In general, they use or leverage public money for their operations and their lifetime is often unlimited. Although it is possible that these funds have statutory life-span limitations, Lerner (2009) argues that once introduced, these funds often become very difficult to “kill off'. Their activity is unlikely to be governed by a limited partnership-like agreement. They are not subject to stringent financial return requirements and have no clearly defined exit strategy. Finally, they are unlikely to bear reputation constraints and thus they do not need to worry about raising follow-on funds.  \n\nManagers of GVC funds, often civil servants, typically have extensive experience in retail credit sectors, law, audit, and financial analysis. This automatically translates into a selection process more akin to credit risk acceptance. As a consequence, GVC funds are also much less streamlined on particular (high growth) industries, and are prone to invest into traditional sectors with more stable cash flows. Furthermore, stand-alone GVC funds are not used for seting up performance-based compensation structures similar to those of private venture capitalists ( Manigart et al, 2002). As a consequence,their managers are lesslikely to have incentives to select the best possible target, place pressure on their portfolio firms, and maximize the exit value of their investments (Leleux and Surlemont, 2003).  \n\nA combination of these factors should undermine the effectiveness of the selection, monitoring, and control mechanisms. In fact, the overall objectives of GVC funds may be different and focus on regional economic development (which has a longer horizon) and job creation. Even though this goal is legitimate, government agents could allocate funds in a less efficient way (Lerner, 2010), and approve investments in non-profitable projects (Lerner, 2002b).  \n\nThis suggests that the operating mode of PVC funds could lead to a more productive resource allocation and consequently to more efficient targets. Therefore our main hypothesis on the efficiency of Belgian VC-backed firms suggests that firms backed by PVC funds will bemore efficient thantheir peers backed byGVCfunds.  \n\n## 4. Methodology and data  \n\n### 4.1. Methodological approach  \n\nTo measure efficiency, we use slacks-based DDEA models (Tone and Tsutsui, 2010). Originally, the DEA methodology was designed to evaluate a firm's productivity with respect to the best firms in a reference group (Charnes et al., 1978; Cook and Seiford, 2009; Cooper et al., 2007). The idea of measuring efficiency relative to a benchmark can be traced to Farrell (1957) and Debreu (1959). One can in principle define efficiency as the ability to produce the maximum possible output given a mix of inputs. Assuming that the form of the optimal production function is known, an efficient frontier of production possibilities for all input mixes can be constructed. More efficient firms are closer to the frontier. Unfortunately, the optimal production function is unknown. In this context, Farrell (1957) suggests (i) that a theoretical one is assumed, like the Cobb-Douglas production function, or (ii) reliance on an empirical one based on the “best results observed in practice\". DEA follows the second approach in evaluating the efficiency of firms relative to the “best practices production frontier\".  \n\nIn their seminal paper, Charnes et al. (1978) suggested that the efficiency of any firm be measured as “\"the maximum of a ratio of weighted outputs to weighted inputs subject to the condition that similar ratios for every firm be less than or equal to unity\". The efficiency of a given firm is then measured with respect to the reference set (other sample firms). Within this reference set, DEA defines the best performers, which form the efficient frontier and have an effciency score equal to one. The remaining firms are benchmarked relative to this frontier and receive a score between O and 1. This can be illustrated using the following example. If firm A belongs to the set of best performers, there is no firm B in the sample that can produce more than A using the same or less resources. If B uses more resources than A, and achieves higher output levels, then B can belong to the set of best performers. But this is only possible if there is no firm C, which produces more than B using the same or less resources than B, and so on. Obviously, the set of best performers will include many firms, but none will“\"outperform\" the other, because their relative efficiencies are equivalent. In this context, the DEA efficiency score is a distance measure, expressed in percentage terms, indicating how far effciency-wise a given firm is from the frontier.  \n\nDEA has several advantages over traditional regression-based models. It allows for the concurrent use of multiple inputs and outputs, and results in a more accurate consideration of productivity. It draws on the microeconomic theory of firms' optimizing behavior and in this sense has stronger theoretical foundations than accounting ratios that are often used in performance studies. DEA requires no statistical assumptions about the nature of production technologies that convert inputs into outputs, which contrasts with other studies that use total factor productivity (Chemmanur et al., 2011; Harris et al., 2005; Lichtenberg and Siegel, 1990) and stochastic frontier modeling (Amess, 2003). For this reason, DEA models are not subject to misspecification errors (Gregoriou et al., 2005).  \n\nThe advantages of DEA come at some cost. Since the point here is the application of the DEA, we discuss the difficulties in their empirical implementation rather than their theoretical limitations. Firstly, DEA does not allow for missing data. A more delicate issue is data negativity. As a general rule, all input and output data is bound to be non-negative, although slight modifications to account for the negative data are available for some DEA models. Secondly, there is an important tradeoff in terms of the number of observation units versus the number of inputs or outputs. Having too few firms and keeping the number of inputs/outputs fixed, results in too many decision-making units being classified as efficient. Conversely, having too many firms results in most of them being inefficient with a zero score.  \n\nOriginal DEA models are cross-sectional. Many applications, however, are more insightful in a longitudinal context, which is why further theoretical advances have enabled an explicit incorporation of the continuous time structure into efficiency measurements (Chen and van Dalen, 2010; Fare and Grosskopf, 1996). One of the latest developments in this field is the dynamic slacks-based measure (DSBM) developed by Tone and Tsutsui (2010). We use the input-oriented DSBM model to evaluate efficiency over a 4-year window between the pre-transaction year (injection year for startups) $\\mathrm{T}-1$ , and 3 years after the transaction, ${\\mathrm{~T~+~}3}$ Toavoid endogeneity issues, inputs are always lagged by 1 year with respect to outputs. Using these models enables us to account explicitly for management's optimizing behavior over time. As a result we observe how efficient (productive) each sample firm was over this period compared with its direct peers. This information is summarized in the global efficiency score. The latter can also be decomposed into term efficiencies (three in our case), which ilustrate the path efficiency followed during this period and make it possible to capture gradual changes in efficiency that occur in underlying portfolio firms.  \n\nTo assess the implications of the type of financial backer on productivity, we regress the obtained cross-section of efficiency scores on variables of interest and a series of controls. All regressions use the Wooldridge-Papke estimator for fractional bounded response variables coined by Papke and Wooldridge (1996) and are particularly suitable for modeling DEA scores. We also implement a series of tests for the specification error (RESET) and for the goodness of functional form (GOFF) (Murteira and Ramalho, forthcoming; Ramalho et al., 2010, 2011, 2014). Model parameters are always estimated with robust standard errors.  \n\n### 4.2. Sample construction  \n\nThe empirical setting of this paper is the Belgian VC industry from 1998 to 2007. Our country choice is driven by two major rationales. Firstly, the Belgian VC industry is well-developed (Manigart et al., 2002) and has several important well-established GVC players that account for approximately half of the VC investments in Belgium during the period under study: Societé Regionale d\"Investissement de Wallonie (SRIW) for the Walloon region, Societe Regionale d\"'Investissement de Bruxelles (SRIB) for the Brussels region, and dozens of local regionalized funds such as Limburgse Reconversie Maatschappij (LRM) (province of Limbourg) and Meusinvest (province of Liege). Some (SRIW, SRIB) have existed in the industry for a considerable amount of time (more than 30 years). All are influenced technically by policy makers and operate as stand-alone funds.4 One particular case is Gewestelijke Investeringsmaatschappij voor Vlaanderen (GIMV), which was established as a GVC fund in the Flanders region and was later privatized.  \n\nSecondly, the Belgian economy is open (exports represent up to $90\\%$ of the gross domestic product) and consequently reflects major European trends. Belgium is also a federal country where the legal, accounting (compliance), social, and fiscal environments were essentially the same during the period under study. The effects of the main GVC options while supporting investments in the SME segment can thus be measured on a similar basis.  \n\nData from different secondary sources were combined to construct the raw dataset. We started by recording first-round VCbacked deals in Belgium using Factiva, various news archives, VC fund annual reports, press releases, newsletters, and announcements. To ensure the validity of the observation units, we cross-checked manually, whenever possible, each hit between the mentioned sources and Venture Economics, Capital IQ, and/or Bureau Van Dijk's Zephyr databases. Each raw data entry contains information on the year of financing round (T), the type of round (we focus on early- and development capital stages only), the target's identification number (VAT number), and the type of sponsor. The total number of unique first-time financings in this raw dataset is 1030. We cross-checked the dataset with the yearbooks of the European Venture Capital and Private Equity Association (EVCA) to verify its completeness. EVCA collects information (on a voluntary basis) directly from investors and disseminates industry statistics. Although we cannot rule out the potential self-reporting bias in EVCA's data, these reports have been used extensively by researchers as a benchmark of the Belgian VC population (Chanine et al, 2007; Manigart et al., 2002). According to EVCA, the number of Belgian firstround injections from 1998 to 2007 was 1162 (EVCA, 1998-2007). These records include replacement and turnaround deals, management buyouts, and investments in financial and real estate sectors. Our set accounts roughly for approximately $90\\%$ of thepopulation described by EVCA. Considering this, we believe that our data is fairly representative of the Belgian VC industry.  \n\nWe obtained firms' annual financial statements, creation dates, and industrial sector codes from Bureau Van Dijk's Bel-first database. Since our focus is on young entrepreneurial ventures we excluded firms from financial and real estate sectors, and those more than 10 years old. All monetary data was adjusted for inflation (base year 2004). Because of the large amount of missing data in Belfirst, our first sample, denoted base sample (BS), includes 515 VC-backed companies (with injection years spanning 1998-2004) for which we have complete data to perform all efficiency estimations over four complete annual cycles.? Details on the treatment of missing data are available in Appendix A.  \n\nPanel A of Table 1 presents the broad industry distribution at the two-digit NACE-BEL 2008 level of the VC-backed firms. In general, investments are concentrated heavily in the high-tech and services sectors (more than $50\\%$ ).Tabulation of the investmentpatterns categorized by the type of investor reveals that this concentration is only relevant for the PVC. GVC funds invest mostly in traditional sectors such as construction, manufacturing, and HORECA. An intuitive interpretation may be that public funds with lower knowledge and experience choose targets from traditional industries. This may also be paralleled with anecdotal evidence that most of the members of investment committees of public funds are former bankers and auditors. Consequently, they could prefer firms with more stable and secure cash flows. Alternatively, this structure could also be an illustration of the money-chasing-deals phenomenon (Gompers and Lerner, 20o0), and/or of the self-selection of high growth potential targets into private and reputable VC companies (Hsu, 2004; Sorensen, 2007).  \n\nPanel B displays the first round investment patterns categorized by injection years. As one would expect, the first round investments in Belgium followed an increasing trend until the dot-com crisis in 2o0o. Interestingly, while we observe the decline in PVC investments after 20oo, it is accompanied by growth in GVC funding. This seems to agree with the premise that GVC funds are supposed to be countercyclical and provide capital to SMEs in bad times when PVCs decrease their investments.  \n\nProductivity patterns can be industry-specific, especially considering the differences in the capital- and labor-intensive industries. Therefore, and similarly to Chemmanur et al. (2011) and Croce et al. (2013), we estimate efficiency separately for each industry sector (2-digit level).  \n\nWith the BS we can only evaluate the efficiency of the treated (i.e., VC-backed) firms. Another interesting question is what their efficiency would be compared with counterfactual firms. To investigate this second matter, we constructed a sample of control firms using the genetic propensity score matching algorithm with 1-to-1 matching without replacement (Diamond and Sekhon, forthcoming). Genetic matching is an iterative goal-seeking process, in which a better post-matching covariate balance is the objective. Diamond and Sekhon (forthcoming) present it as the generalization of the standard propensity score-matching procedure (Rosenbaum and Rubin, 1985; Dehejia and Wahba, 2002).  \n\nA set of possible counterfactuals is required for implementation of the genetic matching algorithm. To construct this set, we started from the entire population of Belgian privately-held firms (excluding the VC-backed ones). The procedure is as follows. Each firm in the BS was first matched to its respective industry (3 digits of the NACE-BEL 2008 classification). Within a given industry, we located the empirical decile to which a focal VC-backed firm belonged. Following Barber and Lyon (1996), this decile was defined on the basis of total assets, in the year before the VC injection occurred $(\\mathrm{T}-1)$ . Next, for a given VC-backed firm, the set of potential counterfactuals was defined as the union of the obtained and two adjacent deciles. If the focal firm belonged to the first or last decile of its industry, then the first or last three deciles were used, respectively. We repeated this sequence for each VC-backed firm in the BS, which gave a large pool of possible counterfactuals of similar size in the year immediately prior to VC financing. Finally, we used the logistic specification of the following propensity score model to define the matches:  \n\n$$\n\\begin{array}{r}{\\operatorname*{Pr}\\Bigl(\\mathsf{V C}_{i}=1|X_{\\mathsf{T}-1,i}\\Bigr)=\\beta_{i}+\\beta_{1}\\mathrm{Fixed~assets}+\\beta_{2}\\mathrm{Headcount}+\\beta_{3}\\mathsf{V a l u e}\\mathrm{~added}+\\beta_{4}\\mathsf{E q u i t y}+\\beta_{5}\\mathsf{R e t u r n~o n}.}\\ {+\\beta_{6}\\mathrm{Herfindahl~index}+\\beta_{7}\\mathsf{C r u d e~e f f i c i e n c y}+\\beta_{8}\\mathsf{F u n d r a i s i n g}+\\beta_{9}\\mathsf{I m v e s t m e n t s}+}\\ {+\\beta_{10}\\mathsf{T r a d e}\\mathrm{~sale(TS)exits}+\\beta_{11}\\mathsf{I P O}\\mathrm{~exits}+\\beta_{12}\\mathsf{H i g h t e c h~d u m m y}+\\mathsf{Y e a r~d u m m i e s}.}\\end{array}\n$$  \n\nwhere ${\\mathrm{VC}}_{i}$ is the treatment indicator for a firm i. All regressors are measured in the pre-transaction year T - 1, and winsorized at the 1st and 99th percentiles. The following section provides formal definitions of the variables.  \n\nTable1 Industry and investment patterns of the base sample.   \n\n\n<html><body><table><tr><td></td><td colspan=\"2\">AllVC-backedfirms</td><td colspan=\"2\">PVC-backed firms</td><td colspan=\"2\">GVC-backedfirms</td></tr><tr><td></td><td>N</td><td>%</td><td>N</td><td>%</td><td>N</td><td>%</td></tr><tr><td colspan=\"7\">PanelA:Industrypatterns-numberoffirmsperindustry</td></tr><tr><td>R & D (72)</td><td>40</td><td>8%</td><td>21</td><td>8%</td><td>19</td><td>8%</td></tr><tr><td>Manufacturing(12-33)</td><td>82</td><td>16%</td><td>26</td><td>10%</td><td>56</td><td>23%</td></tr><tr><td>Construction&commodities（35-43)</td><td>34</td><td>7%</td><td>6</td><td>2%</td><td>28</td><td>12%</td></tr><tr><td>HORECA& transport(45-56)</td><td>83</td><td>16%</td><td>33</td><td>12%</td><td>50</td><td>21%</td></tr><tr><td>IT & telecom (58-63)</td><td>110</td><td>21%</td><td>84</td><td>31%</td><td>26</td><td>11%</td></tr><tr><td>Services(69-71,>73)</td><td>166</td><td>32%</td><td>102</td><td>38%</td><td>64</td><td>26%</td></tr><tr><td colspan=\"7\">PanelB:Timepatterns—numberoffirmsperyear</td></tr><tr><td colspan=\"7\"></td></tr><tr><td>1998</td><td>65</td><td></td><td>35</td><td></td><td>30</td><td></td></tr><tr><td>1999</td><td>87</td><td></td><td>55</td><td></td><td>32</td><td></td></tr><tr><td>2000</td><td>101</td><td></td><td>69</td><td></td><td>32</td><td></td></tr><tr><td>2001</td><td>71</td><td></td><td>39</td><td></td><td>32</td><td></td></tr><tr><td>2002</td><td>72</td><td></td><td>32</td><td></td><td>40</td><td></td></tr><tr><td>2003</td><td>63</td><td></td><td>19</td><td></td><td>44</td><td></td></tr><tr><td>2004</td><td>56</td><td></td><td>23</td><td></td><td>33</td><td></td></tr></table></body></html>\n\nFigures in parentheses are the 2-digit NACE-BEL 2008 codes.  \n\n### 4.3. Variables  \n\n#### 4.3.1. Variables for effciency measurements  \n\nIn the DDEA logic, a decision-making unit (i.e., a firm) uses inputs to produce outputs in each period. Periods are connected via links, which can be desirable (profits) or undesirable (production waste), or free (unconstrained) or fixed (totally constrained). Desirable and undesirable links are treated as outputs and inputs, respectively. Fixed and free links do not enter into the efficiency score calculation directly but affect it via the constraints set (see Tone and Tsutsui (2010) for the discussion). In our analyses of efficiency, we use the input-oriented DsBM model with one output, two inputs, and one desirable link measure.  \n\nWe approximate the usual production factors by the number of employees (Headcount) for labor and by the net fixed assets (Fixed assets) for capital. Consistent with the premise that management should maximize shareholder value, the desirable link measure is the book value of equity capital (Equity) defined as the sum of issued capital and all reserves of the firm. Output is measured with the value added (Value added) variable computed as annual revenue less production costs (cost of goods sold). We use value added because sales revenues are not a mandatory disclosure item for unlisted firms in Belgium. All measures mentioned are used commonly in studies on productivity analysis (Alperovych et al., 2013; Amess, 2003; Chemmanur et al., 2011; Croce et al., 2013; Harris et al., 2005; Lichtenberg and Siegel, 1990). To avoid extreme values, the production factors are winsorized at the 1st and 99th percentiles.  \n\n#### 4.3.2. Variables for regression analyses  \n\nThe general variable of interest is a dummy that equals one when a private investor injects funds in an entrepreneurial firm at the first financing round ( PVC). This variable will be equal to one even when public and private investors syndicate. This is not necessarily an issue as there are reasons to believe that in such cases the leading role would be borne by the private investor (Brander et al., 2002; Lerner, 1994; Lockett and Wright, 2001).7  \n\nOur data enables us to distinguish between investments undertaken by major GVC players in Belgium - SRIW, the INVESTS (nine funds operating in Walloon region), and other GVC investors, which include SRIB, LRM, and some other GVC firms. Corresponding dummies were created for each of these cases. For comparison, we also created a dummy for GIMV - a former GVC investor. We also include a dummy for Syndication that equals one when the deal is syndicated. Another deal-related control that may impact efficiency changes post-financing is the number of financing rounds (Number of rounds) secured by a VC-backed firm after the initial capital injection.  \n\nAt the firm level we control for the age at the time of financing (Age), the initial profitability (ROA, measured as earnings before interest and taxes over total assets in the pre-injection year), and initial financial leverage (Leverage, defined as the sum of financial debt normalized by total assets in the pre-injection year). To control for the firms industry's concentration we construct the Herfindahl index in the same way as Chemmanur et al. (2011). Lastly, we include industry controls in the main regression models.  \n\n#### 4.3.3. Variables for propensity score matching  \n\nThe first VC funding round is defined as a dummy “\"VC\". To estimate the propensity score, we use several firm and VC industry level covariates measured in the pre-investment year. The net fixed assets, number of employees, value added, shareholder capital, ROA, and Herfindahl index have already been defined above. We add a crude measure of initial efficiency (Crude efficiency) computed as the value added over the number of employees.  \n\nThe literature identifies several measures of VC industry conditions as having an impact on the probability of securing VC financing (Gompers, 1996; Gompers and Lerner, 1998; Lerner, 2002a). To proxy for the overall VC supply, we include a log of the amount of funds raised (Fundraising). The demand is approximated by the log of the amount of VC and growth capital invested (Investments). Next, we control for the heat of the IPO market and general exit opportunities with the logs of exit proceeds from trade sales (TS exits), and from IPOs (IPO exits). These variables are defined on a per-portfolio company basis in the year before the first VC round occurs. Finally, injection year dummies and a high-tech sector dummy were included in the propensity score model.  \n\n### 4.4. Descriptive statistics  \n\nWe start with the Bs, for which the summary statistics are reported in Table 2. For convenience, we first discuss the inputs and outputs and then the regression-related variables. All input, link, and output variables of the VC-backed firms show increasing patterns. We also report the yearly percentage changes of the time-varying variables. Average net fixed assets grow from approximately 1448 k (median of 236 k) to $\\epsilon2755\\mathrm{k\\Omega}$ (median of E505 k) 3 years after the transaction. Similarly, we find that all VC-backed companies show steady growth in the average (from 9 to 17) and median (from 2 to 5) number of employees between the pre-transaction and the second posttransaction years. The same patterns are observed for the link variable showing steady increases in shareholder capital on average (from approximately $\\epsilon1326\\mathrm{~k~}$ to $\\epsilon3453\\mathrm{~k~}$ ), and on median (from approximately $\\ttin245k$ to E679 k). Finally, VC-backed firms demonstrate increasing value-added patterns from 327 k to 875 k (average), and from $\\epsilon56\\mathrm{~k~}$ to $\\epsilon260\\mathrm{k\\Omega}$ (median) 3 years after the transaction.  \n\nTable 2 also tabulates the summary for the PVC- and GVC-backed firms. It appears that GVC funds back approximately half $(47\\%)$ of the VC-backed firms in Belgium (243 firms out of 515). In terms of fixed assets, PVC-backed firms are slightly smaller on average before VC injection. They overtake GVC-backed companies by a low margin in the second year. Median-wise, PVC-backed firms are significantly (as suggested by the non-parametric Mann-Whitney tests) smaller than their GVC-backed peers. PVC-backed firms are larger in terms of the headcount and seem to create more jobs on average over time In terms of output, we find that both PVC- and GVC-backed frms are equal on average in the pre-transaction year (future GVC-backed firms produce slightly more value added). Both types of firms display a steady growth in the value added variable on average and on median. However, the output growth accelerates considerably in PVCbacked firms in the second year after the transaction. Firms backed by private investors are also younger (average age is 1.81 vs. 2.27), less profitable (average ROA is -- 0.38 vs. $-0.17,$ ), and less levered (average debt-to-total assets is 0.13 vs. 0.26).  \n\nFew statistically significant differences in averages exist between both types of firms. We observe, however, statistically significant differences in the medians of almost all variables except for the number of employees.  \n\nPanel B of Table 2 reveals interesting information on the geographical distribution of the VC investment flow. Although the global picture is relatively balanced (193 investments in the Flanders region vs. 247 in the Walloon region), the PVC/GVC tabulations show that the vast majority of the PVC flows to the Flanders region $(63\\%)$ whereas the Walloon region leads in terms of the GvC $(82\\%)$ .This result confirms the substantial regional heterogeneity in the Belgian VC industry.  \n\nThe deal-related variables are summarized in Table 3. Consistent with the staging and syndication literature, PVC investors syndicate more often ( $13\\%$ Vs.only $3\\%$ of the total of 515 firms) and engage in more financing rounds (1.24 vs. 1.03) with their portfolio firms (Cumming and Maclntosh, 2007; Davila and Foster, 2003; Gompers, 1995, 1996). It appears that the most active GVC investor is the INVESTS with 196 first-round financings. This represents approximately $38\\%$ of the total number of 515 investments in Belgium from 1998 to 2004 and accounts for more than $75\\%$ of the GVC-financed companies.  \n\nA description of the sample created using the propensity score-matching procedure is reported in Table 4. The combined sample (CS) displays growth in all productivity-related variables. NVC-backed companies show slow-growing or relatively stable levels of fixed assets, and of the headcount. In the VC-backed firms these variables grow significantly. Both types of firms increase their shareholders' capital and output levels between the pre- and third post-transaction years. Pre-transaction VC-backed firms appear to be on average slightly younger (2 vs. 5.32 years old). Their ROA is also much lower compared with their peers ( $\\cdot-0.28$ Vs. $-0.22,$ . Finally, untreated firms show more aggressive financing policies, with an average debt-to-total asset ratio of 3.45 against 0.19 in the VC-backed firms.  \n\nThe differences in growth and in the levels of inputs, output, and link measures may affect efficiency estimations through the returns-to-scale (RTS) assumptions as discussed in Banker et al. (1984). The developments in DEA methodology have suggested one non-parametric and two parametric tests of the RTS assumptions (Banker, 1993, 1996; Banker et al., 2010). Although not tabulated here, we have implemented all three tests. The results reject the null of the constant RTS assumption in favor of the variable assumption (VRs). In what follows, we report only the VRS specification results. Finally, we have analyzed Pearson correlation matrices for the BS and CS and found no indication of potential multicollinearity problems.  \n\n## 5. Results  \n\n### 5.1. Effciency estimations  \n\nTable 5 reports the results of efficiency estimations. In Panels A and B we report the averages of the overall efficiency scores (in bold) and their decomposition into three term efficiencies. Panel C reports a brief summary of the three DEA specific difference  \n\nPlease cite this article as: Alperovych, Y, et al., How does governmental versus private venture capital backing affect a frm's efficiency? Evidence from Belgium, J. Bus. Venturing (2014), http://dx.doi.org/10.1016/jbusvent.2014.11.001  \n\nTable2 Descriptive statistics of the base sample.  \n\n<html><body><table><tr><td></td><td>Mean</td><td>△%</td><td>Median</td><td>%</td><td>SD</td><td>Mean</td><td>%</td><td>Median</td><td>%</td><td>SD</td><td>Mean</td><td>%</td><td>Median</td><td>%</td><td>SD</td><td>t</td><td>MW</td></tr><tr><td>PanelA:Mainvariables</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>Fixed assets, T — 1</td><td>1447.58</td><td></td><td>235.96</td><td>一</td><td>4447.18</td><td>1409.24</td><td></td><td>152.38</td><td>一</td><td>4315.35</td><td>1490.49</td><td>一</td><td>348.55</td><td></td><td>4598.83</td><td></td><td>**求</td></tr><tr><td>Fixed assets, T</td><td>1708.58</td><td>18%</td><td>300.63</td><td>27%</td><td>4469.11</td><td>1689.91</td><td>20%</td><td>227.78</td><td>49%</td><td>4456.23</td><td>1729.47</td><td>16%</td><td>462.90</td><td>33%</td><td>4492.58</td><td></td><td>**求</td></tr><tr><td>Fixed assets, T + 1</td><td>2287.43</td><td>34%</td><td>463.65</td><td>54%</td><td>6105.90</td><td>2345.45</td><td>39%</td><td>326.55</td><td>43%</td><td>6873.87</td><td>2222.49</td><td>29%</td><td>616.73</td><td>33%</td><td>5124.98</td><td></td><td>**亲</td></tr><tr><td>Fixed assets, T + 2</td><td>2755.28</td><td>20%</td><td>504.78</td><td>%6</td><td>9397.85</td><td>2955.14</td><td>26%</td><td>372.75</td><td>14%</td><td>11,712.36</td><td>2531.56</td><td>14%</td><td>670.00</td><td>9%</td><td>5820.17</td><td></td><td></td></tr><tr><td>Headcount, T —1</td><td>9.04</td><td></td><td>2.00</td><td></td><td>34.80</td><td>9.91</td><td></td><td>2.00</td><td></td><td>43.55</td><td>8.06</td><td></td><td>2.00</td><td></td><td>21.12</td><td></td><td></td></tr><tr><td>Headcount, T</td><td>10.55</td><td>17%</td><td>2.67</td><td>33%</td><td>40.06</td><td>11.97</td><td>21%</td><td>2.33</td><td>17%</td><td>51.24</td><td>8.97</td><td>11%</td><td>3.00</td><td>50%</td><td>21.53</td><td></td><td></td></tr><tr><td>Headcount,T + 1</td><td>13.14</td><td>24%</td><td>4.00</td><td>50%</td><td>44.76</td><td>15.52</td><td>30%</td><td>4.00</td><td>71%</td><td>56.98</td><td>10.47</td><td>17%</td><td>3.33</td><td>11%</td><td>24.61</td><td></td><td></td></tr><tr><td>Headcount,T + 2</td><td>17.11</td><td>30%</td><td>5.00</td><td>25%</td><td>55.81</td><td>20.49</td><td>32%</td><td>5.00</td><td>25%</td><td>70.60</td><td>13.33</td><td>27%</td><td>5.00</td><td>50%</td><td>31.75</td><td></td><td></td></tr><tr><td>Equity, T — 1</td><td>1325.69</td><td></td><td>245.14</td><td></td><td>5117.28</td><td>1354.18</td><td></td><td>315.71</td><td></td><td>3601.75</td><td>1293.79</td><td></td><td>202.14</td><td></td><td>6410.17</td><td></td><td></td></tr><tr><td>Equity,T</td><td>1898.20</td><td>43%</td><td>400.00</td><td>63%</td><td>5714.42</td><td>2165.43</td><td>60%</td><td>530.91</td><td>68%</td><td>4879.23</td><td>1599.08</td><td>24%</td><td>295.31</td><td>46%</td><td>6521.29</td><td></td><td>**米</td></tr><tr><td>Equity, T + 1</td><td>2636.00</td><td>39%</td><td>547.00</td><td>37%</td><td>8284.29</td><td>3326.27</td><td>54%</td><td>888.23</td><td>67%</td><td>9192.93</td><td>1863.35</td><td>17%</td><td>350.62</td><td>19%</td><td>7070.69</td><td>*求</td><td>***</td></tr><tr><td>Equity,T + 2</td><td>3453.21</td><td>31%</td><td>678.78</td><td>24%</td><td>13,840.63</td><td>4845.39</td><td>46%</td><td>1016.29</td><td>14%</td><td>18,243.96</td><td>1894.88</td><td>2%</td><td>429.96</td><td>23%</td><td>5433.98</td><td>*求</td><td>***</td></tr><tr><td>Value added, T - 1</td><td>327.22</td><td></td><td>55.60</td><td></td><td>2239.55</td><td>302.10</td><td></td><td>26.33</td><td></td><td>2886.11</td><td>355.34</td><td></td><td>71.47</td><td></td><td>1150.49</td><td></td><td>**求</td></tr><tr><td>Value added, T</td><td>379.23</td><td>16%</td><td>59.01</td><td>6%</td><td>2618.96</td><td>353.99</td><td>17%</td><td>30.45</td><td>16%</td><td>3410.01</td><td>407.48</td><td>15%</td><td>83.72</td><td>17%</td><td>1243.02</td><td></td><td>**求</td></tr><tr><td>Value added, T + 1</td><td>551.75</td><td>45% 32%</td><td>93.97 196.06</td><td>59%</td><td>2877.90</td><td>550.52</td><td>56%</td><td>58.02</td><td>91%</td><td>3691.99</td><td>553.12</td><td>36%</td><td>141.00</td><td>68%</td><td>1525.48</td><td></td><td>**求 **亲</td></tr><tr><td>Value added, T + 2</td><td>727.45 875.20</td><td>20%</td><td>260.00</td><td>109% 33%</td><td>3264.60</td><td>752.01</td><td>37%</td><td>140.76</td><td>143%</td><td>4197.61</td><td>699.95</td><td>27%</td><td>277.00</td><td>96%</td><td>1703.97</td><td></td><td>*</td></tr><tr><td>Value added, T + 3</td><td>2.03</td><td></td><td>0.00</td><td></td><td>3143.01 2.98</td><td>990.38</td><td>32%</td><td>197.10 0.00</td><td>40%</td><td>3993.90 2.67</td><td>746.27</td><td>7%</td><td>314.20</td><td>13%</td><td>1757.07</td><td>米</td><td></td></tr><tr><td>Age,T - 1</td><td>-0.28</td><td></td><td>0.05</td><td></td><td>0.95</td><td>1.81 0.38</td><td></td><td>- 0.12</td><td></td><td></td><td>2.27</td><td>-</td><td>0.00</td><td></td><td>3.28</td><td></td><td>***</td></tr><tr><td>ROA,T - 1</td><td>0.19</td><td>-</td><td>0.05</td><td></td><td>0.25</td><td>0.13</td><td></td><td>0.00</td><td></td><td>0.99</td><td> 0.17</td><td>-</td><td>-0.02</td><td></td><td>0.89</td><td></td><td></td></tr><tr><td>Leverage, T — 1</td><td>0.09</td><td></td><td>0.04</td><td></td><td>0.13</td><td>0.09</td><td></td><td>0.04</td><td></td><td>0.23</td><td>0.26 0.09</td><td></td><td>0.23</td><td></td><td>0.26</td><td></td><td>***</td></tr><tr><td>Herfindahl index, T — 1</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>0.12</td><td></td><td></td><td>04.0</td><td></td><td>0.14</td><td></td><td></td></tr><tr><td>Panel B: Regional split</td><td colspan=\"4\"></td><td colspan=\"8\"></td><td colspan=\"4\"></td></tr><tr><td></td><td colspan=\"4\">All VC-backed firms</td><td colspan=\"8\">PVC-backed firms</td><td colspan=\"4\">GVC-backed firms N %</td></tr><tr><td></td><td colspan=\"4\">N</td><td colspan=\"4\"</table></body></html>  \n\neprtsepst $\\Delta\\%$ shows theyalygrothinthecorreponding arabes MWdenotes the non-pametrict oan-Whitney sged rank tet \\*\\*, and \\* ndicate $5\\%,$ and significance, respectively. All monetary fgures are in 2004 thousands EURO.  \n\nTable 3 Deal-related variables.   \n\n\n<html><body><table><tr><td></td><td>N</td><td>% of (1)</td><td>N</td><td>% of (1)</td><td>Mean</td><td>SD</td></tr><tr><td></td><td colspan=\"2\">Firstroundinvestments</td><td colspan=\"2\">Syndication</td><td colspan=\"2\">Numberofrounds</td></tr><tr><td>PanelA:Generalinfo</td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>VC-backed firms (1)</td><td>515</td><td>100%</td><td>82</td><td>16%</td><td>1.142</td><td>0.480</td></tr><tr><td>PVC-backedfirms</td><td>272</td><td>53%</td><td>69</td><td>13%</td><td>1.239</td><td>0.618</td></tr><tr><td>GVC-backedfirms</td><td>243</td><td>47%</td><td>13</td><td>3%</td><td>1.033</td><td>0.201</td></tr><tr><td colspan=\"7\">PanelB:Byinvestmentfirm</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>GIMV</td><td>15</td><td>3%</td><td></td><td></td><td></td><td></td></tr><tr><td>SRIW</td><td>41</td><td>8%</td><td></td><td></td><td></td><td></td></tr><tr><td>INVESTS</td><td>196</td><td>38%</td><td></td><td></td><td></td><td></td></tr><tr><td>OtherGVC</td><td>46</td><td>9%</td><td></td><td></td><td></td><td></td></tr></table></body></html>\n\nThe table reports the descriptive statistics of the deal-related variables for a sample of the 515 VC-backed firms. For the variable definitions, see Section 4.  \n\ntests for the categories of our interest (Banker, 1993; Banker et al., 2010). For brevity, we aggregate the test results by computing the average number of significance stars. For example, if results from the three tests suggest that a difference is significant at $1\\%,5\\%$ and $10\\%$ respectively $(^{***},^{**},^{*})$ , we report this difference to be roughly significant at $5\\%\\left(^{**}\\right)$  \n\nPanel A highlights the results for the sample of 515 VC-backed firms. The average efficiency level ofVC-backed firms over the 4-year studywindow is approximately 0.56 $(56\\%)$ . The term structure reveals that the overall efficiency increases over the $\\mathrm{T}-1$ to $\\mathrm{T}+3$ period by approximately $6.4\\%$ . The pattern of these improvements seems to be volatile and somewhat concave (also shown in Fig. 1(a)). A tabulation of the GVC- and PVC-backed firms indicates that overall,the latter are more efficient than the former by approximately $10\\%$ This difference is statistically significant at the aggregate $1\\%$ level. In both cases, we observe increases in efficiency following the transaction year. PVC-backed firms show higher pre-transaction efficiency levels, and demonstrate higher gains in efficiency from T - 1 to T. These results indicate that PVC firms may choose potentially more efficient firms within the pool of candidates for VC financing. The difference between PVC- and GVC-backed firms in this period is only marginally significant at the aggregate $10\\%$ level. Both types of portfolio companies lose productivity in the second post-transaction year. The slight growth in efficiency resumes in the PVC-backed firms whereas GVC-backed firms continue to lose productivity. In each post-transaction period, the difference in productivity in the PVC- and GVC-backed firms is significant at the aggregate $1\\%$ level.  \n\nPanel B and Fig. 1(b) report results of the efficiency measurements using the CS. Global efficiency in the SMEs is approximately $47\\%$ VC-backed firms lag $7\\%$ behind the average, and $13\\%$ behind their NvC-backed peers in terms of overall productivity over the window of estimation. The difference between VC- and NVC-backed firms seems to be only marginally significant at the aggregate $10\\%$ level (see Panel C). Consistent with our previous results, the difference in overall productivity of PVC- and GVC-funded firms is significant at the aggregate $1\\%$ level. In the CS we find no differences in the pre-transaction efficiency levels between these two categories. In each posttransaction year, however, the differences are statistically significant at the $5\\%$ or $1\\%$ level. The “underperformance\" of VC appears to be caused by GVC. The difference in productivity of the GVC- and NVC-backed firms is significant at the aggregate $5\\%$ level overall. PVC-backed firms have almost $50\\%$ (0.496) efficiency levels and this is $2\\%$ above the average productivity score of comparable firms. Interestingly, this difference is insignificant (neither are the differences in the term efficiencies), which suggests no effect of PVC funding.  \n\nPanels A& B suggest that INVESTS funds are the source of this subpar “performance\". They seem to choose the least efficient firms and reduce GVC estimates in the post transaction years. This may suggest that our results are driven by this investor. We note however that INVESTS is a category that regroups a set of various GVC funds that operate independently, and that INVESTS is involved in roughly $80\\%$ GVC-backed deals in our sample. We are therefore effectively talking about the major bulk of GVC flow. Moreover, in a series of unreported (but available upon request) tests we verify that INVESTS-backing differs significantly from that by PVC, SRIW, and NVC pre- and posttransaction. We found no difference in efficiency of firms backed by INVESTS compared with those funded by other GVC investors.  \n\nOverall, the evidence is supportive of our main hypothesis. Entrepreneurial firms backed by PVC seem to show greater efficiency levels and improvements compared with their GvC-backed counterparts. Although these results are reassuring, the casual link between investor type and efficiency is still an open question. To understand this link, we move to multivariate regression analyses presented in the following section.  \n\n### 5.2. Type of investor and its implications on efficiency  \n\nTable 6 reports the regressions estimated using the BS of 515 VC-backed firms. Column (0) provides results for the zero-model in which only control variables are used. Models (1) to (5) test the impact of a respective investor type on the overall efficiency over the studyperiod.The $R^{2}$ is computed following Papke and Wooldridge ( 1996) and Ramalho et al. (2010) as a squared correlation between the observed and predicted values of the response. As before, we report GIMV estimations for comparison.  \n\nModel ( 1) suggests that the presence of private investor in the first financing round has a positive and statistically significant $(1\\%)$ effect on the future efficiency of a portfolio frm. The corresponding average partial effect (0.099) implies that the arrival of the PVC investor in the equity of the firm improves productivity by almost $10\\%$ (on average) over the 3 years post-transaction. Models (2) to (5) show results of similar estimations to separate out the effects of different public investors. Model (6) combines all specific public investors and GIMV. As could be expected, GIMV has a statistically significant effect on the productivity of its targets. The gain in  \n\nTable4 Descriptive statistics of the combined sample: genetic matching, criterion: total assets.   \n\n\n<html><body><table><tr><td></td><td></td><td colspan=\"4\">All firms</td><td colspan=\"6\">VC-backedfirms</td><td colspan=\"4\">NVC-backed firms</td><td colspan=\"2\">Tests</td></tr><tr><td></td><td>Mean</td><td></td><td>%</td><td>Median %</td><td>SD</td><td>Mean</td><td>△%</td><td>Median</td><td>%</td><td>SD</td><td>Mean</td><td>%</td><td>Median</td><td>%</td><td>SD</td><td>t</td><td>MW</td></tr><tr><td>Fixed assets, T — 1</td><td></td><td>1364.21</td><td></td><td>236.12</td><td>3830.39</td><td>1372.38</td><td></td><td>235.96</td><td></td><td>3779.12</td><td>1356.04</td><td></td><td>236.28</td><td></td><td>3884.64</td><td></td><td></td></tr><tr><td>Fixed assets, T</td><td></td><td>1458.46</td><td>7%</td><td>253.72</td><td>3763.17</td><td>1635.98</td><td>19%</td><td>300.63</td><td>27%</td><td>3943.61</td><td>1280.93</td><td>-6%</td><td>224.81</td><td>-5%</td><td>3568.65</td><td></td><td></td></tr><tr><td>Fixed assets, T + 1</td><td></td><td>1786.64</td><td>23%</td><td>316.21</td><td>25% 4737.09</td><td>2155.71</td><td>32%</td><td>463.65</td><td>54%</td><td>5041.88</td><td>1417.57</td><td>11%</td><td>220.38</td><td>-2%</td><td>4385.23</td><td>承*</td><td>**求</td></tr><tr><td>Fixed assets, T + 2</td><td></td><td>2045.28</td><td>14%</td><td>341.66</td><td>5762.50</td><td>2444.40</td><td>13%</td><td>504.78</td><td>9%</td><td>5837.88</td><td>1646.15</td><td>16%</td><td>210.75</td><td>-4%</td><td>5663.69</td><td></td><td></td></tr><tr><td>Headcount,T —1</td><td></td><td>7.47</td><td></td><td>2.00</td><td>15.67 16.52</td><td></td><td></td><td>2.00</td><td></td><td>15.78</td><td>7.44</td><td></td><td>2.00</td><td></td><td>15.58</td><td></td><td></td></tr><tr><td>Headcount,T</td><td></td><td>8.33</td><td>12%</td><td>2.00</td><td></td><td>10.71</td><td>15%</td><td>2.67 4.00</td><td>33%</td><td>16.63</td><td>8.01</td><td>8%</td><td>2.00</td><td>0%</td><td>16.41</td><td></td><td></td></tr><tr><td>Headcount,T + 1</td><td></td><td>9.52</td><td>14%</td><td>3.00</td><td>50%</td><td></td><td>24%</td><td></td><td>50%</td><td>19.36</td><td>8.34</td><td>4%</td><td>2.00</td><td>0%</td><td>16.77</td><td></td><td>米京求</td></tr><tr><td>Headcount, T + 2</td><td></td><td>11.34</td><td>19%</td><td>3.00</td><td></td><td>23.19</td><td>31%</td><td></td><td>25%</td><td>25.73</td><td>8.66</td><td>4%</td><td>2.00</td><td>0%</td><td>20.01</td><td>*京米</td><td>米京求</td></tr><tr><td>Equity, T - 1</td><td></td><td>1321.56</td><td></td><td>233.29</td><td>4054.44 31%</td><td>1205.93</td><td></td><td>245.14</td><td></td><td>3433.00</td><td>1437.19</td><td></td><td>222.84</td><td></td><td>4593.11</td><td></td><td></td></tr><tr><td>Equity, T</td><td></td><td>1673.38</td><td>27%</td><td>306.77</td><td>4654.82 21%</td><td>1782.57</td><td>48%</td><td>400.00</td><td>63%</td><td>4372.97</td><td>1564.19</td><td>%6</td><td>224.62</td><td>1%</td><td>4922.41</td><td></td><td>**求 **求</td></tr><tr><td>Equity, T + 1</td><td></td><td>1975.12</td><td>18%</td><td>370.39</td><td>5284.55</td><td>2314.98</td><td>30%</td><td>547.00</td><td>37%</td><td>5323.58</td><td>1635.26</td><td>5%</td><td>241.31</td><td>7%</td><td>5228.32</td><td></td><td>**米</td></tr><tr><td>Equity,T + 2</td><td></td><td>2330.95</td><td>18%</td><td>400.72</td><td>6531.06</td><td>2810.14</td><td>21%</td><td>678.78</td><td>24%</td><td>6652.46</td><td>1851.77</td><td>13%</td><td>229.72</td><td>-5%</td><td>6377.85</td><td></td><td></td></tr><tr><td>Value added, T — 1</td><td></td><td>245.95</td><td>33%</td><td>59.32</td><td>800.72 33%</td><td>228.13</td><td></td><td>55.60</td><td></td><td>832.58</td><td>263.77</td><td></td><td>61.59</td><td></td><td>767.94</td><td></td><td></td></tr><tr><td>Value added,T</td><td></td><td>326.18</td><td>48%</td><td>78.89 104.02</td><td>943.24 32%</td><td>266.04</td><td>17%</td><td>59.01</td><td></td><td>950.72</td><td>386.31</td><td>46%</td><td>97.00</td><td>57%</td><td>932.75</td><td></td><td>**求</td></tr><tr><td>Value added, T + 1</td><td></td><td>482.56 604.05</td><td>25%</td><td>158.37</td><td>1328.76 1532.70</td><td>455.10</td><td>71%</td><td>93.97</td><td>59%</td><td>1349.88</td><td>510.02 565.75</td><td>32% 11%</td><td>106.85</td><td>10%</td><td>1308.04</td><td></td><td>米米</td></tr><tr><td>Value added,T + 2</td><td></td><td>699.66</td><td>16%</td><td>182.79</td><td>1673.90</td><td>642.35 805.38</td><td>41% 25%</td><td>196.06 260.00</td><td>109% 33%</td><td>1585.64 1825.21</td><td>593.94</td><td>5%</td><td>119.30 125.52</td><td>12%</td><td>1478.42 1501.85</td><td></td><td>**求</td></tr><tr><td>Value added, T + 3</td><td></td><td>3.67</td><td></td><td>3.00</td><td></td><td></td><td></td><td></td><td></td><td></td><td>5.32</td><td></td><td></td><td>5%</td><td>2.93</td><td>*京米</td><td></td></tr><tr><td>Age, T - 1</td><td></td><td>0.25</td><td></td><td>-0.03</td><td></td><td></td><td></td><td>0.00</td><td></td><td>2.98</td><td>-0.22</td><td></td><td>5.00</td><td></td><td>0.81</td><td></td><td></td></tr><tr><td>ROA, T - 1</td><td></td><td>1.82</td><td></td><td>0.08</td><td></td><td>-0.28</td><td></td><td>-0.05</td><td></td><td>0.95</td><td></td><td></td><td>-0.01</td><td>-</td><td></td><td></td><td></td></tr><tr><td>Leverage, T —1</td><td></td><td></td><td></td><td></td><td>51.61 0.13</td><td>0.19</td><td></td><td>0.05</td><td>一</td><td>0.25</td><td>3.45</td><td></td><td>0.11</td><td></td><td>72.99</td><td></td><td></td></tr><tr><td>Herfindahl index,T —1</td><td></td><td>0.08 1030</td><td></td><td>0.03</td><td></td><td>0.09 515</td><td>一</td><td>0.04</td><td></td><td>0.13</td><td>0.08 515</td><td>一</td><td>0.03</td><td></td><td>0.12</td><td></td><td>**求</td></tr></table></body></html>\n\nThe tablereports the descriptive statistics forthe matched sample based on the total assets criterion.IndexT denotes the year of theVCinjection. $\\Delta\\%$ shows the yearly growth in the corresponding variables.MW denotes the non-parametrictwo-sidedMann-Whitney signed ranktest\\*\\*, and $^*$ indicate $1\\%$ $5\\%$ and $10\\%$ siifatilit bold. Fixed assets, Headcount, Equity, and Value added are winsorized at the 1st and 99th percentiles.  \n\nTable5 Summary of dynamic efficiency scores.   \n\n\n<html><body><table><tr><td rowspan=\"2\"></td><td colspan=\"5\">By category</td><td colspan=\"5\">By VCsubcategory</td></tr><tr><td>All firms</td><td>NVC</td><td>All VC</td><td>PVC</td><td>GVC</td><td>GIMV</td><td>Other PVC</td><td>SRIW</td><td>INVESTS</td><td>OtherGVC</td></tr><tr><td colspan=\"9\">Panel A:Basesample</td><td></td></tr><tr><td>Overallscore</td><td></td><td></td><td>0.563</td><td>0.608</td><td>0.512</td><td>0.724</td><td>0.602</td><td>0.631</td><td>0.481</td><td>0.561</td></tr><tr><td></td><td>-</td><td>一</td><td>[0.249]</td><td>[0.242]</td><td>[0.247]</td><td>[0.251]</td><td>[0.240]</td><td>[0.242]</td><td>[0.241]</td><td>[0.242]</td></tr><tr><td rowspan=\"2\">Period 0</td><td></td><td>一</td><td>0.511</td><td>0.532</td><td>0.489</td><td>0.633</td><td>0.526</td><td>0.597</td><td>0.442</td><td>0.526</td></tr><tr><td>一</td><td>一</td><td>[0.297]</td><td>[0.300]</td><td>[0.292]</td><td>[0.332]</td><td>[0.298]</td><td>[0.321]</td><td>[0.280]</td><td>[0.317]</td></tr><tr><td rowspan=\"2\">Period 1</td><td>-</td><td>一</td><td>0.590</td><td>0.641</td><td>0.533</td><td>0.771</td><td>0.633</td><td>0.634</td><td>0.501</td><td>0.592</td></tr><tr><td></td><td></td><td>[0.305]</td><td>[0.304]</td><td>[0.298]</td><td>[0.311]</td><td>[0.302]</td><td>[0.265]</td><td>[0.288]</td><td>[0.346]</td></tr><tr><td rowspan=\"2\">Period 2</td><td></td><td>一</td><td>0.575</td><td>0.625</td><td>0.520</td><td>0.722</td><td>0.619</td><td>0.683</td><td>0.489</td><td>0.594</td></tr><tr><td></td><td>一</td><td>[0.308]</td><td>[0.307]</td><td>[0.300]</td><td>[0.348]</td><td>[0.304]</td><td>[0.291]</td><td>[0.294]</td><td>[0.303]</td></tr><tr><td rowspan=\"2\">Period 3</td><td></td><td></td><td>0.575</td><td>0.636</td><td>0.508</td><td>0.769</td><td>0.628</td><td>0.609</td><td>0.493</td><td>0.530</td></tr><tr><td></td><td></td><td>[0.319]</td><td>[0.316]</td><td>[0.309]</td><td>[0.313]</td><td>[0.315]</td><td>[0.295]</td><td>[0.297]</td><td>[0.349]</td></tr><tr><td rowspan=\"2\">Observations</td><td></td><td></td><td>515</td><td>272</td><td>243</td><td>15</td><td>257</td><td>41</td><td>196</td><td>46</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td colspan=\"2\">Panel B: Combined sample Overallscore</td><td>0.476</td><td>0.463</td><td>0.496</td><td>0.426</td><td>0.586</td><td>0.491</td><td>0.495</td><td>0.402</td><td></td></tr><tr><td rowspan=\"2\"></td><td>0.470</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>0.449</td></tr><tr><td>[0.235]</td><td>[0.232]</td><td>[0.237]</td><td>[0.243]</td><td>[0.225]</td><td>[0.288]</td><td>[0.240]</td><td>[0.245]</td><td>[0.216]</td><td>[0.238]</td></tr><tr><td rowspan=\"2\">Period 0</td><td>0.448</td><td>0.457</td><td>0.439</td><td>0.452</td><td>0.424</td><td>0.520</td><td>0.448</td><td>0.504</td><td>0.385</td><td>0.452</td></tr><tr><td>[0.267]</td><td>[0.267]</td><td>[0.268]</td><td>[0.276]</td><td>[0.258]</td><td>[0.305]</td><td>[0.274]</td><td>[0.297]</td><td>[0.246]</td><td>[0.275]</td></tr><tr><td rowspan=\"2\">Period 1</td><td>0.490</td><td>0.493</td><td>0.486</td><td>0.514</td><td>0.455</td><td>0.614</td><td>0.508</td><td>0.529</td><td>0.431</td><td>0.464</td></tr><tr><td>[0.274]</td><td>[0.267]</td><td>[0.282]</td><td>[0.287]</td><td>[0.274]</td><td>[0.352]</td><td>[0.283]</td><td>[0.272]</td><td>[0.263]</td><td>[0.321]</td></tr><tr><td rowspan=\"2\">Period 2</td><td>0.476</td><td>0.480</td><td>0.472</td><td>0.505</td><td>0.434</td><td>0.614</td><td>0.499</td><td>0.506</td><td>0.416</td><td>0.463</td></tr><tr><td>[0.282]</td><td>[0.276]</td><td>[0.288]</td><td>[0.294]</td><td>[0.277]</td><td>[0.373]</td><td>[0.289]</td><td>[0.282]</td><td>[0.267]</td><td>[0.303]</td></tr><tr><td rowspan=\"2\">Period 3</td><td>0.466</td><td>0.476</td><td>0.456</td><td>0.514</td><td>0.392</td><td>0.594</td><td>0.509</td><td>0.439</td><td>0.377</td><td>0.417</td></tr><tr><td>[0.288]</td><td>[0.265]</td><td>[0.309]</td><td>[0.323]</td><td>[0.278]</td><td>[0.339]</td><td>[0.323]</td><td>[0.307]</td><td>[0.265]</td><td>[0.334]</td></tr><tr><td>Observations</td><td>1030</td><td>515</td><td>515</td><td>272</td><td>243</td><td>15</td><td>257</td><td>41</td><td>196</td><td>46</td></tr></table></body></html>  \n\nPanel C: Difference tests   \n\n\n<html><body><table><tr><td rowspan=\"2\"></td><td>BS</td><td colspan=\"4\">CS</td></tr><tr><td>GVCvs.PVC</td><td>GVCvs.PVC</td><td>GVCvs.NVC</td><td>PVC vs.NVC</td><td>NVC vs.VC</td></tr><tr><td>Overallscore</td><td>***</td><td>**串</td><td>**</td><td></td><td>*</td></tr><tr><td>Period 0</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>Period 1</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>Period 2</td><td>**米</td><td>*求</td><td>*求</td><td></td><td></td></tr><tr><td>Period3</td><td>*京*</td><td>***</td><td>***</td><td>*</td><td></td></tr></table></body></html>  \n\nThe table reports a summary of the DDEA estimations of efficiency performed on the BS of 515 VC-backed firms and on the CS of 1030 firms. Scores are estimated using the input-oriented variable returns-to-scale model with industry clustering. The overall score (in bold) is the measure of global efficiency from T — 1 to $\\mathrm{~T~+~}3$ WvithT being the year of VC funding. Period 0 corresponds to years T - 1 to T. Periods 1, 2, and 3 are defined accordingly. VC and NVC indicate VC- and non-VC-backed firms, respectively. PVC and NVC stand for private and government VC backing. For details on the methodology and variables used, see Section 4. Standard errors are given in brackets.\\*,\\*\\*,and \\*indicate 1%, $5\\%,$ and $10\\%$ average significance of the DEA score tests, respectively.  \n\nproductivity can reach $19\\%$ (Model (3)), although in the combined model the effect is at the $15\\%$ level (Model (6)). Conversely, being backed by one of the INVESTS funds leads to a statistically significant destruction in productivity by almost $13\\%$ Allregression tests (see the p-values) reject the errors in specification or functional form.  \n\nTable 7 reports estimations for the Cs. In accordance with our univariate analysis of efficiency, Model (1) reports that in general, the presence of a VC investor in the equity of the firm has a negative and significant $(5\\%)$ impact on the subsequent productivity of portfolio firms. The economic size of the average partial effect implies a loss in productivity of approximately $4.2\\%$ over the study period. The split between different investor types sugests that being financed by a PVC investor (Model (2)) has a positive but rather weak $(10\\%)$ effect. On average, PVC-backed firms see their overall efficiency improve by approximately $3.2\\%$ Models (4) and (5) suggest that GIMV backing has a statistical (at the $5\\%$ level) and positive economic $(12.2\\%)$ effect on the dynamic productivity while INVESTS-sponsored companies lose approximately $11.8\\%$ on average in efficiency over the study period. This latter effect is statistically significant at $1\\%$ and is also confirmed in Model (7). Again, the regression tests suggest no errors in the specifications or functional forms of the models.  \n\nOverall, these findings are supportive of the hypothesis discussed in Section 3 although the CS shows that the presence of PVC investors has a limited effect on post-transaction efficiency. As the efficiency scores can be decomposed into term efficiencies, it is also possible to investigate whether the VC investor type effect persists with time. To answer this question, we run separate unreported regressions of the term efficiency scores on the variables of interest and controls. The results are consistent with our main discussion.  \n\n### 5.3. Selection and endogeneity issues  \n\nSome issues may exist related to the endogenous nature of VC funding and two distinct sorts of biases could apply to the BS and CS. Firstly, there may be a selection problem in which GvC funds target firms that are systematically different along some unobservable characteristics from those financed by PVC funds. f, for example, PVC funds select firms with greater growth prospects ex ante, our statement regarding the benefit of PVC ex post is misleading. The same issue would be expected if GVC funds target firms that are overlooked systematically by PVC funds. To alleviate this concern, we follow (Chemmanur et al., 2011; Croce et al., 2013) and use treatment effect models to control for the effect of the unobservables. The results are reported in Table 8. The dependent variable for the probit selection equation is the PVC-backing. Its specification is similar to that used for the propensity score matching (see Section 4). There are two slight differences because of the relatively small size of the Bs. Firstly, proceeds from IPO exits and TS exits were rolled into one “Exits\" variable. Secondly, injection year dummies were replaced by the “2ooos Dummy\" to control for the bubble years. The outcome equations have the same specification as in previously reported models for the BS. The DEA score is a proportion that falls into the [O;1] interval. It should therefore be transformed before it is used as the dependent variable in the ordinary least squares outcome equation. We use the arcsin-square-root transform because the usual log-odds transform is infeasible in  \n\nTable6 Efficiency regressions using the base sample of 515VC-backed firms.   \n\n\n<html><body><table><tr><td></td><td>(0)</td><td>(1)</td><td>(2)</td><td>(3)</td><td>(4)</td><td>(5)</td><td>(6)</td></tr><tr><td>PVC</td><td></td><td>0.285***</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>SRIW</td><td></td><td></td><td>-0.007</td><td></td><td></td><td></td><td>-0.002</td></tr><tr><td>GIMV</td><td></td><td></td><td></td><td>0.568***</td><td></td><td></td><td>0.437**</td></tr><tr><td>INVESTS</td><td></td><td></td><td></td><td></td><td>-0.384***</td><td></td><td>-0.378***</td></tr><tr><td>Other GVC</td><td></td><td></td><td></td><td></td><td></td><td>0.042</td><td>-0.089</td></tr><tr><td>Age, T - 1</td><td>-0.007</td><td>-0.007</td><td>-0.007</td><td>-0.007</td><td>-0.012</td><td>-0.007</td><td>-0.012</td></tr><tr><td>ROA, T - 1</td><td>-0.076***</td><td>-0.067**</td><td>-0.076***</td><td>-0.077***</td><td>-0.062**</td><td>-0.077***</td><td>-0.061**</td></tr><tr><td>Leverage, T — 1</td><td>-0.738***</td><td>-0.642***</td><td>-0.739***</td><td>-0.759***</td><td>-0.588***</td><td>-0.741***</td><td>-0.602***</td></tr><tr><td>Herfindahl index, T —1</td><td>0.462*</td><td>0.422*</td><td>0.462*</td><td>0.473**</td><td>0.294</td><td>0.449*</td><td>0.333</td></tr><tr><td>Number of rounds</td><td>0.051</td><td>0.016</td><td>0.051</td><td>0.025</td><td>0.018</td><td>0.052</td><td>-0.005</td></tr><tr><td>Syndication</td><td>0.063</td><td>-0.008</td><td>0.064</td><td>0.030</td><td>0.083</td><td>0.061</td><td>0.061</td></tr><tr><td>Industry dummies</td><td>Yes</td><td>Yes</td><td>Yes</td><td>Yes</td><td>Yes</td><td>Yes</td><td>Yes</td></tr><tr><td>Constant</td><td>Yes</td><td>Yes</td><td>Yes</td><td>Yes</td><td>Yes</td><td>Yes</td><td>Yes</td></tr><tr><td>R2</td><td>0.168</td><td>0.202</td><td>0.168</td><td>0.185</td><td>0.226</td><td>0.168</td><td></td></tr><tr><td>Observations</td><td>515</td><td>515</td><td>515</td><td>515</td><td>515</td><td>515</td><td>0.238</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>515</td></tr><tr><td>RESET1, p-val. RESET2, p-val.</td><td>0.133 0.158</td><td>0.666 0.819</td><td>0.135 0.153</td><td>0.363 0.594</td><td>0.827 0.893</td><td>0.130 0.151</td><td>0.706</td></tr><tr><td>GOFF1, p-val.</td><td>0.150</td><td>0.651</td><td>0.152</td><td>0.379</td><td>0.812</td><td>0.146</td><td>0.929 0.701</td></tr><tr><td>GGOFF, p-val.</td><td>0.150</td><td>0.651</td><td>0.152</td><td>0.379</td><td>0.812</td><td>0.146</td><td>0.701</td></tr><tr><td>Average partial effects</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>VC</td><td></td><td>0.099***</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>PVC SRIW</td><td></td><td></td><td>-0.002</td><td></td><td></td><td></td><td></td></tr><tr><td>GIMV</td><td></td><td></td><td></td><td>0.197***</td><td></td><td></td><td>-0.001 0.150**</td></tr><tr><td>INVESTS</td><td></td><td></td><td></td><td></td><td>-0.132***</td><td></td><td>-0.130***</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>Other GVC</td><td></td><td></td><td></td><td></td><td></td><td>0.015</td><td>-0.031</td></tr></table></body></html>\n\nThe table reports regressions of efficiency scores on the variables of interest and controls using a BS of the 515 VC-backed firms. The Wooldridge-Papke estimator for the fractional response variables is used for all models. Coeficients are etimated with robust standard errors \\*\\*\\*, and \\* indicate 1%, $5\\%$ and $10\\%$ signicance,respectively. RESET1, RESET2, GOFF1, and GGOFFlines provide the p-values of the model specification error tests and functional form specification error tests (Murteira and Ramalho, forthcoming; Ramalho et al,2010, 2011, forthcoming).  \n\n![](images/34d81b4abb4bbee2fa9710b6697edf4efd41864f3479e92151b46235c70fe6c4.jpg)  \n\n![](images/0bfdbd2abcf0aef09dcd7ef327acadcab6d4570b91be267bbd7ece7dab6954a5.jpg)  \n(b) Combined sample   \nFig. 1. Efficiency evolution with time. The graph presents the productivity patterns of Belgian VC-backed firms between the first pre- and third post-transaction years The term productivity scores are estimated using the DDEA methodology. For details see Section 4.  \n\nPlease cite this article as: Alperovych, Y., et al, How does governmental versus private venture capital backing affect a frm's efficiency? Evidence from Belgium, J. Bus. Venturing (2014), http://dx.doi.org/10.1016/jbusvent.2014.11.001  \n\nTable7 Efficiency regressions using the combined sample of 1030 firms.   \n\n\n<html><body><table><tr><td></td><td>(0)</td><td>(1)</td><td>(2)</td><td>(3)</td><td>(4)</td><td>(5)</td><td>(6)</td><td>(7)</td></tr><tr><td>VC</td><td></td><td>-0.126**</td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>PVC</td><td></td><td></td><td>0.096*</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>SRIW</td><td></td><td></td><td></td><td>-0.106</td><td></td><td></td><td></td><td>-0.071</td></tr><tr><td>GIMV</td><td></td><td></td><td></td><td></td><td>0.369**</td><td></td><td></td><td>0.283</td></tr><tr><td>INVESTS</td><td></td><td></td><td></td><td></td><td></td><td>-0.359***</td><td></td><td>-0.357***</td></tr><tr><td>Other GVC</td><td></td><td></td><td></td><td></td><td></td><td></td><td>-0.049</td><td>0.115</td></tr><tr><td>Age, T - 1</td><td>0.003</td><td>-0.006</td><td>0.007</td><td>0.003</td><td>0.004</td><td>-0.007</td><td>0.003</td><td>-0.007</td></tr><tr><td>ROA,T - 1</td><td>-0.112***</td><td>-0.111***</td><td>-0.110***</td><td>-0.114***</td><td>-0.113***</td><td>-0.101***</td><td>-0.112***</td><td>-0.101***</td></tr><tr><td>Leverage, T — 1</td><td>-0.001***</td><td>-0.001***</td><td>-0.001***</td><td>-0.001***</td><td>-0.001***</td><td>-0.001***</td><td>-0.001***</td><td>-0.001***</td></tr><tr><td>Herfindahl index, T — 1</td><td>0.588***</td><td>0.582***</td><td>0.580***</td><td>0.592***</td><td>0.591***</td><td>0.504***</td><td>0.593***</td><td>0.521***</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>Industry dummies</td><td>Yes</td><td>Yes</td><td>Yes</td><td>Yes</td><td>Yes</td><td>Yes</td><td>Yes</td><td>Yes</td></tr><tr><td>Constant</td><td>Yes</td><td>Yes</td><td>Yes</td><td>Yes</td><td>Yes</td><td>Yes</td><td>Yes</td><td>Yes</td></tr><tr><td>R2</td><td>0.098</td><td>0.103</td><td>0.101</td><td>0.099</td><td>0.102</td><td>0.129</td><td>0.098</td><td>0.133</td></tr><tr><td>Observations</td><td>1030</td><td>1030</td><td>1030</td><td>1030</td><td>1030</td><td>1030</td><td>1030</td><td>1030</td></tr><tr><td>RESET1, p-val.</td><td>0.890</td><td></td><td></td><td>0.946</td><td>0.964</td><td>0.641</td><td>0.878</td><td>0.695</td></tr><tr><td>RESET2, p-val.</td><td></td><td>0.665</td><td>0.499</td><td>0.560</td><td>0.559</td><td>0.833</td><td>0.592</td><td>0.682</td></tr><tr><td>GOFF1, p-val.</td><td>0.615</td><td>0.854</td><td>0.175</td><td>0.979</td><td>0.998</td><td>0.652</td><td></td><td>0.723</td></tr><tr><td>GGOFF, p-val.</td><td>0.919</td><td>0.657</td><td>0.547 0.547</td><td>0.979</td><td>0.998</td><td>0.652</td><td>0.908 0.908</td><td>0.723</td></tr><tr><td></td><td>0.919</td><td>0.657</td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>Average partial effects</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>VC</td><td></td><td>-0.042**</td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>PVC</td><td></td><td></td><td>0.032*</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>SRIW</td><td></td><td></td><td></td><td>-0.035</td><td></td><td></td><td></td><td>-0.023</td></tr><tr><td>GIMV</td><td></td><td></td><td></td><td></td><td>0.122**</td><td></td><td></td><td>0.093</td></tr><tr><td>INVESTS</td><td></td><td></td><td></td><td></td><td></td><td>-0.118***</td><td></td><td>-0.117***</td></tr><tr><td>Other GVC</td><td></td><td></td><td></td><td></td><td></td><td></td><td>-0.016</td><td>-0.038</td></tr></table></body></html>\n\nThe table reports regressions of efficiency scores on the variables of interest and controls using the CS of 1030 firms. The Wooldridge-Papke estimator for the fractional response variables is used for all models. Coeficients are etimated with robust standard errors. \\*\\* and \\* indicate $1\\%,5\\%,$ and $10\\%$ significance,respectively. RESET1, RESET2, GOFF1, and GGOFF lines provide the p-values of the model specification error tests and functional form specification error tests (Murteira and Ramalho, forthcoming; Ramalho et al, 2010., 2011, forthcoming).  \n\nthe presence of bound values. All regressions were estimated with robust standard errors. Because of space limitations, brief results are reported.  \n\nPanel A shows answers to the question of \"what if' PVC-backed firms were GVC-backed and vice versa? The efficiency of GVCbacked firms would have been approximately $16\\%$ higher if they had received financing from private VC fund. Similarly, PVC-backed firms would have lost approximately $7\\%$ in efficiency if they had been financed by GVC. Both parametric and non-parametric tests suggest that these results are statistically significant at the $1\\%$ level.  \n\nSecondly, an endogeneity problem may exist in our analysis of VC- versus NVC-backed firms. This is related to the potentially different “profile\" of firms that secure VC financing compared with the NVC-backed firms. These ex ante differences may be correlated with ex post target performance. The problem is that we observe these “\"profiles\" only partially. Observable differences between treated and control firms are ruled out by the matching procedure (Chemmanur et al., 2011). However, heterogeneity along the unobservables could still be an issue. To alleviate this concern, we use the similar switching regression methodology with the entire population of Please cite this article as: Alperovych, Y., et al., How does governmental versus private venture capital backing affect a firm's efficiency? Evidence from Belgium, J. Bus. Venturing (2014), http://dx.doi.org/10.1016/jbusvent.2014.11.001  \n\nTable8 Treatment effect of private vs. government VC.   \n\n\n<html><body><table><tr><td colspan=\"3\">PanelA:Basesample</td></tr><tr><td>MeanefficiencyofGVC-backedfirms</td><td>Potentialefficiencyif GVC-backedfirmswerePVC-backed</td><td>Difference ****+++</td></tr><tr><td rowspan=\"2\">0.512 MeanefficiencyofPVC-backedfirms</td><td>0.673</td><td>0.160</td></tr><tr><td>PotentialefficiencyifPVC-backedfirmswereGVC-backed 0.537</td><td>Difference -0.071***,+++</td></tr><tr><td colspan=\"3\">0.608</td></tr><tr><td>PanelB:Combined sample</td><td></td><td></td></tr><tr><td rowspan=\"2\">MeanefficiencyofNvC-backedfirms 0.476</td><td>PotentialefficiencyifNVC-backedfirmswere: PVC-backed 0.476</td><td>Difference 0.000</td></tr><tr><td>GVC-backed 0.377</td><td>-0.100***,+++</td></tr><tr><td>MeanefficiencyofPVC-backedfirms</td><td>PotentialefficiencyifPVC-backedfirmswereNVC-backed</td><td>Difference</td></tr><tr><td rowspan=\"2\">0.496 MeanefficiencyofGVC-backedfirms</td><td>0.515</td><td>0.019</td></tr><tr><td>PotentialefficiencyifGVC-backedfirmswereNVC-backed 0.502</td><td>Difference</td></tr></table></body></html>\n\nThe table reports the results of the switching regressions with endogenous switching models for the base and combined samples.\\*\\*\\*\\* and \\* indicate 1% $5\\%$ and $10\\%$ significance in the t-tests. $^{+++++}$ , and + indicate 1%, $5\\%.$ and $10\\%$ significance in the Mann-Whitny sined rank tests, respectively.  \n\nBelgian SMEs. In this context, we look at distinctions between the PVC and NVC backing, and between the GVC and NVC backing. Our first stage regressions are two probit models of the same specification and on the same population as used in the propensity scorematching procedure. The dependent variable is either PVC or GVC backing. Corresponding inverse Mills ratios (IMRs) were computed for all companies in the population. In the second stage, we use the NvC-backed firms returned from the matched procedure. This is because it is computationally infeasible to estimate efficiency of over $150\\mathrm{k\\Omega}$ firms (the population size). Since IMRs are computed using the entire population, the use of the reduced samples in the second stage should not be problematic. Second stage regressions are estimated via ordinary least squares with robust standard errors and have the same specifications as the models reported previously for theCs.  \n\nThe summarized results are reported in Panel B. The productivity of the control firms would have remained unchanged if they had been funded by PVC. NVC-backed firms would have shown a drop in productivity of $10\\%$ ( significant at $1\\%$ in the parametric and nonparametric tests) if they had secured GVC funding. If PVC-backed firms had not been financed by any VC, their productivity may have been beter, but the difference is insignificant. Finally, it appears that if GVC-backed firms had received no funding they would have gained approximately $7.5\\%$ in productivity. Again, this improvement is statistically significant at the $1\\%$ level in the parametric and non-parametric tests. By controlling for the potential unobservable heterogeneity between the VC-backed and matched firms, our previous results seem to be confirmed.  \n\n### 5.4. Comparison with total factor productivity approach  \n\nPrevious research used the total factor productivity (TFP) measure of efficiency in the VC context (Chemmanur et al., 2011; Croce et al., 2013). It is therefore insightful to see whether our results hold against alternative estimation methods.  \n\nEven though this is a useful check to relate this study to existing literature, implementing the TFP approach raises a number of issues. To measure the TFP properly, we need to estimate the regression of the natural log of output on the natural logs of inputs. The output is sales revenues, whereas the usual inputs are labor and capital. Although we have input data, we lack output data in this context. As mentioned elsewhere, in Belgium, disclosure of sales revenues is subject to managerial decision. Thus, our first issue is that we do not have the complete data on sales in our sample. To estimate the TFP, we rely on the SYS-GMM procedure described in Blundell and Bond (2000). Following Chemmanur et al. (2011) and Croce et al. (2013), we perform a by-industry estimation of the TFP. This gives rise to a second issue, since we have to partition the base or CSs (with an already limited number of firms) into industry subsets. This leads to a further reduction in sample size for the TFP estimations. We nevertheless use these reduced samples to estimate the TFP. The results, available upon request, are materially similar to our main findings and do not change the conclusions of the study.  \n\n## 6. Conclusion  \n\nIn this study, we analyze the implications of VC financing on the productivity of entrepreneurial firms. Our context is the Belgian VC industry. We focus on the relationship between the type of financial backer - government or private - and the productivity of its targets. This question is addressed using a unique hand-collected database of Belgian VC-backed firms from 1998 to 2007. We use a DDEA methodology to estimate efficiency levels and changes between the first pre-transaction year $(\\mathrm{T}-1)$ and the 3 years following VC injection $(\\mathrm{T}+3)$  \n\nOverall, the results suggest the following. Within the pool of Belgian VC-backed firms, being financed by PVC investors improves the efficiency of the portfolio companies significantly. Being financed by a GVC fund, and in particular by sub-regional investment companies (the “INVESTS\"), implies a significant reduction in productivity. SRIW and GIMV have a very limited negative and highly positive influence, respectively, on post-transaction changes in productivity in their targets. Factoring in comparable NvC-backed firms suggests that, in general, VC-backing destroys productivity in Belgium. This, however, comes almost exclusively from GVC backing, especially from INVESTS. Comparing PVC to NVC backing suggests a statistically weak-to-no effect of private VC on productivity.  \n\nOur explicit analysis of investor typology on productivity contributes to ongoing debates on the effects of GvC (Brander et al., forthcoming; Cumming and Li, 2013; Cumming et al., forthcoming), and on the effects of VC on productivity (Chemmanur et al., 2011; Croce et al., 2013). Instead of focusing on output measures alone to assess the incremental impact of VC backing on a firm's success, we examine the causality of this output, namely the efficiency of the production process. We are able to distinguish between financial support and value added provided by the GVC and PVC investors and underline the impact of this distinction on the target's efficiency. This result is important as the latter itself is one of the fundamental drivers of firm performance (Bottazzi et al., 2008a).  \n\nWe are also aware of several important limitations of our study. Our dataset does not contain crucial fund-related characteristics, such as the age and/or the size of the fund and the number of portfolio companies per fund manager. In addition, we do not have any information on the valuations or shareholding stakes in the deals. This, however, would add to our understanding of the effect of VC financier type on target efficiency. Another limitation is from the period under study: the INVESTS have been reorganized under the cupola of the Sowalfin, and the governance of this myriad of sub-regional funds has been revised subsequently. Thus, the results of our study must be preferably interpreted as a comparative approach of different types of VC organizations for a homogenous time period, rather than as a contemporaneous and reliable picture of the current VC industry in Belgium.8  \n\nDespite the aforementioned limitations, our results are insightful for academic research. Analyzing the effects of GVC programs is a challenging task. Therefore, it is beneficial to assess this question in many different ways. Considerable attention is paid to the implications of VC financing on business creation, growth, innovation, regional development, and employment. We investigate another aspect of a firm's performance and favor the conjecture that, for VC, efficiency is also contingent on the financier's profile. Our results are also important for entrepreneurs and for industry. For small firms, venture capitalists provide more than just money, but also advice and networks. The quality of the latter is contingent on the identity of the investor. Considering this, entrepreneurs should be aware of the implications of this investor heterogeneity on their firms' performance before paying the price. Ultimately, our results are potentially useful for Belgian policy makers. Although we do not conclude that their funds are harmful for the economy, our evidence sugests that GVC investments are not helping productivity within their targets. This may imply an ineffcient use of taxpayer money, which is why a reassessment (and possibly in-depth restructuring) of these programs may be warranted.  \n\n# Acknowledgments  \n\nWe are grateful to Gavin Cassar (the editor), the three anonymous referees, Fabio Bertoni, Douglas Cumming, David Devigne, Philipp Geiler, Alexander Peter Groh, Sophie Manigart, William L. Megginson, Pierre-Armand Michel, Bartolome Pascual-Fuster, Andrea Schertler, Armin Schwienbacher, Bernard Surlemont, Marc Umber, Charles Van Wymeersch, Uwe Walz, Mike Wright, and the participants of the MFS 2010 Annual Conference (Barcelona, Spain), the BENELUX Corporate Finance Day 2010 (Groningen, The Netherlands), the VICO final conference 2011 (Stresa, Italy), the 30th International AFFI conference 2013 (Lyon, France), and the 11th Corporate Finance Day 2013 (Liege, Belgium) for their useful comments and remarks on earlier versions of this paper. We also thank Joaquim J.S. Ramalho for sharing the technical details related to the methodological part of this paper. This research benefited from the support of the Belgian “Fonds de la Recherche Fondamentale Collective\". Georges Huibner thanks Deloitte Belgium and Deloitte Luxembourg for their financial support. All remaining errors are ours.  \n\n# Appendix A. Treatment of missing data  \n\nBel-first introduces a considerable amount of missing data in our sample. This is problematic for the DEA methods as they require a balanced panel data structure. One of the reasons for this N/A issue is that startups are allowed to report first-time financial statements after more than twelve months. If this occurs, it creates a missing item for the creation year. In such cases, we correct the first-year items on a pro-ratabasis.  \n\nLiquidated, bankrupt, or completely sold-out companies also result in $\\mathsf{N}/\\mathsf{A}$ data for the corresponding observations. Roughly, these cases correspond to the exit by VC investors of their stakes. Our analyses are related to the $\\mathrm{T}-1/\\mathrm{T}+3$ time window around the transaction date T. Therefore the missing data issue is only relevant for the data points within this interval. Consequently, we checked the exits occurring before the end of the third post-transaction year. Three targets were exited and twenty-five were liquidated in a bankruptcy procedure from T - 1 to $\\mathrm{T}+3.$ This amount constitutes a negligible proportion of less than $2\\%$ of the total number of firms in the raw sample. All remaining firms may have gone bankrupt or been exited after $\\mathrm{T}+3$ years.  \n\nFinally, we note that Bel-first reproduces accounting items as is. This means that if a company reports a zero or blank field for a given item (e.g., financial debt), Bel-first records it in the same way, leading to another $\\mathsf{N}/\\mathsf{A}$ issue. We thus investigated manually the structure of such missing data together with the status of the sample firms. It appears that all the companies concerned were reported as being active. In addition, the missing/blank patterns proved to be unsystematic from one variable to another. Therefore, for the unambiguous cases, we safely inferred zero values out of blanks. Whenever it was not possible, we used a conservative approach, in which we allowed one blank data point per variable. If it occurred on the bounds of the $[\\mathrm{T}-1,\\mathrm{T}+3]$ interval, we used a simple trend line to forecast its value. If it occurred within the stated bounds, we averaged two adjacent non-missing data points to substitute for the blank item.  \n\nAfter applying all these filters and corrections, our final sample, denoted BS, consists of 515 VC-backed companies, for which we have complete data to perform all efficiency estimations.  \n\n# References  \n\nAlperovych, Yan, Hubner, Georges, 2013. Incremental impact of venture capital financing. Small Bus. Econ. 41 (3), 651-666.   \nAlperovych, Yan, Amess, Kevin, Wright, Mike, 2013. Private equity firm experience and buyout vendor source: what is their impact on efficiency? Eur. J. Oper. Res. 228 (3),601-611.   \nAmess, Kevin, 2003. The effect of management buyouts on firm-level technical effciency: evidence from a panel of UK machinery and equipment manufacturers. J. Ind. Econ.51 (1),35-44.   \nBanker, Rajiv D., 1993. Maximum likelihood, consistency and data envelopment analysis: a statistical foundation. Manag. Sci. 39 (10), 1265-1273.   \nBanker, Rajiv D., 1996. Hypothesis tests using data envelopment analysis. J. Prod. Anal. 7, 139-159.   \nBanker, R.D., Charnes, A, Cooper, W.W., 1984. Some models for estimating technical and scale ineficiencies in data envelopment analysis. Manag. Sci. 30 (9), 1078-1092.   \nBanker, Rajiv D., Zheng, Zhiqiang (Eric), Natarajan, Ram, 2010. DEA-based hypothesis tests for comparing two groups of decision making units. Eur. J. Oper. Res. 206 (1), 231-238.   \nBarber, Brad M., Lyon,Joh D., 1996. Detecting abnormal operating performance: the mpirical power and specification of test statistics. J Financ. Econ. 41, 359399.   \nBascha, Andreas, Walz, Uwe, 2006. Financing Practices in the German Venture Capital Industry: An Empirical Assessment. Elsevier Press, pp. 217-248 (chapter 15).   \nBlundell, Richard, Bond, Stephen, 2000. GMM estimation with persistent panel data: an application to production functions. Econ. Rev. 19 (3), 321-340.   \nBottazzi, Giulio, Secchi, Angelo, Tamagni, Federico, 2008a. Productivity, profitability and financial performance. Ind. Corp. Chang. 17 (4), 711-751.   \nBottazzi, Laura, da Rin, Marco, Hellmann, Thomas, 2008b. Who are the active investors? Evidence from venture capital. J. Financ. Econ. 89, 488-512.   \nBrander, James A, Amit, Raphael, Antweiler, Werner, 2002.Venture-capital syndication: improved venture selection vs. the value-added hypothesis. J. Econ. Manag. Strateg. 11 (3), 423-452. Chanine, Salim, Filatotchev, Igor, Wright, Mike, 2007. Venture capitalists, business angels, and performance of entrepreneurial IPOs in the UK and France. J. Bus. Financ. ACC. 34 (3/4), 505-528.   \nChae,ACerWW,de978Meaurinth ffciny f deisnmain its.rJrRe. 2424   \nChemmanur, Thmas J,Krishan,arthik, andy, Dearshi K, 201Hwdoes entre capita nancing mrove efficencyin privat fms? lk eneath th u face. Rev. Financ. Stud. 24 (12), 4037-4090.   \nChen, Chien-Ming, van Dalen, Jan, 2010. Measuring dynamic efciency: theories and integrated methodology. Eur.J. Oper Res. 203, 749-760.   \nCochrane, John H, 2005.he risk and return of venture capital. J. Financ. Econ.75,352.   \nCok,WaforLryamt naisthtyrR19   \nColilwi Software. 2nd. edition. Springer Science and Business Media, LLC.   \nCornelli, Francesca, Yosha, Oved, 203. Stage financing and the role of convertible securities. Rev.Econ. Stud. 70, 132.   \nCroce,Aalistrl 3at fvnu caital  th prdutiity thfreannprerial : srenra added' efect? J. Bus. Ventur. 28, 489-510.   \nCumming,Douglas 2003The structure,gvenance and performance ofUKventure capital trusts.CorLawStud 3 (2), 117.   \nCumminoula 0vement pliytwads entprenrialfnancvatnvstment fJuVntu9   \nCumming,ulas Jhan,fa09-sed gvemnt nue capital fdIntnt   \nCumming,Doulas, Jhan, fia 2014.enture's econmi mact in usralia JTecholTransfr. forthcming)   \nCumminulaDanl nrerhandeecaialtitdStatra4   \nCumming, Douglas J, Maclntosh, Jeffrey G., 2003. Comparative venture capital governance: private versus labour sponsored venture capital funds. CESifo Working Paper 853.   \nCumming,Douglas J,MalntshJffy G, 2006.Crwding out privat equity: Canadian evidence.JBus.ntur. 21, 09.   \nCumming,Douglas J, Maclntosh, Jffrey G., 2007. Mutual funds that invest in private equity? n analysis of lbour-sponsored investment funds. Camb.J Econ. 31, 445-487.   \nCummin,ouglas,Grili Luca, Mutin, ml, Govemetal and indepenent ventre capital investments in Eroe: fm-evel eformance analysis . Corp. Financ. (forthcoming).   \nDa Rin, Marco, Nicodano, Giovanna, Sembenell, Alessandro, 2006. Public policy and the creation of active venture capital markets.J.Public Econ. 90, 16991723. Dailatl Dailastant   \nde Clercq,irMaigatph,hvetrecapita postinestment hasening tlacxfinvlvemntHandbookfRearchnentueail Edward Elgar Publishing Inc.,pp. 193-218 (chapter 7).\"   \nDererdryalyfiquiii   \nDehejaajak 0rsitormatsfoxrnt ual stdia411   \nDiamond, Alexis ekhon,JsetS. 2014 Genticmatching for estimating casual effets: a eneral mltivariate maching method for achieving balance in obsevational studies. Rev. Econ. Stat. 95 (3), 932-945.   \nFare, Rof Grosso hawa996ItmoraldutioFrontieWitDamiD ditopringr ril)   \nFarrell, M.J, 1957. The measurement of productive efficiency. J. R. Stat. Soc. 120 (3),253-290.   \nFlorinJa05caart ftmaand on1   \nGompers, Pal, 1995.ptimal invetment,mnitring,and the staing of ventre capital.J Finac. 50, 141490.   \nGompers, Pal, 1996.Grandstandin in the venture capital industry.J. Financ. Econ. 42, 13156.   \nGompers, Pal, Ler,sh,1996Theuseof covenants: anmirical analysis of venture partership arements. J LaEcon 39 (2), 49.   \nGomerPa,Lesh9ha driventrecaitalfdraiin?rinPa   \nGomeraehanalisfmnsatnntnaitlparhipnac   \nGomers,PaLesh,20nychasing dealsTh mpact offund ilws on rivate qityvalatonFinanc.o 2.   \nGomerCi   \nGreorirrma05.fd maapraisaingdatavmnt naysiurRe1, Grilli LuaMinSml201vement venture capital and th grwthoEran ig-tech enreeurial fmRel, 15253. Handmiatsftod rtrenurcaitavestmnttchlogmaiunu HarrisRihad ena,igtMik 05Assing tmact f angenbuyuts micfcny:lat-l idne fm th Kingdom. Rev. Econ. Stat. 87 (1), 148-153.   \nHeer,Da,eaMrrad005va:riaitlimaymarnua(43 Helmamahtnnhnuanact9   \nHemaqisitfia   \nHelmahmaurMnjhntactwtmakt dain trathlveaitanat4) Helmamrajnureantfnlizanstricalienan   \nHochbrqvistAexaer,Yng00Wmyukwmatterventreapitalr andiestt fannan2 (1), HuDailsls   \nHuDavid04hat ntpeeurpaforventurecaital afliatn?inan5944   \nJensen, Michael C., 1986.Agency costs of free cash flow, corporate finance and takeovers. Am. Econ. Rev. 76 (2), 323-329.   \nJovanoviyaectinndvltnf thndustmetric03   \nKeuschnigg, Christian, Bo Nielsen, Soren, 2001. Public policy for venture capital. Int. Tax Public Financ. 8, 557-572.   \nKnockaert, iram, ckett,ndy,Clarysse, art, right, Mike, 06.hman capita and fud haracteristics drive fow-ubhaviu of earlystage hig-th VCs? Int. J Technol. Manag. 34 (1/2), 7-27.   \nKorteweg, Arthur, Sorensen, Morten, 2010.Risk and return characteristics of venture capital-backed entrepreneurial companies.Rev.Financ. Stud. 23 (10),3733772. Korumssintnnaitvao   \nLeleux, Benot, Surlemont, Bernard, 2003. Public versus private venture capital: seeding or crowding out? A pan-European analysis.J. Bus. Ventur. 18, 81-104. Lerer,J994 icafneai esnnnMa233   \nLerner, Josh, 1995. Venture capital and the oversight of private firms. J. Financ. 50 (1),301318.   \nLerner, Josh,999h govermnt as entre capitalist: the long-run mact f th BIR programs.72 3), 2838.   \nLerer,JhmustiteeaitadustryatactnvaeeBakant   \nLerer, Jshrearamr:tifftivlinu aitgam112477)7 LerhvrfbefrtsttntepnaitwtitK FoundationSeriesnInovation andEntrepreneurshipPrincetonUnivrsityPress,Princetnand Oxor.   \nLerner, Josh, 200The fuure of public efforts to boost entrepreneurship and venture capital Smallus Econ35 2554.   \nLeraial   \nLerner, Josh, choar,Antoinett,Wngsuwai, Wan, 207 mart instiutions, folish choices the lmited parter erformance puzz. J Fnanc 2 (2),7374. Lichtenberg, Frank R, Siegel, Donald, 1990. The effects of leveraged buyouts on productivity and related aspects of firm behavior. J Financ. Econ. 27, 165194. Lockett,dMi0diatnncaitlttMIa93   \nMacmillan, Ian C., Siegel, Robin, Subbanarasimha, P.N., 1985. Criteria used by venture capitalists to evaluate new venture proposals. J. Bus. Ventur. 1 (1), 119-128.  \n\nPlease cite this article as: Alperovych, Y, et al., How does governmental versus private venture capital backing affect a firm's efficiency? Evidence from Belgium, J. Bus. Venturing (2014), http://dx.doi.org/10.1016/jbusvent.2014.11.001  \n\nMacmillan, lanC. Zeman, Lauriann, ubbanarasimha, P, 1987 Criteria distinguishing suceful frm unsucesful ventures in the venture creening process Jus. Ventur. 2 (2), 123-137.   \nManigart, Sophie, Baeyens, Katleen, Van Hyft, Wim, 2002. The survival of venture capital backed companies. Ventur. Cap. 4 (2), 103124.   \nMaula, Markku, Murray, Gordon, Jskelinen, Mik, 207Public financing of young innvative companis n Finland. ehnical Ror MI ublicatins.   \nMetrick, Andrew, Yasuda, Ayako, 2010.The economics of private equity funds. Rev.Financ. Stud. 23 (6), 23032341.   \nMurteira, Jose M.R, Ramalho, Joaquim J.S., 2014. Regression analysis of multivariate fractional data. Econ. Rev. http:/dx.doi.org/10.1080/07474938.2013.806849 (forthcoming).   \nPapke, Leslie E., Wooldridge,Jeffrey M., 1996. Econometric methods for fractional response variables with an application to 401(k) plan participation rates. J. Appl. Econ.11,619-632.   \nPuri, Manju, Zarutskie, Rebecca, 2012. On the life-cycle dynamics of venture-capital and non-venture-capital-financed firms J. Financ. 67 (6), 2247-2293.   \nRamalho,Esmeralda A, Ramalho, Joaquim JS., Henriques, Pedro D., 2010.Fractional rgression modes for second stage DEA effciency analyses. J Prod. Anal. 4, 239-255.   \nRamalh, EmeraldaA,amalh,aqumJS, Murteira,JsM, 1Altnative stimating and testin mpirical strateies fr frational reresn mdelsJ. Surv. 25 (1), 19-68.   \nRamalho, Esmeralda A., Ramalho Joaquim, J.S., Murteira Jose, M.R, 2014. A generalized goodness-of-functional form test for binary and fractional regression models. The Manchester School 82 (4),488-507.   \nRosenbaum, Paul R., Rubin, Donal B., 1985. Constructing a control group using multivariate matched sampling methods that incorporate the propensity score. Am. Stat. 39 (1), 33-38.   \nSamila, Sampsa, Sorenson, Olav, 2011. Venture capital, entrepreneurship and economic growth. Rev. Econ Stat 93 (1), 338-349 (February).   \nSapienza, Harry J., 1992. When do venture capitalists add value? J. Bus. Ventur. 7 (1), 9-27.   \nSapienza, Harry J., Amason, Allen C., Manigart, Sophie, 1994. The level and nature of venture capitalist involvement in their portfolio companies. Manag. Financ. 20 (1), 3-17.   \nSapienza, Harry J, Manigart, Sophie, Vermeir, Wim, 1996. Venture capitalist governance and value added in four countries. J. Bus. Ventur. 11, 439-469.   \nShane, Scott, 2009. Why encouraging more people to become entrepreneurs is bad public policy. Small Bus. Econ 33, 141-149.   \nSorensen, Morten, 2007. How smart is smart money? A two-sided matching model of venture capital. J. Financ. 62 (6), 2725-2762.   \nSunley, Peter, Klagge, Britta, Brendt, Christian, Ron, Martin, 2005. Venture capital programmes in the UK and Germany: in what sense regional policies? Reg. Stud. 39 (2),255-273.   \nThe European Venture Capital and Private Equity Association, 1998-2007 Yearbooks.   \nTone, Kaoru, 2001. A slacks-based measure of effciency in data envelopment analysis. Eur.J. Oper. Res. 130, 498-509.   \nTone, Kaoru, Tsutsui, Miki, 2010. Dynamic DEA: a slacks-based measure approach. OMEGA Int. J. Manag. Sci. 38, 145-156.   \nTyebjee, Tyzoon T., Bruno, Albert V., 1984. A model of venture capitalist investment activity. Manag. Sci. 30 (9), 1051-1066.  "
  },
  "md_amitWhyVentureCapital1998": {
    "reference_markdown": "# WHY DO VENTURE CAPITAL FIRMS EXIST? THEORY AND CANADIAN EVIDENCE  \n\nRAPHAEL AMIT, JAMES BRANDER AND CHRISTOPH ZOTT University of British Columbia, Vancouver, BritishColumbia,Canada  \n\n## EXECUTIVE SUMMARY  \n\nThis paperinvestigates therole of venture capitalists.Weview their“raison d'etre”as their ability toreduce thecost of informational asymmetries.Our theoreticalframeworkfocuses ontwomajorforms ofasymmetricinformation:“hidden information”(leading to adverse selection)and“hidden action\" (leading to moral hazard). Our theoretical analysis suggests four empiricalpredictions.  \n\n1.Venture capitalists operate in environments where their relative effciency in selecting and monitoring investments gives them a comparative advantage over other investors. This suggests strong industry effectsinventurecapitalinvestments.Venturecapitalistsshouldbeprominent inindustrieswhereinformational concernsareimportant,suchasbiotechnology,computersoftware,etc.,ratherthanin“routine”start-ups such as restaurants,retail outlets,etc.Thelatter arerisky,in that returns showhigh variance,buttheyarerelativelyeasytomonitorbyconventional financialintermediaries. 2. Within the class of projects where venture capitalists have an advantage, they will still prefer projects where monitoring and selection costs are relatively low or where the costs of informational asymmetry are less severe. Thus, within a given industry where venture capitalists would be expected to focus, we would also expect venture capitalists to favor firms with some track records over pure start-ups.  \n\nTo clarify the distinction between point1 and point 2,note that point 1 states that if we look across investors, we will see that venture capitalists will be more concentrated in areas characterized by significant informational asymmetry.Point2says that if welook across investment opportunities,venture capitalistswill stillfavor thosesituationswhichprovidebetterinformation(aswill all otherinvestors). Thusventure capitalists perceiveinformational asymmetries as costly,but theyperceive them asless costlythandootherinvestors.  \n\n3.Ifinformational asymmetries areimportant,then the ability of theventure capitalist to“exit”may be significantly affected.Ideally,venture capitalists will sell off theirsharein theventure afterit“goes public”ona stock exchange.If,however,venture investments are madein situations whereinformationalasymmetriesareimportant,itmaybedifficult tosellsharesinapublicmarketwheremost investors are relatively uninformed.This concern invokes two natural reactions.One is that many“exits\" would takeplace through sales to informed investors,such as to otherfirms in the same industry orto the venture's own management orowners.A second reaction is that venture capitalists mighttry to acquire reputations forpresentinggoodqualityventures inpublic offerings.Therefore,wemight expect that the exits that occur in initial public offerings would be drawn from the better-performingventures.  \n\n4.Finally,informational asymmetries suggest that owner-managers will perform best when they have a largestakein theventure.Therefore,we can expect entrepreneurial firms in whichventurecapitalists ownalargesharetoperformlesswellthanotherventures.Thisismoral hazardproblem,ashighervalues of aventure capitalist's share reduce the incentives of theentrepreneur toprovideeffort.Nevertheless,it mightstillbebestinagivensituationfortheventurecapitalisttotakeonahighownershipshare,since this might be the only way of geting sufficient financial capital into the firm. However, we would still expectanegativecorrelationbetweentheventurecapitalownershipshareandfirmperformance.  \n\nOurempirical examination ofCanadianventurecapital shows that these predictions areconsistent with the data. In particular, there are significant industry effects in the data, with venture capitalists having disproportionaterepresentationinindustriesthat are thought tohavehighlevels of informationalasymmetry.Secondly,venture capitalists favor later stage investment to start-upinvestment.Third,most exit is through “insider” sales, particularly management buyouts, acquisitions by third parties, rather than IPOs. However, IPOs have higher returns than other forms of exit. In addition,the data exhibit the negative relationship between the extent of venture capital ownership and firm performance predicted by our analysis. $\\copyright$ 1998ElsevierScienceInc.  \n\n## INTRODUCTION  \n\nIn both Canada and the United States, venture capital finance is a significant form of financial intermediation. There is no strict regulatory definition of the venture capital industry, unlike commercial banking or insurance but, generally speaking, venture capital firms provide privately held “entrepreneurial” firms with equity, debt, or hybrid forms of financing, often in conjunction with managerial expertise. In Canada these firms are playing an increasingly important role. As reported in Macdonald & Associates (1996), between the end of 1991 and the end of 1995, the amount of capital under management by Canadian venture capital firms grew from $\\mathrm{C}\\$3.2$ billion (or about $\\$3.8$ billion in 1995 dollars) to $\\mathrm{C}\\$6$ billion, implying an annualized real growth rate of about $12\\%$ per year. The rate of new investment by venture capital firms grew even more rapidly, rising from $\\mathrm{C}\\$290$ million in 1991 (or $\\mathrm{C}\\$306$ million 1995 dollars) to $\\mathrm{C}\\$669$ million in 1995, which corresponds to real growth of more than $20\\%$ per year.  \n\nDespite its growing importance, the venture capital industry has received much less academic scrutiny than other parts of the financial sector.1 This applies both to theory and to empirical investigation. At the theoretical level, perhaps the most fundamental question to ask about the venture capital industry is why it exists at all. Why have a set of specialized firms that focus on financing the entrepreneurial sector? Even if there were no dedicated venture capital firms, a combination of commercial banks, investment banks, private investors, and stock exchanges providing the necessary intermediation could still be imagined. In fact, among entrepreneurial firms, most finance is provided by banks and private investors (including family members), and many young entrepreneurial firms “go public” on stock exchanges without first seeking venture capital finance. In seeking to understand venture capital finance, it therefore seems important to ask what exactly is the niche filled by venture capital firms.  \n\nThe primary objective of this paper is to present a theory explaining the existence of the venture capital industry and investigate the consistency of this theory with empirical observations. Our basic hypothesis is that informational asymmetries are the key to understanding the venture capital industry. Previous papers have focused on the importance of asymmetric information in venture capital markets, and several authors have suggested that a central distinction between venture capitalists and other financial intermediaries is that venture capitalists operate in situations where asymmetric information is particularly significant. In this paper we provide a simple formal model that distinguishes venture capitalists from other potential investors on the basis of their ability to deal with informational asymmetries. This model is also used to draw inferences about how venture capital financing would be expected to work. These predictions are then compared with the actual pattern of venture capital investment in Canada. This link between theory and empirical evidence is the main contribution of the paper.  \n\nThere are two major forms of informational asymmetry. One type, sometimes referred to as “hidden information,”' occurs when one party to a transaction knows relevant information that is not known to the other party. For example, an entrepreneur developing a new product may have a much better idea about whether the product will actually work than does the venture capitalist who may finance the venture. The problem arises because the informed party typically has an incentive to misrepresent the information. The entrepreneur, for example, may have an incentive to overstate the likelihood of successful product development. Furthermore, the market may become crowded with “low-quality” projects, precisely because it is hard for investors to distinguish between good-quality and poor-quality projects. This phenomenon is called adverse selection. Potential investors understand that adverse selection exists and may therefore be wary of funding such entrepreneurial endeavours.2  \n\nThe other type of informational asymmetry is often described as “hidden action.\" In this situation one party to a transaction cannot observe relevant actions taken by the other party (or at last cannot legally verify these actions). For example, an investor in an entrepreneurial firm might not be able to observe whether the entrepreneur is working hard and making sensible decisions, or whether the entrepreneur is planning to “take the money and run.\" This problem leads to what is called “moral hazard.\" The informed party then has an incentive to act out of self interest, even if such actions impose high costs on the other party.  \n\nBoth adverse selection and moral hazard may arise in any investment environment, but they seem particularly acute in entrepreneurial finance. With large established firms, investments are made safer by the use of existing assets as collateral, and the development of reputation. Collateral and reputation effects can mitigate the negative effects of both adverse selection and moral hazard. Because entrepreneurial firms lack assets to provide as collateral, and because they lack the “track record’\" necessary to establish their reputation, the effects of informational market failures are more severe in entrepreneurial finance than in financing established firms.  \n\nOur central hypothesis is that venture capitalists emerge because they develop specialized abilities in selecting and monitoring entrepreneurial projects. In other words, venture capitalists are financial intermediaries with a comparative advantage in working in environments where informational asymmetries are important. This is their niche.3  \n\nThe next section of our paper provides a brief review of relevant literature, followed by a section that sets out a formal model of venture capital finance with associated empirical predictions. The fourth section describes the data set obtained from Macdonald & Associates, and the fifth section compares the theoretical predictions with the data. The final section contains concluding remarks.  \n\n## LITERATUREREVIEW  \n\nAkerlof (1970) is normally taken as the starting point of the formal analysis of informational asymmetry. Akerlof describes a situation where sellers of used cars have private information about the quality of their cars, but buyers cannot discern quality differences before purchase. In this setting, low-quality cars or “lemons” dominate the market, thus the market “selects” adversely. Akerlof showed that this adverse selection is inefficient in that potentially efficient (i.e., Pareto-improving) trades will not take place.  \n\nAdverse selection problems can arise in many circumstances. For example, in insurance markets, buyers may know their true risk better than insurance companies (as in Pauly (1974)), and in labor markets, workers may be more aware of their abilities than potential employers are (as in Spence (1973)). Spence points out that one natural market response to adverse selection is “signalling,”' where an informed party (usually the seller of the high-quality item) provides some signal of high quality. Thus, for example, product warranties may be signals of high quality. Rothschild and Stiglitz (1976) emphasize the rolle of screening, under which the uninformed party offers a contract or set of contracts that cause informed parties to self-select into different groups.  \n\nHidden action (and moral hazard) was first discussed in insurance markets, where insured parties can take actions that either decrease or increase the risk of hazard. For example, after purchasing auto insurance, the insured party can either drive safely or dangerously. Early infuential work on moral hazard includes Arrow (1973) and Pauly (1974), who showed that moral hazard causes market failure. Moral hazard problems are particularly important in many situations where one party acts as an agent for another party, such as when a client hires a lawyer, or the seller of a house hires a sales agent. In these situations, the “principal\" cannot perfectly observe the effort (or other actions) of the agent. Jensen and Meckling (1976) argue that agency relationships are the key to understanding the modern firm. Thus, for example, the managers of the firm can be viewed as the agents of the owners, who might in turn be viewed as the agents of other investors in the firm.  \n\nAdverse selection and moral hazard are often viewed as crucial determinants of venture capital financing. Sahlman (1990), for example, postulates that contracting practices in the venture capital industry reflect informational asymmetries between venture capitalists and entrepreneurs, and argues that the lack of operational history aggravates the adverse selection problem. MacIntosh (1994) also asserts the basic idea that informational asymmetries are fundamental in the venture capital sector, and this point is also emphasized in Amit, Glosten, and Muller (1993). Various other papers implicitly recognize the importance of informational issues. For example, MacMillan, Zemann, and Narashima (1987) provide a valuable discussion of how venture capitalists screen new projects.  \n\nChan (1983) highlights the role of venture capitalists in reducing the adverse selection problem in the market for entrepreneurial capital. He shows that an adverse selection result derives from the absence of any informed venture capitalists in the sense that only inferior projects are offered to investors. However, the introduction of informed investors may overcome this problem, leading to a Pareto-preferred solution. Amit, Glosten, and Muller (1990) present an agency model in which investors are uncertain about the entrepreneur's type when submitting investment bids. The authors relate the venture capital financing decision to the entrepreneur's skill level and predict which entrepreneurs will decide to enter into an agreement with venture capitalists.  \n\nSahlman (1990) notes that staged investment, which creates an option to abandon the project, is an important means for venture capitalists to minimize agency costs.4 The role of staged investment as a monitoring device is also examined by Gompers (1995). In addition, the active involvement of venture capitalists in the operation of their investee companies might mitigate the moral hazard problem. The empirical significance of the role of venture capitalists as monitors is supported by Barry et al. (1990) and by Lerner (1995). In addition, Lerner (1994) suggests the use of syndication (i.e., coordinated investment by two or more venture capitalists) as a method of reducing problems caused by informational asymmetries. Two other useful papers that describe actions that venture capitalists can take to reduce problems arising from informational asymmetries include Tyebjee and Bruno (1984) and Fried and Hisrich (1994).  \n\nChan, Siegel, and Thakor (1990) seek to explain various “rules of thumb\" in venture capital contracting practices as a response to informational asymmetries and, in a related paper, Hirao (1993) assumes that the entrepreneur's unobservable actions affect the venture capitalist's learning process, and uses this context to study the effects of different contracts. A more general overview of research challenges in the venture capital area is given by Low and MacMillan (1988).  \n\nDespite a number of empirical and descriptive studies on venture capital practices and activities, including some of those already mentioned and also MacMillan, Siegel, and Narashima (1985), Bygrave and Timmons (1992), and Gompers and Lerner (1994), among others, empirical work on venture capital finance is still relatively modest in scope compared to the analysis of other financial intermediaries. Our paper seeks to add to this literature. Specifically, we provide a formal model that uses asymmetric information to explain the existence of venture capitalists, then compare the predictions of this theoretical structure with evidence on venture capital finance in Canada.  \n\n## A THEORYOFVENTURECAPITALFINANCE  \n\nAn entrepreneur has a potential project and seeks potential investors. To keep the analysis simple we assume that the project requires fixed financial input I from an investor. The expected cash flow from the project, net of production costs, is denoted R (for “net operating revenue\"). This expected net operating revenue depends in part on the effort, e, provided by the entrepreneur and it depends in part on the underlying project quality, q. In addition, the outcome depends on a random variable, u, with expected value 0. The realized net cash flow is therefore  \n\n$$\n\\mathtt{R}(\\mathrm{e},\\mathrm{q})+\\mathtt{u}\n$$  \n\nwhere the expected operating revenue is R(e,q). We assume that entrepreneurs and investors are risk-neutral expected value maximizers. We, therefore, ignore u and work with R. Variable u plays one important role, however. Given unobservable random uncertainty, as represented by u, it is not possible for an investor who knows project quality q to infer effort e from the cash flow realization.  \n\nIf e cannot be observed by the investor, then it is a hidden action and gives rise to a moral hazard (or “agency\") problem. If q is known to the entrepreneur, but not to the investor, then it is hidden or private information and gives rise to potential adverse selection. The presence of exogenous uncertainty, as represented by random variable u, does not in itself cause market failure. R is taken to be increasing in e and q. We also assume that there are decreasing marginal returns to effort. The effort effects can be written formally as  \n\n$$\n\\begin{array}{r}{{\\bf R}_{\\mathrm{e}}>0,\\qquad{\\bf R}_{\\mathrm{ee}}<0}\\end{array}\n$$  \n\nwhere subscripts denote (partial) derivatives.  \n\nLet the share of the proceeds that go to the investor (posibly a venture capital firm) be denoted $\\upalpha^{5}$ . The expected return $\\mathrm{v}$ to the investor is  \n\n$$\n{\\bf V}=\\alpha{\\bf R}({\\bf e},{\\bf q})-{\\bf I}\n$$  \n\nThe expected return to the entrepreneurial firm, denoted $\\pi$ (for “profit\"), is its share of the proceeds, net of the costs of effort e.  \n\n$$\n\\pi=(1-\\alpha)\\mathrm{{R}}(\\mathrm{{e},\\mathrm{{q}})-\\mathrm{{e}}}\n$$  \n\nVariable e is normalized so that providing e units of effort imposes cost e on the entrepreneurial firm.  \n\n### Moral Hazard  \n\nTo demonsrate the moral hazard problem, assume initially that q is known to both parties. A profit maximizing entrepreneur will maximize (4) with respect to e, leading to the following first order condition:  \n\n$$\n\\pi_{\\mathrm{e}}=(1-\\alpha)\\mathrm{R}_{\\mathrm{e}}-1=0\\mathrm{or}\\mathrm{R}_{\\mathrm{e}}=1/(1-\\alpha)\n$$  \n\nThe second order condition for a maximum is $(1-\\alpha)\\mathbf{R}_{\\mathrm{ee}}<0.$ Noting that the factor $(1-\\upalpha)$ is presumed to be strictly positive and using (2), this second order condition must hold.  \n\nThe efficient or “first-best\" level of effort $\\mathrm{e}^{*}$ is determined by maximizing the sum of (3) and (4) with respect to e. This sum, denoted S, is  \n\n$$\n\\mathbf{S}=\\mathbf{R}(\\mathbf{e},\\mathbf{q})-\\mathbf{I}-\\mathbf{e}.\n$$  \n\nMaximizing (6) with respect to e yields the following first order condition  \n\n$$\n\\mathtt{R}_{\\mathrm{e}}=1\n$$  \n\nIt follows form (5), (7), and (2) that the entrepreneur will choose less than the effcient level of effort as long as $\\upalpha$ is strictly positive. This is the moral hazard problem. It is illustrated in Figure A1 in Appendix 1. It follows from the corresponding algebra and Figure A1 that effort is declining in $\\upalpha$  \n\n$$\n\\mathrm{de/d\\alpha<0}\n$$  \n\nIt is possible that the moral hazard problem might render the project infeasible. The inveestment is attractive to the investor only if the return equals or exceeds the alternative value that can be obtained by investing Ielsewhere. Let this required return or opportunity cost be denoted r. Then feasibility requires  \n\n$$\n(1+\\mathrm{r})\\mathrm{I}\\le\\alpha\\mathrm{R}(\\mathrm{e}(\\alpha),\\mathrm{q})\n$$  \n\nThe problem is that there may be no value of $\\upalpha$ that allows (9) to be satisfied. If the expected return to the investor is too low, this suggests raising $\\upalpha$ , but then e will fall (from (8)), reflecting the idea that the entrepreneur will provide less effort as his stake in the firm falls.  \n\nFeasibility for the entrepreneur requires that the expected profit given by (4) exceed the return from the entrepreneur's best alternative, which can be normalized to equal 0. It is possible that effort level $\\mathrm{e}^{*}$ would in principle allow feasibility for both investor and entrepreneur, but that the actual effort relationship, $\\operatorname{e}(\\alpha)$ wouldnotallow the project to be financed. Thus the moral hazard problem may cause the market to fail.  \n\nWe now introduce the idea that investors can monitor the entrepreneur and, at some cost, induce the entrepreneur to provide additional effort. Denote the monitoring cost m. The expected return to the investor is therefore  \n\n$$\n\\mathbf{V}=\\alpha\\mathbf{R}(\\mathtt{e}(\\upalpha,\\mathrm{m}),\\mathtt{q})-\\mathrm{~I~}-\\mathfrak{m}\n$$  \n\nIf the responsiveness of e to m is low, then the investor will not bother to monitor, as the cost will exceed the benefit. Some investments may be worthwhile, without monitoring, in spite of the moral hazard problem, but many projects will be abandoned. If e is highly responsive to monitoring, then the investor will undertake monitoring and will elicit an effort level closer to “first-best\" level $\\mathrm{e}^{*}$ . Projects that are not financed by other investors will be feasible for investors who are good at monitoring (i.e., those for whom the responsiveness of e to m is high).  \n\nIt is also possible that the investor provides valuable services, s, to investee companies. These services (e.g., providing strategic and operational advice, aid in fundraising, adding reputation, etc.) are observable by the entrepreneur. Ignoring monitoring for the moment and normalizing the cost of providing s to 1 per unit, the expected return to the investor is now  \n\n![](images/e3a6b48708637e3ca2d8aa859f0331cc85949015ad4186dc8410be8d32e18c7f.jpg)  \nFIGURE 1 Effects of services on expected net revenues.  \n\n$$\n\\mathbf{V}=\\alpha\\mathbf{R}(\\mathtt{e}(\\alpha),\\mathtt{q},\\mathrm{s})\\mathrm{~-~I~-~s~}\n$$  \n\nWe can think of the effect of $\\mathbf s>0$ on the operating revenues $\\mathrm{R}$ in the following way. Services s can produce a direct (positive) effect on R through $\\mathbf{R}_{\\mathrm{s}}>0$ (case 1), 0r can have an indirect (positive) effect on R through enhancing the marginal productivity of the entrepreneur's effort, or $\\mathrm{R}_{\\mathrm{es}}>0$ (case 2). When both effects are present, ${\\bf R}_{\\mathrm{s}}>$ 0 and $\\mathrm{R}_{\\mathrm{es}}>0$ , we have case 3. Figure 1 illustrates these different cases and compares them with the benchmark case where $\\mathbf{s}=0$  \n\nCase 1 is defined as the case in which the investor's provision of s does not affect the entrepreneur's productivity of effort, $\\mathbf{R}_{\\mathrm{e}}$ , but raises revenues directly. Let us assume that this effect is additive. For each effort level e expanded by the entrepreneur, the provision of $\\mathsf{s}>0$ by the investor will increase the venture's revenues by $\\Delta{\\sf R}$ . This is expressed in Figure 1 as a parallel upward shift of the graph of R(e) from the benchmark case to case 1. With respect to the moral hazard problem this means that, relative to the benchmark case, ${\\bf R}_{\\mathrm{e}}$ and thus the entrepreneur's incentive constraint (5) remain unchanged in case 1. Therefore our basic analysis for $\\mathbf{s}=0$ still holds (see equations (1)-(9) and Appendix 1). In other words, the moral hazard problems in the benchmark case and case 1 are identical.  \n\nIn cases 2 and 3, however, the provision of s improves the productivity of e, and $\\mathbf{R}_{\\mathrm{e}}$ is consequently shifted upward. This results in steeper curves for cases 2 and 3 in Figure 1. The entrepreneur's incentive constraint (5) is affected by this change, and therefore a new analysis of the moral hazard problem is required. Let us denote the case where $\\mathbf{s}=0$ with superscript 0 and cases 2 or 3 where $\\mathbf{s}=\\mathbf{k}>0$ with superscript s. “First-best”’ effort levels are denoted $\\mathrm{e}^{*}$ ,\"second-best\" effort levels $\\mathrm{e^{\\prime}}$ . The new situation is depicted in Figure 2.  \n\n![](images/cd1d18ff8260c07291ff82fd8b85610dac9b80bcce6e509baf1f9825bb769662.jpg)  \nFIGURE 2 First- and second-best effort levels in base case $(\\mathrm{{s}}=0)$ )and under $\\mathrm{R}_{\\mathrm{es}}>0$  \n\nFigure 2 is based on the different possibilities of how s can affect R; it also draws on the previous discussion of the standard moral hazard problem (without monitoring or services rendered). It allows us to conclude that the moral hazard problem persists for $\\mathbf s>0$ even if $\\begin{array}{r}{\\mathbf{R}_{\\mathrm{es}}>0.}\\end{array}$ In this case, the “second-best\" effort level $\\mathrm{e^{s^{\\prime}}}$ is still smaller than the “first-best” effort $\\mathrm{e}^{\\mathrm{s}^{\\ast}}$ .However, relative to the base case scenario, the entrepreneur is now willing to put forth more effort $(\\mathrm{e}^{\\mathrm{s}^{\\prime}}>\\mathrm{e}^{0^{\\prime}})$  \n\nThus, the provision of s might contribute to the realization of projects which otherwise would have been abandoned, as they did not fulfill the investor's original feasibility constraint (9). Considering s, the investor's feasibility constraint now becomes  \n\n$$\n(1+{\\mathfrak{r}}){\\mathrm{~I~}}+{\\mathfrak{s}}\\leq\\alpha{\\mathrm{R}}({\\mathfrak{e}}(\\alpha),{\\mathfrak{q}},{\\mathfrak{s}})\n$$  \n\nIf s is not prohibitively high, then it might relax this constraint through its direct and indirect positive effect on R. Thus, investors who are skilled at providing value-creating services to their portfolio companies will undertake certain projects which other, less skilled investors will shun.  \n\nThere is ample evidence that venture capitalists provide valuable services to their portfolio companies. Gorman and Sahlman (1989) compiled a list of such services from a survey of venture capital investors. The five highest ranked and most frequently used activities can either be interpreted as directly enhancing investee reveneus (e.g., introduction to potential customers and suppliers, assistance in obtaining additional financing) or as enhancing the entrepreneur's productivity of effort and thus indirectly boosting investee revenues (e.g., strategic planning, management recruitment, operational planning).  \n\nWe now turn to the case in which both monitoring and services are considered.  \n\nThe effects of s on R might be important enough to render projects feasible which were infeasible even with optimal monitoring. In fact, it seems natural to assume that a combination of monitoring and the provision of services constitutes a powerful tool in the hands of specialized investors to reduce moral hazard problems. Note, for example, that the entrepreneur's “second-best\" effort provided in the case where $\\mathsf{s}>0$ and $\\mathrm{m}>0$ might be higher than the “first-best\" effort in the benchmark case where $\\mathbf{s}=0$ and $\\mathbf{m}=$ 0. (Refer to Figure 2 and recall that if e is sufficiently responsive to m, $\\mathrm{e^{s^{\\prime}}}$ might get fairly cose to $\\mathrm{e^{s^{*}}}$ under an optimal monitoring regime.)  \n\nAnother point worth emphasizing is that providing services to entrepreneurs might make it easier and thus cheaper for investors to monitor them. Denoting $\\mathbf{M}(\\mathbf{m}|\\mathbf{s})$ asthe monitoring costs at a given level of s, it is very likely, for example, that $\\mathbf{M}(\\mathbf{m}|\\mathrm{s}>0)<$ $\\mathbf{M}(\\mathbf{m}|\\mathbf{s}=0)=\\mathbf{m}$ . Thus, the return to the investor given monitoring and services is  \n\n$$\n\\mathbf{V}=\\alpha\\mathbf{R}(\\mathrm{e}(\\mathrm{{\\(\\alpha,m),q,s)}-I-s-M(m|s)}\n$$  \n\nWe note that investors who are good at monitoring and providing valuable services to their portfolio companies are likely to invest in firms with more severe moral hazard problems, as their feasibility constraint is more likely to be fulfilled.  \n\n### Adverse Selection  \n\nA similar pattern emerges when adverse selection is considered. Assume that the venture capitalist chooses the optimal amount of services rendered and the optimal amount of monitoring effort, giving rise to associated values of e and s for any given $\\upalpha$ .Quality level q is now unobservable to the investor. Suppose that the range of q is such that the average quality project does not yield enough expected returns (for any value of $\\upalpha$ to allow both (13) and (4) to be positive. Thus, the average project is not worth funding. Formally, we can write the investor's expected return as  \n\n$$\n\\begin{array}{r}{\\mathrm{EV}=\\int_{\\P}[\\alpha\\mathsf{R}(\\mathsf{e}(\\alpha,\\mathrm{m}(\\alpha)),\\mathsf{q},\\mathsf{s}(\\alpha))-\\mathrm{~I~}-\\mathsf{s}(\\alpha)-\\mathsf{M}(\\mathrm{m}(\\alpha)|\\mathsf{s}(\\alpha))]\\mathsf{f}(\\mathsf{q})\\mathrm{d}\\mathsf{q}<0}\\end{array}\n$$  \n\nwhere f(q) is the probability density function for project quality. To simplify this expression, we subsume the terms that do not bear directly on the analysis of the hidden information problem into investor's costs C. With  \n\n$$\n\\mathbf{C}=\\mathbf{I}+\\mathbf{s}(\\alpha)+\\mathbf{M}(\\mathbf{m}(\\alpha)|\\mathbf{s}(\\alpha))\n$$  \n\ninequality (14) reduces to  \n\n$$\n\\mathrm{{EV}=\\int_{q}[\\alpha R(q)-C]f(q)d q<0}\n$$  \n\nInequality (16) says that the expected value across all projects is negative. However, some of the individual projects (those in the upper end of the quality distribution) may be very valuable. Suppose, for example, that the top $40\\%$ of projects could generate a positive net profit. Unfortunately, the entire market will normally fail in this situation, as it will typically not be worthwhile for investors to provide financing, even though many individual projects are worthwhile.  \n\nNow suppose that an investor can acquire information about the quality of an individual project by spending d before making the actual investment I. Parameter d can be interpreted as the cost of “due diligence.\" This cost determines the probability, p(d), with which an investor can establish whether the quality of a certain project exceeds a thresholdlevel of quality. We denote this threshold level of quality as ${\\mathfrak{q}}^{0}$ . Let us implicitly define ${\\mathfrak{q}}^{0}$ as follows:  \n\n![](images/331ff4356af6f220fa6d812341a5a445123c4e15f972dfb5dc06400ccc87a5ce.jpg)  \nFIGURE 3  Venture capital investment process.  \n\n$$\n\\begin{array}{r l}{\\mathbf{V}=\\alpha\\mathbf{R}(\\mathbf{q})-\\mathbf{C}=0}&{\\qquad\\mathrm{for~}\\mathbf{q}=\\mathbf{q}^{0}}\\ {\\mathbf{V}>0}&{\\qquad\\mathrm{for~}\\mathbf{q}>\\mathbf{q}^{0}}\\ {\\mathbf{V}<0}&{\\qquad\\mathrm{for~}\\mathbf{q}<\\mathbf{q}^{0}}\\end{array}\n$$  \n\nThe “detection function\"” p(d) is assumed to have the following properties:  \n\n$$\n\\begin{array}{l}{\\mathrm{p}(\\mathrm{d}=0)=0,\\mathrm{p}(\\mathrm{d}=\\infty)=1,}\\ {\\mathrm{p}^{\\prime}(\\mathrm{d})>0\\mathrm{and}\\mathrm{p}^{\\prime\\prime}(\\mathrm{d})<0}\\end{array}\n$$  \n\nLet us restate the assumptions concerning the sequence of events in the above model. Investment in an entrepreneurial firm is a one period, multi-stage process as illustrated in Figure 3. In the first stage, the investor incurs an up-front cost of d in order to assess the quality of a potential investment. With probability p(d) the investor will become informed about q and will, therefore, find out whether ${\\mathsf{q}}\\geq{\\mathsf{q}}^{\\mathrm{0}}$ or ${\\mathsf{q}}<{\\mathsf{q}}^{0}$ .Only in the former case an investment will be made. With probability $(1-\\mathsf{p}(\\mathrm{d}))$ , however, the investor will remain uninformed about q and, due to (16), refrain from investing. Stage 3, in which the entrepreneur displays effort and is monitored and supported by the investor, and stage 4, in which the benefits from the investment are reaped and distributed, occur only if in stage $1\\mathrm{~q~}$ is found to be greater than ${\\mathfrak{q}}^{0}$  \n\nThe expected net return to the investor can therefore be expressed as  \n\n$$\n\\mathrm{{EV}=p(d)\\int_{q>q^{0}}{(\\alpha R(q)-C)f(q)d q}-d}\n$$  \n\nFeasibility now requires that  \n\n$$\n\\mathrm{r}(\\mathrm{I}+\\mathrm{d})\\leq\\mathrm{EV}\n$$  \n\nIt follows immediately from (17), (18), and (20) that investors who are good at doing due diligence in the sense that low values of d yield a given value of p are likely to engage in due diligence, select high quality projects (i.e., projects with positive expected return), and make investments.6 These are the investors that become venture capitalists. (For further formal analysis of the advise selection case, see Appendix 2).  \n\nWe should emphasize that we assume that the efforts undertaken by the venture capitalist are not subject to free riding. That is, another investor cannot simply observe the venture capitalist who has undertaken diligence and then underbid him. Typically venture capitalists are able to keep the results of diligence and monitoring confidential until after financial contracts have been signed. Free riding does occur but, given the informational asymmetries in the venture capital sector, it seems plausible to abstract from free riding here.  \n\n### Implications  \n\nThe above formulation provides the simplest configuration that reflects the idea that venture capitalists are those investors who become skilled at selecting good projects in environments with hidden information and are good at monitoring and advising entrepreneurs who might otherwise be vulnerable to moral hazard problems. The implications of this modeling framework are outlined below.  \n\n1. Venture capitalists will operate in environments where their relative efficiency in selecting and monitoring investments and providing value-enhancing services gives them a comparative advantage over other investors. For example, as we have seen in the “hidden action” case, it may take effective monitoring m and specific services s to make a project attractive for an investor. In the “hidden information\"” case, on the other hand, market failure can be avoided if the probability of detecting whether a project is worth supporting is high enough for sufficiently low due diligence costs. This suggests strong industry effects in venture capital investments. We would expect venture capitalists to be prominent in industries where informational concerns are important, such as biotechnology, computer software, etc., rather than in “routine'\" start-ups such as restaurants, retail outlets, etc. The latter are risky, in the sense that random variable u has high variance, but they are situations that are relatively easy to monitor by conventional financial intermediaries, whereas the former draw much of their value from idiosyncratic knowledge that is much harder to assess. In principle, in-depth knowledge of traditional industries, such as retailing, is not less advantageous than in-depth knowledge of high-tech industries, but there is some evidence that such wisdom is harder to obtain for knowledge-based industries where informational asymmetries are, therefore, likely to be higher. (See Industry Canada (1994) on the particular difficulties and challenges that investors and lenders face with regard to the assessment of knowledge-based small- and medium-sized enterprises.)  \n\n2. Within the class of projects where venture capitalists have an advantage, venture capitalists will still prefer projects where selection, monitoring, and service costs are relatively low or, in other words, where the costs of informational asymmetry are less severe. In the presence of moral hazard, investors would prefer projects for which e is more responsive to m, and/or for which R and/or $\\mathbf{R}_{\\mathrm{e}}$ are more responsive to s.  \n\nIn the presence of adverse selection, projects with a highly responsive p(d) would be favored over those where the detection of quality is more difficult and thus more costly. Thus, within a given industry where venture capitalists would be expected to focus, we would expect venture capitalists to favor firms with some track record over pure start-ups. To clarify the distinction between point 1 and point 2, note that point 1 states that if we look across investors, we will see that venture capitalists will be more concentrated in areas characterized by significant informational asymmetry. Point 2 says that if we look across investment opportunities, venture capitalists will still favor those situations that provide better information (as will all other investors). Thus venture capitalists perceive informational asymmetries as costly, but they perceive them as less costly to deal with than do other investors.  \n\n3. If informational asymmetries are important, then the ability of the venture capitalist to “exit\" may be significantly affected. Ideally, the venture capitalists might wish to sell off their share in the venture after it “goes public\" on a stock exchange. If, however, these investments are made in situations where informational asymmetries are important, it may be difficult to sell shares in a public market where most investors are relatively uninformed. Public investors probably have a less responsive function p(d) and therefore (19) could be negative for them. This concern invokes two natural reactions: One is that many “exits” would take place through sales to informed investors, such as other firms in the same industry as the venture or to the venture's own management or owners. These informed investors probably have similar, if not better detection functions p(d) than the venture capitalist. A second reaction is that venture capitalists might try to acquire reputations for only presenting good quality ventures in public offerings. (However, this is an argument drawing on a multiperiod scenario and would therefore require an extension of our model). Therefore, we might expect that the exits that occur in initial public offerings would be drawn from the betterperforming ventures.?  \n\n4. The model implies that dR/de $(=\\mathbf{R}_{\\mathrm{e}})>0$ and $\\mathrm{de/d\\alpha<0}$ . Together these two properties imply $\\mathrm{dR/d\\alpha}<0$ . Other things equal, we can expect entrepreneurial firms in which venture capitalists own a large share to generate lower net returns. This would be due to the moral hazard problem. Higher values of $\\upalpha$ reduce the incentives of the entrepreneur to provide effort. Nonetheless, it still might be optimal in a given situation for the venture capitalist to take on a high ownership share, as this might be the only way of getting sufficient financial capital into the firm. However, we would still expect a negative correlation between the venture capital ownership share and firm performance.  \n\nWe note, however, that the model also suggests a negative relationship between R and $\\upalpha$ for another reason. Specifically, the selection constraint for investors is that $\\alpha\\mathrm{R}\\geq$ $(1+\\mathbf{r})\\mathbf{I}$ or $\\upkappa\\geq(1+\\mathrm{r})\\mathrm{I}/\\upalpha$ If the venture capital market were very competitive so that investors earned no rents, then this selection constraint would hold with equality, and there would be an exact negative relationship between expected net operating revenues and $\\upalpha$ , whether or not moral hazard was present. Even if venture capitalists earn some expected rents, this selection constraint will still rule out combinations of low $\\upalpha$ and low R, which will tend to induce a negative correlation between R and $\\upalpha$ . The basic logic is that, for a given investment I, investors will need to be compensated by a large ownershipshare $\\upalpha$ if the expected net operating revenues are relatively low.  \n\n## THEDATASET  \n\nThe data used for this study were collected by Macdonald & Associates Ltd. and made available to us on a confidential and anonymous basis. In addition, no individual firmspecific information is reported or discussed in our analysis. The data are derived from two surveys. The first survey, referred to as the “investment survey,\" began as an annual survey in 1991 and became quarterly in 1994. It asks just over 100 Canadian venture capital firms to identify their investees and provide some information about each investment and divestiture. Investees are recorded in the database and follow-up information is requested in subsequent surveys. The investment survey asks about the amount and stage of each investment and also seeks information about the venture capitalist's ultimate divestiture of its holdings in each investee.8  \n\nThis survey, which covers the period from 1991 through the first quarter of 1996, seeks to obtain comprehensive information from all Canadian venture capital providers. In an effort to get full information about the investee firms, the survey is sent to venture capital companies (as just noted) and other investors who have investments in the venture-backed investees. However, some relevant venture capital providers may have been overlooked in the survey, and some surveyed venture capitalists may not report all of their investments. Nonetheless, Macdonald & Associates Ltd. estimate that the investment survey identifies $90{-}95\\%$ of the underlying population of Canadian firms supported by Canadian venture capitalists.  \n\nThe second survey, referred to as the “economic impact”’ survey, began in 1993 and is conducted annually. It seeks additional information about the investees identified in the investment survey. Thus, economic impact information is sought about each investee that received an investment in or after 1991. Retrospective information is also requested. Suppose, for example, that an investee received an investment in 1991. The venture capitalist making the investment would have received a 1993 economic impact questionnaire asking for information about this investee going back as far as 1987. In many cases not much retrospective information can be provided, but the database contains economic information on a reasonable number of investees going back as far as 1987. The date of the investee's original startup (which in some cases is well before 1987) is also reported.  \n\nThe response rate for the economic impact survey over its three year life has varied between $56\\%$ and $74\\%$ (i.e., information has been received on $56\\%$ to $74\\%$ of the targeted investee firms). If the investment survey identifies $90{-}95\\%$ of the relevant underlying population, then the effective sample coverage is between $50\\%$ (.9 times $56\\%$ and $70\\%$ of the underlying population. The economic impact survey collects balance sheet and income statement information on the investees (including revenues and taxes paid). It also collects information on the structure and amount of their employment, and the nature of their industry.  \n\nA typical investee enters the data set when it receives its first investment from a venture capitalist. It may receive investments from additional venture capitalists as well. Subsequent rounds of investment may also occur. Eventually, an investee leaves the sample. This occurs when all venture capitalists have either written off (in the case of failure) or “cash in\" their holdings in the investee. Thus, the data set contains a series of “life histories\" for venture capital-backed firms.  \n\nA “record” refers to information for one particular investee firm for one particular year. There are 387 investee firms in the data availabale from the economic impact survey, but information on about 18 of these firms is significantly incomplete. The remaining 369 firms provide 1,298 reasonably complete records, and, therefore, have an average of about 3.5 records each. The investment survey data includes information on 1,086 Canadian investees. For some purposes, complete matched records are necessary, but much interesting and relevant information is available from just the economic impact data (1,298 records on 369 companies) or just the investment data (2,017 records on 1,086 companies).  \n\nThese data sets target Canadian investees supported by the Canadian venture capital industry. A Canadian entrepreneurial company that received support exclusively from venture capitalists based in the United States or Asia and had no support from Canadian venture capitalists would not be in our data set. This set of firms is probably fairly small, but there is no data available on its magnitude. It seems unlikely that this omission introduces much systematic bias over most subjects of interest in the data. Despite some possible selection bias in the economic impact data, the data set as a whole remains an important and unique data source.  \n\n## INVESTMENT PRACTICES OF CANADIAN VENTURE CAPITALISTS  \n\nWe now present some empirical evidence that addresses the predictions of the theoretical framework outlined in section 3. Some of this data, together with other empirical information on the Canadian venture capital industry is provided by Amit, Brander, and Zott (1997). Before considering the implications of informational asymmetries, we provide a general characterization of important financial variables in the data, as shown in Table 1. All relevant table entries are in thousands of 1995 Canadian dollars. As this table implies, the size of investee companies varies substantially, with a few large firms that make the average values much larger than the median values. The median investee has about 50 Canadian employees and annual revenues of $\\mathrm{C}\\$6$ million. A typical ownership share for the venture capitalist is approximately $30\\%$  \n\nThe data in Table 1 also imply that firms in the data set spend, on average, about $3.5\\%$ of their revenues on R&D. This is about the same as the overall ratio of R&D spending to revenues for the Canadian economy as a whole. We should note, however, that these rather moderate R&D expenses may be due to different accounting standards that prevail in small and relatively young companies in contrast to large and established firms. Revenues per Canadian employee are $\\$148,800$ , and the average long term debt to equity ratio is a conservative 0.77. (The long term debt to equity ratios derived from Canadian COMPUSTAT data is estimated to be 1.75 for companies of all sizes, and  \n\nTABLE 1 Summary Financial Data: 1987-94 (in Real \\$1995)   \n\n\n<html><body><table><tr><td></td><td>Mean ($000s)</td><td>Median ($000s)</td><td>Standard deviation</td><td>No.of records</td></tr><tr><td>Total assets</td><td>22,928</td><td>5,540</td><td>70,707</td><td>1,277</td></tr><tr><td>Total equity</td><td>8,777</td><td>1,893</td><td>25,254</td><td>1,274</td></tr><tr><td>VC-share of equity (%)</td><td>34</td><td>30</td><td>30</td><td>1,218</td></tr><tr><td>Retained earnings</td><td>848</td><td>154</td><td>10,098</td><td>1,127</td></tr><tr><td>Totalfixedassets</td><td>10,745</td><td>1,996</td><td>52,353</td><td>1,257</td></tr><tr><td>Long-term debt</td><td>6,729</td><td>1,056</td><td>28,122</td><td>1,157</td></tr><tr><td>Revenue</td><td>23,657</td><td>6,177</td><td>56,077</td><td>1,290</td></tr><tr><td>Investments in property, plant and equipment</td><td>1,954</td><td>222</td><td>8,180</td><td>1,161</td></tr><tr><td>R&D expenditures</td><td>837</td><td>79</td><td>2,098</td><td>1,067</td></tr><tr><td>Taxes paid</td><td>461</td><td>25</td><td>1,315</td><td>1,027</td></tr><tr><td>#of Canadian employees</td><td>159</td><td>50</td><td>301</td><td>1,293</td></tr></table></body></html>\n\nSource: Macdonald & Associates Ltd. Economic Impact Database  \n\n0.90 for companies with annual sales less than $\\$100$ million.) The low debt-equity ratio may reflect the limited borrowing capacity of entrepreneurial firms. We note also that the average investee is profitable enough to pay nontrivial amounts of tax.  \n\nWe now consider the implications of the information-based model described in Section 3. One of the implications was that venture capital would be focused on industries where the importance of monitoring and due diligence expertise is particularly great. Table 2 presents information about the industry breakdown of the investee companies, and compares these investment shares with the shares of these industries in total output (as measured by Canadian gross domestic product (GDP)).  \n\nTABLE 2  Industry Classification   \n\n\n<html><body><table><tr><td rowspan=\"2\"></td><td rowspan=\"2\">Early stage investment* (no. of investees)</td><td rowspan=\"2\">Total investment*</td><td colspan=\"3\"></td></tr><tr><td>% of early (no. of investees) investment</td><td>% of total investment</td><td>% of total output</td></tr><tr><td rowspan=\"2\">Biotechnology</td><td>95.4</td><td>121.5</td><td rowspan=\"2\">17</td><td rowspan=\"2\">6</td><td rowspan=\"2\">0</td></tr><tr><td>(43)</td><td>(51)</td></tr><tr><td rowspan=\"2\">Communications</td><td>83.7</td><td>225.1</td><td rowspan=\"2\">15</td><td rowspan=\"2\">10</td><td rowspan=\"2\">5</td></tr><tr><td>(32)</td><td>(63)</td></tr><tr><td rowspan=\"2\">Manufacturing and industrial equipment</td><td>78.7</td><td>461.6</td><td rowspan=\"2\">13</td><td rowspan=\"2\">21</td><td rowspan=\"2\">24</td></tr><tr><td>(82)</td><td>(261)</td></tr><tr><td rowspan=\"2\">Computer (hardware and software)</td><td>70.0</td><td>314.4</td><td rowspan=\"2\">12</td><td rowspan=\"2\">14</td><td rowspan=\"2\">3</td></tr><tr><td>(100)</td><td>(182)</td></tr><tr><td rowspan=\"2\">Miscellaneous</td><td>67.1</td><td>314.7</td><td rowspan=\"2\">12</td><td rowspan=\"2\">15</td><td rowspan=\"2\">34</td></tr><tr><td>(58)</td><td>(178)</td></tr><tr><td rowspan=\"2\">Medical/health</td><td>58.4</td><td>176.1</td><td rowspan=\"2\">10</td><td rowspan=\"2\">8</td><td rowspan=\"2\">3</td></tr><tr><td>(34)</td><td>(59)</td></tr><tr><td rowspan=\"2\">Energy/environmental technology</td><td>57.4</td><td>134.6</td><td rowspan=\"2\">10</td><td rowspan=\"2\">6</td><td rowspan=\"2\">4</td></tr><tr><td>(33)</td><td>(68)</td></tr><tr><td rowspan=\"2\">Consumer related</td><td>31.7</td><td>296.3</td><td rowspan=\"2\">6</td><td rowspan=\"2\">14</td><td rowspan=\"2\">26</td></tr><tr><td>(27)</td><td>(109)</td></tr><tr><td rowspan=\"2\">Electrical components and instruments</td><td>25.0</td><td>125</td><td rowspan=\"2\">4</td><td rowspan=\"2\">6</td><td rowspan=\"2\">2</td></tr><tr><td>(42)</td><td>(89)</td></tr><tr><td rowspan=\"2\">Total:</td><td>567.2**</td><td>2169.3</td><td rowspan=\"2\">99**</td><td rowspan=\"2\">100</td><td rowspan=\"2\">101**</td></tr><tr><td>(451)</td><td>(1060)</td></tr></table></body></html>\n\n\\* In C\\$ mill; \\*\\* Due to rounding. Sources: Macdonald & Associates Ltd. Investment Database. Output shares are based on estimates from Statistics Canada “Gross Domestic Product by Industry,” 1996, cat. no. 15-001-XPB.  \n\nTABLE 3 Age of Venture-Backed Companies   \n\n\n<html><body><table><tr><td>Yearfounded</td><td>#of companies</td><td>% of total</td></tr><tr><td>1994</td><td>23</td><td>6</td></tr><tr><td>1993</td><td>22</td><td>6</td></tr><tr><td>1992</td><td>20</td><td>5</td></tr><tr><td>1991</td><td>28</td><td>7</td></tr><tr><td>1984-1990</td><td>163</td><td>42</td></tr><tr><td>19741983</td><td>85</td><td>22</td></tr><tr><td>Before1974</td><td>38</td><td>12</td></tr><tr><td>Total</td><td>379</td><td>100</td></tr></table></body></html>\n\nSource: Macdonald & Associates Ltd. Economic Impact Database.  \n\nAs can be seen from Table 2, venture capital is much more heavily represented in biomedical areas, computers, and communications than would be implied by overall output shares of these industries in the economy as a whole. Venture capital has a slightly smaller share of manufacturing and industrial equipment than the economy as a whole, and a much lower share of \"consumer related'” and “miscellaneous\"” industries. The main components of these categories are the retail sector and various services. This picture is even more pronounced when only early stage venture capital investments are considered. It seems very plausible that the industries where venture capitalists concentrate the most are those where informational asymmetries are most severe. It is, of course, possible that venture capitalists invest relatively heavily in high-tech industries for reasons unrelated to information. For example, the high-tech sector may simply have a disproportionately large number of new investment opportunities. More specifically, it is a growth sector, and any growth sector will appear to have high levels of new investment from most financial intermediaries, including venture capitalists. Even so, venture capitalists have a heavier relative investment in high-tech industries than other financial intermediaries, and informational reasons offer a plausible explanation for this. Thus, Table 2 is consistent with our theoretical expectations.  \n\nThe second major implication of the information-based theory developed in Section 3 is that within the sectors where venture capitalists operate, they still prefer to invest in firms where the adverse selection and moral hazard problems are least severe. The following information is consistent with this expectation. First, Table 3 shows the age structure of the investee firms.  \n\nAs shown on Table 3, quite a few investee companies are surprisingly old. Fully $12\\%$ of the 379 companies for whom information on age is available were founded prior to 1974. Since the data set is limited to firms that received at least one infusion of venture capital in 1991 or later, some firms obtain venture capital financing long after being founded. (We note, however, that these firms might have obtained earlier venture capital infusions. Our data suggests that many recorded investments are indeed followup investments.)  \n\nFurthermore, this information suggests that it takes longer than commonly perceived, and perhaps more venture capital than originally anticipated, to bring some investee firms to the stage at which exit is feasible. A company may be founded well before it obtains its first venture capital investment. These data raise the possibility that venture capital focuses on expansion of existing small companies rather than on the start-up phase. Tables 4 and 5 provide more information on this point.  \n\nTable 4 shows how many investments correspond to each stage in the entrepreneurial firm's life. It is based on investment records of investee companies that are in the  \n\nTABLE 4 Number of Investments by Stage and Year   \n\n\n<html><body><table><tr><td></td><td colspan=\"3\">Early stages</td><td colspan=\"5\">Later stages</td><td></td></tr><tr><td></td><td>SE</td><td>ST</td><td>ES</td><td>EX</td><td>AC</td><td>TU</td><td>WC</td><td>OT</td><td>Count</td></tr><tr><td>1991</td><td>3</td><td>100</td><td></td><td>85</td><td>12</td><td>22</td><td>一</td><td>36</td><td>258</td></tr><tr><td>1992</td><td>15</td><td>111</td><td>一</td><td>65</td><td>23</td><td>41</td><td>2</td><td>50</td><td>307</td></tr><tr><td>1993</td><td>5</td><td>116</td><td>一</td><td>125</td><td>18</td><td>23</td><td>25</td><td>37</td><td>349</td></tr><tr><td>1994</td><td>3</td><td>128</td><td>11</td><td>206</td><td>12</td><td>23</td><td>一</td><td>15</td><td>398</td></tr><tr><td>1995</td><td>8</td><td>130</td><td>112</td><td>241</td><td>11</td><td>21</td><td>2</td><td>44</td><td>569</td></tr><tr><td>1996(Q1)</td><td>5</td><td>42</td><td>12</td><td>54</td><td>3</td><td>11</td><td>一</td><td>9</td><td>136</td></tr><tr><td>Total</td><td>39</td><td>627</td><td>135</td><td>776</td><td>79</td><td>141</td><td>29</td><td>191</td><td>2017</td></tr></table></body></html>\n\nKey: SE $=$ seed; $\\mathrm{ST}=$ start-up; $\\mathrm{ES}= $ other early stage investments; EX $=$ expansion;_AC $=$ acquisition; TU $=$ urnaround; $\\mathrm{WC}=$ working capital; and ${\\mathrm{OT}}=$ other. Source: Macdonald & Associates Ltd. Investment Database.  \n\nInvestment Database and includes investments made betwen 1991 and the first quarter of 1996. A given investee may obtain financing from multiple venture capitalists, and may also receive multiple rounds of investment from a given venture capitalist. Each investment, which may include debt, equity, or both, is recorded separately. We observe that a full $60\\%$ of the investments made over the period covered by our sample are late stage investments. As early stage investments are both smaller (from Table 5) and less numerous (Table 4) than late stage investments, we can infer that the venture capital industry seems to focus more on growth and development of firms than on start-up activity. Tables 3 to 5 show that venture capitalists focus on firms with a long enough track record to provide significant information about the underlying quality of the venture. Pure start-up activity, where adverse selection and moral hazard problems are most severe, is less significant than later stage investment.  \n\nFigure 4 depicts the relative importance of debt and equity in an average or representative investment by stage. There are, for example, 39 seed investments in total. The total equity in these 39 investments is $\\$21.89$ million, giving an average of $\\$561,000$ while the total debt is $\\$2.34$ million, resulting in an average of only $\\$60,000$ (note that most seed investments have no debt). Figure 4 shows that equity is relatively more important at the early stages, and debt becomes more significant later, although equity remains more important in abolute terms for every stage except working capital.  \n\nThe third major implication of our information-based approach is that we might expect exit to be dominated by “insider” activity rather than by public offerings. Figure 5 shows the pattern of exits in the data and indicates that only about $16\\%$ of exits occur after initial public offerings (IPOs). About $10\\%$ are third party acquisitions, often by a firm in the same industry as the venture. The largest category of exit is company buyouts, in which the venture capitalist's holding is sold to officers or managers of the investee.Fully $37\\%$ of exits are in this category. Secondary purchases are purchases of the venture capitalist's holding by a third party in a private transaction that is not an overall acquisition. The “other” category consists of exits for which the exit mode was not identified, but we believe that most of these are company buyouts. Approximately $17\\%$ of exits were in the “write-off”’ category. If informational asymmetries are important, it is not surprising that IPOs account for only a small share of exits while company buyouts are much more important. We wish to note, however, that the small share of IPOs may also partly reflect a minimum scale necessary to sustain a public market in a stock.  \n\nTABLE 5 Average Size of Investments by Stage and Year (in $\\mathbf{C}\\boldsymbol{\\mathfrak{S}}000^{\\mathfrak{s}},$   \n\n\n<html><body><table><tr><td></td><td colspan=\"3\">Early stages</td><td colspan=\"5\">Later stages</td><td></td></tr><tr><td></td><td>SE</td><td>ST</td><td>ES</td><td>EX</td><td>AC</td><td>TU</td><td>WC</td><td>OT</td><td>Total</td></tr><tr><td>1991</td><td>489</td><td>678</td><td></td><td>1165</td><td>2003</td><td>1424</td><td>一</td><td>1374</td><td>1058</td></tr><tr><td>1992</td><td>900</td><td>617</td><td>一</td><td>1104</td><td>1283</td><td>628</td><td>480</td><td>1480</td><td>925</td></tr><tr><td>1993</td><td>836</td><td>1101</td><td>一</td><td>1714</td><td>1665</td><td>1620</td><td>362</td><td>1662</td><td>1394</td></tr><tr><td>1994</td><td>425</td><td>677</td><td>854</td><td>1227</td><td>2338</td><td>1521</td><td>一</td><td>2391</td><td>1128</td></tr><tr><td>1995</td><td>414</td><td>688</td><td>1005</td><td>1300</td><td>2341</td><td>436</td><td>1378</td><td>1564</td><td>1098</td></tr><tr><td>1996(Q1)</td><td>101</td><td>1034</td><td>847</td><td>1297</td><td>2260</td><td>1601</td><td>一</td><td>890</td><td>1151</td></tr><tr><td>1991-96</td><td>621</td><td>771</td><td>997</td><td>1316</td><td>1824</td><td>1107</td><td>378</td><td>1559</td><td>1127</td></tr></table></body></html>\n\nSource:Macdonald & Associates Ltd.Investment Database.  \n\n![](images/68d78bd59b8abdd0558d57ba83fa22b36e4070ae6375722c5c6344c8a5a8c4ea.jpg)  \nFIGURE 4  Average debt and equity by investment stage 1991-1996(Q1).  \n\nOur theoretical framework also suggests that returns would differ by exit vehicle and that, in particular, IPOs would have high returns precisely because venture capitalists seek to reduce the adverse selection problem confronted by buyers of IPOs by only \"going public with relatively strong investee firms. These returns shown in Table 6 are consistent with our expectations. Write-offs, of course, represent a $100\\%$ lossoverthe holding period. Among the other forms of exit, IPOs are relatively profitable. Secondary purchases (i.e., secondary sales from the exiting venture capitalist's point of view) are similarly profitable in aggregate, although with only 11 observations, it is diffcult to regard the return to secondary purchases as highly meaningful. In any case, the high return to IPOs is consistent with our expectations.  \n\n![](images/af864a7ed06d0c8bbf1cf5b2797cf8d9cdb11ca922d9d034f5b428e3f72cfd6b.jpg)  \nFIGURE 5 Distribution of venture capital exits (percentage of exits)  \n\nThe final prediction of our model is that the venture capitalist's ownership share should be negatively associated with the firm's performance. This derives both from moral hazard and the venture capitalist's participation constraint that expected returns should at least equal the return from alternative investments. In addition, it is possible that a negative correlation between a venture capitalist's ownership share $\\upalpha$ and a measure of firm performance could arise from dilution in a multi-period process (i.e., the possibility that low performance leads to high $\\upalpha$ ). Unfortunately, we do not have adequate data, such as data on a venture capitalist's ownership share in the start-up phase, to correct for dilution.  \n\nIt is difficult to measure firm performance directly, but revenues per unit asset and taxes paid should both be good measures of performance. Table 7 reports the results arising from regressing these measures of firm performance on the venture capital ownership share, correcting for age of the firm.  \n\nTABLE 6 Estimated Real Annual Returns by Exit Type   \n\n\n<html><body><table><tr><td rowspan=\"2\"></td><td rowspan=\"2\">Meanof individualreal annualreturns*</td><td rowspan=\"2\">Standard deviationof individual returns</td><td rowspan=\"2\"></td><td rowspan=\"2\">Realannual return of sum ofinvestments**</td></tr><tr><td>No.of observations</td></tr><tr><td>IPO</td><td>43%</td><td>62%</td><td>26</td><td>26%</td></tr><tr><td>Acquisition</td><td>36%</td><td>61%</td><td>16</td><td>9</td></tr><tr><td>Secondarypurchase</td><td>23%</td><td>41%</td><td>11</td><td>29%</td></tr><tr><td>Company buyout</td><td>2%</td><td>15%</td><td>37</td><td>0%</td></tr><tr><td>Writeoff</td><td>100%loss over</td><td></td><td>24</td><td>100%lossover</td></tr><tr><td></td><td>holding period</td><td></td><td></td><td>holding period</td></tr><tr><td>Other</td><td>2%</td><td>18%</td><td>7</td><td>13%</td></tr></table></body></html>\n\n\\* Individual annual returns are calculated as: {(Proceeds from investment - cost of investment) ^ (1/holding period) - 1). $^{**}$ This number is calculated as: (Sum of proceeds from investment - sum of costs of investment) ^ (1/average holding period) - 1). Source: Macdonald & Associates Ltd. Investment Database.  \n\nTABLE 7 Effect of Venture Capital Share on Performance (Tobit Regressions)   \n\n\n<html><body><table><tr><td>Dependent vbl.</td><td>Expl. variable</td><td>Coefficient</td><td>Std.error</td><td>T-stat</td><td>P-value</td></tr><tr><td rowspan=\"3\">TaxesPaid</td><td>VCshare</td><td>-10.59</td><td>1.95</td><td>-5.44</td><td>.000</td></tr><tr><td>log(Age)</td><td>454</td><td>61</td><td>7.44</td><td>.000</td></tr><tr><td>Const.</td><td>-696</td><td>155</td><td>-4.50</td><td>.000</td></tr><tr><td rowspan=\"3\">TaxesPaid/Assets (×10000)</td><td>VCshare</td><td>-28.27</td><td>5.94</td><td>-4.76</td><td>.000</td></tr><tr><td>log(Age)</td><td>488</td><td>187</td><td>2.61</td><td>.009</td></tr><tr><td>Const.</td><td>-578</td><td>474</td><td>-1.22</td><td>.223</td></tr><tr><td rowspan=\"3\">Revenues/Assets (×1000)</td><td>VCshare</td><td>-46</td><td>20</td><td>-2.30</td><td>.021</td></tr><tr><td>log(Age)</td><td>-386</td><td>649</td><td>-0.60</td><td>.55</td></tr><tr><td>Const.</td><td>8958</td><td>1604</td><td>5.59</td><td>.000</td></tr></table></body></html>\n\nSource: Macdonald & Associates Ltd. Economic Impact Database.  \n\nAs can be seen from these regressions, there is a statistically strong negative relationship between the venture capitalist's ownership share and these measures of firm performance. Ideally, we would like to use profit as a measure of success, but profit is not available in the data. However, profit is closely related to taxes paid, so taxes should normally be a good proxy for profit. We acknowledge, however, that for emerging growth companies, taxes paid may be a poor preditor of their value creation potential. Note that taxes are truncated from below at 0. (Firms do not pay negative taxes no matter how poor their performance.) Accordingly the estimation is done using Tobit estimation rather than ordinary least squares. The basic finding is that there is a strong negative relationship between whatever measure of performance we use and the share of the venture owned by the venture capitalist. This could be the result of either the moral hazard or the venture capitalist's self-selection constraint. It is also possible that ventures for which $\\upalpha$ is high pay out more earnings to the venture capitalist, and, therefore, have lower future earnings. However, normalizing for asset size should mitigate thisconcern.  \n\nWe emphasize that the amount of variation explained by the venture capital share is low. Thus, while the coefficient on the venture capital share is significant, variations in this share are, at most, a minor determinant of performance. It is also important that these results not be interpreted as suggesting that venture capital investment should be viewed as a negative influence, or that other sources of finance are better than venture capital. Venture capital investments could be an imortant positive infuence on every firm in the data set, and could be the best source of financial capital available, and we would still expect to observe a negative correlation between venture capital ownership and performance. What the negative correlation tells us is that the best performing companies tend to be those in which the venture capital ownership share is not too high. However, if financial requirements are high and the owner's sources are meagre, then a substantial venture capital share might be the best option, even if there is an associated moral hazard problem, as the alternative might be outright failure of the company.  \n\n## CONCLUDING REMARKS  \n\nThe theoretical framework we offer focuses on informational issues. Specifically, we view asymmetric information as the central feature of venture capital investment. Both major forms of asymmetric information, “hidden information” (leading to adverse selection) and “hidden action\" (leading to moral hazard) are included in our analysis. While the model abstracts from some important elements of the venture investment process (such as bargaining, syndication, etc.), we believe that the informational issues are perhaps the most central issues to focus on at this stage.  \n\nWe have shown that this information-based approach is consistent with the data on Canadian venture capital investments. Moral hazard and adverse selection create a market failure in entrepreneurial financing, which might lead many worthwhile projects to be unfunded or underfunded. The more skilled the venture capitalist is in reducing these sources of market failure, the more effectively this sector will function. Venture capitalists exist because they are better at this function than unspecialized investors. However, venture capitalists cannot eliminate adverse selection and moral hazard. Furthermore, these problems are more acute for younger firms, and most acute for startups. This explains why venture capitalists focus on later stage entrepreneurial firms. Later stage firms have a track record that provides information to the entrepreneur, and they have enough assets to reduce the problem associated with limited collateral under limited liability. By virtue of their expertise, venture capitalists are better at dealing with informational problems than are other investors (on average), but this advantage shows up most in later stage entrepreneurial firms rather than at the start-up stage.  \n\nThis theoretical structure is also consistent with the pattern of exit. If asymmetric information is important, and remains important even at the exit stage, then outside public investors will not be in the best position to evaluate the assets of the entrepreneurial firm, and insiders will be in a better situation to buy out the venture capitalist's position. These insiders might be management or officers of the investee, or they might be other firms in a related business. Thus, it is not surprising that IPOs account for only a modest fraction of exit. In addition, our model predicts a negative relationship between the extent of venture capital ownership and firm performance. This relationship is found in the data.  \n\nThere are several natural extensions to the line of reasoning presented in the paper. One complicating factor is the possibility that a venture capitalist's cost of monitoring an entrepreneur might vary with the venture capitalist's ownership share. It is sometimes suggested that it is easier for the venture capital firm to monitor if it has a larger ownership share. In our model, this would suggest that m would exogenously depend on $\\upalpha$ Furthermore, we recognize that many aspects of venture capital activity have not been captured in our analysis. In particular, we abstract from staged investment, which is a common feature in venture capital finance and can serve to ameliorate problems caused by asymmetric information. It would be interesting to extend our model to a multiperiod analysis.  \n\nThe challenge we and other researchers face is to develop theoretical structures that can be subject to empirical investigation. Ideally such theories should also provide normative implications for practice. Our paper is a small but hopefully useful step in this direction.  \n\n## REFERENCES  \n\nAdmati, A., and Pfeiderer, S. 1994. Robust financial contracting and the role of venture capitalists Journal of Finance 49(2):371-402.  \n\nAkerlof, G. 1970. The market for lemons: Quality uncertainty and the market mechanism. Quarterly Journal of Economics 84(3):488-500.   \nAmit, R., Brander, J., and Zott, C.1997. Venture capital fnancing of entrepreneurship in Canada. In Paul Halpern, ed., Capital Market Issues in Canada. Industry Canada, Ottawa.   \nAmit, R., Glosten, L., and Muller, E. 1990. Entrepreneurial ability, venture investments, and risk sharing. Management Science 36(10):1232-1245.   \nAmit, R., Glosten L., and Muller, E. 1993. Challenges to theory development in entrepreneurship research. Journal of Management Studies 30(5):815-834.   \nArrow, K. 1973. The Limits of Organization. New York: Norton.   \nBarry, C., Muscarella, C., Peavy, J., and Vetsuypens, M. 1990. Venture capital in the creation of public companies: evidence from the going-public process. Journal of Financial Economics 27(2): 447-71.   \nBusiness Development Bank of Canada (Annual, 1993-95), Economic Impact of Venture Capital (Montreal).   \nBygrave, W., and Timmons, J. 1992. Venture Capital at the Crossroads. Boston, MA: Harvard Business School Press.   \nChan, Y. 1983. On the positive role of financial intermediation in allocations of venture capital in a market with imperfect information. Journal of Finance 38(5):1543-1561.   \nChan, Y, Sigel, D., and Thakr, A190.Leaning, corporate contrland pformance requremets in venture capital contracts. International Economic Review 31(2):365-381.   \nFried, V., and Hisrich, R.1994.Toward a model of venture capitalinvestment decision making. Financial Management 23(3):28-37.   \nGompers, P. 1995. Optional investment, monitoring and the staging of venture capital. Journal of Finance 50(5):1461-1489.   \nGompers, P. 1996. Grandstanding in the venture capital industry. Journal of Financial Economics 42(1):133-156.   \nGompers, P., and Lerner, J. 1994. A note on the venture capital industry. Harvard Business School Note N9-295-065.   \nGorman, M., and Sahman, W.A. 1989. What do venture capitalists do? Journal of Business Venturing 4(4):231-248.   \nHellmann, T. 1994. Financial structure and control in venture capital. Stanford University Working Paper.   \nHirao, Y. 1993. Learning and incentive problems in repeated partnerships. International Economic Review 34(1):101-119.   \nIndustry Canada, June 1994. Financing the new economy: towards a positive conspiracy. Project Report.   \nJensen, M., and Meckling, W.1976. Theory of the frm: managerial behavior, agency costs, and owership structure. Journal of Financial Economics 3(4):305-360.   \nLerner, J. 1994. The syndication of venture capital investment. Financial Management 23(3):16-27.   \nLerner, J. 1995. Venture capitalists and oversight of private firms. Journal of Finance 50(5):301-318.   \nLow, M., and MacMillan, 1. 1988. Entrepreneurship: past research and future challenges. Journal of Management 14(2):139-161.   \nMacdonald& Associates Ltd.(annual) Venture Capitalin Canada: Annual Statistical Review and Directory, (Association of Canadian Venture Capital Companies: Toronto).   \nMacIntosh, Jeffrey G. 1994. Legal and Institutional Barriers to Financing Innovative Enterprise in Canada, Discussion Paper 94-10, School of Policy Studies, Queen's University, Kingston.   \nMacMillan, I., Siegel, R., and Narashima, P. 1985. Criteria used by venture capitalists to evaluate new venture proposals. Journal of Business Venturing 1(1):119-128.   \nMacMillan, I.,Zemann, L., and Narashima, P.1987. Criteria distinguishing succesfulfrom unsuccesful ventures in the venture screening process. Journal of Business Venturing 2(2):123-137.   \nMegginson, W., and Weiss, K. 1991. Venture capitalist certification in initial public offerings. Journal of Finance 46(3):879-903.   \nPauly, M. 1974. Overinsurance and public provision of insurance: the roles of moral hazard and adverse selection. Quarterly Journal of Economics 88:(1):44-54.   \nRothschild, M., and Stiglitz, J. 1976. Equilibrium in competitive Insurance Markets: an essay on the economics of imperefect information. Quarterly Journal of Economics 90(9):629-649.   \nSahlman, W. 1990. The structure and governance of venture-capital organizations. Journal of Financial Economics 27(2):473-521.   \nSpence, M. 1973. Job market signalling. Quarterly Journal of Economics 87(3):355-374.   \nTyebjee, T., and Bruno, A. 1984. A model of venture capital investment activity. Management Science30(9):1051-1066.  \n\n## APPENDIX 1  \n\n### Mlustration of the Basic Moral Hazard Problem  \n\nFigure A1 shows the marginal cost of effort (a horizontal line) and the marginal expected benefit of effort (given by $\\mathbf{R}_{\\mathrm{e}}$ ). The efficient amount of effort occurs where marginal benefit equals marginal cost, and is denoted $\\mathrm{e}^{*}$ in the diagram. The marginal benefit perceived by the entrepreneur is only $(1{\\mathrm{~-~}}\\alpha)\\mathrm{R}_{\\mathrm{e}}$ , which is strictly below $\\mathbf{R}_{\\mathrm{e}}$ It follows that the amount of effort actually chosen, denoted $\\mathrm{e^{\\prime}}$ , is less than the efficient amount. The basic problem is that the entrepreneur cannot precommit to provide effort level $\\mathrm{e}^{*}$ . Once financing is obtained and share $\\upalpha$ of the firm has been sold to the investor, the entrepreneur will only provide effort level $\\mathrm{e^{\\prime}}$ . If the investor and the entrepreneur could contract over e, then they could agree that $\\mathrm{e}^{*}$ would be provided, but this is impossible under the assumption that e cannot be observed (or at least legally verified) by the investor.  \n\n![](images/a85406d509f85c00882612cb40ca3f27e50b3a3021c0d85054daf7e633f60878.jpg)  \nMarginal Return   \nFIGURE A1 Moral hazard.  \n\n## APPENDIX 2  \n\n### Formal Analysis of the Adverse Selection Problem  \n\nFrom (18) we derive the first-order condition  \n\n$$\n\\mathrm{EV_{d}=p^{\\prime}(d)\\int_{q^{0}}^{\\infty}{(\\alpha R(q)-C)f(q)d q}-1}=0\\\n$$  \n\nwhere $\\mathrm{F}$ is the cumulative distribution of q. Let  \n\n$$\n{\\bf K}=\\int_{{\\bf q}^{0}}^{\\infty}{(\\alpha{\\bf R}({\\bf q})-{\\bf C})}{\\bf f}({\\bf q}){\\bf d q}\n$$  \n\nThen (A2.1) simplifies to  \n\n$$\n\\mathrm{p^{\\prime}}(\\mathrm{d})=\\frac{1}{\\mathrm{K}}\n$$  \n\nTo derive the second-order condition, $\\mathrm{EV_{d}}$ is differentiated with respect to $\\mathrm{^d}$ yielding  \n\n$$\n\\begin{array}{l}{{\\displaystyle{\\tt E V}_{\\scriptscriptstyle\\mathrm{dd}}={\\tt p}^{\\prime\\prime}({\\bf d})\\int_{\\bf q}^{\\infty}\\left(\\alpha{\\bf R}({\\bf q})-{\\bf C}\\right){\\bf f}({\\bf q}){\\bf d q}}}\\ {{\\displaystyle~={\\bf p}^{\\prime\\prime}({\\bf d}){\\bf K}}}\\end{array}\n$$  \n\nIt follows from (17) and (18) that (A2.4) is strictly negative, which is the precondition for (A2.3) to yield a maximum.  \n\n(A2.3) has interesting implications. Suppose that $\\mathtt{R}({\\mathfrak{q}})$ is such that there are many worthwhile projects and a few projects that have very low negative expected returns. ${\\mathfrak{q}}^{0}$ is therefore low. Specifically, assume that K is relatively large, resulting in a rather low value of $\\mathrm{p^{\\prime}}(\\mathrm{d})$ , which in term implies a relatively large optimal value of d (if a solution to (A2.3) exists at all). Thus, with such a constellation of parameters, it pays to invest high d in due diligence. On the other hand, if $\\mathtt{R}({\\mathfrak{q}})$ is such that K is relatively small (which may happen if there are only few attractive projects and many “lemons, i.e., if ${\\mathfrak{q}}^{0}$ is high), this will result in a relatively small optimal value of d (depending, of course, on the shape of p(d)).  \n\nIn order to illustrate the point that an investor with a highly responsive detection function p(d) (say, investor h with a detection function $\\mathrm{p}(\\mathrm{d}^{\\mathrm{h}}))$ is more likely to invest in projects with high asymmetry of information than an investor with a less responsive $\\mathrm{p(d)}$ (say, investor 1 with a detection function $\\mathrm{p(d^{\\mathrm{I}})}$ o, let us consider the following case. Assume that ${\\mathfrak{q}}^{0}$ is high and K is small, resulting, according to (A2.3), in a large $\\mathrm{p}^{\\prime\\prime}(\\mathrm{d})$ This is fairly realistic, as the pattern of returns of venture capitalists is usually skewed with most investments generating either disappointing or negative returns and only a few becoming ‘stars'.  \n\nIt may happen that investor h finds it worthwhile to spend $\\smash{\\mathrm{d}^{\\mathrm{h}^{*}}>0}$ (which is the value of $\\mathrm{d}^{\\mathrm{h}}$ that satisfies A2.3) and go ahead with project ${\\mathfrak{q}}\\geq{\\mathfrak{q}}^{0}$ , while investor l finds that the optimal value of $\\mathrm{d}^{\\mathrm{l}}$ is $\\mathbf{d}^{\\mathrm{\\tiny{l}^{\\ast}}}=0$ and thus refrains from investing. (Of course, even if $\\mathrm{{d}^{\\mathrm{{h}^{\\ast}}}>0}$ , the investor's feasibility constraint (20) has to hold before investment I is made.) These points are illustrated in Figure A2.  \n\nNote that for some values of K, both $\\mathrm{d^{\\ast}}$ and $\\mathrm{d}^{\\mathrm{h}^{*}}$ can be positive in our example. Then it pays even for investor I to do due diligence. Again, it also depends on constraint (20) whether either investor 1 or h or both find the investment attractive.  \n\n![](images/41ba91007fbcfcfafa83a74acd6ed70a25e300f35c8eb4a839491d0b450e3388.jpg)  \nFIGURE A2   Optimal due diligence for different detection functions p(d)  "
  },
  "md_atanasovDoesReputationLimit2012": {
    "reference_markdown": "# Does Reputation Limit Opportunistic Behavior in the VC Industry? Evidence from Litigation againstVCs  \n\nVLADIMIR ATANASOV, VLADIMIR IVANOV, and KATE LITVAK\\*  \n\n# ABSTRACT  \n\nWe examine the role of reputation in limiting opportunistic behavior by venture capitalists towards four types of counterparties: entrepreneurs, investors, other VCs, and buyers of VC-backed startups. Using a hand-collected database of lawsuits, we document that more reputable VCs (i.e., VCs that are older, have more deals and funds under management, and syndicate with larger networks of VCs) are less likely to be litigated. We also find that litigated VCs suffer declines in future business relative to matched peers. These declines are larger for more reputable VCs, and for VCs that are defendants to multiple lawsuits or sued by entrepreneurs.  \n\nREPUTATION OFTEN SERVES AS an informal enforcement mechanism in theoretical settings with incomplete contracts and informational asymmetries (Klein and Leffler (1981, “KL\"hereafter), Kreps and Wilson (1982), and Shapiro (1983)). In these buyer-seller models, reputational capital is defined as the present value of a stream of quasi-rents that a seller earns from delivering contracted quality.  \n\nReputation helps enforce contracts, because existing or potential counterparties can respond to a breach of contract by terminating or adjusting the terms of their business relationship and causing the breaching party to lose its entire stream of quasi-rents.  \n\nEmpirical evidence consistent with the importance of reputation in contract design and outcomes comes from a variety of economics studies (see MacLeod (2007) for a review). The finance literature on reputation predominantly shows that various types of corporate misconduct result in reputational losses, but these losses are not uniform across types of contractual relationships. In a review of this literature, Karpoff (2011) notes that, typically, opportunism against business counterparties such as customers1 or investors2 leads to reputational losses that are much larger than any legal penalties, while opportunism against unrelated parties (e.g., environmental pollution) results in no reputational losses.  \n\nKarpoff (2011) also finds that the vast majority of the finance literature on reputation measures reputational loss by stock price declinean important, yet indirect, measure of the loss of future quasi rents. Only a few exceptions, like Graham, Li, and Qiu (2008) and Murphy, Shrieves, and Tibbs (2009), try to identify the real reputational effects of counterparties adjusting their behavior (e.g., customers canceling orders, lenders changing debt contract clauses, etc.). There is even less evidence about the deterrent effects of reputation on corporate misconduct, the information channels that enable reputational mechanisms, or the interactions between reputational mechanisms on the one hand and contracts, courts, and other institutions on the other.  \n\nOur paper focuses on the venture capital industry and examines two previously unexplored research questions. First, we document whether reputational concerns limit opportunistic behavior by venture capitalists (VCs). Second, we investigate whether alleged opportunistic behavior by VCs leads to direct reputational losses caused by VC counterparties (startup founders, investors, or other VCs) adjusting the terms of their relationships with the opportunistic VCs. Along this line of inquiry, we also examine whether stronger evidence of opportunism is associated with larger reputational losses and study the variation in reputational losses by type of counterparty.  \n\nVCs are in the nexus of contractual relationships with many types of counterparties. We examine the role ofreputation in the relationships between VCs and four such counterparties: (1) startup founders/entrepreneurs, (2) investors in VC funds (limited partners or LPs), (3) other VCs, and (4) buyers of VC-backed startups. The role of reputation in limiting opportunistic behavior against each of these counterparties could vary because the contracts regulating their relationships with VCs differ in the allocation of contractual rights and protections. Contracts between VCs and entrepreneurs do little to protect entrepreneurs against VCs; their primary role is to protect VCs against entrepreneur misbehavior (e.g., Hellmann (1998), Kaplan and Stromberg (2003)). As Gilson (2003, P. 1085) puts it, “Reducing the agency costs of the entrepreneur's discretion by transferring it to the venture capital fund also transfers to the venture capitalist the potential for agency costs—the opportunity to use that discretion opportunistically with respect to the entrepreneur.\" Reputation can serve a critical role in limiting the contractually enabled VC opportunism against entrepreneurs. In contrast, the contracts between VCs and their investors (limited partners) provide significant protections to investors (Litvak (2004)) and thus may leave a smaller role for reputational mechanisms in the regulation of VC-limited partners relationships.  \n\nAn empirical study of the role of reputation in the VC industry requires the identification of two types of proxies—(1) proxies for opportunistic behavior and (2) proxies for reputation with each type of counterparty. Opportunistic behavior, especially in privately held companies or limited partnerships, is difficult to observe or quantify. We resolve this problem by hand-collecting a large sample of lawsuits filed against VCs and using these lawsuits as a proxy for alleged opportunistic behavior.? Based on the lawsuit plaintiff, we can further identify whether the VC allegedly behaved opportunistically against founders, limited partners, other VCs, buyers of VC-backed startups, or other parties (angels, creditors, employees, etc.).  \n\nWe choose proxies for VC reputation with each of the four types of VC counterparties based on existing research. First, the number of deals that a VC invests in serves as proxy for the VC's reputation with entrepreneurs. Second, VCs raise a series of funds, and thus regularly return to investors to raise new capital. We use the amount of funds under management to proxy for the VC's reputation with investors. Third, the VC's network centrality, defined by Hochberg, Ljungqvist, and Lu (2007) as the scaled number of relationships that a VC has with other VCs, serves as proxy for the VC's reputation with other VCs. Last, we use the percentage of companies in the VC's portfolio that go public to proxy for the VC's reputation with buyers of VC-backed startups. In our analysis, these proxies serve two roles: first, they proxy for the value of reputation, and second, they measure the real impact that litigation has on the relationships between VCs and each of the four types of counterparties, which in turn will result in the loss of reputational quasi rents.  \n\nWe use the hand-collected data set of lawsuits and our proxies for reputation calculated using VentureXpert data to perform two sets of empirical tests. First, we test the hypothesis that reputation is negatively related to a VC's propensity to be involved in litigation. We estimate a probit model at the VC-startup level and find that most proxies for reputation are negatively associated with the probability of a VC-startup investment ending in litigation. These findings suggest that more reputable VCs are less likely to behave opportunistically against entrepreneurs and other startup investors.  \n\nSecond, we study the consequences of litigation on a VC's reputation with entrepreneurs, investors, other VCs, and buyers of VC-backed startups. To control for possible endogeneity and spurious correlation between the reputation proxies and impacts of litigation, we implement several matching techniques to identify peer nonlitigated VCs that are otherwise similar to the litigated ones. We then calculate peer-adjusted changes in each of our four reputation proxies as differences in differences—the post- minus prelawsuit measures for litigated VCs minus the post- minus prelawsuit measures for peers.  \n\nWe find strong evidence that litigated VCs invest in a smaller number of deals, raise smaller funds, and syndicate with a smaller number of VCs relative to their nonlitigated peers. The effects are economically large. Using 2002 as a base (the median lawsuit filing year), litigated VCs experience a mean peer-adjusted decline in the number of deals of 430-1,840 investment rounds and a 380-690 million dollar decline in fundraising (depending on matching technique). The reputational losses are even larger when VCs are defendants to multiple lawsuits. Furthermore, we find that lawsuits filed by founders, especially when such lawsuits are lost by the VC, lead to more than three times larger peer-adjusted declines in the number of deals and funds under management relative to other lawsuits. Our main results are robust to alternative corrections for endogeneity such as Heckman (1976)-type selection models. They also survive large-scale comparisons of the litigated VCs to bootstrapped peer samples and various other robustness checks.  \n\nOverall, our findings indicate that reputational mechanisms discipline and deter widespread abuse of power by VCs, especially against founders. Furthermore, our analysis suggests that litigation can support contract enforcement directly, by serving as a channel to inform other counterparties of VC misbehavior, or indirectly, by providing factual material about alleged misbehavior that general or specialized media outlets can disseminate.  \n\nThe remainder of the paper is organized as follows. Section I provides background on the relationships in the VC industry and the potential role of reputation. Section II develops our hypotheses. Section IHI discusses the data. We present the results of litigation propensity models in Section IV and post- versus prelawsuit analysis of changes in VC reputational measures in Section V. SectionVI concludes.  \n\n## 1. Relationships in the VC Industry and the Role of Reputation  \n\nVCs interact with various counterparties. VCs raise capital from qualified investors. They invest in startup companies and deal with their founders and other equity investors. VCs often syndicate their investments with other VCs or invest in follow-up rounds in which the original VCs do not. Finally, when VCs exit their investment in a startup they either sell the startup to a strategic acquirer or take it public by selling shares to IPO investors with the intermediation of investment banks. In this section we describe the nature of the four most important contractual relationships in the VC industry with a special focus on potential for opportunistic behavior by the VCs. We also discuss possible roles for reputation in limiting such behavior.  \n\n### A. VCs and Entrepreneurs  \n\nSeveral theoretical papers raise the possibility of VC opportunistic behavior against entrepreneurs. Ueda (2004) models potential expropriation of enterpreneurs by VCs and suggests that banks could mitigate this confict. Yosha (1995) and Bhattacharya and Chiesa (1995) develop models in which a financier has the incentive to support the spillover of interim knowledge across firms in her portfolio since that increases the likelihood of breaking even on each individual investment. VCs often get a contractual right to replace founders, and they do so regularly (Hellmann and Puri (2002)). In addition, VCs tend to encourage their portfolio firms to enter into strategic relationships with one another, the so-called “Keiretsu network\" (see Lindsey (2008)). Thus, they could engage in transfer pricing by arranging for one portfolio firm to purchase intellectual property, services, or other assets from another portfolio company at non-arm's-length prices. VCs could also allocate business opportunities unequally among the firms in their portfolios.  \n\nVCs could behave opportunistically toward founders. Their formal contracts with entrepreneurs provide the ability to do so, and background legal rules add little to protect founders beyond whatever the contracts provide. Yet if opportunistic behavior were too widespread, venture capital could not fourish as it has, nor could formal contracts be written, in equilibrium, in the strongly pro-VC manner documented by Kaplan and Stromberg (2003). So there must be some informal constraints on VC behavior. Reputation could be one mechanism that limits the opportunistic behavior of VCs. A reputation for dealing fairly with entrepreneurs can generate future high-quality deal fow or better financing terms for VCs. For example, Hsu (2004) shows that reputable VCs are able to invest at lower valuations and hence receive larger equity stakes for given investment amounts. Reputational mechanisms benefit not only the VCs, but also the entrepreneurs. In the model of Bachmann and Schindele (2006), for example, entrepreneurs are willing to spend more effort on developing their ideas and achieve better startup performance if VC investors have a reputation for not stealing entrepreneurs’ intellectual property.  \n\n### B. VCs and Investors in VC Funds  \n\nThe structure of VC limited partnerships, the management of multiple partnerships by the same VC, and the lack of objective information about the performance of startup investments before exit offer VCs various venues to behave opportunistically at the expense of their limited partners. They can use partnership capital to invest in companies controlled by related parties, consume excessive perks, or divert business opportunities from one partnership to another. Limited partners receive some contractual protections. They have to approve transfers between limited partnerships controlled by the same VC and often require periodic audited disclosures. Still, contractual provisions cannot prevent all opportunistic behavior.  \n\nThe VC-investor relationship is structured to facilitate the role of reputation. Most institutional investors pick VCs based on their past performance and prefer VCs with a long track record. Also, venture funds are organized as limited-term partnerships, which forces VCs to go back to investors to raise capital for new funds every few years. Better reputation with investors earns VCs quasi-rents. More reputable VCs are able to raise more capital, able to raise capital faster, and can negotiate better terms with their limited partners, that is, charge higher management fees and/or take a bigger share ofthe profits ofthefund.  \n\n### C. VCs and Other VCs  \n\nVCs often syndicate investments with other VCs or invest in later rounds in startups that other VCs have previously invested in. VCs investing in latter rounds can dilute or seize control from early-round VCs. Latter-round VCs can also negotiate better exit terms in an acquisition for themselves at the expense of previous investors. Such behavior is often impossible to control with a contract, yet there are very few anecdotes of VCs abusing other VCs, suggesting that reputational mechanism are at work. Indeed, a VC with a better reputation among other VCs will presumably find it easier to syndicate its own investments, and will receive better syndication offers from other VCs. For example, Lerner (1994) finds that reputable VCs tend to syndicate with other reputable VCs. Hochberg, Ljungqvist, and Lu (2007) investigate the role of VCs' network centrality (which measures the relative importance of a VC in a VC network by looking at the number and quality of VCs with which it has a relationship, and the frequency with which it is invited to coinvest in other VCs' deals or it invites other VCs to invest in its deals), and find that better-networked VCs experience significantly better performance. The prospect of losing such quasi-rents can ensure that VC opportunism against other VCs is rare.  \n\n### D. VCs and Startup Acquirers and IPO Investors  \n\nVCs exit from investments by selling them to strategic acquirers or to public markets through an IPO. In either case, a chief worry of buyers is the adverse selection resulting from the seller's superior information about the startup company's true value. Reputational concerns can alleviate this adverse selection. There is ample empirical evidence on the importance of reputation during VC exits through IPO. Krishnan et al. (2011) find that IPOs backed by more reputable VCs enjoy better post-IPO long-run performance. Lin and Smith (1998) find that more reputable VCs are less likely to sell overpriced shares in an IPO. Baker and Gompers (2003) find that IPOs backed by reputable VCs have more independent boards and less powerful CEOs than non-VC-backed IPOs and IPOs backed by less reputable VCs.  \n\n### E.Interactions between Reputational Mechanisms  \n\nOur choice to analyze four types of contractual relationships increases the dimensions of possible interactions relative to classic reputational models. It is possible for counterparties of other types to terminate their relationship with a VC following alleged VC opportunism. For example, a VC that has expropriated an entrepreneur can face reduced fundraising as limited partners reconsider their involvement with the VC, either because the limited partners understand that the VC will experience a reduced number of deals due to avoidance by other entrepreneurs or because they have updated their beliefs about how likely the VC is to expropriate them as well. In addition, some limited partners are university endowments that often motivate their investments in VC funds with strong intent to stimulate entrepreneurship, innovation, and economic growth. Such limited partners will be especially sensitive to how their VCs treat entrepreneurs. Thus, the need to preserve reputation with limited partners will further constrain some VC activities that might harm entrepreneurs.  \n\nConversely, the tightness of the VC community may work against a complaining founder, instead of against a misbehaving VC, if the merits of the complaints are hard to estimate and if VCs tend to support their own and distrust “trouble-makers.\" The “no lunch in this town\" gossip one can often hear in founder circles indicates that the fear (warranted or not) of VCs’ implicit collusion not to fund complaining founders may restrict the fow of information about VC misbehavior and thus induce more misbehavior.  \n\n## II. Proxies and Testable Hypotheses  \n\nBefore we develop testable hypotheses about the role of reputation in limiting opportunistic behavior in the VC industry, we need to choose proxies for both reputation and opportunistic behavior. We use the age of the VC as a general proxy for reputation with any counterparty (Diamond (1989)). The specific reputation ofVCs with entrepreneurs, limited partners, other VCs, and startup buyers is not observable. We proxy for unobservable specific reputation using the extent of VC relationships with counterparties of a specific type. First, we use number of deals, calculated as the scaled number of investment rounds that all limited partnerships managed by the VC have participated in, as a proxy for reputation with entrepreneurs. Second, following Kaplan and Schoar (2005), we use the scaled sum of funds under management across all limited partnerships managed by a VC as a proxy for reputation with investors. Third, we consider VC network centrality as a proxy for reputation with other VCs, where we use the network degree measure defined by Hochberg, Ljungqvist, and Lu (2007) as the number of relationships a VC has with other VCs, scaled by the number of maximum relationships possible. Last, we use the fraction of VC portfolio firms that go public as a proxy for reputation with startup buyers.  \n\nPrior studies have used accounting restatements, bankruptcy, SEC enforcement activities, product failures, and litigation as proxies for opportunistic behavior (Karpoff (2011)). Only the last of these proxies is suitable for our study, because it measures alleged misbehavior against a variety of counterparties and is available for privately held startups and limited partnerships. Litigation is surely a noisy proxy for opportunistic behavior. On the one hand, perhaps only a small percentage of opportunistic behavior will result in litigation. Some disputes can be resolved out of court; in other cases the counterparties may be reluctant to file a lawsuit because the costs of doing so may outweigh the benefits. Thus, litigation may be associated only with cases of severe opportunistic behavior. On the other hand, not all litigation may reflect opportunistic behavior on the part of the VC. Some lawsuits may be without merit, filed by disgruntled entrepreneurs or other parties in search for deep pockets. In addition, even an appropriately behaving VC may be sued if founders seek to retain private benefits of control while a VC seeks to maximize the value of the company.  \n\nWe believe that the percentage of lawsuits without merit filed by entrepreneurs, limited partners, or other VCs is small. Litigation against VCs is very costly for founders, who must incur legal expenses, emotional stress, the near-certainty that they will never again obtain VC funding for a future venture, and, for compact communities like Silicon Valley or Route 128, possible difficulty in obtaining future employment in a related field. Similarly, limited partners and other VCs will resort to litigation only when they truly believe that the offending VC has behaved opportunistically and the dispute cannot be settled in a private manner.  \n\nNote that litigation not only serves as a proxy for opportunistic behavior for our research design, but also provides a mechanism to inform other counterparties of VC misbehavior. Another information channel at play in the highly networked VC industry could be informal conversations. This channel will be available to VCs, limited partners, and serial entrepreneurs, who will undoubtedly chat about their past experiences dealing with particular VCs. The litigation information channel can be especially important for new entrepreneurs, who are not as networked as VC investors or other VCs.4 More plausibly, however, both channels will operate. Entrepreneurs and VCs will communicate informally, but litigation will be a subject of conversation, and will strengthen the credibility of informal complaints, because the costs of frivolous litigation provide certification to any claims of VC misbehavior filed in a lawsuit. Moreover, litigation against VCs generates news that can be covered by the general media or specialized outlets such as the Venture Capital Litigation Reporter The validity of our empirical tests will remain the same regardless of whether litigation directly conveys information about misbehavior or is only associated with misbehavior that is communicated in other ways.  \n\nAfter choosing our proxies for reputation and opportunistic behavior, we next formulate our testable hypotheses. Our first hypothesis relates reputation to the probability of behaving opportunistically. KL predict that more reputable  \n\nVCs will be less likely to behave opportunistically. If we assume that being litigated is a proxy for opportunistic behavior, this prediction implies that more reputable VCs will be less likely to be involved in litigation. This leads to the following hypothesis:  \n\nHYPOTHEsIs 1: More reputable VCs are less likely to face lawsuits.  \n\nFollowing Karpoff (2011), the next three hypotheses relate occurrences ofVC opportunistic behavior to direct reputational losses resulting from counterparties discontinuing or adjusting the terms of their business relationship with opportunistic VCs. Using our proxies for reputation/extent of business relationships, we formulate the following hypothesis about the impact of litigation on operations that drive a reputational loss:  \n\nHYPOTHESIs 2: Lawsuits filed against VCs will result in declines in the number of deals, the size of funds under management, the degree of network centrality, and the percentage of deals that go public.  \n\nBased on the prediction in KL that more reputable parties that behave opportunistically would suffer proportionally larger impacts on their business relationships and hence larger reputational losses, we test the following hypothesis:  \n\nHYPOTHESIs 3: More reputable VCs will suffer a larger adverse impact on their business relationshipsfollowing lawsuits.  \n\nWe also conjecture that some lawsuits will lead to larger adverse operational impacts and thus greater reputational losses than others. This leads to a set of hypotheses about the variation in reputational impacts following litigation. First, reputational models imply that opportunistic behavior towards one counterparty will result in the adverse adjustment of contract terms by other current and (to the extent they learn about it) potential counterparties of the same type. Such contract adjustments will be reflected in a reduction in the VC's business with this type of counterparty. For example, VC opportunism against an entrepreneur will result in a larger reduction in the number of investments made by the VC than opportunism against a limited partner, another VC, or a startup buyer. Substituting litigation for VC opportunism leads to the following hypothesis:  \n\nHYPOTHESIs 4A: Litigation filed by a particular counterparty will result in a larger adverse impact on the VC firm's business relationships with similarcounterparties.  \n\nSecond, when it comes to the possibility of VC misbehavior, founders are the least contractually protected VC counterparty. Therefore, VC reputation should be most important in the VC-founder relationship, and we expect lawsuits in which the founder is the plaintiff to result in greater reputational losses for VCs. This results in the following hypothesis:  \n\nHYPOTHEsIs 4B: Litigation filed by founders will result in a larger adverse impact on the litigated VC's business relationships.  \n\nThird, we also expect that VCs that are litigated and lose the lawsuit or that are defendants to multiple lawsuits will suffer greater reputational loss. The reason is that in those cases the inference about VC misbehavior is more precise. Thus, our last hypothesis is as follows:  \n\nHYPOTHESIs 4C: VCs that are defendants to multiple lawsuits or lose a lawsuit will experience a larger adverse impact on their business relationships than other litigatedVCs.  \n\n## IH1. Data and Summary Statistics of Lawsuits  \n\nHaving developed our testable hypotheses, we next turn to discussing our unique data set of lawsuits involving VCs. In addition to describing the sample selection and data manipulations, we also analyze characteristics of the sample lawsuits, litigated VCs, and VC-backed startups involved in litigation.  \n\n### A. Data Collection  \n\nWe collect a large sample of lawsuits involving VCs over the period 1975-2007. We gather lawsuits from Westlaw's databases that include both judicially resolved cases (in databases containing judgments) and unresolved cases (in databases of complaints and other docket materials). We search using the terms “venture” and “venture capital,” alone and together with terms such as “dilution,” “freeze out, “founder,” and so forth. We also search using the names of venture capital firms identified by the National Venture Capital Association and cross-checked with VentureXpert. Using Westlaw's lawsuit database avoids the usual problem of collecting cases from PACER or Lexis.5 The standard procedure of collecting cases from Lexis produces only judicially resolved cases. Such searches do not include ongoing litigation, as well as cases that were voluntarily dismissed, settled, removed to a different court, and so forth. In contrast, we look at both resolved and unresolved cases. Our searches are also superior to searches in PACER because PACER contains only federal cases. Although Westlaw is the most comprehensive source of litigation data, it covers only those cases that make it to court. In an effort to identify cases that do not reach the courts, we also contemplated searching arbitration databases to obtain cases that could have been resolved through arbitration, but after surveying lawyers from five major law firms that have large specialized VC practices, we concluded that such a search would produce very few, if any, observations.6  \n\nOurWestlaw search identifies 342 lawsuits thathave all available data and 258 lawsuits that have only partial information available, such as case number, type of court (state or federal), names of defendants and plaintiffs, and year of the lawsuit. We augment our sample of lawsuits from Westlaw with the lawsuits listed in the 2004-2006 issues of the Venture Capital Litigation Reporter (VCLR). The VCLR is a specialized magazine disseminated mostly to lawyers that reports lawsuits involving VCs, either as plaintiff or defendant. The VCLR collects lawsuits in situ from Californian courts, and from communications with lawyers and VCs. From the 2004-2006 issues of the VCLR we obtain an additional 39 cases with full information in which a VC is a defendant.  \n\nWe then read each case and exclude those that do not involve litigation by or against a venture capital firm. The defendant's name is not dispositive, because some non-VC firms include the term “venture,”“venture partners,” or even “venture capital.\" We verify that each firm is indeed a venture capital firm. Consequently, we drop nine lawsuits that involve companies that are clearly not VCs.7 We then match the firms involved in the remaining 372 lawsuits against the VentureXpert database (by hand, since many names are similar but not identical). We drop all lawsuits involving VC frms that are not covered by VentureXpert, which leaves us with 265 lawsuits. We further drop two lawsuits that include one particular VC, 3i Group PLC, since it is publicly traded, and seven lawsuits because the VC firms have missing data on their fund size prior to the year of litigation. In addition, we drop 55 lawsuits in which the VC is a plaintiff. We therefore end up with a full information sample of 201 lawsuits involving 189 VC frms and resulting in 243 unique VC firm-lawsuit combinations.  \n\nOf the 258 lawsuits with partial information, we are able to match the names of 29 VC firms resulting in 61 unique VC firm-lawsuit matches. For four ofthose cases we do not have information on funds raised by the VC from VentureXpert, so we drop them from the sample. This leaves us with 25 VC firms, 57 lawsuits, and 57 unique VC firm-lawsuit matches. After dropping 13 cases in which the VC is a plaintiff, we are left with 44 lawsuits involving 24 VC firms and 44 unique VC firm-lawsuit combinations.  \n\nThe final sample comprises 245 lawsuits (201 full-information $+44$ partialinformation) involving 200 VCs and 287 unique VC firm-lawsuit combinations. Figure 1 plots the time distribution of the lawsuits in our sample. Most of our cases are concentrated in the late 1990s and early 2000s. The mean (median) lawsuit filing year is 2001 (2002). Figure 2 plots the unconditional probability of a VC being involved in a lawsuit (the number ofVCs that have been litigated in the past divided by the total number of active VCs in VentureXpert). Consistent with the time distribution of lawsuits in Figure 1, the unconditional probability of VC litigation almost doubles to $1\\%$ in 1994 compared with prior years. Thereafter, it gradually increases until it reaches roughly $4\\%$ attheend of our sample period. This indicates that the number of lawsuits grew faster than the number of VCs.  \n\n![](images/8a0a438dd919616535e3f0bd3daedfc16a079bf85474ed111e4e9db6334bacf5.jpg)  \nFigure 1. Time series of the number of lawsuits filed against VCs. The figure plots the distribution of a total of 245 lawsuits filed against VCs over the 1975-2007 period. Sample lawsuits are identified using searches in West Law, business media, PACER, and the lawsuits listed in the 2004 -2006 issues of the Venture Capital Litigation Reporter. We keep only the lawsuits in which the names of the defendant VCs match with the universe of VCs in VentureXpert.  \n\n### B. Characteristics of Lawsuits Filed against VCs  \n\nWe classify the lawsuits in our sample into six categories by plaintiff type—-(1) lawsuits filed by founders, (2) lawsuits filed by VC investors (limited partners), (3) lawsuits fled by other VCs, (4) lawsuits filed by startup acquirers or IPO investors, (5) lawsuits fled by other parties, and (6) lawsuits that do not have sufficient data to identify plaintiff types. Table I reports the distribution of lawsuits in our sample across these six categories and provides examples of lawsuits of each type.  \n\nLawsuits against VCs are most commonly filed by aggrieved entrepreneurs. Our sample includes 39 such lawsuits filed against 51 VCs, which represents $16\\%$ of the lawsuits in our sample. One common theme of such lawsuits is the claim that VCs use financial transactions to siphon wealth from founders to themselves. Common examples include allegations of dilution and freeze-out, where VCs use their broad contractual powers to oust founders and take over the company. An example of such lawsuits is Cooper v. Parsky, in which the plaintiff Stanley Cooper, founder/CEO of VC-backed startup U.S. Petroleum, is fired by the defendant VCs (Southwest Venture Partners and WSGP, with Gerald Parsky one of the owners of WSGP) and his ownership in the company is diluted to zero in a series of transactions.  \n\n![](images/cb297ed8765aa764875402dcaeb5850b07c1fb9b33779d1164be5c8f7a353552.jpg)  \nFigure 2. Unconditional probability of VC participation in a lawsuit. The figure plots the unconditional probability (defined as the cumulative number of VCs litigated as of a given year divided by total number of VCs founded prior to that year) of a VC being sued for the 1975-2007 period. Sample lawsuits are identified using searches in West Law, business media, PACER, and the lawsuits listed in the 2004-2006 issues of the Venture Capital Litigation Reporter. We keep only the lawsuits in which the names of the defendant VCs match with the universe of VCs in VentureXpert.  \n\nAnother common claim involves expropriation of firm assets. Cooper actually wins the Cooper v. Parsky lawsuit and the court awards significant damages that Cooper should receive from the startup company. Despite the favorable court decision, Cooper does not receive any award, because the VCs transfer all of the assets of the startup to other companies and Cooper is left with payment claims against an empty shell. Ajaxo v. $E^{*}$ Tradeis another lawsuit that alleges expropriation of firm assets. This time the corporate venture arm of $\\mathbf{E}^{*}$ Trade Group Inc. (the defendant) breaches a mutual nondisclosure agreement with Ajaxo Inc. (the plaintiff) by disclosing proprietary information to Everypath Inc., which was one of $\\mathbf{E}^{*}$ Trade's portfolio companies  \n\n# TableI Characteristics of Lawsuits Filed against VCs  \n\nWe collect lawsuits filed against VCs over the period 1975-2007 using searches in West Law, business media, PACER, and the lawsuits listed in the 2004-2006 issues of the Venture Capital Litigation Reporter. We keep only the lawsuits in which the names of the defendant VCs match with the universe of VCs in VentureXpert. We classify plaintiffs into the six categories listed in the first column of the table. The third column reports the number of Lawsuit $\\times\\mathrm{VC}$ observations(e.g., a lawsuit against two VC defendants generates two lawsuit $\\times\\mathrm{VC}$ observations). The numbers in parentheses are the corresponding number of observations in the 1975-2005 period, which is used in the empirical analysis of the outcomes of litigation in Section V of the paper.  \n\n<html><body><table><tr><td>Plaintiff</td><td>Number of Lawsuits</td><td>J0 % Lawsuit Sample</td><td>Number of Lawsuits × VCs</td><td>Examples</td></tr><tr><td>Entrepreneur</td><td>39 (39)</td><td>15.9% (18.0%)</td><td>51 (51)</td><td>Cooper v. Parsky (equity dilution, freeze-out, asset transfers) Ajaxo v.E*Trade(transfer ofintellectual</td></tr><tr><td>Investor in VC funds</td><td>21 (18)</td><td>8.6% (8.3%)</td><td>21 (18)</td><td>property to another startup) CMSTechAccessSubpartnershipv.GMG Management (fraudulent disclosures, asset transfers from partnership, diversion of business opportunities)</td></tr><tr><td>Another VC</td><td>9 (7)</td><td>3.7% (3.2%)</td><td>10 (6)</td><td>SyndicatedCommunicationVenturePartnersv. Baystar Capital (breach of fiduciary duty, asset transfer, mismanagement of VC-backed startup)</td></tr><tr><td>Startup buyer</td><td>16 (15)</td><td>6.5% (6.9%)</td><td>31 (30)</td><td>Equifax INC v.AustinVentures (false and misleading information provided by VC prior to acquisition)</td></tr><tr><td>Other</td><td>109 (88)</td><td>44.5% (40.5%)</td><td>123 (101)</td><td>Bruhu.BessemerVenturePartners III L.P. (angel investor) AT&Tv.Walker (bankruptcy) Blackburnv.TVFanfarePublications(employee sexual harassment against VC-backed</td></tr><tr><td>Unable to classify plaintiff</td><td>51 (50)</td><td>20.8% (23.0%)</td><td>51 (50)</td><td>Alliance Technology,INC (trademark)</td></tr><tr><td>Total</td><td>245 (217)</td><td></td><td>287 (258)</td><td></td></tr></table></body></html>  \n\nat the time. Ajaxo won the lawsuit and was awarded $\\$1.3$ millionin damages.  \n\nThe second category included in Table I consists of lawsuits filed by investors (limited partners) in VC partnerships (roughly $7\\%$ of the VC lawsuit sample). An example of such lawsuits is CMS Tech Access v. GMG Management. The limited partner (CMS Partners) alleges fraudulent disclosures by the VC (CMG Capital Partners) to attract a more than $\\$20$ million investment in the VC's early funds. After CMS and other limited partners invested in the VC partnership, the VC allegedly transferred assets from the partnership, diverted attractive investment opportunities to follow-up funds, and misled the limited partners to invest directly in startups controlled and then looted by the VC.  \n\nThe fewest lawsuits in our sample are lawsuits filed by other VCs $4\\%$ of the lawsuit sample). One example of such lawsuits is Syndicated Communication Venture Partners v. Baystar Capital. The plaintiff, Syndicated Communication Venture Partners, alleges that the defendant VC (Baystar) mismanaged the startup, ClickRadio, Inc., in which they jointly invested. Baystar also transferred tangible assets and intellectual property to related companies and caused the failure ofthe startup. Syndicated Communication Venture Partners wonthecase.  \n\nThe fourth category of lawsuits includes seven lawsuits by strategic acquirers of VC-backed startups $(6.5\\%$ of the lawsuit sample), usually alleging that the VCs misrepresented the quality of the sold company. A typical example of such lawsuits is Equifax v. Austin Ventures, where the plaintiff (Equifax) alleges that the defendant VC, Austin Ventures, furnished materially false and misleading information and intentionally manipulated the financial statements of its portfolio company Naviant, Inc. upon its merger with Equifax. In addition, the category includes nine class-action lawsuits initiated by shareholders in VC-backed IPO firms. These class-action suits are directed mainly towards underwriters and company directors and officers, but also name the VCs as defendants.  \n\nThe largest group of lawsuits in the “Other” category $(44.5\\%$ of the sample), comprises 15 lawsuits filed by other common stockholders in a VC-backed startup. One such lawsuit is Bruh v. Bessemer Venture Partners, filed by an angel investor that claims his stake was diluted in the conversion of convertible preferred shares held by the defendant, Bessemer, into common stock before the VC-backed startup VistaCare went public in an IPO. The second largest group of lawsuits in this category consists of bankruptcy cases. Creditor lawsuits against shareholders are common when a startup firm goes into bankruptcy, and VCs are a tempting deep-pocketed target. Our data include 11 bankruptcy cases. An example of such lawsuits is AT&T v. Walker, in which creditors to a startup backed by the Carlyle Group (PT Cable, Inc.) allege (among other claims) fraudulent transfer, in which the startup paid an “illegal\" dividend to the defendant, Carlyle, before the startup defaulted on its obligations. The remaining cases in this category are a mixture of intellectual property, labor law, and other difficult-to-classify allegations.  \n\nOf the 245 lawsuits in the sample, 222 name only one VC as defendant, 14 lawsuits name two VC defendants, five name three, two name five, and two lawsuits name six VC defendants. Almost two-thirds of our lawsuits are filed in federal courts, and four states—CA, NY, DE, and MA—dominate in terms of both federal and state court filings. The most frequently alleged opportunistic behavior on the part of VCs is asset transfer and acquisition on unfavorable terms. We also note that 49 lawsuits are dismissed or otherwise lost by the plaintiff, 134 lawsuits are ongoing or there are not enough data to determine their outcome, and 41 lawsuits are settled or lost in court by the VC. The Internet Appendix presents some additional characteristics of our lawsuitsample.  \n\n### C. Characteristics of Litigated VCs  \n\nFrom VentureXpert, we collect data on VC age, investment stage and industry focus, number of funds, fund size and portfolio firms, and the network centrality degree measure of Hochberg, Ljungqvist, and Lu (2007). As a measure of the number of deals we use the number ofinvestment rounds that a VC fund participates in. To account for time-series variation in the VC industry, which is well documented in the literature (Gompers and Lerner (1999)), we scale the size of VC funds (number of deals) by the total amount of committed VC capital (total number of VC deals) in the year in which a particular fund is raised. For each VC firm in our sample we compute VC firm funds under management (number of deals) as the sum of the scaled fund sizes (number of deals).  \n\nEven some very reputable firms, such as Kleiner Perkins, Charles River Ventures, Sevin Rosen Associates, and New Enterprise Ventures, are involved in litigation cases with various counterparties. Also, there are different types of VCs in our sample: traditional VCs (Kleiner Perkins and Charles River Ventures),corporateVCs( $\\mathbf{E}^{*}$ Trade and Xerox Corporation), and venture arms of banks (J.P. Morgan Partners and Citigroup). Of the 200 VCs appearing in our sample, 153 are involved in only one lawsuit, 31 in two lawsuits, six in three, six in four, and four in five or more lawsuits. The company with the highest number of lawsuits is Citicorp Venture Capital, which is a defendant to15lawsuits.  \n\nPanel A of Table II presents summary statistics for the VCs involved in litigation and 10 randomly chosen VCs per VC-lawsuit pair that appear in the same year as each lawsuit but are never litigated. It can be seen from the table that litigated VCs are older, larger, and better connected than VCs from a randomly selected sample. In addition, litigated VCs tend to invest in more deals and tend to make more early-stage investments. This suggests that controlling for these differences when analyzing the effect of litigation on reputation is crucial for the validity of our inferences.  \n\nPanel B reports summary statistics for the VCs participating in the different types of lawsuits. We compare the VC characteristics of the five major lawsuit groups to the characteristics of VCs in the “Other” category. The differences reported in Panel B are somewhat intuitive. Relative to the “Other” category, VCs litigated by their limited partners have fewer deals, are less connected, and have a smaller percent of deals going public. VCs litigated by founders or other VCs have more deals, while VCs litigated by startup buyers have a higher percent of deals going public.  \n\n# TableII Summary Statistics for Reputational Proxies  \n\nPanel A presents mean (median) values for characteristics of VCs involved as defendants in lawsuits over the 1975-2007 period and 10 randomly drawn samples of never litigated VCs that have the same distribution of years as the lawsuit sample. The unit of observation is a VC $\\times$ year. Panel B presents mean (median) values for reputational measures and Hi-tech and Early-stage dummy for the VCs involved as defendants in lawsuits over the 1975-2007 period by lawsuit type. The six types of lawsuits are the same as in Table I. All variables are measured at the time of the lawsuit. VC age is the number of years between the year of lawsuit and the year of founding the first fund of the VC. Number of deals is the sum of all investment rounds that all VC's funds have participated in, converted into 2002 equivalent number of deals. Funds under management is the sum of capital under management of all VC's funds, converted into 2002 dollars. Network degree is defined by Hochberg (2007) and measures how many partners a VC has syndicated with relative to the total number of possible relationships over the entire history of a VC. Percent deals going public is the proportion of VC portfolio companies going public. Hi-tech is a dummy equal to one if a VC specialized in hi-tech industries. Early stage is a dummy equal to one if a VC specializes in early-stage investments. The column named $^{\\mathrm{6}}P$ value of Difference” reports the $p$ -values of the $t$ -test of equality of means (rank test for equality of medians) between litigated VCs and the randomly drawn samples of never-litigated VCs. \\* $^{**}$ ， $***$ indicate means (medians) that are significantly different at, respectively, the $10\\%$ ， $5\\%$ , and $1\\%$ confidence level relative to the means (medians) for Other lawsuits.  \n\nPanel A. Mean (Median) Reputational Measures for Litigated VCs and Random Nonlitigated VCs   \n\n\n<html><body><table><tr><td colspan=\"2\"></td><td rowspan=\"2\">Random Samples of Nonlitigated VCs</td><td rowspan=\"2\">P-value of Difference</td></tr><tr><td></td><td>Litigated VCs</td></tr><tr><td rowspan=\"2\">VCage</td><td>14.47</td><td>7.83</td><td>0.00</td></tr><tr><td>(12.00)</td><td>(5.00)</td><td>(0.00)</td></tr><tr><td rowspan=\"2\">Number of deals</td><td>7,478</td><td>701</td><td>0.00</td></tr><tr><td>(1,166)</td><td>(141)</td><td>(0.00)</td></tr><tr><td rowspan=\"2\">Funds under management (Mil.)</td><td>1,917</td><td>329</td><td>0.00</td></tr><tr><td>(272)</td><td>(16)</td><td>(0.00)</td></tr><tr><td rowspan=\"2\">Network degree</td><td>0.03</td><td>0.01</td><td>0.00</td></tr><tr><td>(0.01)</td><td>(0.00) 0.12</td><td>(0.00)</td></tr><tr><td rowspan=\"2\">Percent deals going public</td><td>0.09 (0.00)</td><td>(0.00)</td><td>0.08</td></tr><tr><td>0.16</td><td>0.16</td><td>(0.16) 0.85</td></tr><tr><td rowspan=\"2\">Hi-tech</td><td>(0.00)</td><td>(0.00)</td><td>(0.85)</td></tr><tr><td>0.29</td><td>0.20</td><td>0.00</td></tr><tr><td rowspan=\"2\">Early stage</td><td>(0.00)</td><td>(0.00)</td><td>(0.00)</td></tr><tr><td>263</td><td>2,630</td><td></td></tr><tr><td>N Obs.</td><td></td><td></td><td></td></tr></table></body></html>  \n\nPanel B. Mean (Median) Reputational Measures for Litigated VCs by Lawsuit Type   \n\n\n<html><body><table><tr><td></td><td>Other</td><td>Founder</td><td>LP</td><td>VC</td><td>Buyer</td><td>Missing</td></tr><tr><td>VC age</td><td>14.03</td><td>14.62</td><td>11.86</td><td>15.80</td><td>14.93</td><td>15.70</td></tr><tr><td>Numberofdeals</td><td>(10.00) 7,775</td><td>(13.00) 6,225</td><td>(8.00) 1,177</td><td>(18.00) 14,221</td><td>(13.50) 5,000</td><td>(17.00) 10,927</td></tr><tr><td>Fundsunder</td><td>(917) 2,147</td><td>(3,087)*** 1702</td><td>(523)* 281</td><td>(7,125)**</td><td>(1,664)</td><td>(523) 1,178</td></tr><tr><td>management</td><td></td><td>(607)***</td><td></td><td>4,923</td><td>2,420</td><td></td></tr><tr><td></td><td>(152)</td><td></td><td>(46)</td><td>(1,231)***</td><td>(393)**</td><td></td></tr><tr><td>(Mil.)</td><td></td><td></td><td></td><td></td><td></td><td>(117)</td></tr></table></body></html>  \n\nTable I—Continued   \n\n\n<html><body><table><tr><td colspan=\"7\">Panel B.Mean(Median)ReputationalMeasures for Litigated VCsbyLawsuit Type</td></tr><tr><td></td><td>Other</td><td>Founder</td><td>LP</td><td>VC</td><td>Buyer</td><td>Missing</td></tr><tr><td rowspan=\"2\">Networkdegree</td><td>0.03</td><td>0.04</td><td>0.01*</td><td>0.04</td><td>0.04</td><td>0.04</td></tr><tr><td>(0.01)</td><td>(0.02)</td><td>(0.01)</td><td>(0.01)</td><td>(0.03)***</td><td>(0.01)</td></tr><tr><td>Percentdealsgoing public</td><td>0.08</td><td>0.08</td><td>0.03*</td><td>0.10</td><td>0.22***</td><td>0.08</td></tr><tr><td rowspan=\"2\">Hi-tech</td><td>(0.00)</td><td>(0.04)</td><td>(0.00)*</td><td>(0.00)</td><td>(0.18)***</td><td>(0.00)</td></tr><tr><td>0.15</td><td>0.15</td><td>0.19</td><td>0.10</td><td>0.20</td><td>0.14</td></tr><tr><td rowspan=\"2\">Earlystage</td><td>(0.00) 0.31</td><td>(0.00) 0.28</td><td>(0.00) 0.48</td><td>(0.00) 0.30</td><td>(0.00)</td><td>(0.00)</td></tr><tr><td></td><td></td><td></td><td></td><td>0.23</td><td>0.21</td></tr><tr><td></td><td>(0.00)</td><td>(0.00)</td><td>(0.00)</td><td>(0.00)</td><td>(0.00)</td><td>(0.00)</td></tr></table></body></html>  \n\n### D. Characteristics of VC-Backed Startups Involved in Litigation  \n\nWe read the filings associated with each lawsuit in our sample and identify the names ofVC-backed startup companies that are involved in the lawsuit, if any. We are able to identify 118 portfolio companies as parties to lawsuits in our sample. Sometimes a lawsuit does not involve a portfolio company (for example, if the lawsuit is filed by an investor in a VC fund or a VC employee). In other instances, we could not identify the company from the court documents. We match the reported names of startups in the lawsuits with the startups in the VentureXpert universe. For 29 companies we are not able to find information on their exit strategy from VentureXpert. We drop nine startups involved in classaction lawsuits following their IPO from the subsequent empirical analysis (otherwise the percentage of litigated startups going public will be artificially inflated). The final number of startups with sufficient data is 80, which are associated with 89 litigated VCs and a total of 126 VC-startup pairs.  \n\nTable II reports summary statistics of the startups involved in litigation and compares them with randomly chosen other startups funded by the 89 litigated VCs in the same year as the first investment of each litigated startup, and randomly chosen startups of nonlitigated VCs that also received their first investment in the same year. The litigated startups are slightly younger, receive more investment rounds, and are much more likely to go public, which suggests that litigation is positively associated with startup success.  \n\n### E. Identifying Observationally Similar Peer Nonlitigated VCs  \n\nFor the analysis that follows, we select a sample of peer VCs that have never been litigated. It is important to carefully select peer VCs that are as similar to our litigated VCs as possible, as otherwise our tests could be biased by possible endogeneity. For example, imagine that we do not match on number of deals. Table II shows that the litigated VCs have a much larger number of deals than the typical VC in the VentureXpert database. Note that a large percentage of our lawsuits are filed in the 2001-2003 period, which is a crisis period for the  \n\n# TableIII Summary Statistics for Litigated Startups  \n\nThe table presents summary statistics for the startups identified in the lawsuits reported in Table I. We exclude startups that were subject to post-IPO class-action lawsuits. For comparison, we also include the same statistics for randomly drawn samples (10 startups per each litigated startup) of other startups of the litigated VCs and startups by nonlitigated VCs that have received the first VC-backed rounds in the same year as the litigated startups. The columns named $^{\\mathrm{6}}P$ valueof Difference\"report the $p$ -valuesofthe $t$ test of equality of means (rank test for equality of medians) between litigated startups and nonlitigated startups of the litigated VCs and between litigated startups and the randomly drawn sample of startups of never-litigated VCs.  \n\n<html><body><table><tr><td></td><td>Litigated Startups</td><td>Random Startups of Litigated VCs</td><td>P-value of Difference</td><td>Random Other Startups</td><td>P-value of Difference</td></tr><tr><td>Startup age</td><td>3.14 (1.00)</td><td>3.12 (1.00)</td><td>0.99 (0.05)</td><td>4.44 (0.00)</td><td>0.27 (0.08)</td></tr><tr><td>Number of rounds</td><td>4.45 (4.00)</td><td>4.19 (3.00)</td><td>0.45 (0.42)</td><td>2.41 (2.00)</td><td>0.00 (0.00)</td></tr><tr><td>Total VC capital invested</td><td>36,977 (22,340)</td><td>43,960 (21,796)</td><td>0.58 (0.90)</td><td>17,656 (6,155)</td><td>0.00 (0.00)</td></tr><tr><td>($ thousand) Startup IPO</td><td>0.23</td><td>0.18</td><td>0.31</td><td>0.13</td><td>0.02</td></tr><tr><td>Experienceof</td><td>(0.00) 9.98</td><td>(0.00) 12.08</td><td>(0.31) 0.04</td><td>(0.00)</td><td>(0.02)</td></tr><tr><td>VC syndicate</td><td>(8.00)</td><td>(10.00)</td><td>(0.02)</td><td>11.83 (10.00)</td><td>0.13 (0.29)</td></tr><tr><td>VCinvestment</td><td>0.64</td><td>0.66</td><td>0.72</td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td>0.45</td><td>0.00</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>in early</td><td>(1.00)</td><td>(1.00)</td><td>(0.72)</td><td>(0.00)</td><td>(0.00)</td></tr><tr><td>rounds</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>N Obs.</td><td>80</td><td>800</td><td></td><td>800</td><td></td></tr></table></body></html>  \n\nVC industry. It is likely that during this period most VCs experienced a decline in the number of deals, with larger VCs probably experiencing a larger-thanaverage drop. In this case, we will find that following litigation, litigated VCs do indeed experience a larger drop in the number of deals but this effect is not due to litigation but to the systematic differences in prelawsuit deal flow between litigated and nonlitigated VCs. In addition, VCs could be sued not because of misbehavior, but because they specialize in areas that are prone to lawsuits. For example, VCs that invest in early-stage companies might be more likely to end up in litigation not because they behave opportunistically but because such investments are associated with higher levels of uncertainty and information asymmetry and a lower degree of syndication, which in turn could create a more litigious environment.  \n\nTo allay concerns of endogeneity, we identify peer VCs that have never been litigated but are as similar to litigated VCs along all five reputational proxies—age, number of deals, funds under management, network degree, and percent of deals going public, as calculated in the year of the lawsuit. We employ three commonly used methodologies for multidimensional matching: (1) the methodology developed by Abadie and Imbens (2002) and implemented in the Stata procedure nnmatch (see Abadie et al. (2004), (2) matching using the Mahalanobis distance measure (Rubin (1980)), and (3) propensity-based matching (Rosenbaum and Rubin (1983), Deheja and Wahba (1999, 2002)).8 All three methodologies convert the difference between the vectors of matching characteristics for each litigated VC $i$ and each never-litigated $\\mathrm{VC}j$ into a scalar distance measure. We then pick the peer VC with the smallest distance measure (the nearest neighbor) to the litigated VC. The only modification we make is that we calculate the distance measures separately for each lawsuit year $t$ instead of for the entire panel. Thus, each litigated VC is matched to a peer as of the year of the lawsuit. We perform all matching with replacement (the same VC can be used more than once as a match) because Abadie and Imbens (2002) argue that this reduces bias.  \n\nIn particular, the Abadie and Imbens (2002) and Mahalanobis matching methodologies calculate the distance measure as the vector norm $[(x_{i}-$ $x_{j})\\mathrm{\\bar{T}V}^{-1}(x_{i}-x_{j})\\mathrm{\\bar{l}}^{1/2},$ where $x_{i}$ and $x_{j}$ are the vectors of matching characteristics for litigated VC $i$ and nonlitigated VC $j$ and $V$ is a positive definite matrix. The difference between the two techniques is that Abadie and Imbens (2002) use the diagonal of the variance-covariance matrix of matched characteristics in the full sample of litigated and peer VCs while the Mahalanobis approach uses the entire variance-covariance matrix. To implement the propensity-based matching, we estimate a VC-year level probit model reported in the Internet Appendix. The distance measure is then the difference between the probitestimated propensity score (expected probability) to be litigated for each litigated VC $i$ and nonlitigated $\\mathrm{VC}j$ in year t. Again, we pick with replacement the nearest neighbor with the smallest difference in propensity score.  \n\nTable IV reports the mean (median) values for the five reputation proxies, the hi-tech and early stage dummies, and the propensity to litigate for the sample of litigated VCs and their nonlitigated peers identified using each of the three matching methodologies. All three techniques produce matches that are largely similar to the litigated VCs along all dimensions. Only 9 of the 48 means and medians are significantly different from the litigated sample at the level of $10\\%$ significance. Moreover, the differences across matched samples are in different measures, so results based on all three methodologies should not suffer from bias caused by the litigated VCs being observationally different from their matches.  \n\n## IV. Predicting VC Litigation  \n\nThe first part of our empirical analysis tests the prediction of Hypothesis 1 that more reputable VCs should be less likely to get sued. To test Hypothesis 1 we employ a probit model using VC-startup-level data in which the unit of observation is the investment of VC firm $i$ in a startup company s. An  \n\n# TableIV Mean (Median) Proxies for Litigated VCs and Matched Peers  \n\nThe table presents mean (median) values for the reputational proxies and the Hi-tech and Early stage dummies for the VCs involved as defendants in lawsuits over the 1975-2005 period and oneto-one matched peers using three different matching methodologies—Abadie and Imbens (2002), Mahalanobis, and propensity matching. All variables are measured at the time of the lawsuit. Total number of deals are converted into 2002 equivalent number of deals. Funds under management are converted into 2002 dollars. The columns named $^{\\mathrm{{\\scriptsize~6}}}P$ value of Difference\"reports the $p$ valuesof the $t$ -test of equality of means (rank test for equality of medians) between litigated VCs and each matched sample of never-litigatedVCs.  \n\n<html><body><table><tr><td></td><td colspan=\"3\">Abadie and</td><td colspan=\"3\"></td><td></td></tr><tr><td></td><td>Litigated VCs</td><td>Imbens (2002)</td><td>P-value of Difference</td><td>Mahalanobis</td><td>P-value of Difference</td><td>Propensity</td><td>P-value of Difference</td></tr><tr><td>VCage</td><td>14.34 (11.00)</td><td>13.75 (11.00)</td><td>0.55 (0.73)</td><td>13.45 (11.00)</td><td>0.36 (0.54)</td><td>16.61 (14.00)</td><td>0.04 (0.10)</td></tr><tr><td>Number of deals</td><td>7,731 (1,274)</td><td>4,398 (1,247)</td><td>0.18 (0.43)</td><td>4,023 (1,247)</td><td>0.13 (0.42)</td><td>5,383 (469)</td><td>0.35 (0.00)</td></tr><tr><td>Funds under management</td><td>1,835 (299)</td><td>1,361 (229)</td><td>0.35 (0.70)</td><td>1,047 (197)</td><td>0.11 (0.52)</td><td>1,456 (100)</td><td>0.48 (0.00)</td></tr><tr><td>(Mil.) Network degree</td><td>0.04</td><td>0.03</td><td>0.44</td><td>0.03</td><td>0.31</td><td>0.03</td><td>0.18</td></tr><tr><td>Percent deals</td><td>(0.01) 0.10</td><td>(0.01) 0.10</td><td>(0.74) 0.99</td><td>(0.01) 0.10</td><td>(0.59) 0.87</td><td>(0.01) 0.10</td><td>(0.02) 0.94</td></tr><tr><td>going public Hi-tech</td><td>(0.02) 0.15</td><td>(0.04) 0.14</td><td>(0.48) 0.70</td><td>(0.04) 0.15</td><td>(0.51) 0.90</td><td>(0.00) 0.15</td><td>(0.42) 0.90</td></tr><tr><td></td><td>(0.00)</td><td>(0.00)</td><td>(0.70)</td><td>(0.00)</td><td>(0.90)</td><td>(0.00)</td><td>(0.90)</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td>(0.00)</td><td>(0.00)</td><td>(0.09)</td><td>(0.00)</td><td>(0.06)</td><td>(0.00)</td><td></td></tr><tr><td></td><td></td><td></td><td>0.09</td><td></td><td></td><td></td><td></td></tr><tr><td>Early stage</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td>0.29</td><td>0.23</td><td></td><td>0.22</td><td>0.06</td><td>0.31</td><td>0.62</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>(0.62)</td></tr><tr><td>Propensity to be</td><td>0.02</td><td>0.02</td><td>0.11</td><td>0.02</td><td>0.07</td><td>0.02</td><td>0.40</td></tr><tr><td>litigated</td><td>(0.01)</td><td>(0.01)</td><td>(0.52)</td><td>(0.01)</td><td>(0.36)</td><td>(0.01)</td><td>(0.99)</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>N Obs.</td><td>235</td><td>235</td><td></td><td>235</td><td></td><td>235</td><td></td></tr></table></body></html>  \n\nalternative is to use a panel data probit with VC-year-level data.9 However, there is a concern that the larger number of deals, funds under management, and network centrality that come with more years of existence may mechanically increase the probability of a VC being sued.10 We use the sample of litigated startups, all other startups of the same litigated VCs that have received their first investment round in one of the first-round years ofthe litigated startups, and startups by nonlitigated matched VCs (see the previous section for matching procedures). The dependent variable equals one if a VC-startup pair has been involved in litigation and zero otherwise. Compared to a VCyear probit model, the VC-startup-level probit data have more observations for VCs with more startup investments, and allow us to use startup-specific and deal-specific variables to predict litigation in addition to VC-level measures.  \n\nThe main independent variables of interest are the five reputational proxies —age ofthe VC firm (VC age), cumulative number ofinvestment rounds (Number of deals), cumulative funds under management (Funds under mgmt), network centrality (Network degree), and percent of deals going public (Pct. deals going public). We also include the variable Number of previous lawsuits to capture the number of times the VC firm was litigated in previous years. The presence of multiple lawsuits against a given VC might reveal a particular type of behavior on the part of that VC towards entrepreneurs and other investors in its portfolio firms. Alternatively, it might be a sign that something is wrong at the organizational level of the VC firm. Thus, we expect frms that have participated in multiple lawsuits in the past to be more likely to get involved in a lawsuit in the future.  \n\nThe other control variables include several VC-specific and startup-specific variables. The VC-specific variables include a dummy variable equal to one if the VC is the lead VC in a particular deal (Litigated VC is a lead VC) and a dummy variable equal to one if the VC invested in the early financing rounds of the company (VC investment in early rounds). The startup-specific variables include the age of the company when the VC first invested in it (Company age), the total number of rounds the startup received (Number of rounds), the total amount of funds invested in the startup (Total funds invested in company), the average experience (in years) of the VC syndicate (Experience of VC' syndicate), and a dummy variable equal to one if the startup went public (IPO outcome).  \n\nThe results of the VC-startup analysis are presented in Table V. Panel A presents the results using peer VCs selected via the Abadie and Imbens (2002) methodology, while in Panel B the peer VCs are selected using propensity score matching.11 We find that the probability of a VC-backed startup being involved in litigation is negatively related to all proxies for VC reputation, except Pct. deals going public. When we combine all variables in a single regression (Model 1 in each panel), only the coefficients on VC' age and Network degree are statistically significant. However, since these reputational proxies tend to be correlated, in the next models we use them one at a time. In both panels, the coefficients on these variables are negative and statistically significant, suggesting that more reputable VCs are less likely to be involved in litigation.  \n\nThe economic effects are significant as well. Based on the results in Panel A, a one-standard-deviation increase in VC age, centered around the mean, changes the probability of a VC investment ending up in litigation from $0.67\\%$ to $0.48\\%$ (a $28\\%$ decrease). Similarly, a one-standard-deviation increase in Number of deals changes the litigation probability from $0.71\\%$ to $0.39\\%$ (a $45\\%$ decrease), while a one-standard-deviation increase in Funds under mgmt changes the litigation probability from $0.70\\%$ to $0.44\\%$ (a $37\\%$ decrease).  \n\nSome of the control variables are also significantly related to the likelihood of litigation. For example, the average reputation (age) of the syndicate members that have invested in startup companies significantly lowers the likelihood of litigation. Litigated startups have also attracted significantly less VC capital,  \n\n# TableV Probability of VC Litigation: Startup-Level Analysis  \n\nThe table presents the results of a pooled probit model using VC-backed startups that are litigated. The sample consists of 80 startups involved in lawsuits against 89 VCs for which information on portfolio companies involved in the litigation is available, the nonlitigated startups that the litigated VC firms have invested in, and the startups that a set of peer VCs have invested in. In Panel A, the set of peer VCs is determined using Abadie and Imbens (2002) matching; in Panel B the set of peer VCs is determined using propensity score matching. The unit of observation is the year of the first round of investment in a portfolio company by a litigated VC. The dependent variable is equal to one if a given portfolio company participates in a lawsuit and zero otherwise. Syndicate experience is the average age of all VCs investing in a company. Stage at frst round is a dummy variable equal to one if the startup is at early stage at the first round and zero otherwise. IPO outcome is a dummy variable equal to one if the portfolio company went public and zero otherwise. All other variables are defined in Tables II and III. All specifications include year fixed effects. Standard errors are robust to heteroscedasticity and clustering at the VC-firm level. $t$ statistics are reported in parentheses. \\*,\\*, and \\*\\*\\* denote significance at $10\\%$ ， $5\\%$ ,and $1\\%$ level, respectively.  \n\n<html><body><table><tr><td colspan=\"6\">Panel A.Deal-Level Probit of the Startups of Litigated VCs and Peer VCs Matched Using Abadie and Imbens (2002)</td></tr><tr><td>Variable</td><td>Model 1</td><td>Model 2</td><td>Model 3</td><td>Model 4</td><td>Model 5</td><td>Model 6</td></tr><tr><td>VC age</td><td>-0.069*</td><td>-0.157***</td><td></td><td></td><td></td><td></td></tr><tr><td rowspan=\"2\">Number of deals</td><td>(-1.67)</td><td>(-4.21)</td><td></td><td></td><td></td><td></td></tr><tr><td>-0.887</td><td></td><td>-2.294***</td><td></td><td></td><td></td></tr><tr><td rowspan=\"2\"></td><td></td><td></td><td>(-3.92)</td><td></td><td></td><td></td></tr><tr><td>(-0.75)</td><td></td><td></td><td>-1.264***</td><td></td><td></td></tr><tr><td rowspan=\"2\">Funds under mgmt</td><td>0.264</td><td></td><td></td><td>(-2.96)</td><td></td><td></td></tr><tr><td>(-0.36) -1.440***</td><td></td><td></td><td></td><td>-2.408***</td><td></td></tr><tr><td rowspan=\"2\">Network degree</td><td>(-2.98)</td><td></td><td></td><td></td><td>(-3.24)</td><td></td></tr><tr><td>0.155</td><td></td><td></td><td></td><td></td><td>-0.110</td></tr><tr><td rowspan=\"2\">Pct deals going public Previous lawsuits</td><td>(0.71)</td><td></td><td></td><td></td><td></td><td>(-0.54)</td></tr><tr><td>0.049**</td><td>0.057**</td><td>0.029</td><td>0.021</td><td>0.045*</td><td>0.029</td></tr><tr><td rowspan=\"2\">LitigatedVCisaleadVC</td><td>(2.22)</td><td>(2.51)</td><td>(1.20)</td><td>(0.73)</td><td>(1.86)</td><td>(1.05)</td></tr><tr><td>0.091</td><td>0.054</td><td>0.085</td><td>0.070</td><td>0.062</td><td>0.028</td></tr><tr><td rowspan=\"2\"></td><td>(1.32)</td><td>(0.77)</td><td>(1.25)</td><td>(1.05)</td><td>(0.86)</td><td>(0.39)</td></tr><tr><td>-0.003</td><td>-0.003</td><td>-0.003</td><td>-0.002</td><td>-0.004</td><td>-0.003</td></tr><tr><td rowspan=\"2\">Company age Number of rounds</td><td>(-0.90)</td><td>(-0.85)</td><td>(-0.82)</td><td>(-0.65)</td><td>(-0.97)</td><td>(-0.78)</td></tr><tr><td>0.025**</td><td>0.025**</td><td>0.025**</td><td>0.024**</td><td>0.025**</td><td>0.024**</td></tr><tr><td rowspan=\"2\"></td><td>(2.30)</td><td>(2.22)</td><td>(2.20)</td><td>(2.16)</td><td>(2.28)</td><td>(2.12)</td></tr><tr><td>-0.001**</td><td>-0.001**</td><td>-0.001**</td><td>-0.001**</td><td>-0.001**</td><td>-0.001**</td></tr><tr><td rowspan=\"2\">Totalfundsinvested in company</td><td>(-2.01)</td><td>(-2.31)</td><td>(-2.02)</td><td>(-2.06)</td><td>(-2.31)</td><td>(-2.52)</td></tr><tr><td>0.272***</td><td>0.266***</td><td>0.265***</td><td>0.262***</td><td>0.273***</td><td>0.257***</td></tr><tr><td rowspan=\"2\">IPO outcome ExperienceofVCsyndicate</td><td>(3.60)</td><td>(3.54)</td><td>(3.50)</td><td>(3.48)</td><td>(3.65)</td><td>(3.45)</td></tr><tr><td>-0.016**</td><td>-0.016**</td><td>-0.018***</td><td>-0.020***</td><td>-0.018***</td><td>-0.020***</td></tr><tr><td rowspan=\"2\">VCinvestmentinearlyrounds</td><td>(-2.54)</td><td>(-2.54)</td><td>(-2.93)</td><td>(-3.21)</td><td>(-2.89)</td><td>(-3.25)</td></tr><tr><td>-0.068</td><td>-0.070</td><td>-0.076</td><td>-0.081</td><td>-0.050</td><td>-0.064</td></tr><tr><td></td><td>(-0.94)</td><td>(-0.96)</td><td>(-1.05)</td><td>(1.10)</td><td>(-0.69)</td><td>(-0.87)</td></tr><tr><td>N Obs. p-value of x2</td><td>20,439</td><td>20,439</td><td>20,439</td><td>20,439</td><td>20,439</td><td>20,439</td></tr><tr><td colspan=\"7\">0.00 0.00 0.00 0.00 0.00 0.00 Panel B. Deal-Level Probit of the Startups of Litigated VCs and Peer VCs Matched Using Propensity Score</td></tr><tr><td>VC age</td><td>-0.102***</td><td>Matching -0.184***</td><td></td><td></td><td></td><td></td></tr><tr><td rowspan=\"2\">Number of deals</td><td>(-2.67)</td><td>(-5.09)</td><td></td><td></td><td></td><td></td></tr><tr><td>-0.518</td><td></td><td>-2.270***</td><td></td><td></td><td></td></tr><tr><td rowspan=\"2\">Funds under mgmt</td><td>(-0.54)</td><td></td><td>(-4.25)</td><td></td><td></td><td></td></tr><tr><td>-0.383</td><td></td><td></td><td>-1.256***</td><td></td><td></td></tr><tr><td rowspan=\"2\">Network degree</td><td>(0.71)</td><td></td><td></td><td>(-3.32)</td><td></td><td></td></tr><tr><td>-1.593***</td><td></td><td></td><td></td><td>-2.779***</td><td></td></tr><tr><td rowspan=\"2\">Pct deals going public</td><td>(-3.52)</td><td></td><td></td><td></td><td>(-3.54)</td><td></td></tr><tr><td>0.079 (0.42)</td><td></td><td></td><td></td><td></td><td>-0.163 (-0.90)</td></tr></table></body></html>  \n\n(Continued)  \n\nTable V—Continued   \n\n\n<html><body><table><tr><td colspan=\"7\">PanelB.Deal-LevelProbitoftheStartupsofLitigatedVCs andPeerVCsMatchedUsingPropensityScore Matching</td></tr><tr><td>Variable</td><td>Model 1</td><td>Model 2</td><td>Model 3</td><td>Model 4</td><td>Model 5</td><td>Model 6</td></tr><tr><td rowspan=\"2\">Previouslawsuits</td><td>0.040</td><td>0.047*</td><td>0.017</td><td>0.009</td><td>0.032</td><td>0.015</td></tr><tr><td>(1.56)</td><td>(1.85)</td><td>(0.58)</td><td>(0.26)</td><td>(1.10)</td><td>(0.46)</td></tr><tr><td rowspan=\"2\">LitigatedVC is aleadVC</td><td>0.103</td><td>0.068</td><td>0.100</td><td>0.082</td><td>0.071</td><td>0.035</td></tr><tr><td>(1.47)</td><td>(0.95)</td><td>(1.45)</td><td>(1.21)</td><td>(0.95)</td><td>(0.48)</td></tr><tr><td rowspan=\"2\">Companyage</td><td>-0.004</td><td>-0.003</td><td>-0.003</td><td>-0.003</td><td>-0.004</td><td>-0.003</td></tr><tr><td>(-0.93)</td><td>(-0.86)</td><td>(-0.85)</td><td>(-0.70)</td><td>(-1.03)</td><td>(-0.79)</td></tr><tr><td rowspan=\"2\">Numberofrounds</td><td>0.029***</td><td>0.028**</td><td>0.028**</td><td>0.028**</td><td>0.028**</td><td>0.027**</td></tr><tr><td>(2.58)</td><td>(2.41)</td><td>(2.48)</td><td>(2.43)</td><td>(2.57)</td><td>(2.32)</td></tr><tr><td rowspan=\"2\">Totalfundsinvested</td><td>-0.001*</td><td>-0.001**</td><td>-0.001**</td><td>-0.001**</td><td>-0.001**</td><td>-0.001**</td></tr><tr><td>(-1.95)</td><td>(-2.29)</td><td>(-2.03)</td><td>(-2.06)</td><td>(-2.36)</td><td>(-2.56)</td></tr><tr><td>in company IPOoutcome</td><td>0.271***</td><td>0.267***</td><td>0.259***</td><td>0.254***</td><td>0.272***</td><td>0.257***</td></tr><tr><td rowspan=\"2\">ExperienceofVCsyndicate</td><td>(3.56)</td><td>(3.51)</td><td>(3.36)</td><td>(3.34)</td><td>(3.57)</td><td>(3.42)</td></tr><tr><td>-0.018***</td><td>-0.018***</td><td>-0.021***</td><td>-0.022***</td><td>-0.020***</td><td>-0.023***</td></tr><tr><td rowspan=\"2\">VCinvestmentinearlyrounds</td><td>(-2.93)</td><td>(-2.87)</td><td>(-3.45)</td><td>(-3.66)</td><td>(-3.30)</td><td>(-3.67)</td></tr><tr><td>-0.068</td><td>-0.074</td><td>-0.078</td><td>-0.085</td><td>-0.049</td><td>-0.069</td></tr><tr><td></td><td>(-0.90)</td><td>(-0.99)</td><td>(-1.04)</td><td>(-1.12)</td><td>(-0.65)</td><td>(-0.92)</td></tr><tr><td>N Obs.</td><td>19,022</td><td>19,022</td><td>19,022</td><td>19,022</td><td>19,022</td><td>19,022</td></tr><tr><td>p-value ofx2</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td></tr></table></body></html>  \n\nhave received more investment rounds, and are significantly more likely to be successful in going public. We are also interested in the extent to which participation in multiple lawsuits affects the likelihood of future litigation. In most of the models Number of previous lawsuits is positive but not significant.  \n\nBy and large, the results in Table V provide support for Hypothesis 1 in showing that more reputable VCs are less likely to be litigated. Possible endogeneity could be a concern for our analysis of the impact of reputation on the probability of VC litigation. The litigated VCs could simply be low-quality VC frms that are matched with on average low-quality startups. Low-quality startups may be more likely to be involved in a lawsuit, which can result in a spurious correlation between low VC reputation and a high propensity to be litigated. The validity of this concern rests on the conjecture that litigated startups are of below-average quality. This conjecture is not borne by the data. Both Table III and Table V show that litigated startups are more likely to go public (even after excluding class-action lawsuits) relative to random startups ofVCs that have never been litigated or other startups of litigated and peer VCs. An IPO is considered the most successful exit for a VC-backed company, which suggests that startups involved in litigation are not necessarily low-quality companies.  \n\n## V. Business Consequences of VC Litigation  \n\nWe next examine the impact of litigation on the business performance ofVCs involved in lawsuits. Our Hypothesis 2 predicts that litigated VCs would suffer negative reputational consequences (adverse adjustments in business dealings by counterparties), and Hypotheses 3 and 4 assert that these reputational consequences would be more severe for more reputable VCs and for VCs that are alleged to have engaged in opportunistic behavior against a counterparty of the same type, that are litigated by founders, that have lost the lawsuit, or that are defendants to multiple lawsuits. By definition, the size ofthe reputation loss for VCs is the present value of lost business opportunities. These lost business opportunities are a result of the operational effects (changes in funding, deal fow, syndication participation) that our reputational proxies try to capture. Thus, while we do not measure the size of the reputational losses themselves, the results we document are consistent with litigation being associated with reputational loss. We use the same four proxies for VC reputation—number of deals, funds under management, network centrality, and the fraction of portfolio firms that go public.  \n\nWe conduct a before-and-after analysis of these measures using the subsample of lawsuits that commenced in or before year 2o05. We stop at the end of 2005 to allow VCs at least 4 years (our VentureXpert data end in 2009) to raise new funds after the lawsuit. Since VCs raise new funds every 2 to 3 years (see Fenn, Liang, and Prowse (1998), 4 years should be enough time for the majority of VCs litigated in or before 2005. Our sample contains 258 unique VC-lawsuit observations (235 VC-year observations). In the calculation of postlawsuit variables we use all funds raised by a VC from the year after the lawsuit up to 2009 (results using a 5-year window are similar but noisier).  \n\nOur main empirical approach is based on standard difference-in-differences estimation. We calculate the post-minus-prelawsuit values of the four reputation proxies for each litigated VC firm and its corresponding matching firm and calculate the difference between the two post-minus-prelawsuit differences. We perform both univariate analysis of the difference-in-differences (peer-adjusted changes in reputation proxies) and regression analysis of the determinants of variation in these peer-adjusted changes.  \n\n### A. Univariate Tests of Changes in VC Reputation Measures Following Litigation  \n\nAfter selecting observationally similar peers for the litigated VC in our sample,we are now ready to test the implication of Hypothesis 2 that litigation will be associated with a drop in VC reputation (alternatively, VC counterparties will punish VCs for opportunistic behavior). We calculate peer-adjusted after-minus-prelawsuit differences in the four reputational proxies and in Table VI report the mean differences for the entire sample of lawsuits and the subsamples based on plaintiff type, lawsuit outcome, and repeat litigation. For comparison, we report results using the Abadie and Imbens (2002) and propensity-based matching methodologies. In the Internet Appendix we report the results from the Mahalanobis matching, as well as other matching procedures (see Section V.C).  \n\nThe overall peer-adjusted differences in number of deals, funds under management, and network centrality are negative and generally significantly different from zero at high confidence levels (the exceptions are number of deals and funds under management using propensity matching). Not only are the  \n\n# TableVI Mean Peer-Adjusted Changes in VC Reputational Proxies Following Litigation  \n\nThe sample includes only lawsuits that are filed by the end of 2005. For each sample VC we use the four reputation measures: (1) number of deals, (2) funds under management, (3) network degree, and (4) percent of deals going public. We calculate the (Post - Pre) difference of each measure as the difference between the postlitigation and prelitigation value of the measure. We peer-adjust the (Post - Pre) difference by subtracting the $(\\mathrm{Post}-\\mathrm{Pre})$ value of the corresponding matching firms. The columns titled $^{\\mathrm{{}}^{\\mathrm{{6}}}}\\mathrm{{AI2002^{\\mathrm{{9}}}}}$ use the matching procedure in Abadie and Imbens (2002). Columns titled “Prop.\" use the matching procedure based on propensity to be litigated calculated using a probit model reported in the Internet Appendix. Older VCs are defined as VCs in the top quartile of the age distribution of all VCs in the year of the lawsuit. We report in parentheses the $p$ -values of $t$ -tests for the mean peer-adjusted differences equaling zero. \\*, \\*\\*, and $***$ denote significance at $10\\%$ $5\\%$ , and $1\\%$ level, respectively.  \n\n<html><body><table><tr><td rowspan=\"2\"></td><td rowspan=\"2\"></td><td colspan=\"2\">Number of Deals</td><td colspan=\"2\">Funds under Mgmt</td><td colspan=\"2\">Network Degree</td><td colspan=\"2\">Pct Deals Going Public</td></tr><tr><td>AI2002</td><td>Prop.</td><td>AI2002</td><td>Prop.</td><td>AI2002</td><td>Prop.</td><td>AI2002</td><td>Prop.</td></tr><tr><td>Sample All litigated</td><td>Obs. 258</td><td>-0.013***</td><td>-0.003</td><td>-0.013***</td><td>-0.007</td><td>-0.006***</td><td>-0.008***</td><td>0.004</td><td>-0.023*</td></tr><tr><td>VCs OlderVCs</td><td>128</td><td>(0.00) -0.031***</td><td>(0.40) -0.006</td><td>(0.01) -0.030***</td><td>(0.18) -0.023***</td><td>(0.01) -0.017***</td><td>(0.00) -0.014***</td><td>(0.69) 0.0089</td><td>(0.08) -0.025</td></tr><tr><td>VCs with</td><td>66</td><td>(0.00) -0.050***</td><td>(0.37) -0.000</td><td>(0.00) -0.049***</td><td>(0.01) -0.016**</td><td>(0.00) -0.024***</td><td>(0.00) -0.025***</td><td>(0.51) -0.002</td><td>(0.18) 0.002</td></tr><tr><td>previous lawsuits VCs with multiple</td><td>41</td><td>(0.00) -0.044*** (0.01)</td><td>(0.96) -0.010 (0.32)</td><td>(0.00) -0.047*** (0.01)</td><td>(0.09) -0.020 (0.11)</td><td>(0.00) -0.026*** (0.00)</td><td>(0.00) -0.026*** (0.00)</td><td>(0.91) -0.007 (0.75)</td><td>(0.92) 0.033** (0.05)</td></tr><tr><td>lawsuits in sameyear VClost</td><td>68</td><td>-0.017</td><td>-0.006</td><td>-0.014</td><td>-0.003</td><td>-0.008**</td><td>-0.009**</td><td>0.012</td><td>-0.039</td></tr><tr><td>VClost lawsuit by founder</td><td>20</td><td>(0.12) -0.065** (0.04)</td><td>(0.37) -0.025*** (0.01)</td><td>(0.16) -0.051** (0.04)</td><td>(0.81) -0.006 (0.57)</td><td>(0.05) -0.020* (0.09)</td><td>(0.04) -0.019 (0.11)</td><td>(0.44) 0.025 (0.36)</td><td>(0.12) -0.032 (0.47)</td></tr><tr><td>Lawsuit by founder</td><td>51</td><td>-0.028** (0.03)</td><td>-0.029*** (0.00)</td><td>-0.028*** (0.01)</td><td>-0.017** (0.03)</td><td>-0.010** (0.04)</td><td>-0.008</td><td>0.0156</td><td>-0.025</td></tr><tr><td>Lawsuit by LP</td><td>18</td><td>-0.002 (0.44)</td><td>-0.005 (0.30)</td><td>-0.002 (0.23)</td><td>-0.004 (0.11)</td><td>0.002 (0.12)</td><td>(0.13) 0.001 (0.60)</td><td>(0.32) 0.004 (0.89)</td><td>(0.45) 0.074*** (0.01)</td></tr><tr><td>Lawsuit by otherVCs</td><td>8</td><td>-0.001 (0.98)</td><td>0.006 (0.81)</td><td>-0.012 (0.85)</td><td>-0.022 (0.43)</td><td>-0.041 (0.29)</td><td>-0.0340</td><td>-0.0701</td><td>-0.094</td></tr><tr><td>Lawsuits by buyer</td><td>30</td><td>-0.010 (0.13)</td><td>-0.004 (0.61)</td><td>-0.025 (0.14)</td><td>-0.037* (0.10)</td><td>0.008 (0.14)</td><td>(0.18) 0.004</td><td>(0.11) -0.032</td><td>(0.22) -0.088 (0.11)</td></tr></table></body></html>  \n\ncoefficients consistent with Hypothesis 2, but they also imply large economic impacts. The scaling of our variables allows for easy conversion from the reported percentages to levels. If we take 2002 as a benchmark (the filing year of the median lawsuit), we just need to multiply the mean effects in the first row of Table VI by the 2002 values in VentureXpert for total number of investment rounds and funds raised to calculate the mean postlawsuit peer-adjusted declines in the levels of reputation proxies. The resulting numbers indicate that, relative to their peers, litigated VCs invest in 430-1,840 fewer deals (investment rounds), raise 380-690 million dollars less following a lawsuit, and syndicate with 42-55 fewer partners. When we divide these numbers by the average prelawsuit number for litigated VCs reported in Table IV, we get rough estimates (a ratio of averages is generally not equal to an average of ratios) for the peer-adjusted percentage drop in number of deals of $6\\%$ to $23\\%$ in funds under management of $21\\%$ to $38\\%$ , and in network centrality of $15\\%$ to $19\\%$  \n\nTable VI also provides some preliminary evidence about the predictions of Hypothesis 3 and Hypothesis 4. The mean effects on number of deals, funds under management, and network degree are more negative for older VCs (defined as VCs in the top quartile of the VC age distribution in the year of the lawsuit), suggesting that the negative impact of litigation is larger for more reputable VCs. Consistent with Hypothesis 4C, the negative effects of litigation on peer-adjusted changes in the first three reputational proxies are larger in absolute magnitude when the litigated VCs have been litigated in the past or when they have multiple lawsuits in the same year. The data also offer strong support for Hypothesis 4B as the largest negative effects in Table VI occur when VCs have been litigated by founders and have lost the lawsuit. There is weak evidence in support of Hypothesis 4A. Lawsuits filed by founders do indeed have a larger negative effect on number of deals, but they also have a significant impact on funds under management, the proxy for reputation with limited partners. Lawsuits fled by VCs have a larger negative effect on network centrality, but the latter effect is not statistically significantly different from zero (perhaps because there are only eight observations of lawsuits filed by other VCs). Moreover, neither lawsuits filed by limited partners nor lawsuits fled by startup buyers are associated with a disproportionate effect on funds under management and percent of deals going public, respectively.  \n\n### B. Multivariate Tests of Changes in VC Reputation Measures Following Litigation  \n\nTo directly test the predictions of Hypotheses 3 and 4, we need to analyze the variation in postlitigation peer-adjusted changes in each reputation proxy and relate this variation to plaintiff type, lawsuit outcome, and measures of repeat litigation. We perform this analysis in a series of OLS regressions in which the dependent variables are peer-adjusted changes in number of deals, funds under management, network centrality, and percent of deals going public, and the independent variables include a set of dummies identifying the categories in Table VI, with the addition of a continuous variable measuring the number of prior lawsuits filed against the VCs. We report the results from these regressions in Table VII.  \n\nThe regressions in Table VII indicate that VC counterparties not only react to the mere fact of a lawsuit filed against a VC, but also pay close attention to the characteristics of the VC and lawsuit.VCs that have been litigated in the past suffer stronger negative reactions by their counterparties. Lawsuits filed by founders, especially when the VCs lose these lawsuits, are associated with larger-than-average negative impacts on number of deals and funds under management, suggesting that the communities of founders and limited  \n\n# TableVII Determinants of Peer-Adjusted Changes in VC Reputational Proxies  \n\nThe table presents OLS regressions of peer-adjusted changes in number of deals, funds under management, network degree, and percent of deals going public. The sample includes lawsuits from 1970 to 2005. The columns titled“ $\\mathrm{AI2002^{\\mathfrak{N}}}$ use the matching procedure in Abadie and Imbens (2002). Columns titled “Prop.\" use the matching procedure based on the propensity to be litigated calculated using a probit model reported in the Internet Appendix. Older VCs is a dummy equal to one if a VC is in the top quartile of the age distribution of all VCs in the year of the lawsuit. Multiple lawsuits in same year is a dummy equal to one if a VC is defendant to more than one lawsuit fled in the same year. Prior number of lawsuits is a variable measuring the number of previous lawsuits the VC firm has participated in. Founder lawsuit, LP lawsuit, VC lawsuit, and Buyer lawsuit are dummies for lawsuits filed by founders, limited partners, other VCs or startup buyers. Robust $t$ -statistics are in parentheses. \\*, \\*\\*, and \\*\\* denote significance at $10\\%$ $5\\%$ and $1\\%$ level, respectively.  \n\n<html><body><table><tr><td></td><td colspan=\"2\">Number of Deals</td><td colspan=\"2\">Funds under Mgmt</td><td colspan=\"2\">Network Degree</td><td colspan=\"2\">Pct Deals Going Public</td></tr><tr><td></td><td>AI2002</td><td>Prop.</td><td>AI2002</td><td>Prop.</td><td>AI2002</td><td>Prop.</td><td>AI2002</td><td>Prop.</td></tr><tr><td>OlderVC</td><td>-0.022***</td><td>-0.003</td><td>-0.013</td><td>-0.016</td><td>-0.011**</td><td>-0.004</td><td>0.005</td><td>0.006</td></tr><tr><td></td><td>(-2.95)</td><td>(-0.40)</td><td>(-1.39)</td><td>(1.44)</td><td>(-2.42)</td><td>(-0.98)</td><td>(0.24)</td><td>(0.19)</td></tr><tr><td>VC lost = 1</td><td>0.017</td><td>-0.000</td><td>0.007</td><td>0.000</td><td>0.004</td><td>0.003</td><td>0.009</td><td>-0.031</td></tr><tr><td>AND Founder</td><td>(1.39)</td><td>(-0.04)</td><td>(0.50)</td><td>(0.00)</td><td>(0.79)</td><td>(0.69)</td><td>(0.39)</td><td>(-0.86)</td></tr><tr><td>lawsuit = 0 VC lost=0 AND</td><td>0.007 (0.70)</td><td>-0.036** (2.52)</td><td>-0.015 (1.18)</td><td>-0.035** (-2.53)</td><td>0.004 (0.70)</td><td>0.007 (1.24)</td><td>0.013 (0.50)</td><td>-0.008 (-0.15)</td></tr><tr><td>Founder lawsuit = 1 VC lost = 1 AND</td><td>-0.049**</td><td>-0.029**</td><td>-0.048**</td><td>-0.012</td><td>-0.009</td><td>-0.009</td><td>0.026</td><td>-0.017</td></tr><tr><td>Founder lawsuit = 1 Lawsuit by LP</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td>-0.007 (-1.19)</td><td>-0.011 (-1.59)</td><td>-0.014** (-2.21)</td><td>-0.019 (-1.60)</td><td>0.002 (0.58)</td><td>0.004 (1.16)</td><td>-0.001 (-0.02)</td><td>0.112*** (3.25)</td></tr><tr><td>Lawsuit by</td><td>0.017</td><td>0.003</td><td>-0.001</td><td>-0.016</td><td>-0.029</td><td>-0.028</td><td>-0.082**</td><td>-0.056</td></tr><tr><td>other VCs</td><td>(0.32)</td><td>(0.12)</td><td>(-0.01)</td><td>(-0.76)</td><td>(-0.90)</td><td>(-1.16)</td><td>(-2.15)</td><td>(-0.79)</td></tr><tr><td>Lawsuits by</td><td>-0.004</td><td>-0.009</td><td>-0.030*</td><td>-0.048**</td><td>0.012*</td><td>0.010</td><td>-0.034</td><td>-0.063</td></tr><tr><td>buyer</td><td>(-0.48)</td><td>(-0.91)</td><td>(-1.67)</td><td>(-2.11)</td><td>(1.95)</td><td>(1.35)</td><td>(-0.68)</td><td>(-1.07)</td></tr><tr><td>Missing</td><td>0.010</td><td>0.007</td><td>-0.003</td><td>0.001</td><td>0.011**</td><td>0.005</td><td>0.021</td><td>0.025</td></tr><tr><td>plaintiff type</td><td>(0.70)</td><td>(0.46)</td><td>(-0.19)</td><td>(0.05)</td><td>(2.47)</td><td>(1.15)</td><td>(0.75)</td><td>(0.73)</td></tr><tr><td>Multiple</td><td>-0.015</td><td>-0.004</td><td>-0.012</td><td>0.007</td><td>-0.014***</td><td>-0.012**</td><td>-0.031</td><td>0.063**</td></tr><tr><td>lawsuits in</td><td>(-1.19)</td><td>(-0.38)</td><td>(-0.71)</td><td>(0.60)</td><td>(-2.91)</td><td>(-2.07)</td><td>(1.14)</td><td>(2.47)</td></tr><tr><td>same year Number of</td><td>-0.011***</td><td>-0.002</td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>previous</td><td>(-7.94)</td><td>(-0.57)</td><td>-0.015*** (-7.73)</td><td>-0.013*** (7.43)</td><td>-0.007*** (-10.45)</td><td>-0.006*** (-9.24)</td><td>0.005 (1.20)</td><td>-0.003 (-0.88)</td></tr><tr><td>lawsuits N obs.</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr></table></body></html>  \n\npartners respond especially strongly to such lawsuits. Thus, Hypotheses 4B and 4C fit the data well. In contrast, there is weak support for Hypothesis 4A. Last, there is some evidence that older VCs experience larger decreases in deal fow and syndication following litigation, consistent with the predictions of Hypothesis 3.  \n\n### C. Robustness Checks  \n\nWe run a battery of other tests to examine the robustness of the findings in Tables VI and VII and report the results in the Internet Appendix. First, we use several alternative matching techniques. We begin with Mahalanobis and rank matching. In the rank-based matching we rank all peer VCs on each of the five reputational measures in terms of absolute difference between the value for the reputational measure for the litigated VC and the value for the peer VCs. The best match is then determined as the peer VC that has the smallest sum of ranks across all five measures. We also use a bootstrapping technique to select matching firms without imposing any specific restrictions on them. For each litigated VC-year observation we randomly pick a VC in the same year from the universe of never-litigated VCs and then calculate the peer-adjusted post-pre differences in the four reputation measures using the post-pre differences of the randomly drawn VC. We repeat the procedure 1,000 times and then calculate the means from Table VI and run the regressions from Table VII on the 1,0oo bootstrapped samples substituting frequencies for $p$ -values. The results for number of deals, funds under management, and network centrality are similar to the original results, but statistically stronger.  \n\nWe further report results from sequential matching by characteristics as is more common in finance. We first match litigated VCs with peers on age. Then, of the subsample of VCs that are close in age to litigated VCs, we select peers that have similar funds under management and from these we choose ones that have similar percent of deals going public. The results from the univariate and regression analysis of peer-adjusted differences are stronger, although the resulting peer samples are very close to the litigated VCs on age and funds under management, and have similar percent of deals going public, but are significantly different on the other characteristics in Table II.  \n\nSecond, we estimate the matching techniques without replacement (using a peer VC only once for matching). We get somewhat stronger results, which is in line with the results from the matching literature that matching with replacement leads to a smaller bias while matching without replacement leads to smaller standard errors.  \n\nThird, to address the potential impact of outliers, we estimate all models after dropping Citigroup Venture Capital, which has 15 observations in our sample. Results remain the same with the exception of the coefficients on previous number of lawsuits in Table VII, which become a lot smaller but remain significant in most specifications. We also winsorize at $1\\%$ the peer-adjusted differences and recalculate Tables VI and VII. The effect on the results is negligible.  \n\nLast, we estimate the other commonly used methodology to address endogeneity between treatment (in our case litigation) and outcomes (changes in reputational measures), namely Heckman (1976)-type treatment models that take into account the fact that treatment is endogenously chosen (see Maddala (1983) for a review). Campa and Kedia (2002) is one notable application of such treatment models in finance (in a study of the diversification discount). Compared to our matching plus difference-in-differences methodology, one benefit of the endogenous treatment models is that they could in theory account for endogeneity arising from unobservable factors, as long as there are exogenous instruments that identify the choice of treatment that are not directly correlated with the outcomes from treatment. The main deficiencies of using treatment models in our empirical analysis are that first, they cannot easily account for more than one treatment (e.g., lawsuits by different types of plaintiffs), and second, they are not designed to deal directly with panel data.  \n\nWe estimate a series of treatment regressions and try to the best of our abilities to correct for their two deficiencies (see discussion of our implementation in the Internet Appendix). We first estimate models that are similar to the univariate tests in Table VI, which examine the question of whether the impact of litigation on reputational proxies is negative, and then estimate models that are similar to the regressions in Table VII, which test whether the reputational impact of a particular type of lawsuit is different from the impact of other lawsuits. The results from this estimation are reported in the Internet Appendix. Even though we keep relatively similar peer VCs, the estimated treatment effects from litigation are still much larger than the coefficients in Table VI1. The signs for number of deals, funds under management, and network centrality are nevertheless all negative and significant.  \n\n## VI. Conclusion  \n\nThis paper performs the first systematic analysis of the role of reputation in policing opportunistic behavior by venture capitalists towards four types of counterparties: entrepreneurs, investors, other VCs, and acquirers of VCbacked startups. We find that more reputable VCs are less likely to be litigated on a per deal basis. Following lawsuits, litigated VCs invest in fewer deals, raise significantly less capital, and syndicate with fewer VCs than their peers. Relative to other litigated VCs, VCs that are defendants to multiple lawsuits suffer a larger negative impact on their business relationships. At the same time, VCs sued by founders subsequently invest in fewer deals and raise significantly less capital, and these effects are more pronounced when the VCs lose such lawsuits. Our results suggest that reputational mechanisms act to prevent widespread abuse of power by VCs and that litigation can enhance reputational enforcement mechanisms by informing other counterparties of VC misbehavior.  \n\nOverall, we present evidence that the VC industry uses a complex web of legal and nonlegal mechanisms to ameliorate the possible abuse of contractual discretion by VCs. Reputational mechanisms can complement contracts and courts in penalizing VC opportunism ex post and reducing the likelihood of opportunism ex ante, and thus can improve the efficiency of this important market for financing innovation and growth.  \n\n# REFERENCES  \n\nAbadie, Aiberto, David Drukker, Jane Leber Herr, and Guido Imbens, 2uu4, Implementing matching estimators for average treatment effects in Stata, Stata Journal 4, 290-311.   \nAbadie, Alberto, and Guido Imbens, 2002, Simple and bias-corrected matching estimators, Technical report, University of California, Berkeley.   \nBachmann, Ralph, and Ibolya Schindele, 2006, Theft and syndication in venture capital fnance, Working paper, Norwegian Business School.   \nBaker, Malcolm, and Paul Gompers, 2003, The determinants of board structure at the initial public offering, Journal of Law and Economics 46, 569-598.   \nBhattacharya, Sudipto, and Gabriella Chiesa, 1995, Proprietary information, financial intermediation, and research incentives, Journal of Financial Intermediation 4, 328-357.   \nBorenstein, Severin, and Martin Zimmerman, 1988, Market incentives for safe commercial airline operation, American Economic Review 78, 913-935.   \nCampa, Jose, and Simi Kedia, 2002, Explaining the diversifcation discount, Journal of Finance 57, 1731-1762.   \nDehejia, Rajeev, and Sadek Wahba, 1999, Causal effects in non-experimental studies: Reevaluatingthe evaluation oftraining programs, Journal ofthe American Statistical Association 94, 1053-1062.   \nDehejia, Rajeev, and Sadek Wahba, 2002, Propensity score matching methods for non-experimental causal studies, Review of Economics and Statistics 84, 151-161.   \nDiamond, Douglass, 1989, Reputation acquisition in debt markets, Journal of Political Economy 97, 828-862.   \nFenn, George, Nellie Liang, and Stephen Prowse, 1998, The private equity market: An overview, Financial Markets, Institutions & Instruments 6, 1-106.   \nGande, Amar, and Craig M. Lewis, 2009, Shareholder-initiated class action lawsuits: Shareholder wealth effects and industry spillovers, Journal of Financial and Quantitative Analysis 44, 823-850.   \nGilson, Ronald, 2003, Engineering venture capital markets: Lessons from the American experience, Stanford Law Review 55, 1067-1103.   \nGompers, Paul, and Josh Lerner, 1999, The Venture Capital Cycle (MIT Press, Cambridge, MA).   \nGraham, John, Si Li, and Jiaping Qui, 2008, Corporate misreporting and bank loan contracting, Journal of Financial Economics 89, 44-61.   \nHeckman, James, 1976, The common structure of statistical models of truncation, sample selection and limited dependent variables and a simple estimator for such models, Annals of Economic and Social Measurement 5, 475-492.   \nHellmann, Thomas, and Manju Puri 2002, Venture capital and the professionalization of start-up firms: Empirical evidence, Journal of Finance 57, 169-197.   \nHochberg, Yael, Alexander Ljungqvist, and Yang Lu, 2007, Whom you know matters: Venture capital networks and investment performance, Journal of Finance 62, 251-301.   \nHsu, David, 2004, What do entrepreneurs pay for venture capital affliation? Journal of Finance 59,1805-1844.   \nImbens, Guido, 2004, Nonparametric estimation of average treatment effects under exogeneity: A review, Review of Economics and Statistics 86, 4-30.   \nJarrell, Gregg, and Sam Peltzman, 1985, The impact of product recalls on the wealth of sellers, Journal of Political Economy 93, 512-536.   \nKaplan, Steven, and Antoinette Schoar, 2005, Private equity performance: Returns, persistence, and capital fows, Journal of Finance 60, 1791-1823.   \nKaplan, Steven, and Per Stromberg, 2003, Financial contracting meets the real world: An empirical analysis of venture capital contracts, Review of Economic Studies 70, 281-316.   \nKarpoff, Jonathan, 2011, Does Reputation Work to Discipline Corporate Misconduct?,in The Oxford University Handbook of Corporate Reputation (Oxford University Press Oxford, UK).   \nKarpoff, Jonathan, D. Scott Lee, and Gerald Martin, 2008, The cost to firms of cooking the books, Journal of Financial and Quantitative Analysis 43, 581-612.   \nKarpoff Jonathan, and Jon Lott, 1993, The reputational penalty firms bear from committing criminal fraud, Journal of Law and Economics 36, 757-802.   \nKellogg, Robert L., 1984, Accounting activities, security prices, and class action lawsuits, Journal of Accounting and Economics 6, 185-204.   \nKlein, Benjamin, and Keith Leffer, 1981, The role of market forces in assuring contractual performance, Journal of Political Economy 89, 615-641.   \nKreps, David, and Robert Wilson, 1982, Reputation and imperfect information, Journal of Economic Theory 27, 253-279.   \nKrishnan, C.N.V., Vladimir Ivanov, Ronald Masulis, and Ajay Singh, 2011, IPOs and venture capital reputation, Journal of Financial and Quantitative Analysis 46, 1295-1333.   \nLerner, Josh, 1994, The syndication of venture capital investments, Financial Management 23, 16-27.   \nLin, Timothy, and Richard Smith, 1998, Insider reputation and selling decisions: The unwinding of venture capital investments during equity IPOs, Journal of Corporate Finance 4, 241-263.   \nLindsey, Laura, 2008, Blurring frm boundaries: The role of venture capital in strategic alliances, Journal of Finance 63, 1137-1168.   \nLitvak, Katherine, 2004, Governance through exit: Default penalties and walkaway options in venture capital partnership agreements, Willamette Law Reuiew 40, 771-812.   \nMacLeod, W. Bentley, 2007, Reputations, relationships, and contract enforcement, Journal of Economic Literature 45, 595-628.   \nMaddala, Gangadharrao S., 1983, Limited-Dependent and Qualitative Variables in Econometrics (Cambridge University Press, Cambridge, MA).   \nMurphy, Deborah, Ronald Shrieves, and Samual Tibbs, 2009, Understanding the penalties associated with corporate misconduct: An empirical examination of earnings and risk, Journal of Financial and Quantitative Analysis 44, 55-83.   \nPontiff Jeffrey, 2007, Damages in corporate lawsuits: The impact of deep pockets, Working paper, Boston College.   \nRomano, Roberta, 1991, The shareholder suit: Litigation without foundation? Journal of Law, Economics, and Organizations 7, 55-87.   \nRosenbaum, Paul, and Donald Rubin, 1983, The central role ofthe propensity score in observational studies for causal effects, Biometrika 70, 41-55.   \nRubin, Donald, 1980, Bias reduction using Mahalanobis' metric matching, Biometrics 36, 293-298.   \nRubin, Donald, 2006, Matched Sampling for Causal Effects (Cambridge University Press, New York).   \nRubin, Paul, Dennis Murphy, and Gregg Jarrell, 1988, Risky products, risky stocks, Regulation 12, 35-39.   \nShapiro, Carl, 1983, Premiums for high-quality products as returns to reputations, Quarterly Journal of Economics 98, 659-680.   \nUeda, Masako, 2004, Banks versus venture capital: Project evaluation, screening, and expropriation, Journal of Finance 59, 601-621.   \nYosha, Oved, 1995, Information disclosure costs and the choice of financing source, Journal of Financial Intermediation 4, 3-20.  "
  },
  "md_bacon-gerasymenkoHowWhenInvestment2020": {
    "reference_markdown": "# How and When Investment Horizons Determine Venture Capital Firms' Attention Breadth to Portfolio Companies  \n\nVioletta Bacon-Gerasymenko' @, Jonathan D. Arthurs', and Sam Y. Cho'  \n\n## Abstract  \n\nThis study develops and tests a theory about the antecedents of venture capital firms' (VCs') attention breadth to their portfolio companies (PFCs). We find that VCs expand their attention breadth but only up to a certain level of expected investment horizons for each PFC,after which attention breadth narrows. We also find that this inverted U-shaped relationship is contingent upon the VC investment horizon dispersion and the number of co-investors in a given PFC. Our research advances the entrepreneurship and venture capital literature and provides novel insight into the broader literature on investment horizons and strategic alliances.  \n\n## Keywords  \n\nventure capital, attention breadth, expected investment horizons, investment horizon dispersion, syndication  \n\nScholars have long been interested in how and under what conditions venture capital firms (VCs) add value to their portfolio companies (PFCs) (De Clercq & Manigart, 2007; Drover et al., 2017). Specifically, researchers have primarily focused on understanding the individual, organizational, and institutional factors that may explain inter-VC differences in their ability to add value to different domains (Drover et al., 2017) and performance (Rosenbusch, Brinckmann, & Muiller, 2013). A small amount of research has sought to explain intra-VC differences. This research has focused on PFC characteristics such as CEOs′ experience, stage of development, level of innovativeness (Sapienza & Gupta, 1994), relative standing to other PFCs (Ozmel & Guler, 2015), and PFC performance (Sapienza, 1992). However, we still lack an understanding of how $V C$ characteristics may explain intra-VC variation in added value found among PFCs (see a detailed review by De Clercq & Manigart, 2007). Because such added value accounts for most of the variance in PFC valuation (Fitza, Matusik, & Mosakowski, 2009) and revenue growth (Croce,  \n\nMarti, & Murtinu, 2013), opening this black box could provide additional insight into the venture capital literature and practices (De Clercq & Manigart, 2007).  \n\nBy combining insights from the attention-based view of the firm (Ocasio, 1997), temporal research (Reilly, Souder, & Ranucci, 2016), and strategic alliance literature, we theorize and examine the impact of VCs’ expected investment horizons (Barrot, 2017) on their breadth of attention to PFCs. We consider the breadth of attention, a count of the domains such as finance, strategy, business models and others, as one of the essential, yet understudied, ways in which VCs add value to a PFC. We conceptualize VC investment horizon as an ex ante expectation of time-to-exit from a PFC (Barrot, 2017; Souder, Reilly, Bromiley, & Mitchell, 2016). Surprisingly, apart from the study of Souder et al. (2016), theory-driven predictions about the consequences of different horizons have not been offered (Reilly et al., 2016, p. 1186). Our theory suggests an inverted U-shaped relationship between the length of expected investment horizon and VCs' breadth of attention to a focal PFC. We further examine two contingencies of the investment horizon-attention breadth inverted U-shaped relationship: VC investment horizon dispersion (whether a VC invests in PFCs with similar or different time-to-exit periods) and VC syndication.  \n\nTo test our theory, we rely on a unique dataset collected via a mixed research method (Plano Clark & Creswell, 2008) from young French VCs specialized in early-stage funding. First, we find evidence that a longer expected investment horizon increases the breadth of their attention to PFCs but only up to a certain threshold, after which the attention breadth narrows. Second, we show that VC investment horizon dispersion and the size of a VC syndicate moderate the investment horizon-attention breadth inverted U-shaped relationship. Specifically, we found that the turning point of the inverted U-shaped relationship occurred at longer predicted investment horizons and, to our surprise, the inverted U-shaped curve fipped and became U-shaped for VCs with a high investment horizon dispersion. Finally, we demonstrate that the inverted U-shaped relationship is accentuated and the turning point occurs at longer predicted investment horizons for VCs in larger syndicates.  \n\nThe contributions of our research are manifold. First, our study contributes to venture capital literature by offering a novel explanation for the variance of VCs? breadth of attention on a project-by-project basis. By incorporating these findings in their future research, scholars may grasp important nuances in the VC-PFC relationship. Second, our study contributes to temporal research (Reilly et al., 2016) by demonstrating the consequences of expected investment horizons for the novel but critical output, breadth of organizational attention, and how a distinction between project- and firm-level investment horizons could explain essential within-firm differences. We discuss the remaining contributions in the final part of this study.  \n\n## Theoretical Development  \n\n### Attention Breadth, Investment Horizons, and Syndication in the Venture Capital Context  \n\nScholars studying organizational attention, defined as the noticing, encoding, interpreting, and focusing of time and effort on both issues such as problems, opportunities, and threats as well as answers such as proposals, routines, projects, programs, and procedures (Ocasio, 1997, p. 189), have acknowledged that broader attention is generally better (Bansal, Kim, & Wood, 2018). For instance, firms with broader attention exhibit a greater readiness to seize new product opportunities (Yadav, Prabhu, & Chandy, 2007) and higher social performance (Crilly & Sloan, 2012). VCs? attention covers everything from identifying problems or challenges faced by PFCs to answers by advising in finance, strategy, marketing, business planning, and other domains (De  \n\nClercq, Fried, Lehtonen, & Sapienza, 2006). Because early-stage ventures typically lack expertise in some critical business domains (McDougall, Shane, & Oviatt, 1994), broader VC attention may be highly advantageous. For instance, broader VC attention may expose ventures to information about more attractive customer segments and innovative business models (Gerasymenko, De Clercq, & Sapienza, 2015). Additionally, broader VC attention may help PFCs “discern threats or opportunities in a timely manner and relate appropriate advice or source relevant expertise from its network to the venture's management team\" (Dimov & Martin de Holan, 2010, p. 138). As evidenced from our interviews, VCs’ attention to the domain of human resource management, for instance, encompasses identifying the potential need to replace the founder-CEO, specifying the venture's milestones, and suggesting potential “answers\"” such as identifying the profile of a new CEO, developing an incentive plan, and so forth. Arguably, such value-adding attention to a given PFC encompasses substantial effort and time from a VC. Therefore, we conceptualize a VC's breadth of attention vis-a-vis a PFC as the number of domains to which a focal VC devotes considerable and value-adding attention. Whereas VCs and other stakeholders may use different means and approaches to add value to ventures as documented in earlier research (e.g., Busenitz, Fiet, & Moesel, 2004; Sapienza, Manigart, & Vermeir, 1996), we consider the VCs' breadth of attention as one of the critical ways in which VCs may add valuetoPFCs.  \n\nWhile a substantial body of research has emphasized the importance of added value by VCs to PFCs (see Drover et al., 2017, for a detailed literature review), for the most part, these studies examined inter-VC firm differences. For instance, Dimov and Shepherd (2005) analyzed the impact of human capital of VCs’ managers on the proportion of PFCs that go public and bankrupt, while Bruton, Filatotchev, Chahine, and Wright (2010) and Sapienza et al. (1996) compared VCs in different parts of the world. Other scholars demonstrated that the variance in value-adding among VCs may be attributed to their experience (Bottazzi & Da Rin, 2002; Sapienza et al., 1996) and early versus late-stage investment focus (Sapienza, Amason, & Manigart, 1994). Surprisingly, only a handful of studies focused on intra-VC differences. For instance, the frequency of VC-CEO interaction was greater for PFCs that had less experienced top managers, were at earlier stages of development, yet pursued a higher level of innovativeness (Sapienza & Gupta, 1994). Also, the ventures with weaker teams benefited more from the VCs’ advising in different domains (Baum & Silverman, 2004; Beckman, Burton, & O'Reilly, 2007). Finally, a higher quality venture relative to other ventures in a VC's portfolio benefited from the VC affiliation in a more substantial way (Ozmel & Guler, 2015). Despite valuable insights, these studies looked only at one part of the puzzle—the PFC characteristics; whereas the potential influence of VC characteristics on the intra-VC variance in adding value, including via differences in attention breadth to PFCs, remains a “black box.” The importance of starting to open such a “black box\" is further underscored by empirical findings suggesting that both the VC firm organizational capital and the general partners’ (GPs') human capital explain the PFC performance (Ewens & Rhodes-Kropf, 2015).  \n\nTo unpack the “black box,” our study draws on the attention-based view of the firm (Ocasio, 1997), temporal research on investment horizons, and strategic alliance literature to inform theorizing about VC-specific antecedents of intra-VC differences in attention breadth following initial investment in PFCs. In particular, we draw on two fundamental premises in the attention-based view of the firm that may influence organizational attention breadth. The first one is the situated attention, which implies that the properties of attention depend on organizational context or situation. The second——the structural distribution of attention—means that the breadth of a decision maker's attention may be affected by firm processes and social relationships (Ocasio,1997).  \n\nVC investment horizon. While VC funds are typically considered long-term investment vehicles with an investment lifetime of 10 years fixed ex ante, empirical evidence suggests that VCs may pursue investments with potentially different levels of maturity and, therefore, different investment horizons depending on the VC funds’ age (Barrot, 2017) and external market conditions (Nanda & Rhodes-Kropf, 2013). Investment horizon is the ex ante managerial expectation about the duration of time over which potential firm investments will generate returns (Souder et al., 2016). To assess a project investment horizon, VCs may rely on established clues (i.e., age, patenting activity, etc.) for identifying the stage and the expected duration of project development. Because VCs realize returns upon exit (generally via an initial public offering [IPO] or a trade sale), scholars and practitioners refer to “time-to-exit”\" and “investment horizon\" interchangeably (De Clercq et al., 2006). Interestingly, more experienced VCs seem to be better at matching project investment horizons with the life cycle of their funds (Barrot, 2017) that could result in systematically higher VC performance (Kaplan & Schoar, 2005). Whereas such matching could be a sign of the VCs’ superior ability to make accurate predictions (Bacon-Gerasymenko, Coff, & Durand, 2016), it could also result from their superior ability to add value given the expected time-to-exit. Moreover, how soon VCs expect such exits to realize may shape their motivation for when and how broadly their value-adding attention to focal PFCs will be allocated. Understanding the impact of the VCs’ expected investment horizons on the breadth of attention paid to PFCs, therefore, represents a highly salient research question.  \n\nWe theorize how two interdependent latent factors may explain the effects of the VCs’ short, intermediate and long expected investment horizons on the VCs' breadth of attention to multiple domains. These two factors include (a) VCs' motivation to expand their attention across domains, and (b) VCs' ability to expand attention across domains concerning each PFC. Because both of these latent factors are necessary and complement each other in terms of VCs’ expansion of attention to multiple domains, the number of domains that a VC will attend to in a given PFC should be determined by a multiplicative function (Haans, Pieters, & He, 2016, pp. 1178-1180) of these two interrelated latent forces arising from the VCs’ expected investment horizon. Interacting these two functions (VCs' motivation and ability) will result in a curvilinear (inverted U-shaped) relationship between VCs′ expected investment horizon lengths and the VCs? breadth of attention allocated to ventures shortly after their investment.  \n\nShort investment horizon. When VCs invest in projects expecting a short-term payoff, their motivation to maximize potential return on these investments by expanding the breadth of attention within these ventures will be high. Because only a few VCs' investments may become sizable successes, achieving a successful exit sooner rather than later would represent higher performance. As a result, VCs will be motivated to broaden their attention to more domains in hopes of “fixing\" more issues in a venture with a short time-to-exit to maximize the payoff. Because VCs often rely on the same limited partners (LPs) for their subsequent funds (Gompers & Lerner, 2004), by assuring a faster return, a VC may build a positive reputation (Gompers, 1996) and increase the likelihood and even the amount (Lee & Wahal, 2004) of re-investment. Because GPs usually start fundraising for a subsequent fund before the financial returns from their last fund are fully realized (De Clercq et al., 2006), such early returns are especially crucial to young VCs without history of earlier funds to back up their reputation (Nahata, 2008; Turban &Cable,2003).  \n\nHowever, when VCs expect a short time-to-exit from a given investment, their ability to expand attention to many domains will be limited, given the little time they potentially have. Because effectively attending to each domain requires significant effort and time (De Clercq & Fried, 2005; Gifford, 1997) and VCs’ attention is bounded (Ocasio, 1997), VCs will need to restrain their breadth of attention to fewer domains for PFCs they expect to retain in portfolio for only a short time. As one of the VCs we interviewed explained:  \n\nWhen we expect a quick exit, we know that we won't be able to fix everything. Instead, one of the main challenges and keys to a successful exit is to identify and focus all our attention on a few critical strategic domains.  \n\nIntermediate investment horizon. We expect that VCs will have the broadest attention breadth at intermediate lengths of expected investment horizons. In such cases, VCs will still feel quite strongly motivated to expand attention to more domains, because VCs will think that they have enough time and cognitive availability to attend to multiple domains in a PFC in a hope to add value and increase potential return on investment. At the same time, VCs will feel less constrained by a limited amount of time to attend to different domains in ventures they project to have an intermediate time-to-exit. Thus, their relatively high motivation and ability to allocate effort and time will allow them to attend to multiple domains effectively.  \n\nLong investment horizon. When VCs expect a long time-to-exit from their investments, they may feel less motivated to expand attention to many domains right away following the investment. Because VCs feel less urgency about identifying solutions for long-term projects (Maruping, Venkatesh, Thatcher, & Patel, 2015), they may be more inclined to limit their attention to a few essential domains and adopt a “wait and see” attitude regarding how projects unfold. Yet, VCs may have a high ability to allocate value-adding attention to focal ventures in many different domains for three reasons. First, PFCs with a longer expected time-to-exit are most likely in an earlier stage of development (Barrot, 2017). Thus, VCs might perceive the opportunity of shaping the PFCs as higher. Second, extending the breadth of attention to more domains at the time of initial investment will allow VCs to gain a better understanding of potential challenges and the needs of the venture, and therefore address them more effectively over time. Third, VCs will be less bounded by a limited amount of time, suggesting that VCs can effectively attend to each domain that requires significant effort to identify and resolve diverse challenges of PFCs.  \n\nIn summary, VCs are likely to be highly motivated to expand attention to multiple domains for investments with expected short investment horizons in hopes of showing positive returns early on. However, such motivation will decrease monotonically since VCs will be much less motivated to expand attention breadth towards projects with longer expected investment horizons. On the contrary, the ability of VCs to allocate attention to many domains will be low when expected investment horizons are short. Such ability will increase monotonically with the increase of expected investment horizon but with diminishing margins since some ventures' needs and opportunities may only appear over time (Busenitz et al., 2004) and cannot be addressed by VCs at the time of investment. All in all, the influence of the VCs'expected investment horizon, via the two latent mechanisms of VCs’ ability and motivation, will result in an inverted U-shaped curve such that the VCs' breadth of attention will be broadest at intermediate lengths of expected investment horizons. Our first hypothesis is stated as follows:  \n\nHypothesis 1: There is an inverted $U$ shaped relationship between the length of VCs' predicted investment horizons and the VCs' breadth of attention to PFCs.  \n\nTo gain a more comprehensive theory-driven understanding of the VCs’ investment horizon-- attention breadth relationship, we further examine two contingent factors confined within the second important premise of the attention-based view: the structural distribution of attention. We thus consider the VCs’ investment horizon dispersion that captures the extent to which VCs select and manage projects that have different investment horizons and the VCs’ participation in interorganizational relationships such as syndicates, broadly known as strategic alliances.  \n\nVC investment horizon dispersion. Some VCs may show consistency in their investment horizon choices (have no or little dispersion concerning investment horizons for their investments), while others may invest and manage projects with a high horizon dispersion (Barrot, 2017). We extend earlier research on antecedents of investment horizons and their diversity (e.g., Graham & Harvey, 2001; Judge & Spitzfaden, 1995; Souder & Bromiley, 2012) by focusing on the impact of VCs? investment horizons dispersion. Specifically, we propose that VCs? investment horizon dispersion will affect the inverted U-shaped relationship between expected investment horizons and the breadth of attention in two distinct ways: the slopes of the inverted U-shaped curve will be less steep, and the “\"turning point’ will shift to the right for VCs with high investment horizon dispersion compared with VCs that have a low investment horizon dispersion. Such a moderating effect will manifest itself by influencing the two latent forces discussed in our first hypothesis: VCs' ability and motivation.  \n\nFirst, the overall ability to expand attention across multiple domains will be lower for VCs with high investment horizon dispersion because the evaluation and management of projects with different horizons require higher cognitive effort and attention. Firms that manage projects with diverse investment horizons put greater effort into both technological and business aspects and take into account a greater array of strategic, technological, and other relevant factors (Judge & Spitzfaden, 1995). Similarly, VCs that invest and manage projects with a higher investment horizon dispersion will need to consider a greater variety of factors. Such VCs may direct cognitive efforts into forward-looking thinking (Gavetti & Levinthal, 2000) that may help them anticipate future challenges and opportunities for their PFCs. All in all, managing different investment horizons is a more complex cognitive task requiring higher levels of knowledge, cognitive effort, and attention (Judge & Spitzfaden, 1995; Souder & Bromiley, 2012). Because VCs? attention is limited, VCs with greater investment horizon dispersion will have less attention available, and, as a result, will limit their attention to fewer domains. This will cause the turning point of the inverted U-shaped curve to shift to the right.  \n\nSecond, we expect that VC investment horizon dispersion will condition the latent motivation mechanism of VCs’investment horizon on VCs'breadth of attention, such that the incentive to expand their attention to multiple domains in projects with shorter expected investment horizons will decrease. This is because a VC that manages projects with dispersed investment horizons will likely have more realistic expectations of the time and effort needed to allocate attention to each domain effectively. Such VCs may realize that the desire to fix too many issues when the expected investment horizon is short may be wishful thinking. VCs that manage projects with dispersed horizons may also realize that their expectations of short-term investments may not turn out to be accurate, reducing their motivation to attend to many domains upfront. According to one of the VCs that manage ventures with dispersed investment horizons:  \n\nThere is always a high level of risk and uncertainty around exits, such that one can never be sure that it will happen until it does.  \n\nIn sum, we expect the negative slope of the latent motivation mechanism to be less steep for VCs with a high investment horizon dispersion, resulting in a flattening of the inverted U-shaped curve. Our second set of hypotheses is formulated as follows:  \n\nHypothesis2a:Theinverted $U.$ shapedrelationshipbetweenthelengthofVCs'predictedinvestment horizon and theVCs’breadth of attention to PFCs is moderated by VCs'investment horizon dispersion such thatitsturningpoint occurs atshorter predictedinvestmenthorizonsforVCswitha low investment horizon dispersion, and at longer predicted investment horizons for VCs with a high investmenthorizondispersion.  \n\nHypothesis 2b:The inverted U-shaped relationship between the length of VCs'predicted investment horizon and theVCs'breadth of attention toPFCs is moderated by VCs'investment horizon dispersion such that it is attenuated for VCs with a high investment horizon dispersion and accentuated for VCswith a low investment horizon dispersion.  \n\nVC syndication. Venture capital syndicates are a form of inter-firm strategic alliance in which two or more VCs co-invest in a PFC and share a joint payoff (Wright & Lockett, 2003). There has been considerable attention paid to the extent (Bygrave, 1987), rationale (Hopp & Rieder, 2011), and determinants of syndication (Gu & Lu, 2014; Lerner, 1994; Lockett & Wright, 2001; Verwaal, Bruining, Wright, Manigart, & Lockett, 2010). Although these prior studies are insightful, for the most part, they examine the impact of the syndicate on the overall portfolio-level behavior of VCs. This is unfortunate, because “it is at the PFC level that needs are assessed, partners′ contributions to the alliance are evaluated, alliance governance structure is determined, and the project's outcomes for partners are appraised\" (Dimov & Milanov, 2010, p. 332). In other words, a more fine-grained PFC-level approach could explain VCs’ attention variation devoted to investments. In our study, we probe how the size of VC syndicates will moderate the inverted U-shaped relationship between the VCs' investment horizons and breadth of attention in two distinct ways.  \n\nFirst, we expect that the size of the VC syndicate will condition the latent effect of the motivation of the VCs′ predicted investment horizons on the breadth of attention such that the negative effect will be stronger (i.e., the curve will be steeper) in big syndicates and, as a result, the inverted U-shaped curve will be more pronounced. It is well established in the literature that relationships in syndicates rely on trust, reputation, and reciprocity (Manigart et al., 2006). Young VCs need to demonstrate energy and effort in identifying and building promising ventures (Pollock, Lee, Jin, & Lashley, 2015) to syndicate with high-status partners, thereby contributing to their reputation, status, and access to networks and knowledge (Milanov & Shepherd, 2013). Moreover, because VCs prefer repeating syndication with the partners they trust and whose expertise they value (Lockett & Wright, 2001), young VCs have an incentive to demonstrate a strong ability to infuence ventures? capabilities and growth (Lee, Pollock, & Jin, 2011). As a result, a focal VC may experience greater social pressure to expand value-adding attention to multiple domains, as this may be one of the essential ways that a VC can establish and maintain a positive reputation, high status, and future inter-firm relationships with multiple partners (Nooteboom, Berger, & Noorderhaven, 1997). The increased motivation stemming from the social pressure of syndicate partners should be stronger in projects with shorter expected investment horizons because, on average, investors prefer a faster return on investment (Dasgupta & Maskin, 2005; Laibson, 1997). Thus, a larger syndicate size will strengthen the negative effect of the latent motivation function, resulting in a more pronounced inverted U-shaped relationship between VCs’ predicted investment horizons and breadth of attention.  \n\nSecond, we expect that the size of the VC syndicate will condition the latent ability mechanism of the VCs’ predicted investment horizons on breadth of attention such that the ability function will move down (i.e., VCs that are part of bigger syndicates will have, in general, lower ability to attend to multiple domains upon investment), such that the turning point of the inverted U-shaped curve will shift to the right. First, coordination and cooperation are necessary among parties (Gulati, Lawrence, & Puranam, 2005) if the syndicate is to function properly and achieve shared objectives and joint payoffs for investors (Doz, 1996). Such proper functioning may require a significant expenditure of time (Wright & Lockett, 2003) and effort on the part of syndicate partners, and therefore come at the cost of attention they could have instead devoted to their investments (Cumming, 2006). Second, big syndicates will likely have a greater diversity of expectations and preferred investment horizons concerning exits than a single VC (Dalziel, White, & Arthurs, 2011). Achieving congruence around investment horizons (Brander, Amit, & Antweiler, 2002; Ferrary, 2010) may require negotiation and debate, and may lead to relational conflict among syndicate partners (Forbes, Korsgaard, & Sapienza, 2010), escalating the demand of focal VCs’ time and attention. Because attention is a limited resource (Ocasio, 1997) and high syndicate costs require substantial attention, being part of a large syndicate will limit the VCs' ability to attend to multiple domains effectively.  \n\nAdditionally, co-investors may prefer to leverage each other's strengths and encourage the focal VC to focus attention on fewer selected domains, potentially those in which the VC has some specialized or unique expertise (Sorenson & Stuart, 2001). Often syndicates are formed with partners who can provide complementary idiosyncratic knowledge (Hopp, 2010) and networks (De Clercq & Dimov, 2008); this specialization in knowledge domains may result in higher quality attention and potentially superior venture performance. The size of a VC syndicate is likely to limit VCs? attention to specialized expertise and thus reduce their attention to fewer domains. As such, we expect that the moderating effect of the VC syndicate will move the curve of the VCs' latent ability mechanism to attend to many domains downward, causing the turning point of the inverted U-shaped curve to shift to the right. By combining these arguments, we formulate our third hypothesis as follows:  \n\nHypothesis 3a:The inverted U-shaped relationship between the length of theVCs'predicted investment horizon and theVCs'breadth of attention to PFCs is moderated by VC syndicate size such that it is attenuated for VCs in small syndicates and accentuated for VCs in larger syndicates.  \n\nHypothesis3b:Theinverted $U.$ shapedrelationshipbetweenthelengthof theVCs'predictedinvestmenthorizonand theVCs'breadthof attention toPFCsismoderatedbytheVCsyndicatesizesuch that its turning point occurs at shorter predicted investment horizons for VCs in small syndicates, and at longer predicted investment horizons for VCs in larger syndicates.  \n\nThe general theoretical model is presented in Figure 1.  \n\n## Methods  \n\n### Empirical Context and Mixed Method Data Collection  \n\nTo collect our data, we approached the entire population of early-stage French VCs in 2006. These VC firms were recently established and managed the first generation of funds, created as closed-end funds with a limited lifespan of 10 years. Early-stage projects usually demand greater attention and involvement than do later-stage ventures (Sapienza, 1992), and as a result represent a fruitful setting to study VCs’ attention breadth. We relied on the exploratory sequential design of the mixed methods research (Bryman, 2006; Plano Clark & Creswell, 2008) to collect our data. We first explored our research question through qualitative data collection and analysis by conducting semistructured interviews that included open-ended questions about investment criteria and the postinvestment role of focal VCs in PFCs with $10\\mathrm{GPs}$ from 10 different VCs and 5 CEOs of PFCs. On average, the interviews lasted $65\\mathrm{min}$ , ranging from $30\\mathrm{min}$ to $2\\mathrm{~hr}$ Such an exploratory stage enabled us to gain a deeper understanding of our key constructs, such as VCs' breadth of attention and investment horizons and informed our subsequent quantitative (survey) phase (Greene, Caracelli, & Graham, 1989, p. 262).  \n\n![](images/e48728647ceb5e730c4d88904b8bccb601d0cb17ba1b15ef6c0da10a0ef92255.jpg)  \nFigure I. Theoretical model.  \n\nOur survey, preliminarily pretested by five GPs, reflected questions about VCs' value-adding activities in domains featured in earlier studies (e.g., MacMillan, Kulow, & Khoylian, 1989; Sapienza, 1992) that were confirmed and augmented by other domains identified through our interviews. Our in-person visits assured a high response rate of $72\\%$ : our survey was completed by GPs from 23 out of 32 early-stage French VC firms regarding a total of 300 investments. Each GPfrom $23~\\mathrm{VCs}$ and a total of 112 GPs responded to the questionnaire about those PFCs on the board of which he or she was seated. In such situations, GPs were undoubtedly knowledgeable about the entire set of activities and domains attended by the VC regarding focal PFCs. Additionally, GPs of the same VC typically relied on each other's help in filing any needs or knowledge gaps that they could not fulfill individually. As De Clercq & Manigart (2007, p. 204) summarize in their review of the knowledge exchange between venture capitalists, “as the partners and associates have to some extent varying backgrounds and skills, and each may hold different ^chunks’ of knowledge, entrepreneurs may benefit from investors who foster effective communication routines with their colleagues within the venture capital firm.” As one of the GPs we interviewed explained:  \n\nWhile a GP who serves on board of a particular PFC serves as the principal liaison between our fund and the PFC's top managers, we regularly discuss every single investment we have made at our meetings, and we all try to contribute to their success in the ways we can. This goes back to the days when we were creating our fund—we wanted to make sure that we (GPs) work well together, yet each has unique knowledge, skills, abilities, and networks to bring to the table.  \n\nIn combining insights from past research and the qualitative part of our study, we concluded that our critical variables of interest (VCs’ breadth of attention and expected investment horizons) refect the VC-level constructs and go beyond those of individual GPs, who might have a potentially higher weight in more mature venture capital markets and firms (Ewens & RhodesKropf, 2015).  \n\nWe structured our dataset at the PFC level to represent one observation per VC-backed PFC in the sample. Our entire dataset encompassed information on 300 ventures that stayed in the portfolio of $23\\mathrm{VCs}$ for different time lengths. Specifically, $9\\%$ of ventures were in a VC portfolio for less than a year, $4\\%$ for about a year, $12\\%$ for 2 years, $22\\%$ for 3 years, $14\\%$ for 4 years, and the remaining $39\\%$ for 5 or more years. To respect the temporal causality of our theoretical model (i.e., the infuence of investment horizon on attention breadth), we relied on the final sample of 76 PFCs (financed by $21\\mathrm{VCs}$ or $25\\%$ of the sample that stayed in the VCs’ portfolio for not more than 2 years. By restricting our sample in this way, we ensured that our VC investment horizon construct captured VCs’ expectations of time-to-exit upon investment in a given PFC and that such expectations remained unaltered, as GPs indicated in our interviews, over the 2-year period when we measured VCs’ attention breadth to PFCs. Given the reduction in our sample size to 76 PFCs, we estimated Cohen's $d$ for each coefficient using a sampsi command in Stata 13. Our results confirmed that our coefficients had enough statistical power.  \n\n### Measures  \n\nDependent variable. Our dependent variable, VC Breadth of Attention, is a count of the domains to which a focal VC devoted considerable and value-adding attention regarding each PFC. To measure the construct, we followed several phases as part of the exploratory sequential research design. To obtain information without constraints, when interviewing GPs, we first asked such open-ended questions as: Could you explain your investment selection process? What criteria do you account for when making an investment decision? How would you describe your VC's role and activities in the postinvestment stage? When interviewing CEOs of PFCs, we asked related questions: How would you describe the process of fundraising from a focal VC? Why do you think the VC invested in your venture? How would you define the role of the VC and your relationships with the VC following the investment? Such questions were followed by a semistructured interview that inquired about specific aspects of VCs’ roles and activities and connected them with constructs featured in earlier studies. This process led to two outcomes of interest. First, it helped us gain an understanding of the complexity of the knowledge and processes that lay behind attention to each domain. By comparing answers from GPs in different VCs, we were able to identify the most cited (typical) activities that characterized value-adding attention in each of the domains. These served as a foundation for defining each domain that we included in our survey. Also, by comparing the answers from interviews with domains reported in earlier studies, we identified similarities and differences from earlier research. While these interviews confirmed how common it was for French VCs to attend to many of the same domains as American VCs (finance, strategy, marketing, etc.), we discovered that French VCs focused considerable attention on advising PFCs on internationalization, public grants, and other forms of financial aid available exclusively in France. In all, we identified 13 domains that French VCs devoted their attention to such as finance, marketing, strategy, human resource management, public aid, business plan, business model, networking, internationalization, exit preparation, science and technology, partnerships, and investors.  \n\nBased on the analysis of this information, we designed and pretested our survey where we asked GPs to mark those domains where their VC was competent and in which they added value to PFCs by dedicating substantial value-adding attention. Whereas relying on such self-reported data has been a norm in venture capital literature (e.g., Busenitz et al., 2004; MacMillan et al., 1989), we additionally validated the VCs′ responses with 15 CEOs or top managers of PFCs and found overall similar responses. We also followed up with questions about the VCs’ attention to specific domains such as “whether your VC devoted considerable and value-adding attention to the domain X of the PFC Y? If a GP reported that the VC devoted substantial and value-adding attention to a specific domain regarding a focal PFC, we coded the answer as 1, and 0 otherwise. VC Breadth of Attention was thus a count of all domains that were coded as 1.  \n\n#### Independent Variables  \n\nVC Investment Horizon is a VC's ex ante expectation of the time-to-exit (in years) from the year of initial investment in a PFC. In line with earlier research, this measure captures the timing expectations over which a given investment will generate a return (i.e., Souder & Bromiley, 2012; Souder & Shaver, 2010). VCs reported their expected time-to-exit for $45\\%$ of300ventures in semiannual financial reports to LPs. We then compared and found no difference between this information and the expectations of investment horizons regarding the same ventures indicated by VCs in our survey. Finally, one of the questions in our survey explicitly asked the VCs to specify whether the investment horizon they indicated corresponded to the time-to-exit projected at the time of investment.  \n\nIn summary, having taken these steps, we felt confident that our construct remained unaltered and refected the VC's initial time-to-exit expectations. VC Investment Horizon Dispersion is a standard deviation from a VC's average investment horizon estimated from the investment horizons of all investments in the VC's portfolio between the time of initial investment in the PFC under consideration and 2006, the year of questioning the GPs. This measure is in line with horizon dispersion measures used in past research (i.e., Judge & Spitzfaden, 1995). A high standard deviation means that a focal VC manages investments with diverse investment horizons. VC Syndication is measured as the number of institutional co-investors (all individual investors were grouped into a single category in a given PFC).  \n\n#### Control Variables  \n\nWe controlled for several VC and PFC characteristics that could influence theVCs'breadth of attention to value-adding domains. We controlled for VC Attention Availability as a reversecoded number of PFCs per GP within a given VC; a high number means higher attention availability (lower number of PFCs per GP). Because VCs may attend to many different value-adding domains based on a forecast exit type (IPO versus trade sale), we controlled for VC Forecast, a binary variable that equals 1 if the forecast is IPO and O otherwise. We also controlled for the amount of capital invested by a focal VC, VC Investment (In), estimated as a natural logarithm of the total investment in USD made by a VC in a given PFC. This is important because a greater financial commitment could encourage a VC to attend to a greater number of domains within a given PFC. Finally, the VCs in our sample invested in information and communication technologies (ICT), biotechnologies, or both. Because of the impact of inter-industry selection on investment performance (Rosenbusch et al., 2013) and the substantial differences between these sectors, we controlled for VC Industry Focus, as the percentage of a VC's ventures in biotechnologies among the total number of ventures. The value of $100\\%$ means that the VC focused solely on biotechnologies, $0\\%$ means it exclusively invested in ICT, and percentages between these two extreme values imply that a VC invested in both sectors. We also controlled for several critical characteristics of the PFCs. We measured PFC Valuation (Iln), as a natural logarithm, after adding 1 to each value to avoid having O values, of the percentage of change between the firm's valuation at the focal VC's initial investment round and the venture's valuation in 2006. Because we focus on newly made investments, we did not observe any decreases in valuation.  \n\nThe VCs in our sample invested in ventures in either a seed or a start-up stage. Because the stage of development may have implications for the breadth of VCs? attention, we controlled for PFC Stage of the focal VC's investment, with 1 if the venture was in a start-up stage, and 0 otherwise. We also included the Heckman Value, that is, the inverse Mills ratio derived from the first-stage regression of a Heckman test as described below. Our findings remained robust to tests with some other control variables such as the size of the VC team, the percentage of the focal VC's ownership in a PFC, the size of the VC investment relative to the size of the VC fund, among others and remained consistent with the results reported below.  \n\n### Potential Research Method Biases  \n\nWe took essential steps to minimize potential survey-related biases. Specifically, we addressed social desirability biases by focusing on objective questions instead of performance questions (Podsakoff, Podsakoff, MacKenzie, & Klinger, 2013). We addressed also recall bias by interviewing VC partners immediately after they completed the survey to elicit specific examples of advising activities. Finally, we know that common method variance bias (CMB) may be an issue if data come primarily from the same survey responses (Podsakoff, MacKenzie, & Podsakoff, 2012). That was not of great concern in our study due to the procedural remedies we took when planning our research. In particular, we collected data on the dependent variable and independent variables from different sources whenever possible, as well as cross-validated the data between the two sources. As Podsakoff et al. (2012) explain, such procedural ex ante remedies are more effective in eliminating or minimizing a CMB than post hoc measures (i.e., CFA).  \n\nAnother procedural treatment that Podsakoff et al. (2012) recommend is to reduce ambiguity associated with construct measurements. As we explained concerning our dependent variable, we took every possible step to decrease potential ambiguity related to capturing the VCs' breadth of attention (e.g., exploratory semistructured interviews, open-ended questions, a pretest of the survey, ex post validation ofVCs' responses, etc.). As our moderating variables come from VCs' financial reports, they reflect actual quantitative measures. As a result, a CMB should not be of concern, given such precautions. Still, we conducted a Harman one-factor test and the common factor analysis (CFA) to detect any potential CMB (Podsakoff et al., 2012).  \n\nFirst, we investigated common method variance by conducting a Harman one-factor test (Podsakoff & Organ, 1986). The test yielded six factors with an eigenvalue exceeding 1. Such factors accounted for $67\\%$ of the variance. The factor with the highest eigenvalue accounted for Only $33\\%$ of the variance. Because no single factor emerged as a dominant factor accounting for most of the variance, common method variance was unlikely to be a serious problem for the data. Second, following another recommended post hoc CMB procedure by Podsakoff, MacKenzie, Lee, and Podsakoff (2003), we conducted a CFA test with all our control and independent variables. Our CFA analysis indicated that a single method would not fit our sample well with $\\mathrm{CFI}=.560\\$ and $\\mathrm{RMSEA}=.132.$ The CFA test provided additional evidence that our results were not subject to CMB or other unobserved systematic variance among the constructs in our model.  \n\n### Statistical Methods and Endogeneity  \n\nBecause our dependent variable is a count variable, we used negative binomial regression to test our hypotheses and a robust cluster option to account for inter-VC differences. We controlled also for year fixed effects to account for any macro-level factors. Our robustness test with a Poisson regression model produced similar results.  \n\nTwo pertinent instances may cause endogeneity and affect our research findings, such as omitted variables and simultaneous causality (Hamilton & Nickerson, 2003). Specific measures were taken to correct for potential endogeneity (Bascle, 2008). First, it is essential to recognize that some omitted variables may influence $\\mathrm{VCs}'$ investment horizon and the decision whether or not to keep a company in the portfolio. To correct for this potential endogeneity problem, we used a two-stage procedure similar to a standard Heckman model (Sartori, 2003). We calculated the inverse Mills ratio from a first-stage probit model, which in our case predicts whether or not a venture was a new PFC in a VC's portfolio (part of a VC's portfolio for no more than 24 months). This dependent variable, New PFC, was coded 1 if a focal PFC was a new investment and 0 otherwise. We included one independent variable in the first-stage model to predict the likelihood of being a new venture but not the $\\mathrm{VCs}'$ attention breadth. The predictor is the VC Average Investment Horizon measured as the average investment horizon across the VC portfolio. Because making new investments and attending to PFCs require substantial effort and attention, VCs that keep ventures longer in their porfolio may have less time available for search and due diligence of new investments (Ocasio, 1997) and, as a result, will be less likely to have newer investments (New PFC). In line with our logic, the results of the first-stage probit regression featured in Table 1 showed that VCs with longer average investment horizons are less likely to hold newly made investments (VC Average Investment Horizon, $p<.001\\$ ). We included the inverse Mills ratio, Heckman Value, in the second-stage negative binomial regression model to account for the potential bias associated with endogeneity (Table 4).  \n\nTable I. Probit Regression (First-Stage Model of Heckman Procedure) Predicting the Likelihood of Being a New PFC in the Focal VC Portfolio.   \n\n\n<html><body><table><tr><td>Variables</td><td>New PFC</td></tr><tr><td>VCAverageInvestmentHorizon</td><td>-0.344***</td></tr><tr><td>VCAttentionAvailability</td><td>(0.066) -0.459***</td></tr><tr><td>VC Forecast (IPO = I)</td><td>(0.125) -0.103</td></tr><tr><td>VC Investment (In)</td><td>(0.372) 0.345***</td></tr><tr><td>VC Industry Focus</td><td>(0.097) 0.001</td></tr><tr><td>PFCValuation (In)</td><td>(0.003)</td></tr><tr><td></td><td>0.129 (0.101)</td></tr><tr><td>PFC Stage (Start-up = I)</td><td>-0.863+</td></tr><tr><td></td><td>(0.450)</td></tr><tr><td>Year Fixed Effects</td><td>Yes</td></tr><tr><td></td><td></td></tr><tr><td>Constant</td><td>-0.946</td></tr><tr><td></td><td></td></tr><tr><td></td><td>(1.616)</td></tr><tr><td>Pseudo R2</td><td></td></tr><tr><td></td><td></td></tr><tr><td></td><td>0.298</td></tr><tr><td>x²</td><td>144.9*k</td></tr></table></body></html>\n\nNote. $N=300.+p<.10$ $\\tilde{\\mathbf{\\Delta}}_{\\tilde{P}}<.001$ .Standard errors are in parentheses.  \n\nThe second instance that may give rise to endogeneity seen in our results is a simultaneous causality between VC Investment Horizon and VC Breadth of Attention. While our theory and semistructured interviews suggested that investment horizon influences VC's breadth of attention, it is possible that a VC's evaluation of a PFC's needs could partially affect investment horizon expectations. We used another common strategy to address simultaneous causality by using an instrumental variables (IV) method where the first step regression is an OLS regression with an IV and the second stage is a negative binomial regression with corrected values for the potentially endogenous regressor. We use VC Experience of Failure, the number of VC's investments that failed, as an instrument for $V C$ Investment Horizon and its squared term since we reasoned that VCs who experience more failures may feel greater pressure to exit and therefore choose a shorter investment horizon. Following the recommended procedures, we examined the relevance of the instrument. Stock and Yogo (2005) established that the $F$ statistic for the significance of the instrument or instruments in the first stage would be significant and exceed a value of 10. By using the test function in Stata for the IV after the first-stage regression, the reported $F$ statistic was above a value of 10 (14.16) and significant $(p<.01)$ ,suggesting that the $V C$ Experience of Failure was a relevant instrument. The results of the first-stage OLS regression are reported in Table 2.  \n\nTable 2. The First-Stage OLS Model With an Instrumental Variable Predicting the VC Investment Horizon.   \n\n\n<html><body><table><tr><td>Variables</td><td>VCInvestmentHorizon</td></tr><tr><td>VCExperienceofFailure</td><td>-0.146** (0.041)</td></tr><tr><td>VC Investment Horizon Dispersion</td><td>0.433* (0.19)</td></tr><tr><td>VC Syndication</td><td>0.006</td></tr><tr><td>VCAttentionAvailability</td><td>(0.058) -0.600+</td></tr><tr><td>VC Forecast (IPO = I)</td><td>(0.297) -0.27</td></tr><tr><td>VC Investment (In)</td><td>(0.313) -0.043</td></tr><tr><td>VC Industry Focus</td><td>(0.131) -0.004</td></tr><tr><td>PFC Valuation (In)</td><td>(0.004) -0.135*</td></tr><tr><td>PFC Stage (Start-up = I)</td><td>(0.064) -0.173</td></tr><tr><td>Year Fixed Effects</td><td>(0.312) Yes</td></tr><tr><td>Constant</td><td>2.889+</td></tr></table></body></html>\n\nNote. $N=76$ (2I VC clusters). $^+p<.10.^{*}p<.05.^{**}p<.01.^{***}p<.001.$ Standard errors are in parentheses.  \n\nWe report our final second-stage negative binomial regression results separately for both endogeneity procedures discussed above. Following earlier studies, we report the second stage model for the IV method only for the main effect (our first hypothesis). Because other models involve interactions with our potentially endogenous variable, such an analysis would require a higher number of instruments that in turn may lead to biased results (Wooldridge, 2002). The results of our two-stage model and additional verification gave us confidence that even with the interaction terms, any impact of endogeneity would be quite limited.  \n\n## Results  \n\nDescriptive statistics and correlations are shown in Table 3. Multicollinearity was not a problem, with most correlations below 0.4 and the variance inflation factors (VIFs) below 2.27, well below the maximum threshold of 10 suggested by Freund and Littell (1991). The only two instances of correlation coefficients higher than O.4 were related to correlations of variables with the Heckman Value. As discussed below, endogeneity does not appear to be an issue, since the Heckman Value was not significant and its inclusion did not alter our findings. We, therefore, conclude that multicollinearity was not a problem in our analysis.  \n\nTable 4 shows the results of the second-stage negative binomial regression model predicting VC Breadth of Attention to their portfolio companies, correcting for the two potential sources of endogeneity by using both the Heckman and IV procedures. In models 1-3 and 5-7 of Table 4, we inserted the Heckman Value. Model 4 of Table 4 shows the second-stage negative binomial regression model results for predicted values of the main effect estimated from the first-stage OLS regression with IV. As a matter of caution, we mean-centered our independent and moderating variables (Aiken & West, 1991), even though such a procedure is no longer considered necessary and has no impact on regression results (Haans et al., 2016).  \n\nModel 1 of Table 4 includes control variables only. Our control variables revealed some interesting determinants of the $\\mathrm{VCs}'$ attention breadth. First, when a VC had a broad investment horizon dispersion, it exhibited a more narrow breadth of attention (VC Investment Horizon Dispersion is negative and slightly significant, $p<.10$ ). Second, when GPs had more attention available for each PFC, they expanded attention toward more domains (VC Attention Availability is positive and significant, $p<.001\\$ ). Third, VCs focused on fewer domains when they expected a PFC to go public (VC Forecast was negative and slightly significant, $p<.10\\AA,\\quad$ 0. Fourth, VCs that invest to a greater extent in biotechnologies attended to fewer domains (VC Industry Focus is negative and significant, $p<.01$ ). Finally, VCs exhibited broader attention toward PFCs in the start-up than seed stages (PFC Stage was positive and significant, $p<.01$ ). The Heckman Value was not significant throughout the models, suggesting that endogeneity (due to potential omitted variable bias) was not an issue in our data.  \n\nTo test our first hypothesis, we added $V C$ Investment Horizon to Model 2. The coefficient for this variable was positive but not significant. We next added its squared term, VC Investment Horizon Squared, in Model 3. The direct term becomes positive and significant $(p<.05)$ and the squared term is negative and significant $(p<.01)$ , providing evidence of a curvilinear relationship and potential support for our first hypothesis (H1). To assure the correct interpretation of the results, we closely followed the steps recommended by Haans et al., (2016). First, we tested the joint significance of the direct and squared terms of $V C$ Investment Horizon following the procedure developed by Aiken & West (1991, p. 63), whereby a significant and negative squared coefficient indicated an inverted U-shaped relationship. Second, to provide additional evidence of the inverted U-shaped relationship between $V C$ Investment Horizon and VC Breadth of Attention, we wanted to make sure that the slopes were sufficiently steep at both ends of the data range (Haans et al., 2016, pp. 1881-1882).  \n\nTo illustrate this, we undertook two essential steps. We present the findings graphically (Figure 2) to show that both positive and negative slopes are quite steep which provides evidence of the inverted U-shaped relationship between VC Investment Horizon and VC Breadth of Attention. Next, we followed the procedure developed by Lind and Mehlum (2010) using the utest command in Stata. The results provided additional evidence of the positive slope at a lower bound that was positive (.42) and significant $(t=2.72,p<.001)$ and of the negative slope at an upper bound that was negative $(-.52)$ and significant $(t=-3.69,p<.001)$ . The overall test of the presence of the inverted U-shaped curve was also significant $(t=2.72,p<.001)$ . Finally, for the relationship to be significant, the turning point needed to be within the data range. Additional simple analysis showed that the confidence interval of the turning point was within the data range of $V C$ Investment Horizon, providing support for H1. We also followed a recommended robustness test by adding a cubic term of $V C$ Investment Horizon to test whether the relationship could be S-shaped rather than U-shaped. The cubic coefficient was not significant, and the overall model fit significantly decreased, providing stronger support for an inverted U-shaped relationship and our first hypothesis.  \n\n'o' >d ne sueis e pioq u! suaao  = N'o   \n\n\n<html><body><table><tr><td></td><td>0.363 0.307 6000 1.370</td></tr><tr><td>0</td><td>0.134 0.640 0.483</td></tr><tr><td>9</td><td>-0.190 -0.309 4.220 .220 5.753 0</td></tr><tr><td>8</td><td>611'0- 0.047 -0.237 32.421 37.832 0 100</td></tr><tr><td>7</td><td>-0.021 -0.077 0.056 0.003 11.382 1.029 5.707 12.899</td></tr><tr><td>6</td><td>160'0- 0.025 -0.088 0.241 0.183 0.093 0.293</td></tr><tr><td>5</td><td>0.049 0.198 0.111 0.086 -0.104 -0.045 1.820 0.543 3</td></tr><tr><td>4</td><td>-0.181 -0.116 0.056 -0.046 -0.042 -0.003 -0.059 0.293 0.818 4</td></tr><tr><td>-0.062 3</td><td>0.133 -0.191 -0.370 0.173 0.029 161'0 0.601 1.401 0.998 3.32</td></tr><tr><td>0.364 2</td><td>-0.229 -0.095 -0.097 -0.282 0.003 -0.229 0.018 0.488 4.173 1.070 2 7</td></tr><tr><td>-0.142 -0.360</td><td></td></tr><tr><td>0.009</td><td>0.308 -0.174 0.216 -0.349 0.301 -0.261 -0.158 5.907 3.814 0 2</td></tr><tr><td>VC Breadth of Attention VC Investment Horizon VC Attention Availability VC Investment Horizon VC Forecast (IPO = I) VC Investment (In) VC Industry Focus VC Syndication Dispersion Variables # 8 2 5 4 9</td><td>PFC Stage (Start-up = I) PFC Valuation (In) Heckman Value Std. Dev. Mean Min Max</td></tr></table></body></html>  \n\n(pano))   \n  \n  \n\n\n<html><body><table><tr><td>7 Heckman Procedure 5 IV Procedure 3 Heckman Procedure 2 Variables</td></tr></table></body></html>  \n\nanuuo   \n\"sasaypuaued u! aue suoua piepuens'l00' >doc\\*'l0' >d\\*'so'>d\\*01'>d(sasnp ^1z) 9L=N\\*n   \n  \n\n\n<html><body><table><tr><td rowspan=\"10\">7 HeckmanProcedure 5 IVProcedure 3 Heckman Procedure 2</td><td rowspan=\"9\">0.934* (0.471) 1.190*</td><td>-0.784+ -1.251** (0.463) 1.325** (0.412) (0.395) -0.834 (0.934) Yes -0.799 (0.878) Yes (0.977)</td></tr><tr><td>1.822*** -1.704*** (0.368) (0.35) (0.481) -0.997* (0.473)</td></tr><tr><td>-0.678 Yes</td></tr><tr><td>3.558** (1.101) Yes</td></tr><tr><td>-0.758 570.8*** (0.925) Yes</td></tr><tr><td>-0.532 (0.756) Yes</td></tr><tr><td>-0.732 (0.709) Yes</td></tr><tr><td></td></tr><tr><td>VC Investment Horizon xVC Syndication VC Investment Horizon Squared x VC Year Fixed Effects Syndication Constant</td></tr><tr><td colspan=\"2\">VC Investment Horizon x VC Investment VC Investment Horizon Squared x VC Horizon Dispersion Variables</td></tr></table></body></html>  \n\n![](images/58cde3a26c37543ce17baed85a5c9e5002ca61bd975e2ce3673659ad2969d755.jpg)  \nFigure 2. Relationship between VC investment horizon and VC breadth of attention (HI).  \n\nModel 4 shows the second-stage model following the IV procedure. If endogeneity due to simultaneous causality were an issue, one would see a decrease in the significance of the main effect. However, we observe just the opposite: The coefficients for both the direct and the squared terms of the VC Investment Horizon were higher and more significant $(p<.001)$ in Model 4 than Model 3. This provides additional validation that our model was not subject to simultaneous causality and our overall regression results were not subject to endogeneity.  \n\nFinally, to test our second and third sets of hypotheses, to assure that multicollinearity (which may happen when multiple interaction terms are simultaneously introduced in the same model) was not an issue in our study, we first tested our second and third hypotheses by entering moderation terms in two separate models, Models 5 and 6 respectively. Finally, we examined the two moderation effects simultaneously in Model 7. In our second set of hypotheses, we argued that the inverted U-shaped relationship predicted in H1 would be moderated by $V C$ Investment Horizon Dispersion. The interaction effect of $V C$ Investment Horizon Dispersion with $V C$ Investment Horizon was found to be positive and significant $(p<.05)$ in Model 5 and Model 7 and its interaction effect with $V C$ Investment Horizon Squared negative and significant in Model 5 $(p<.05)$ and Model 7 $(p<.10)$ . These results provide potential support for the moderation effect, even though we note that the significance of the interaction effect with VC Investment Horizon Dispersion Squared decreased, due to multicollinearity, in the full Model 7. To understand if such moderation is in line with our H2a and $_{\\textrm{H2b}}$ predictions, we plotted the results graphically, as illustrated in Figure 3. In line with H2a, the “turning point’ shifted to the right. Interestingly, while we predicted that the slopes would be less steep as a result of moderation, we found even stronger evidence for our theory in that the inverted U-shaped curve turned into a U-shaped curve for VCs with a high investment horizon dispersion. Following recommendations of Haans et al. (2016, p. 1190), we further investigated whether the main effect hypothesis (H1) holds for values of VC Investment Horizon Dispersion between one standard deviation below and above the mean. Using the utest function in Stata, we found that the simple slopes of $V C$ Investment Horizon on VC Breadth of Attention were highly significant $(p<.000)$ as well as the $t\\cdot$ -value for the presence of an inverted U-shape $(p<.000)$ , thus supporting an inverted U-shaped relationship across the relevant range of $V C$ Investment Horizon Dispersion.  \n\n![](images/462803594273d0316394a6e6e7f014cdd66cbc699c71062827e7eb85c77ee9a6.jpg)  \nFigure 3. Moderating effect ofVC investment horizon dispersion (H2a, H2b)  \n\nIn our third and final set of hypotheses, we argued that $V C$ Syndication would moderate the inverted U-shaped relationship between $V C$ Investment Horizon and VC Breadth of Attention. The results shown in Table 2 provide strong support for the existing moderating relationship since the interaction effects of $V C$ Syndication with both the direct and squared terms of $V C$  \n\n![](images/89f5d0a74e1f8e061fccd95407d46b9c3155c0d29924e0c26730c14b7ec24afa.jpg)  \nFigure 4. Moderating effect ofVC syndication (H3a, H3b)  \n\nInvestment Horizon are respectively positive and negative and are significant in Model 6 $(p<$ .001)andMode1 7 $(p<.01)$ . We further investigate this moderation effect in Figure 4. In line with our predictions, VC Syndication moderates the relationship between VC Investment Horizon and VC Breadth of Attention in two distinct ways: it steepens the curve (H3a) and shifts the turning point to the right (H3b).  \n\n## Discussion  \n\nThe principal motivation behind this study was to explain the variation in VCs' breadth of attention among PFCs. By combining insights from the attention based-view, temporal research, and strategic alliance literature, we examined the effect of VCs’ expected investment horizons on VCs' attention breadth in PFCs. We also analyzed how this relationship was contingent upon the VCs’ investment horizon dispersion and the size of VC syndicates. We examined these questions by relying on a unique dataset of young early-stage French VCs and their investments. Our analysis provides valuable insight into entrepreneurship, investment horizons, and strategic alliances literature.  \n\nFirst, our study contributes to entrepreneurship literature by providing valuable insights into the determinants of significant intra-VC differences in their attention breadth among PFCs, one of the important ways in which VCs add value to their investments. While a considerable body of literature exists on the value-adding role of VCs, scholars approached this research topic from either a descriptive angle (documenting the types and frequency of VCs’ different value-adding activities), by comparing VCs’ contributions at the overall portfolio or country-level (Bruton et al., 2010) or accounting only for PFC-specific factors (e.g., Ozmel & Guler, 2015; Sapienza et al., 1994). We extend earlier venture capital research by underscoring the importance of accounting for expected investment horizons in decision-making by demonstrating that part of the explanation for intra-VC variance resides in VCs’ expected investment horizons vis-a-vis portfolio companies. Also, our analysis of the contingencies of such relationship shows it is moderated by such structural attentional factors as dispersion of investment horizons and the size of the VC syndicates.  \n\nOur results regarding the moderation effect of the investment horizon dispersion are quite surprising and therefore deserve further discussion. In particular, whereas our theory predicted a flattening of the inverted U-shaped curve for VCs that manage projects with high investment horizon dispersion, we found that the curve “flipped’” such that the relationship between expected investment horizon and breadth of attention became U-shaped. In a nutshell, this reveals that VCs that manage projects with highly diverse investment horizons will be much less inclined to expand their attention breadth to PFCs such that their attention breadth will become narrower unless the projected time-to-exit from a PFC is quite long (i.e., the turning point shifted to the right). VCs with projects of diverse investment horizons may rely much less on their time-to-exit predictions knowing that such expectations are likely to change over time. Such VCs may believe that extending attention across multiple domains soon after investment may not be worthwhile given the high level ofuncertainty and likely changes in PFCs and their environment. Furthermore, the flipped U-shaped curve may also point to some additional inherent differences in VCs' investment approaches. Specifically, because VCs that invest in projects with diverse investment horizons spend much more time and effort evaluating their investments than VCs with PFCs with more similar investment horizons, the former may consider their selection capabilities as overall more important for investment performance than their subsequent breadth of attention (Baum & Silverman, 2004). In other words, it is possible that such VCs put much more emphasis on the \"horse, (i.e., the business) as they decide on the potential time-to-exit length (Kaplan, Sensoy, & Stromberg, 2009). Interestingly, such trade-off between investing in projects with diverse investment horizons and attention breadth disappears (and the relationship between expected investment horizon and attention breadth becomes positive) only for projects with long expected time-to-exit.  \n\nSecond, our study advances temporal research on investment horizons in several ways. By focusing on time-to-exit as a distinct construct from VCs’ expected return on investment or types of exits, our study responds to recent calls for studying the investment horizon as a construct apart from risk, uncertainty and other factors relevant for attention and other resource allocation decisions in organizations (Reilly et al., 2016; Souder & Bromiley, 2012; Souder et al., 2016). In addition, by departing from established research on antecedents of investment horizons (Reilly et al., 2016), we extend the paucity of recent research on the consequences of investment horizons (Souder et al., 2016). Our study contributes to this research by providing evidence for the influence of investment horizons on a critical mechanism, the breadth of attention, by which firm performance is affected (Souder et al., 2016). In addition, our study takes the first step in understanding how investment horizons explain not only across but within-firm differences. As Souder et al. (2016) noted in discussing the limitations of their work, “a firm that focused most of its investments in a given horizon may have a very different strategy than a firm with extremely varied horizons but the same mean horizons.\" Our research addresses such critical limitations and illustrates the importance of distinguishing between project-level investment horizons and firm-level investment horizon dispersion.  \n\nFinally, our research provides novel insights into research on VC syndicates and strategic alliances more generally. Even though such research is relatively abundant (i.e., Gu & Lu, 2014; Jaaskelainen, 2012), we have contributed to this wealth of knowledge by analyzing the moderating impact of the size of a VC syndicate on the novel investment horizon-attention breadth relationship. While earlier research viewed bigger syndicates as a source of complementary knowledge and networks (e.g., De Clercq & Dimov, 2008), we provided novel insights on the costs and benefits of participating in bigger strategic alliances. Our findings reveal that collaboration with diverse partners affects focal VCs breadth of attention under different investment horizon expectations. Even though larger syndicates encourage the focal VC to focus on core competencies, the focal VC may experience social pressure to broaden attention to include more domains when an expected time-to-exit is relatively short. Given the strong motivation to maximize return on short-term investments (Marginson & McAulay, 2008) and the importance of value-adding attention for PFCs' performance (Croce et al., 2013; Fitza et al., 2009), our study suggests that social pressure from syndicate partners when the investment horizon is short constitutes an important factor that may motivate a VC to widen its attention breadth and thereby potentially contribute to establishing its own reputation and syndicate performance. In addition, we find that the coordination (Gulati et al., 2005) and conflict-related costs of bigger syndicates or strategic alliances (Nahapiet & Ghoshal, 1998) may reduce VCs’ attention breadth. As part of a big syndicate, the focal VC will divide its attention between PFCs and syndicate management such that the VC's attention to PFCs will become limited to fewer domains. This is consistent with the strategic alliance literature that suggests that having diverse alliance partners increases the coordination costs of alliances (Jiang, Tao, & Santoro, 2010). In summary, our study suggests that there are two opposing forces related to large syndicates, social pressure and coordination costs, and adds important nuances to earlier findings on both the pros and cons of syndication.  \n\n### Limitations and Future Research Directions  \n\nLike any research, ours is not without its limitations. As noted in the Methods section, we collected comprehensive data from $72\\%$ of the population of French VC firms specializing in early-stage venture funding and their portfolio companies. This required extensive legwork and interviewing as well as significant time and reflection on the part of the VCs. This level of engagement is noteworthy and unique; we know of no other sample or published research on VCs that exhibits the richness embodied in our sample. Although we were able to gather VCs' expectations concerning investment horizons as well as domains of their value-adding attention regarding different portfolio ventures, we were not able to track this information longitudinally. Despite the VCs’ generosity with their time, a longitudinal survey of each engagement was not possible, given the time required. Thus, each venture may exhibit uniqueness that needs broader or more focused attention for reasons that are not captured. We believe this limitation is minimized by the fact that expected investment horizons did not change among the sample of firms during the chosen 2-year window from time of investment. We were also able to control for essential characteristics of PFCs and VCs that further minimized our concerns.  \n\nIn interpreting these findings, it is important to keep in mind that our sample is from young early-stage French VCs, and represents a different population from that of the United States, which tends to be larger, older, and make more investments. The generalizability of our findings to more mature VC markets shall, therefore, be done with caution (Manigart et al., 2002). At the same time, we believe that our findings represent an opportunity for scholars to study how new VCs and other young organizations form and respond to the expectations of different investment horizons when utilizing limited resources and attention.  \n\nSecond, while our research focus was also on one specific property of organizational attention, its breadth (Bansal et al., 2018; Yadav et al., 2007), future research could contrast our findings with other measures such as attention depth. Because managing attention breadth and depth underscores potential trade-offs, given bounded attention (Cyert & March, 1963), understanding how VCs manage both the depth and the breadth of their attention under different contingencies would provide valuable insights to this topic. Such an approach would allow researchers to capture the multidimensional aspects of attention and gain a more holistic view of the impact of investment horizon expectations on VCs’ attention and subsequent performance. Besides, while our study focused exclusively on the attention breadth of early-stage VCs, researchers could examine attention by other stakeholders (investment bankers, lawyers, co-investors) to uncover potential complementarities and tensions that may exist when different stakeholders allocate their attention to PFCs. Finally, some VCs may have dedicated GPs specialized in managing projects of different investment horizons. Whereas we did not come across such specialization in our sample, future research should consider and account for the difference that such specialization may have on organizational attention allocation.  \n\nAs demonstrated by Souder et al. (2016), the expectations of investment horizons are often based on an interaction between investors and managers, and the agreement or lack thereof regarding the length of expected investment horizons influences organizational performance. Because VCs, ventures' CEOs, and other stakeholders (co-investors) may hold different perspectives and expectations about investment horizons, future research could advance venture capital and investment horizon literature by examining potential investment horizon congruence or incongruence on the effectiveness of inter-firm relationships and performance.  \n\nFinally, we focused on VCs′ initial expectations of investment horizons. Given that it is typical for VCs and organizations, in general, to revise their expectations over time (BaconGerasymenko et al., 2016), scholars could add substantial value to the venture capital literature and temporal research by studying how and when VCs review their horizon expectations and the consequences for such changes in attention, behavior, and performance. In the end, we hope that our research, along with its strengths and limitations, inspires other researchers to explore new research avenues and directions on this important topic.  \n\n### Declaration of Conflicting Interests  \n\nThe author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.  \n\n### Funding  \n\nThe author(s) received no financial support for the research, authorship, and/or publication of this article.  \n\n### ORCID ID  \n\nVioletta Bacon-Gerasymenko $\\textcircled{1}$ http:/orcid.org/0000-0002-1314-1481  \n\n## References  \n\nAiken, L. S., & West, S. G. (1991). Multiple regression: Testing and interpreting interactions. London, UK: SagePublication.   \nBacon-Gerasymenko, V., Coff, R., & Durand, R. (2016). Taking a second look in a warped crystal ball: Explaining the accuracy of revised forecasts. Journal of Management Studies, 53(8), 1292-1319.   \nBansal, P., Kim, A., & Wood, M. O. (2018). Hidden in plain sight: The importance of scale in organizations? attention to issues. Academy of Management Review, 43(2), 217-241.   \nBarrot, J. N. (2017). Investor horizon and the life cycle of innovative firms: Evidence from venture capital. Management Science, 63(9), 3021-3043.   \nBascle, G. (2008). Controlling for endogeneity with instrumental variables in strategic management research. Strategic Organization, 6(3), 285-327.   \nBaum, J. A. C., & Silverman, B. S. (2004). Picking winners or building them? Alliance, intellectual, and human capital as selection criteria in venture financing and performance of biotechnology startups. Journal of Business Venturing, 19(3), 411-436.   \nBeckman, C. M., Burton, M. D., & O'Reilly, C. (2007). Early teams: The impact of team demography on VC financing and going public. Journal of Business Venturing, 22(2), 147-173.   \nBottazzi, L., & Da Rin, M. (2002). Venture capital in Europe and the financing of innovative companies. Economic Policy, 17(34), 229-270.   \nBrander, J. A., Amit, R., & Antweiler, W. (2002). Venture-capital syndication: Improved venture selection vs. the value-added hypothesis. Journal of Economics and Management Strategy, 11(3), 423-452.   \nBruton, G. D., Filatotchev, I., Chahine, S., & Wright, M. (2010). Governance, ownership structure, and performance of IPO frms: The impact of different types of private equity investors and institutional environments. Strategic Management Journal, 31, 491-509.   \nBryman, A. (2006). Integrating quantitative and qualitative research: How is it done? Qualitative Research, 6(1), 97-113.   \nBusenitz, L. W., Fiet, J. O., & Moesel, D. D. (2004). Reconsidering the venture capitalists \"value added\" proposition: An interorganizational learning perspective. Journal of Business Venturing, 19(6), 787-807.   \nBygrave, W. D. (1987). Syndicated investments by venture capital frms: A networking perspective. Journal of Business Venturing, 2(2), 139-154.   \nCrilly, D., & Sloan, P. (2012). Enterprise logic: Explaining corporate attention to stakeholders from the \\*inside-out'. Strategic Management Journal, 33(10), 1174-1193.   \nCroce, A., Marti, J., & Murtinu, S. (2013). The impact of venture capital on the productivity growth of European entepreneurial frms: Screening? or 'value added’ effect? Journal of Business Venturing. 28(4), 489-510.   \nCumming, D. J. (2006). The determinants of venture capital portfolio size: Empirical evidence. The Journal of Business, 79(3), 1083-1126.   \nCyert, R. M., & March, J. G. (1963). A behavioral theory of the firm (2nd ed). Malden, MA: Blackwell Publishers.   \nDalziel, T, White, R. E., &Arthurs, J. D. (2011). Principal costs in initial public offerings. Journal of Management Studies, 48(6), 1346-1364.   \nDasgupta, P., & Maskin, E. (2005). Uncertainty and hyperbolic discounting. American Economic Review, 95(4), 1290-1299.   \nDe Clercq, D., & Dimov, D. (2008). Internal knowledge development and external knowledge access in venture capital investment performance. Journal of Management Studies, 45(3), 585-612.   \nDe Clercq, D., & Manigart, S. (2007) The venture capital post-investment phase: Opening the black box of involvement. In H. Landstrom (Ed.), Handbook of research on venture capital. Cheltenham, UK: Edward Elgar Publishing.   \nDe Clercq, D., & Fried, V. H. (2005). Executive forum: How entrepreneurial company performance can be improved through venture capitalists? communication and commitment. Venture Capital, 7(3), 285-294.   \nDe Clercq, D., Fried, V. H., Lehtonen, O., & Sapienza, H J. (2006).An entrepreneur's guide to the venture capital galaxy. Academy of Management Perspectives, 20(3), 90-112.   \nDimov, D., & Martin de Holan, P. (2010). Firm experience and market entry by venture capital frms (1962-2004). Journal of Management Studies, 47(1), 130-161.   \nDimov, D., & Milanov, H. (2010). The interplay of need and opportunity in venture capital investment syndication. Journal of Business Venturing, 25(4), 331-348.   \nDimov, D. P., & Shepherd, D. A. (2005). Human capital theory and venture capital firms: Exploring “home runs\" and \"strike outs\". Journal of Business Venturing, 20(1), 1-21. cesses? Strategic Management Journal, 17(S1), 55-83.   \nDrover, W., Busenitz, L., Matusik, S., Townsend, D., Anglin, A., & Dushnitsky, G. (2017). A review and road map of entrepreneurial equity financing research: Venture capital, corporate venture capital, angel investment, crowdfunding, and accelerators. Journal of Management, 43(6), 1820-1853.   \nEwens, M., & Rhodes-Kropf, M. (2015). Is a VC partnership greater than the sum of its partners? The Journal of Finance, 70(3), 1081-1113.   \nFerrary, M. (2010). Syndication of venture capital investment: The art of resource pooling. Entrepreneurship: Theory & Practice, 34, 885-907.   \nFitza, M., Matusik, S. F., & Mosakowski, E. (2009). Do VCs matter? The importance of owners on performance variance in start-up firms. Strategic Management Journal, 30(4), 387-404.   \nForbes, D. P., Korsgaard, M. A., & Sapienza, H. J. (2010). Financing decisions as a source of conflict in venture boards. Journal of Business Venturing, 25(6), 579-592.   \nFreund, R. J., & Littell, R. C. (1991). SAS system for regression. Cary, NC: SAS Institute.   \nGavetti, G., & Levinthal, D. (2000). Looking forward and looking backward: Cognitive and experiential search. Administrative Science Quarterly, 45(1), 113-137.   \nGerasymenko, V., De Clercq, D., & Sapienza, H. J. (2015). Changing the business model: Effects of venture capital firms and outside CEOs on portfolio company performance. Strategic Entrepreneurship Journal, 9(1), 79-98.   \nGifford, S. (1997). Limited attention and the role of the venture capitalist. Journal of Business Venturing. 12(6), 459-482.   \nGompers, P. A. (1996). Grandstanding in the venture capital industry. Journal of Financial Economics, 42(1), 133-156.   \nGompers, P. A., & Lerner, J. (2004). The venture capital cycle. Cambridge, MA and London: The MIT Press.   \nGraham, J. R., & Harvey, C. R. (2001). The theory and practice of corporate finance: Evidence from the field. Journal of Financial Economics, 60(2-3), 187-243.   \nGreene, J. C., Caracelli, V. J., & Graham, W. F. (1989). Toward a conceptual framework for mixed-method evaluation designs. Educational Evaluation and Policy Analysis, 11(3), 255-274.   \nGu, Q., & Lu, X. (2014). Unraveling the mechanisms of reputation and alliance formation: A study of venture capital syndication in China. Strategic Management Journal, 35(5), 739-750.   \nGulati, R., Lawrence, P. R., & Puranam, P. (2005). Adaptation in vertical relationships: Beyond incentive conflict. Strategic Management Journal, 26(5), 415-440.   \nHaans, R. F. J., Pieters, C., & He, Z. -L. (2016). Thinking about U: Theorizing and testing U- and inverted U-shaped relationships in strategy research. Strategic Management Journal, 37(7),1177-1195.   \nHamilton, B. H., & Nickerson, J. A. (2003). Correcting for endogeneity in strategic management research. Strategic Organization, 1(1), 51-78.   \nHopp, C. (2010). When do venture capitalists collaborate? Evidence on the driving forces of venture capital syndication. Small Business Economics, 35(4), 417-431.   \nHopp, C., & Rieder, F. (2011). What drives venture capital syndication? Applied Economics, 43(23), 3089-3102.   \nJudge, W. Q., & Spitzfaden, M. (1995). The management of strategic time horizons within biotechnology firms: The impact of cognitive complexity on time horizon diversity. Journal of Management Inquiry, 4, 179-196.   \nJaaskelainen, M. (2012). Venture capital syndication: Synthesis and future directions. International Journal of Management Reviews, 14(4), 444 463.   \nJiang, R. J., Tao, Q. T., & Santoro, M. D. (2010). Alliance portfolio diversity and firm performance. Strategic Management Journal, 31(10), 1136-1144.   \nKaplan, S. N., & Schoar, A. (2005). Private equity performance: Returns, persistence, and capital Hows. The Journal of Finance, 60(4), 1791-1823.   \nKaplan, S. N., Sensoy, B. A., & Stromberg, P. (2009). Should Investors BET on the Jockey or the horse? Evidence from the evolution of firms from early business plans to public companies. The Journal of Finance, 64(1), 75-115.   \nLaibson, D. (1997). Golden eggs and hyperbolic discounting. The Quarterly Journal of Economics, 12(2), 443-478.   \nLee, P M., Pollock, T. G., & Jin, K. (2011). The contingent value of venture capitalist reputation. Strategic Organization, 9(1), 33-69.   \nLee, P. M., & Wahal, S. (2004). Grandstanding, certification and the underpricing of venture capital backed IPOs. Journal of Financial Economics, 73(2), 375-407.   \nLerner, J (1994). The Syndication of venture capital investments. Financial Management, 23(3), 16-27.   \nLind, J. T., & Mehlum, H. (2010). With or without U? The appropriate test for a U-shaped relationship. Oxford Bulletin of Economics and Statistics, 72(1), 109-118.   \nLockett, A., & Wright, M. (2001). The syndication of venture capital investments. Omega, 29(5), 375-390.   \nMacMillan, I. C., Kulow, D. M., & Khoylian, R. (1989). Venture capitalists involvement in their investments: Extent and performance. Journal of Business Venturing, 4(1), 27-47.   \nManigart, S., De Waele, K., Wright, M., Robbie, K., Desbrieres, P., Sapienza, H. J., & Beekman, A. (2002). Determinants of required return in venture capital investments: A five-country study. Journal of Business Venturing, 17(4), 291-312.   \nManigart, S., Locket, A., Meuleman, M.,Wright, M., Landstrom, H, Bruining, H., .Hommel, U. (2006). Venture capitalists' decision to syndicate. Entrepreneurship: Theory & Practice, 30, 131-153.   \nMarginson, D., & McAulay, L. (2008). Exploring the debate on short-termism: A theoretical and empirical analysis. Strategic Management Journal, 29(3), 273-292.   \nMaruping, L. M., Venkatesh, V., Thatcher, S. M. B., & Patel, P. C. (2015). Folding under pressure or rising to the occasion? Perceived time pressure and the moderating role of team temporal leadership. Academy of Management Journal, 58(5), 1313-1333.   \nMeDougall, P. P., Shane, S., & Oviatt, B. M. (1994). Explaining the formation of international new ventures: The limits of theories from international business research. Journal of Business Venturing, 9, 451-544.   \nMilanov, H., & Shepherd, D. A. (2013). The importance of the first relationship: The ongoing influence of initial network on future status. Strategic Management Journal, 34(6), 727-750.   \nNahapiet, J., & Ghoshal, S. (1998). Social capital, intellctual capital, and the organizational advantage. Academy of Management Review, 23(2), 242-266.   \nNahata, R. (2008). Venture capital reputation and investment performance. Journal of Financial Economics, 90(2), 127-151.   \nNanda, R., & Rhodes-Kropf, M. (2013). Investment cycles and startup innovation. Journal of Financial Economics,110(2), 403-418.   \nNooteboom, B., Berger, H., & Noorderhaven, G. (1997). Effects of trust and governance on relational risk. Academy of Management Journal, 40, 308-338.   \nOcasio, W. (1997). Towards an attention-based view of the firm. Strategic Management Journal, 18(S1), 187-206.   \nOzmel, U., & Guler, I. (2015). Smallfsh, big fish: The impact of venture capital porfolio composition on affliation benefits. Strategic Management Journal, 36, 2039-2057.   \nPlano Clark, V. L., & Creswell, J. W. (2008). The mixed methods reader. Thousand Oaks, CA: SAGE Publications, Inc.   \nPodsakoff, P. M., MacKenzie, S. B., Lee, J. -Y., & Podsakoff, N. P. (2003). Common method biases in behavioral research: A critical review of the literature and recommended remedies. Journal of Applied Psychology, 88(5),879-903.   \nPodsakoff, P. M., MacKenzie, S. B., & Podsakoff, N. P. (2012). Sources of method bias in social science research and recommendations on how to control it. Annual Review of Psychology, 63(1), 539-569.   \nPodsakoff, P. M., & Organ, D. W. (1986). Self-reports in organizational research: Problems and prospects. Journal of Management, 12(4), 531-544.   \nPodsakoff, N. P., Podsakoff, P. M., MacKenzie, S. B., & Klinger, R. L. (2013). Are we really measuring what we say we're measuring? Using video techniques to supplement traditional construct validation procedures. Journal of Applied Psychology, 98(1), 99-113.   \nPollock, T. G., Lee, P. M., Jin, K., & Lashley, K. (2015). (Un)Tangled: Exploring the asymmetric coevolution of new ventures capital frms reputation and status. Administrative Science Quarterly, 60, 482-517.   \nReilly, G., Souder, D., & Ranucci, R. (2016). Time horizon of investments in the resource allocation process: Review and framework for next steps. Journal of Management, 42, 1169-1194.   \nRosenbusch, N., Brinckmann, J., & Muiller, V. (2013). Does acquiring venture capital pay off for the funded firms? A meta-analysis on the relationship between venture capital investment and funded firm financial performance. Journal of Business Venturing, 28(3), 335-353.   \nSapienza, H. J. (1992). When do venture capitalists add value? Journal of Business Venturing, 7(1), 9-27.   \nSapienza, H. J., Amason, A. C., & Manigart, S. (1994). The level and nature of venture capitalist involvement in their portfolio companies: A study of three European countries. Managerial Finance, 20(1), 3-17.   \nSapienza, H. J., & Gupta, A. K. (1994). Impact of agency risks and task uncertainty on venture capitalist-CEO interaction. Academy of Management Journal, 37, 1618-1632.   \nSapienza, H. J., Manigart, S., & Vermeir, W. (1996). Venture capitalist governance and value added in four countries. Journal of Business Venturing, 11(6), 439-469.   \nSartori, A. E. (2003). An estimator for some binary-outcome selection models without exclusion restrictions. Political Analysis, 11(02), 111-138.   \nSorenson, O., & Stuart, T. E. (2001). Syndication networks and the spatial distribution of venture capital investments. American Journal of Sociology, 106(6), 1546-1588.   \nSouder, D., & Bromiley, P (2012). Explaining temporal orientation: Evidence from the durability of frms capital investments. Strategic Management Journal, 33(5), 550-569.   \nSouder, D., Reilly, G., Bromiley, P., & Mitchell, S. (2016). A behavioral understanding of investment horizon and frm performance. Organization Science, 27(5), 1202-1218.   \nSouder, D., & Shaver, J. M. (2010). Constraints and incentives for making long horizon corporate investments. Strategic Management Journal, 31(12), 1316-1336.   \nStock, J. H., & Yogo, M. (2005). Testing for weak instruments in linear IV regression. In J. H. Stock & D. W. K. Andrews (Eds.), Identification and inference for econometric models: Essays in honor of Thomas J. Rothenberg (Vol. 5, p. 80-108). Cambridge: Cambridge University Press.   \nTurban, D. B., & Cable, D. M. (2003). Firm reputation and applicant pool characteristics. Journal of Organizational Behavior, 24(6), 733-751.   \nVerwaal, E., Bruining, H., Wright, M., Manigart, S., & Lockett, A. (2010). Resources access needs and capabilities as mediators of the relationship between VC frm size and syndication. Small Business Economics, 34(3), 277-291.   \nWooldridge, J. (2002). Econometric analysis of cross section and panel data. Cambridge, Massachusets, London, England: MIT Press.   \nWright, M., & Lockett, A. (2003). The structure and management of alliances: Syndication in the venture capital industry. Journal of Management Studies, 40(8), 2073-2102.   \nYadav, M. S., Prabhu, J. C., & Chandy, R. K. (2007). Managing the future: CEO attention and innovation outcomes. Journal of Marketing, 71(4), 84-101.  \n\n## Author Biographies  \n\nVioletta Bacon-Gerasymenko is Assistant Professor of Strategy and Entrepreneurship at the College of Business, Oregon State University, Corvallis, OR 97331, USA.  \n\nJonathan D. Arthurs is Professor of Strategy and Entrepreneurship and Associate Dean for Faculty and Research at the College of Business, Oregon State University, Corvallis, OR 97331, USA.  \n\nSam Y. Cho is Assistant Professor of Strategy and Entrepreneurship at the College of Business, Oregon State University, Corvallis, OR 97331, USA.  "
  }
}